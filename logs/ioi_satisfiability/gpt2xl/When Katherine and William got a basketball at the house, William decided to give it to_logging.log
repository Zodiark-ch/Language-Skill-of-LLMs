[2024-07-24 10:22:53,037][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isWhen Katherine and William got a basketball at the house, William decided to give it to
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Katherine
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:22:53,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit11', 'circuit28']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit27']
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:22:53,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit16', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:22:53,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit24']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:22:53,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit16', 'circuit17', 'circuit26']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:22:53,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit17']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit13', 'circuit26']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:22:53,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:22:53,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:22:53,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit25']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit21']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:22:53,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:22:53,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit28']
[2024-07-24 10:22:53,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13']
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit27']
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13']
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:22:53,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,060][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit4', 'circuit9', 'circuit12', 'circuit16']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:22:53,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit22', 'circuit26']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit25']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit25']
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit26']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit21']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:22:53,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14']
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit22']
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:22:53,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,073][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit26']
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,074][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:22:53,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit22', 'circuit25']
[2024-07-24 10:22:53,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17']
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7']
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit25']
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit24']
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:22:53,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,088][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:22:53,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,092][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit28']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit26']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit17']
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21']
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:22:53,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit21', 'circuit26']
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,099][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:22:53,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit27']
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:22:53,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit2', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit26']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit5', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit27']
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,118][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,120][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit26']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,122][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,124][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,127][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22']
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:22:53,129][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:22:53,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19']
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,132][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:22:53,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit16']
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:22:53,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,137][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,140][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,142][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:22:53,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,145][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit6', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,146][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:22:53,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,150][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit20', 'circuit21']
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,153][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,154][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit5', 'circuit6', 'circuit13']
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit13', 'circuit18', 'circuit20']
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit23']
[2024-07-24 10:22:53,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21']
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,157][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:22:53,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,161][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:22:53,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,165][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:22:53,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:22:53,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit21', 'circuit27']
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,170][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,171][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:22:53,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,176][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,177][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:22:53,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:22:53,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2', 'circuit25']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit22', 'circuit25']
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,183][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,184][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,189][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:22:53,190][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:22:53,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:53,193][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:22:54,384][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:54,385][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,386][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,387][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,388][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,389][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,390][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,390][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,391][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,392][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,393][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,394][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,395][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,396][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9054, 0.0946], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,397][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([1.0927e-04, 9.9989e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,399][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.8425, 0.1575], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,400][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.0886, 0.9114], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,402][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.2560, 0.7440], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,403][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0142, 0.9858], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,404][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.8002, 0.1998], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,406][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.9782, 0.0218], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,407][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.8354, 0.1646], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,408][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.9203, 0.0797], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,410][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.7082, 0.2918], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,411][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7376, 0.2624], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,413][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7615, 0.1802, 0.0584], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,414][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0042, 0.0012, 0.9945], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,415][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4144, 0.0278, 0.5578], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,417][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2451, 0.0940, 0.6609], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,418][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5616, 0.2631, 0.1754], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,420][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2181, 0.0054, 0.7765], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,421][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6048, 0.3695, 0.0257], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,422][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4333, 0.3605, 0.2062], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,424][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2509, 0.0384, 0.7107], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,425][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6148, 0.1261, 0.2591], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,427][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6423, 0.1099, 0.2479], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,428][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5373, 0.1205, 0.3422], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,429][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.5270, 0.1933, 0.2269, 0.0529], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,430][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ William] are: tensor([3.3313e-04, 6.3636e-03, 1.0746e-04, 9.9320e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,431][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.4666, 0.3319, 0.1016, 0.0999], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,432][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ William] are: tensor([2.1858e-03, 8.5800e-03, 7.4780e-05, 9.8916e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,433][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0744, 0.2017, 0.0149, 0.7090], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,434][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ William] are: tensor([1.4942e-02, 2.4501e-04, 2.9278e-06, 9.8481e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,434][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.3486, 0.3897, 0.0980, 0.1638], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,434][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.3405, 0.1474, 0.3780, 0.1340], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,435][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.3699, 0.2073, 0.2094, 0.2134], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,435][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.5099, 0.2032, 0.2297, 0.0572], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,435][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.4253, 0.1264, 0.1647, 0.2836], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,436][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.4144, 0.1914, 0.2101, 0.1841], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,436][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.4842, 0.1216, 0.1099, 0.0687, 0.2156], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,436][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ got] are: tensor([4.9840e-04, 2.3759e-03, 9.1662e-04, 4.7734e-04, 9.9573e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,438][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.5627, 0.0423, 0.1894, 0.0802, 0.1254], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,439][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0572, 0.0020, 0.0131, 0.0104, 0.9174], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,440][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.3776, 0.0450, 0.0456, 0.0522, 0.4796], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,441][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ got] are: tensor([1.2122e-02, 3.3974e-04, 9.5180e-05, 1.2648e-04, 9.8732e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,443][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.3523, 0.2622, 0.0414, 0.2529, 0.0912], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,444][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.2597, 0.1294, 0.2143, 0.1758, 0.2208], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,445][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.3468, 0.0741, 0.3400, 0.1399, 0.0992], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,447][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.4384, 0.1025, 0.2346, 0.1061, 0.1184], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,448][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.3822, 0.0937, 0.1948, 0.0568, 0.2724], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,450][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.4706, 0.1014, 0.2278, 0.0894, 0.1108], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,451][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4918, 0.2169, 0.0478, 0.0614, 0.1471, 0.0350], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,452][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.4072e-03, 8.4507e-04, 6.0562e-03, 1.7229e-03, 1.3902e-03, 9.8658e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,453][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4282, 0.0766, 0.2495, 0.0777, 0.1165, 0.0515], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,455][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0707, 0.0112, 0.0383, 0.0304, 0.1003, 0.7491], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,456][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2093, 0.0466, 0.0410, 0.0586, 0.4657, 0.1788], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,458][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1229, 0.0045, 0.1343, 0.0067, 0.0326, 0.6989], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,459][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3185, 0.2990, 0.0136, 0.1765, 0.1782, 0.0142], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,461][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1659, 0.0741, 0.1298, 0.1264, 0.2216, 0.2822], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,462][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0520, 0.0130, 0.2273, 0.0216, 0.0562, 0.6299], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,463][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3661, 0.1060, 0.2015, 0.0844, 0.0937, 0.1484], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,465][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3417, 0.0835, 0.2016, 0.0721, 0.0649, 0.2362], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,466][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3567, 0.1029, 0.1810, 0.0980, 0.1257, 0.1358], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,468][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.3071, 0.1341, 0.1316, 0.0593, 0.0852, 0.0752, 0.2075],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,469][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([8.0198e-04, 2.2619e-03, 2.3760e-04, 4.6703e-04, 1.7218e-03, 1.8211e-04,
        9.9433e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,470][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.4083, 0.0427, 0.1427, 0.0529, 0.0496, 0.1185, 0.1854],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,471][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([2.8609e-03, 1.6675e-04, 1.9198e-05, 2.4954e-04, 2.9304e-03, 1.7184e-04,
        9.9360e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,472][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0409, 0.0162, 0.0040, 0.0197, 0.0290, 0.0133, 0.8769],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,473][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([2.6065e-03, 2.3694e-04, 1.5675e-07, 1.8429e-05, 1.2063e-06, 1.0869e-07,
        9.9714e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,475][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.2633, 0.2252, 0.0931, 0.1360, 0.0431, 0.0767, 0.1627],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,476][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.1768, 0.0189, 0.1192, 0.1187, 0.1687, 0.2690, 0.1286],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,477][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.3235, 0.0546, 0.1683, 0.0390, 0.0685, 0.1932, 0.1528],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,479][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.4326, 0.0908, 0.1642, 0.0976, 0.0881, 0.1105, 0.0162],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,480][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.3095, 0.0686, 0.1483, 0.0554, 0.0532, 0.0859, 0.2792],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,482][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.2116, 0.1339, 0.1741, 0.0837, 0.1290, 0.1259, 0.1418],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,483][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2958, 0.2313, 0.0482, 0.0816, 0.1769, 0.0673, 0.0682, 0.0308],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,484][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.6169e-03, 1.5045e-03, 5.4833e-03, 3.8140e-04, 1.2725e-04, 1.8793e-03,
        1.7861e-04, 9.8883e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,485][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.3186, 0.0517, 0.1674, 0.0520, 0.1278, 0.0594, 0.0812, 0.1418],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,486][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([4.0037e-03, 8.4332e-04, 2.7553e-03, 1.1121e-03, 1.2699e-02, 3.7504e-02,
        2.8575e-02, 9.1251e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,486][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1214, 0.0253, 0.0185, 0.0326, 0.1806, 0.0707, 0.2622, 0.2887],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,487][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0770, 0.0046, 0.0146, 0.0019, 0.0079, 0.0183, 0.0086, 0.8672],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,487][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1527, 0.2343, 0.0173, 0.1693, 0.0982, 0.0204, 0.2854, 0.0224],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,487][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0837, 0.0405, 0.0545, 0.0689, 0.0989, 0.1972, 0.1498, 0.3065],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,488][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0631, 0.0094, 0.3103, 0.0234, 0.0669, 0.3362, 0.0283, 0.1623],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,488][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2629, 0.0634, 0.1649, 0.0753, 0.0855, 0.1243, 0.0897, 0.1338],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,489][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2219, 0.0729, 0.1650, 0.0575, 0.0547, 0.1177, 0.0683, 0.2419],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,489][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3256, 0.0803, 0.1259, 0.0698, 0.0788, 0.0664, 0.0906, 0.1625],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,490][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3812, 0.2218, 0.0270, 0.0921, 0.0939, 0.0216, 0.1177, 0.0208, 0.0238],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,491][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.2634e-03, 9.3163e-04, 5.7166e-02, 3.8457e-03, 1.7094e-04, 4.4424e-02,
        2.6685e-04, 5.6384e-02, 8.2755e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,493][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3019, 0.0429, 0.1310, 0.0585, 0.1280, 0.0384, 0.0623, 0.2003, 0.0368],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,494][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0283, 0.0027, 0.0061, 0.0063, 0.0167, 0.0704, 0.0361, 0.1866, 0.6469],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,495][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1931, 0.0393, 0.0262, 0.0425, 0.1391, 0.0602, 0.1238, 0.2070, 0.1688],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,497][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1274, 0.0128, 0.1227, 0.0155, 0.0599, 0.2361, 0.0096, 0.0749, 0.3411],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,498][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1665, 0.2641, 0.0043, 0.1514, 0.0757, 0.0044, 0.3234, 0.0075, 0.0026],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,500][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0776, 0.0215, 0.0340, 0.0291, 0.0576, 0.0890, 0.0992, 0.2914, 0.3005],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,501][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0194, 0.0048, 0.1364, 0.0103, 0.0290, 0.3207, 0.0227, 0.0635, 0.3932],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,503][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2580, 0.0721, 0.1328, 0.0724, 0.0723, 0.0995, 0.0715, 0.1126, 0.1088],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,504][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2615, 0.0696, 0.1381, 0.0751, 0.0426, 0.1236, 0.0552, 0.0796, 0.1548],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,506][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2253, 0.0908, 0.1079, 0.0676, 0.0736, 0.1123, 0.0925, 0.1064, 0.1236],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,507][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.2111, 0.0537, 0.0640, 0.0670, 0.0348, 0.0670, 0.2314, 0.0293, 0.0642,
        0.1774], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,508][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ house] are: tensor([2.2980e-04, 6.7087e-04, 1.2357e-03, 1.4131e-03, 9.8312e-04, 4.8589e-04,
        3.2383e-04, 4.5604e-04, 2.6143e-04, 9.9394e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,509][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.2132, 0.0838, 0.0871, 0.1187, 0.0412, 0.0757, 0.1980, 0.0892, 0.0734,
        0.0198], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,510][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ house] are: tensor([7.1228e-03, 9.0754e-04, 1.5524e-04, 6.6430e-04, 1.0664e-03, 6.4059e-04,
        5.6163e-02, 5.5839e-03, 4.2088e-03, 9.2349e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,512][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0650, 0.0263, 0.0041, 0.0030, 0.0341, 0.0075, 0.0379, 0.0186, 0.0242,
        0.7794], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,513][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ house] are: tensor([7.8255e-03, 4.3944e-04, 1.4250e-05, 6.5810e-04, 2.9608e-05, 1.5176e-05,
        8.8758e-05, 1.6072e-06, 9.1442e-06, 9.9092e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,514][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.1210, 0.4078, 0.0174, 0.1337, 0.0144, 0.0114, 0.1520, 0.0080, 0.0117,
        0.1227], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,515][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0764, 0.0048, 0.0399, 0.0082, 0.1428, 0.1137, 0.0389, 0.1445, 0.3600,
        0.0707], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,517][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.2276, 0.0664, 0.1053, 0.0497, 0.0775, 0.0935, 0.1240, 0.0715, 0.1280,
        0.0565], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,518][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.2199, 0.0804, 0.1067, 0.0831, 0.0682, 0.0909, 0.1610, 0.0817, 0.0938,
        0.0144], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,520][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.1449, 0.0634, 0.1177, 0.0638, 0.0572, 0.0978, 0.0874, 0.0573, 0.0723,
        0.2381], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,521][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.3616, 0.0977, 0.0753, 0.0843, 0.0492, 0.0461, 0.0675, 0.0875, 0.0349,
        0.0958], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,523][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4103, 0.1420, 0.0151, 0.0666, 0.1064, 0.0270, 0.0861, 0.0181, 0.0486,
        0.0688, 0.0111], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,524][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.0960e-03, 3.1975e-04, 2.0232e-02, 2.0733e-04, 2.6249e-04, 3.2643e-04,
        4.4077e-05, 2.4366e-03, 9.4237e-04, 1.2855e-04, 9.7100e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,525][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2896, 0.0360, 0.1125, 0.0191, 0.0276, 0.0101, 0.0205, 0.0537, 0.0125,
        0.0091, 0.4092], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,527][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0359, 0.0015, 0.0028, 0.0009, 0.0098, 0.0127, 0.0103, 0.0525, 0.1347,
        0.0350, 0.7040], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,528][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4118, 0.0221, 0.0126, 0.0347, 0.0380, 0.0158, 0.0343, 0.0847, 0.0407,
        0.0489, 0.2564], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,529][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1167, 0.0227, 0.1693, 0.0357, 0.0368, 0.1269, 0.0096, 0.1076, 0.1194,
        0.0275, 0.2278], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,531][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2094, 0.1920, 0.0077, 0.1522, 0.0574, 0.0090, 0.2556, 0.0125, 0.0053,
        0.0938, 0.0051], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,532][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0342, 0.0185, 0.0145, 0.0235, 0.0280, 0.0417, 0.0341, 0.1048, 0.1656,
        0.2107, 0.3244], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,534][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0290, 0.0048, 0.1515, 0.0086, 0.0154, 0.1426, 0.0075, 0.0614, 0.2179,
        0.0169, 0.3442], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,535][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2231, 0.0611, 0.1158, 0.0661, 0.0657, 0.0805, 0.0608, 0.0930, 0.0862,
        0.0566, 0.0912], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,537][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1786, 0.0722, 0.1371, 0.0759, 0.0599, 0.0871, 0.0579, 0.0995, 0.0847,
        0.0455, 0.1015], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,538][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2141, 0.0736, 0.1020, 0.0641, 0.0740, 0.0624, 0.0758, 0.1124, 0.0531,
        0.0566, 0.1120], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,539][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.2834, 0.1315, 0.1067, 0.0347, 0.0417, 0.0465, 0.0471, 0.0610, 0.0627,
        0.0350, 0.1157, 0.0340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,539][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ William] are: tensor([1.3333e-04, 1.3129e-03, 2.2556e-05, 5.0605e-01, 2.0719e-05, 2.6606e-05,
        9.6107e-06, 3.6052e-05, 8.2994e-05, 4.5201e-05, 1.1737e-05, 4.9225e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,540][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.1743, 0.1848, 0.0481, 0.0673, 0.0474, 0.0592, 0.1522, 0.0670, 0.0709,
        0.0170, 0.0545, 0.0575], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,540][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ William] are: tensor([1.3026e-04, 5.7707e-05, 2.1910e-07, 5.4720e-03, 3.7629e-07, 4.9766e-06,
        2.6240e-05, 5.9919e-06, 1.7921e-05, 2.3007e-04, 1.3203e-05, 9.9404e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,541][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0109, 0.0157, 0.0014, 0.0571, 0.0011, 0.0013, 0.0105, 0.0053, 0.0048,
        0.0479, 0.0123, 0.8317], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,541][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ William] are: tensor([2.2987e-03, 7.2933e-05, 4.0106e-07, 5.9780e-01, 1.7177e-06, 3.4150e-07,
        1.0657e-06, 2.1058e-07, 2.9440e-07, 5.2215e-06, 1.2135e-07, 3.9982e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,541][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.1525, 0.2531, 0.0474, 0.1298, 0.0154, 0.0361, 0.0870, 0.0147, 0.0558,
        0.0376, 0.0459, 0.1247], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,542][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0580, 0.0107, 0.0223, 0.0094, 0.0158, 0.0520, 0.0185, 0.1157, 0.1444,
        0.1232, 0.2712, 0.1588], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,543][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.1187, 0.0820, 0.0828, 0.1004, 0.0256, 0.0601, 0.1783, 0.0522, 0.0763,
        0.0352, 0.0788, 0.1094], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,545][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.1904, 0.0954, 0.1006, 0.0269, 0.0554, 0.0689, 0.1262, 0.0748, 0.0874,
        0.0581, 0.0906, 0.0252], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,546][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.1374, 0.0656, 0.0826, 0.2416, 0.0244, 0.0529, 0.0277, 0.0496, 0.0575,
        0.0209, 0.0523, 0.1876], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,548][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.1442, 0.0858, 0.0595, 0.0725, 0.1252, 0.0452, 0.0640, 0.0660, 0.0337,
        0.1497, 0.0622, 0.0920], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,549][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.3213, 0.0806, 0.0357, 0.0600, 0.0676, 0.0321, 0.0227, 0.0378, 0.0392,
        0.0510, 0.0434, 0.0744, 0.1342], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,550][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([4.2124e-04, 7.5070e-04, 2.0330e-04, 7.4459e-04, 1.2746e-02, 4.1436e-04,
        5.3364e-04, 1.3307e-04, 9.4456e-05, 5.6886e-05, 5.3906e-05, 3.6592e-04,
        9.8348e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,551][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2146, 0.0357, 0.0658, 0.0479, 0.1023, 0.0510, 0.2407, 0.0550, 0.0544,
        0.0146, 0.0247, 0.0434, 0.0498], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,552][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.1956e-04, 6.2163e-06, 8.9566e-06, 2.7634e-06, 9.8185e-05, 2.6826e-05,
        2.1930e-04, 1.0294e-04, 1.5236e-04, 4.3512e-04, 9.5972e-04, 3.1266e-04,
        9.9676e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,554][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0394, 0.0042, 0.0050, 0.0011, 0.0077, 0.0071, 0.0092, 0.0236, 0.0145,
        0.0269, 0.0265, 0.0077, 0.8271], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,554][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.1282e-02, 3.5219e-04, 4.4786e-05, 1.5373e-04, 2.1531e-03, 5.7168e-06,
        1.9889e-05, 1.9065e-05, 1.8316e-06, 2.3470e-06, 1.9805e-06, 4.4252e-05,
        9.8592e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,556][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1447, 0.1533, 0.0198, 0.1302, 0.0387, 0.0250, 0.0916, 0.0175, 0.0161,
        0.0885, 0.0157, 0.1590, 0.0999], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,557][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0434, 0.0165, 0.0122, 0.0063, 0.0217, 0.0404, 0.0034, 0.0720, 0.1121,
        0.0259, 0.2914, 0.1278, 0.2271], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,559][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1284, 0.0241, 0.1013, 0.0457, 0.0694, 0.1024, 0.0403, 0.0837, 0.1332,
        0.1095, 0.0841, 0.0560, 0.0218], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,560][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1882, 0.0631, 0.0844, 0.0552, 0.0701, 0.0640, 0.0644, 0.0668, 0.0700,
        0.0782, 0.0782, 0.0607, 0.0566], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,562][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1708, 0.0451, 0.0779, 0.0378, 0.0720, 0.0656, 0.0692, 0.0557, 0.0654,
        0.0294, 0.0623, 0.0329, 0.2160], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,563][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.3301, 0.0427, 0.0815, 0.0472, 0.0471, 0.0440, 0.0372, 0.1092, 0.0329,
        0.0345, 0.0881, 0.0455, 0.0601], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,565][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2295, 0.0818, 0.0224, 0.0372, 0.0751, 0.0216, 0.1031, 0.0196, 0.0298,
        0.0603, 0.0261, 0.0505, 0.2268, 0.0160], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,566][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.7917e-03, 5.4864e-05, 3.9652e-02, 9.5745e-05, 4.6688e-04, 1.6740e-03,
        1.7876e-05, 1.9513e-02, 1.9053e-03, 8.5550e-05, 8.6321e-03, 4.8688e-05,
        2.9705e-05, 9.2203e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,567][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2003, 0.0241, 0.1015, 0.0321, 0.0551, 0.0265, 0.0214, 0.1388, 0.0292,
        0.0319, 0.0631, 0.0304, 0.0684, 0.1772], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,568][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.0995e-03, 1.9812e-05, 2.8064e-04, 3.9879e-05, 8.1625e-04, 1.6089e-03,
        1.4465e-03, 3.4927e-03, 1.5027e-02, 5.4846e-03, 3.6922e-02, 4.4151e-03,
        9.8830e-02, 8.2552e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,569][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.1965e-02, 5.9989e-04, 1.3372e-03, 1.0186e-03, 1.9389e-02, 3.6973e-03,
        1.1469e-02, 7.7583e-03, 6.1535e-03, 1.2621e-02, 9.0894e-03, 1.2060e-02,
        8.0507e-01, 9.7767e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,571][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0437, 0.0007, 0.0892, 0.0054, 0.0496, 0.2127, 0.0018, 0.0208, 0.1749,
        0.0095, 0.0178, 0.0021, 0.0057, 0.3661], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,572][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1042, 0.0617, 0.0056, 0.0461, 0.0490, 0.0047, 0.0794, 0.0205, 0.0039,
        0.0904, 0.0047, 0.0733, 0.1501, 0.3064], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,574][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0266, 0.0065, 0.0056, 0.0065, 0.0093, 0.0112, 0.0131, 0.0242, 0.0400,
        0.0331, 0.1061, 0.1307, 0.3284, 0.2587], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,575][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0164, 0.0029, 0.0982, 0.0050, 0.0164, 0.1323, 0.0110, 0.0481, 0.2114,
        0.0210, 0.1770, 0.0073, 0.0075, 0.2454], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,577][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1510, 0.0399, 0.0908, 0.0504, 0.0527, 0.0737, 0.0499, 0.0759, 0.0796,
        0.0492, 0.0758, 0.0530, 0.0557, 0.1025], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,578][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1240, 0.0356, 0.1116, 0.0416, 0.0641, 0.0923, 0.0482, 0.0844, 0.0841,
        0.0399, 0.0783, 0.0339, 0.0461, 0.1159], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,580][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1807, 0.0595, 0.0841, 0.0507, 0.0665, 0.0535, 0.0449, 0.0852, 0.0405,
        0.0403, 0.0875, 0.0496, 0.0710, 0.0860], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,581][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2465, 0.0531, 0.0307, 0.0300, 0.0697, 0.0267, 0.0599, 0.0187, 0.0308,
        0.1028, 0.0268, 0.0357, 0.1915, 0.0282, 0.0490], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,582][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([6.2512e-04, 4.0383e-04, 5.1222e-04, 3.6753e-04, 4.3847e-03, 4.6100e-04,
        3.5028e-05, 7.7514e-04, 2.1334e-04, 8.4881e-05, 1.6726e-04, 2.0770e-04,
        1.3264e-03, 5.6386e-04, 9.8987e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,584][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1911, 0.0340, 0.0521, 0.0328, 0.0880, 0.0413, 0.0583, 0.0781, 0.0509,
        0.0420, 0.0336, 0.0300, 0.1079, 0.1103, 0.0497], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,585][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([8.9531e-04, 1.0287e-06, 4.9628e-06, 4.3407e-06, 3.2006e-05, 3.7199e-05,
        4.1196e-05, 6.5339e-05, 2.1119e-04, 6.8426e-04, 9.0824e-04, 6.8073e-04,
        8.8002e-03, 8.6010e-03, 9.7903e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,586][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0402, 0.0186, 0.0057, 0.0076, 0.0090, 0.0087, 0.0087, 0.0213, 0.0147,
        0.0493, 0.0252, 0.0554, 0.1184, 0.1115, 0.5056], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,587][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([9.2316e-03, 1.7495e-04, 5.0153e-05, 4.1974e-04, 1.4835e-03, 4.0196e-05,
        2.9485e-05, 3.3140e-05, 2.2233e-05, 5.8795e-06, 3.1432e-06, 1.2208e-04,
        1.6475e-04, 8.3961e-06, 9.8821e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,589][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1192, 0.1115, 0.0129, 0.1167, 0.0293, 0.0144, 0.1217, 0.0122, 0.0124,
        0.1583, 0.0124, 0.1521, 0.0905, 0.0114, 0.0249], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,590][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0252, 0.0033, 0.0057, 0.0046, 0.0086, 0.0122, 0.0041, 0.0241, 0.0314,
        0.0259, 0.0865, 0.0791, 0.1450, 0.3104, 0.2340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,591][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0765, 0.0225, 0.0906, 0.0238, 0.0751, 0.0743, 0.0383, 0.0658, 0.0945,
        0.0662, 0.0985, 0.0303, 0.0425, 0.1565, 0.0447], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,592][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1294, 0.0406, 0.0749, 0.0489, 0.0603, 0.0640, 0.0568, 0.0621, 0.0646,
        0.0564, 0.0700, 0.0543, 0.0704, 0.0923, 0.0550], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,592][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1066, 0.0258, 0.0693, 0.0376, 0.0761, 0.0603, 0.0339, 0.0667, 0.0574,
        0.0360, 0.0605, 0.0369, 0.0619, 0.0809, 0.1903], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,593][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2757, 0.0423, 0.0943, 0.0375, 0.0546, 0.0277, 0.0348, 0.0828, 0.0213,
        0.0340, 0.0665, 0.0321, 0.0520, 0.0653, 0.0793], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,593][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.2947, 0.0861, 0.0216, 0.0377, 0.0513, 0.0134, 0.0265, 0.0174, 0.0198,
        0.0692, 0.0244, 0.0482, 0.1562, 0.0151, 0.0789, 0.0397],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,594][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ it] are: tensor([3.1327e-03, 4.7549e-04, 2.0973e-03, 5.9184e-04, 2.5788e-04, 3.3394e-03,
        7.3815e-05, 6.0153e-04, 1.0979e-02, 2.6630e-05, 7.2914e-04, 3.7764e-04,
        1.1508e-04, 3.1587e-03, 4.1414e-04, 9.7363e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,594][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1681, 0.0220, 0.0802, 0.0322, 0.1087, 0.0244, 0.0251, 0.0661, 0.0253,
        0.0385, 0.0444, 0.0308, 0.1308, 0.0968, 0.0739, 0.0325],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,595][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ it] are: tensor([8.5056e-04, 8.4260e-06, 1.4901e-05, 2.3821e-05, 5.9045e-05, 1.0275e-04,
        8.3964e-05, 2.5913e-04, 8.7182e-04, 3.7613e-04, 3.2423e-03, 3.7098e-03,
        9.4130e-03, 1.8024e-02, 7.2666e-02, 8.9030e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,596][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0457, 0.0032, 0.0056, 0.0026, 0.0159, 0.0062, 0.0097, 0.0131, 0.0134,
        0.0187, 0.0248, 0.0181, 0.2733, 0.0922, 0.1940, 0.2635],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,597][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ it] are: tensor([2.6629e-02, 2.0813e-03, 4.1785e-03, 6.7388e-04, 8.1012e-03, 6.5796e-03,
        1.4380e-03, 1.8962e-03, 8.3118e-03, 1.2117e-03, 4.4965e-04, 1.5094e-04,
        1.0281e-03, 1.9165e-03, 5.6431e-04, 9.3479e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,598][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.1121, 0.1224, 0.0057, 0.0883, 0.0422, 0.0055, 0.1756, 0.0061, 0.0037,
        0.0988, 0.0047, 0.1338, 0.1349, 0.0078, 0.0509, 0.0073],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,600][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0258, 0.0021, 0.0041, 0.0026, 0.0060, 0.0067, 0.0039, 0.0162, 0.0188,
        0.0197, 0.0607, 0.0391, 0.0691, 0.1731, 0.2954, 0.2568],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,601][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0304, 0.0034, 0.0840, 0.0078, 0.0327, 0.1295, 0.0237, 0.0401, 0.1794,
        0.0239, 0.1196, 0.0099, 0.0144, 0.1096, 0.0253, 0.1663],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,603][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.1543, 0.0470, 0.0753, 0.0432, 0.0502, 0.0574, 0.0407, 0.0599, 0.0641,
        0.0411, 0.0658, 0.0457, 0.0457, 0.0843, 0.0571, 0.0683],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,604][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.1106, 0.0334, 0.0694, 0.0328, 0.0378, 0.0676, 0.0305, 0.0512, 0.0852,
        0.0213, 0.0554, 0.0277, 0.0399, 0.0674, 0.0423, 0.2275],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,606][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.2180, 0.0512, 0.0620, 0.0430, 0.0459, 0.0378, 0.0440, 0.0695, 0.0329,
        0.0391, 0.0736, 0.0401, 0.0581, 0.0651, 0.0685, 0.0514],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,607][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2017, 0.0699, 0.0181, 0.0319, 0.0648, 0.0181, 0.0879, 0.0155, 0.0246,
        0.0502, 0.0209, 0.0427, 0.1941, 0.0129, 0.0761, 0.0553, 0.0154],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,608][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8642e-03, 2.3287e-05, 1.7570e-02, 4.1684e-05, 2.1397e-04, 7.1508e-04,
        8.8103e-06, 8.8272e-03, 8.9409e-04, 4.1683e-05, 4.6306e-03, 2.3598e-05,
        1.4758e-05, 4.6290e-01, 4.0144e-04, 6.5269e-04, 5.0017e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,609][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1533, 0.0184, 0.0767, 0.0259, 0.0437, 0.0200, 0.0171, 0.1057, 0.0221,
        0.0250, 0.0484, 0.0250, 0.0549, 0.1351, 0.0567, 0.0275, 0.1445],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,610][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.6395e-03, 3.1394e-06, 4.0773e-05, 4.9626e-06, 8.5012e-05, 1.4144e-04,
        1.2911e-04, 2.4134e-04, 9.9453e-04, 3.8112e-04, 2.5220e-03, 2.7207e-04,
        6.2115e-03, 4.7912e-02, 4.0163e-01, 9.8658e-02, 4.3913e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,612][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0134, 0.0005, 0.0012, 0.0008, 0.0147, 0.0025, 0.0074, 0.0045, 0.0035,
        0.0068, 0.0050, 0.0061, 0.4296, 0.0497, 0.2329, 0.0619, 0.1594],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,613][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0268, 0.0005, 0.0610, 0.0037, 0.0355, 0.1536, 0.0012, 0.0153, 0.1246,
        0.0063, 0.0113, 0.0014, 0.0039, 0.2569, 0.0090, 0.0521, 0.2368],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,615][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0710, 0.0412, 0.0036, 0.0319, 0.0332, 0.0030, 0.0533, 0.0137, 0.0024,
        0.0610, 0.0030, 0.0513, 0.1042, 0.2096, 0.0564, 0.0079, 0.2533],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,616][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0208, 0.0037, 0.0032, 0.0036, 0.0042, 0.0045, 0.0052, 0.0079, 0.0126,
        0.0112, 0.0333, 0.0402, 0.0956, 0.0704, 0.1463, 0.2592, 0.2780],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,618][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0118, 0.0020, 0.0689, 0.0036, 0.0118, 0.0912, 0.0079, 0.0334, 0.1436,
        0.0157, 0.1238, 0.0052, 0.0054, 0.1701, 0.0138, 0.0880, 0.2036],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,619][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1184, 0.0314, 0.0704, 0.0407, 0.0425, 0.0572, 0.0409, 0.0585, 0.0613,
        0.0407, 0.0594, 0.0430, 0.0456, 0.0793, 0.0538, 0.0699, 0.0869],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,621][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0888, 0.0256, 0.0787, 0.0314, 0.0499, 0.0696, 0.0401, 0.0659, 0.0656,
        0.0343, 0.0639, 0.0289, 0.0402, 0.0965, 0.0481, 0.0746, 0.0980],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,623][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1611, 0.0501, 0.0725, 0.0439, 0.0578, 0.0461, 0.0359, 0.0704, 0.0341,
        0.0321, 0.0686, 0.0397, 0.0567, 0.0692, 0.0553, 0.0363, 0.0703],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,640][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:54,641][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,641][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,642][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,642][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,642][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,643][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,643][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,643][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,644][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,644][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,644][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,645][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,645][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9054, 0.0946], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,645][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([1.0927e-04, 9.9989e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,646][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.8425, 0.1575], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,646][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.0886, 0.9114], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,646][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.2560, 0.7440], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,647][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0142, 0.9858], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,647][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.8002, 0.1998], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,647][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.9782, 0.0218], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,648][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.8354, 0.1646], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,648][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.9203, 0.0797], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,648][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.7082, 0.2918], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,649][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.7376, 0.2624], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,649][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7615, 0.1802, 0.0584], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,649][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0042, 0.0012, 0.9945], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,650][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4144, 0.0278, 0.5578], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,650][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2451, 0.0940, 0.6609], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,650][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5616, 0.2631, 0.1754], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,651][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2181, 0.0054, 0.7765], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,652][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6048, 0.3695, 0.0257], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,653][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4333, 0.3605, 0.2062], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,655][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2509, 0.0384, 0.7107], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,656][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6148, 0.1261, 0.2591], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,657][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6423, 0.1099, 0.2479], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,659][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5373, 0.1205, 0.3422], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,660][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.5270, 0.1933, 0.2269, 0.0529], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,661][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([3.3313e-04, 6.3636e-03, 1.0746e-04, 9.9320e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,662][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.4666, 0.3319, 0.1016, 0.0999], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,663][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([2.1858e-03, 8.5800e-03, 7.4780e-05, 9.8916e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,664][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0744, 0.2017, 0.0149, 0.7090], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,665][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([1.4942e-02, 2.4501e-04, 2.9278e-06, 9.8481e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,666][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.3486, 0.3897, 0.0980, 0.1638], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,666][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.3405, 0.1474, 0.3780, 0.1340], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,667][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.3699, 0.2073, 0.2094, 0.2134], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,667][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.5099, 0.2032, 0.2297, 0.0572], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,667][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.4253, 0.1264, 0.1647, 0.2836], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,668][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.4144, 0.1914, 0.2101, 0.1841], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,668][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.4842, 0.1216, 0.1099, 0.0687, 0.2156], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,668][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([4.9840e-04, 2.3759e-03, 9.1662e-04, 4.7734e-04, 9.9573e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,669][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.5627, 0.0423, 0.1894, 0.0802, 0.1254], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,670][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0572, 0.0020, 0.0131, 0.0104, 0.9174], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,671][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.3776, 0.0450, 0.0456, 0.0522, 0.4796], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,672][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([1.2122e-02, 3.3974e-04, 9.5180e-05, 1.2648e-04, 9.8732e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,674][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.3523, 0.2622, 0.0414, 0.2529, 0.0912], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,675][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2597, 0.1294, 0.2143, 0.1758, 0.2208], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,676][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3468, 0.0741, 0.3400, 0.1399, 0.0992], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,678][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.4384, 0.1025, 0.2346, 0.1061, 0.1184], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,679][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.3822, 0.0937, 0.1948, 0.0568, 0.2724], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,681][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.4706, 0.1014, 0.2278, 0.0894, 0.1108], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,682][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4918, 0.2169, 0.0478, 0.0614, 0.1471, 0.0350], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,683][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.4072e-03, 8.4507e-04, 6.0562e-03, 1.7229e-03, 1.3902e-03, 9.8658e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,684][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4282, 0.0766, 0.2495, 0.0777, 0.1165, 0.0515], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,686][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0707, 0.0112, 0.0383, 0.0304, 0.1003, 0.7491], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,687][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2093, 0.0466, 0.0410, 0.0586, 0.4657, 0.1788], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,688][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1229, 0.0045, 0.1343, 0.0067, 0.0326, 0.6989], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,690][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3185, 0.2990, 0.0136, 0.1765, 0.1782, 0.0142], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,691][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1659, 0.0741, 0.1298, 0.1264, 0.2216, 0.2822], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,693][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0520, 0.0130, 0.2273, 0.0216, 0.0562, 0.6299], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,694][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3661, 0.1060, 0.2015, 0.0844, 0.0937, 0.1484], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,696][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3417, 0.0835, 0.2016, 0.0721, 0.0649, 0.2362], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,697][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3567, 0.1029, 0.1810, 0.0980, 0.1257, 0.1358], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,698][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.3071, 0.1341, 0.1316, 0.0593, 0.0852, 0.0752, 0.2075],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,699][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([8.0198e-04, 2.2619e-03, 2.3760e-04, 4.6703e-04, 1.7218e-03, 1.8211e-04,
        9.9433e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,701][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.4083, 0.0427, 0.1427, 0.0529, 0.0496, 0.1185, 0.1854],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,702][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([2.8609e-03, 1.6675e-04, 1.9198e-05, 2.4954e-04, 2.9304e-03, 1.7184e-04,
        9.9360e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,703][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0409, 0.0162, 0.0040, 0.0197, 0.0290, 0.0133, 0.8769],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,704][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([2.6065e-03, 2.3694e-04, 1.5675e-07, 1.8429e-05, 1.2063e-06, 1.0869e-07,
        9.9714e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,706][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.2633, 0.2252, 0.0931, 0.1360, 0.0431, 0.0767, 0.1627],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,707][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.1768, 0.0189, 0.1192, 0.1187, 0.1687, 0.2690, 0.1286],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,709][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.3235, 0.0546, 0.1683, 0.0390, 0.0685, 0.1932, 0.1528],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,710][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.4326, 0.0908, 0.1642, 0.0976, 0.0881, 0.1105, 0.0162],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,711][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.3095, 0.0686, 0.1483, 0.0554, 0.0532, 0.0859, 0.2792],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,713][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.2116, 0.1339, 0.1741, 0.0837, 0.1290, 0.1259, 0.1418],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,714][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2958, 0.2313, 0.0482, 0.0816, 0.1769, 0.0673, 0.0682, 0.0308],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,715][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.6169e-03, 1.5045e-03, 5.4833e-03, 3.8140e-04, 1.2725e-04, 1.8793e-03,
        1.7861e-04, 9.8883e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,717][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3186, 0.0517, 0.1674, 0.0520, 0.1278, 0.0594, 0.0812, 0.1418],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,717][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([4.0037e-03, 8.4332e-04, 2.7553e-03, 1.1121e-03, 1.2699e-02, 3.7504e-02,
        2.8575e-02, 9.1251e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,719][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1214, 0.0253, 0.0185, 0.0326, 0.1806, 0.0707, 0.2622, 0.2887],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,719][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0770, 0.0046, 0.0146, 0.0019, 0.0079, 0.0183, 0.0086, 0.8672],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,719][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1527, 0.2343, 0.0173, 0.1693, 0.0982, 0.0204, 0.2854, 0.0224],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,720][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0837, 0.0405, 0.0545, 0.0689, 0.0989, 0.1972, 0.1498, 0.3065],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,720][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0631, 0.0094, 0.3103, 0.0234, 0.0669, 0.3362, 0.0283, 0.1623],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,720][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2629, 0.0634, 0.1649, 0.0753, 0.0855, 0.1243, 0.0897, 0.1338],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,721][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2219, 0.0729, 0.1650, 0.0575, 0.0547, 0.1177, 0.0683, 0.2419],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,721][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.3256, 0.0803, 0.1259, 0.0698, 0.0788, 0.0664, 0.0906, 0.1625],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:54,722][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3812, 0.2218, 0.0270, 0.0921, 0.0939, 0.0216, 0.1177, 0.0208, 0.0238],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,723][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.2634e-03, 9.3163e-04, 5.7166e-02, 3.8457e-03, 1.7094e-04, 4.4424e-02,
        2.6685e-04, 5.6384e-02, 8.2755e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,724][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3019, 0.0429, 0.1310, 0.0585, 0.1280, 0.0384, 0.0623, 0.2003, 0.0368],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,725][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0283, 0.0027, 0.0061, 0.0063, 0.0167, 0.0704, 0.0361, 0.1866, 0.6469],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,727][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1931, 0.0393, 0.0262, 0.0425, 0.1391, 0.0602, 0.1238, 0.2070, 0.1688],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,728][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1274, 0.0128, 0.1227, 0.0155, 0.0599, 0.2361, 0.0096, 0.0749, 0.3411],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,729][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1665, 0.2641, 0.0043, 0.1514, 0.0757, 0.0044, 0.3234, 0.0075, 0.0026],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,731][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0776, 0.0215, 0.0340, 0.0291, 0.0576, 0.0890, 0.0992, 0.2914, 0.3005],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,732][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0194, 0.0048, 0.1364, 0.0103, 0.0290, 0.3207, 0.0227, 0.0635, 0.3932],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,734][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2580, 0.0721, 0.1328, 0.0724, 0.0723, 0.0995, 0.0715, 0.1126, 0.1088],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,735][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2615, 0.0696, 0.1381, 0.0751, 0.0426, 0.1236, 0.0552, 0.0796, 0.1548],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,737][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2253, 0.0908, 0.1079, 0.0676, 0.0736, 0.1123, 0.0925, 0.1064, 0.1236],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:54,738][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.2111, 0.0537, 0.0640, 0.0670, 0.0348, 0.0670, 0.2314, 0.0293, 0.0642,
        0.1774], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,739][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([2.2980e-04, 6.7087e-04, 1.2357e-03, 1.4131e-03, 9.8312e-04, 4.8589e-04,
        3.2383e-04, 4.5604e-04, 2.6143e-04, 9.9394e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,740][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.2132, 0.0838, 0.0871, 0.1187, 0.0412, 0.0757, 0.1980, 0.0892, 0.0734,
        0.0198], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,741][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([7.1228e-03, 9.0754e-04, 1.5524e-04, 6.6430e-04, 1.0664e-03, 6.4059e-04,
        5.6163e-02, 5.5839e-03, 4.2088e-03, 9.2349e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,743][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0650, 0.0263, 0.0041, 0.0030, 0.0341, 0.0075, 0.0379, 0.0186, 0.0242,
        0.7794], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,744][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([7.8255e-03, 4.3944e-04, 1.4250e-05, 6.5810e-04, 2.9608e-05, 1.5176e-05,
        8.8758e-05, 1.6072e-06, 9.1442e-06, 9.9092e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,745][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.1210, 0.4078, 0.0174, 0.1337, 0.0144, 0.0114, 0.1520, 0.0080, 0.0117,
        0.1227], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,747][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0764, 0.0048, 0.0399, 0.0082, 0.1428, 0.1137, 0.0389, 0.1445, 0.3600,
        0.0707], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,748][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.2276, 0.0664, 0.1053, 0.0497, 0.0775, 0.0935, 0.1240, 0.0715, 0.1280,
        0.0565], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,750][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.2199, 0.0804, 0.1067, 0.0831, 0.0682, 0.0909, 0.1610, 0.0817, 0.0938,
        0.0144], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,751][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.1449, 0.0634, 0.1177, 0.0638, 0.0572, 0.0978, 0.0874, 0.0573, 0.0723,
        0.2381], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,752][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.3616, 0.0977, 0.0753, 0.0843, 0.0492, 0.0461, 0.0675, 0.0875, 0.0349,
        0.0958], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:54,754][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4103, 0.1420, 0.0151, 0.0666, 0.1064, 0.0270, 0.0861, 0.0181, 0.0486,
        0.0688, 0.0111], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,755][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.0960e-03, 3.1975e-04, 2.0232e-02, 2.0733e-04, 2.6249e-04, 3.2643e-04,
        4.4077e-05, 2.4366e-03, 9.4237e-04, 1.2855e-04, 9.7100e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,756][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2896, 0.0360, 0.1125, 0.0191, 0.0276, 0.0101, 0.0205, 0.0537, 0.0125,
        0.0091, 0.4092], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,758][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0359, 0.0015, 0.0028, 0.0009, 0.0098, 0.0127, 0.0103, 0.0525, 0.1347,
        0.0350, 0.7040], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,759][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4118, 0.0221, 0.0126, 0.0347, 0.0380, 0.0158, 0.0343, 0.0847, 0.0407,
        0.0489, 0.2564], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,761][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1167, 0.0227, 0.1693, 0.0357, 0.0368, 0.1269, 0.0096, 0.1076, 0.1194,
        0.0275, 0.2278], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,762][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2094, 0.1920, 0.0077, 0.1522, 0.0574, 0.0090, 0.2556, 0.0125, 0.0053,
        0.0938, 0.0051], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,764][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0342, 0.0185, 0.0145, 0.0235, 0.0280, 0.0417, 0.0341, 0.1048, 0.1656,
        0.2107, 0.3244], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,765][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0290, 0.0048, 0.1515, 0.0086, 0.0154, 0.1426, 0.0075, 0.0614, 0.2179,
        0.0169, 0.3442], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,767][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2231, 0.0611, 0.1158, 0.0661, 0.0657, 0.0805, 0.0608, 0.0930, 0.0862,
        0.0566, 0.0912], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,768][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1786, 0.0722, 0.1371, 0.0759, 0.0599, 0.0871, 0.0579, 0.0995, 0.0847,
        0.0455, 0.1015], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,770][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2141, 0.0736, 0.1020, 0.0641, 0.0740, 0.0624, 0.0758, 0.1124, 0.0531,
        0.0566, 0.1120], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:54,771][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.2834, 0.1315, 0.1067, 0.0347, 0.0417, 0.0465, 0.0471, 0.0610, 0.0627,
        0.0350, 0.1157, 0.0340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,771][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([1.3333e-04, 1.3129e-03, 2.2556e-05, 5.0605e-01, 2.0719e-05, 2.6606e-05,
        9.6107e-06, 3.6052e-05, 8.2994e-05, 4.5201e-05, 1.1737e-05, 4.9225e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,772][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.1743, 0.1848, 0.0481, 0.0673, 0.0474, 0.0592, 0.1522, 0.0670, 0.0709,
        0.0170, 0.0545, 0.0575], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,772][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([1.3026e-04, 5.7707e-05, 2.1910e-07, 5.4720e-03, 3.7629e-07, 4.9766e-06,
        2.6240e-05, 5.9919e-06, 1.7921e-05, 2.3007e-04, 1.3203e-05, 9.9404e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,773][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0109, 0.0157, 0.0014, 0.0571, 0.0011, 0.0013, 0.0105, 0.0053, 0.0048,
        0.0479, 0.0123, 0.8317], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,773][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([2.2987e-03, 7.2933e-05, 4.0106e-07, 5.9780e-01, 1.7177e-06, 3.4150e-07,
        1.0657e-06, 2.1058e-07, 2.9440e-07, 5.2215e-06, 1.2135e-07, 3.9982e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,773][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.1525, 0.2531, 0.0474, 0.1298, 0.0154, 0.0361, 0.0870, 0.0147, 0.0558,
        0.0376, 0.0459, 0.1247], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,774][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0580, 0.0107, 0.0223, 0.0094, 0.0158, 0.0520, 0.0185, 0.1157, 0.1444,
        0.1232, 0.2712, 0.1588], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,775][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.1187, 0.0820, 0.0828, 0.1004, 0.0256, 0.0601, 0.1783, 0.0522, 0.0763,
        0.0352, 0.0788, 0.1094], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,777][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.1904, 0.0954, 0.1006, 0.0269, 0.0554, 0.0689, 0.1262, 0.0748, 0.0874,
        0.0581, 0.0906, 0.0252], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,778][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.1374, 0.0656, 0.0826, 0.2416, 0.0244, 0.0529, 0.0277, 0.0496, 0.0575,
        0.0209, 0.0523, 0.1876], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,780][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.1442, 0.0858, 0.0595, 0.0725, 0.1252, 0.0452, 0.0640, 0.0660, 0.0337,
        0.1497, 0.0622, 0.0920], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:54,781][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.3213, 0.0806, 0.0357, 0.0600, 0.0676, 0.0321, 0.0227, 0.0378, 0.0392,
        0.0510, 0.0434, 0.0744, 0.1342], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,782][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([4.2124e-04, 7.5070e-04, 2.0330e-04, 7.4459e-04, 1.2746e-02, 4.1436e-04,
        5.3364e-04, 1.3307e-04, 9.4456e-05, 5.6886e-05, 5.3906e-05, 3.6592e-04,
        9.8348e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,783][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.2146, 0.0357, 0.0658, 0.0479, 0.1023, 0.0510, 0.2407, 0.0550, 0.0544,
        0.0146, 0.0247, 0.0434, 0.0498], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,784][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.1956e-04, 6.2163e-06, 8.9566e-06, 2.7634e-06, 9.8185e-05, 2.6826e-05,
        2.1930e-04, 1.0294e-04, 1.5236e-04, 4.3512e-04, 9.5972e-04, 3.1266e-04,
        9.9676e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,786][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0394, 0.0042, 0.0050, 0.0011, 0.0077, 0.0071, 0.0092, 0.0236, 0.0145,
        0.0269, 0.0265, 0.0077, 0.8271], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,786][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.1282e-02, 3.5219e-04, 4.4786e-05, 1.5373e-04, 2.1531e-03, 5.7168e-06,
        1.9889e-05, 1.9065e-05, 1.8316e-06, 2.3470e-06, 1.9805e-06, 4.4252e-05,
        9.8592e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,788][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1447, 0.1533, 0.0198, 0.1302, 0.0387, 0.0250, 0.0916, 0.0175, 0.0161,
        0.0885, 0.0157, 0.1590, 0.0999], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,789][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0434, 0.0165, 0.0122, 0.0063, 0.0217, 0.0404, 0.0034, 0.0720, 0.1121,
        0.0259, 0.2914, 0.1278, 0.2271], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,791][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1284, 0.0241, 0.1013, 0.0457, 0.0694, 0.1024, 0.0403, 0.0837, 0.1332,
        0.1095, 0.0841, 0.0560, 0.0218], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,792][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.1882, 0.0631, 0.0844, 0.0552, 0.0701, 0.0640, 0.0644, 0.0668, 0.0700,
        0.0782, 0.0782, 0.0607, 0.0566], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,794][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1708, 0.0451, 0.0779, 0.0378, 0.0720, 0.0656, 0.0692, 0.0557, 0.0654,
        0.0294, 0.0623, 0.0329, 0.2160], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,795][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.3301, 0.0427, 0.0815, 0.0472, 0.0471, 0.0440, 0.0372, 0.1092, 0.0329,
        0.0345, 0.0881, 0.0455, 0.0601], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:54,797][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2295, 0.0818, 0.0224, 0.0372, 0.0751, 0.0216, 0.1031, 0.0196, 0.0298,
        0.0603, 0.0261, 0.0505, 0.2268, 0.0160], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,798][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.7917e-03, 5.4864e-05, 3.9652e-02, 9.5745e-05, 4.6688e-04, 1.6740e-03,
        1.7876e-05, 1.9513e-02, 1.9053e-03, 8.5550e-05, 8.6321e-03, 4.8688e-05,
        2.9705e-05, 9.2203e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,799][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2003, 0.0241, 0.1015, 0.0321, 0.0551, 0.0265, 0.0214, 0.1388, 0.0292,
        0.0319, 0.0631, 0.0304, 0.0684, 0.1772], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,800][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.0995e-03, 1.9812e-05, 2.8064e-04, 3.9879e-05, 8.1625e-04, 1.6089e-03,
        1.4465e-03, 3.4927e-03, 1.5027e-02, 5.4846e-03, 3.6922e-02, 4.4151e-03,
        9.8830e-02, 8.2552e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,801][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.1965e-02, 5.9989e-04, 1.3372e-03, 1.0186e-03, 1.9389e-02, 3.6973e-03,
        1.1469e-02, 7.7583e-03, 6.1535e-03, 1.2621e-02, 9.0894e-03, 1.2060e-02,
        8.0507e-01, 9.7767e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,803][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0437, 0.0007, 0.0892, 0.0054, 0.0496, 0.2127, 0.0018, 0.0208, 0.1749,
        0.0095, 0.0178, 0.0021, 0.0057, 0.3661], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,804][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1042, 0.0617, 0.0056, 0.0461, 0.0490, 0.0047, 0.0794, 0.0205, 0.0039,
        0.0904, 0.0047, 0.0733, 0.1501, 0.3064], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,806][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0266, 0.0065, 0.0056, 0.0065, 0.0093, 0.0112, 0.0131, 0.0242, 0.0400,
        0.0331, 0.1061, 0.1307, 0.3284, 0.2587], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,807][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0164, 0.0029, 0.0982, 0.0050, 0.0164, 0.1323, 0.0110, 0.0481, 0.2114,
        0.0210, 0.1770, 0.0073, 0.0075, 0.2454], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,809][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1510, 0.0399, 0.0908, 0.0504, 0.0527, 0.0737, 0.0499, 0.0759, 0.0796,
        0.0492, 0.0758, 0.0530, 0.0557, 0.1025], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,810][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1240, 0.0356, 0.1116, 0.0416, 0.0641, 0.0923, 0.0482, 0.0844, 0.0841,
        0.0399, 0.0783, 0.0339, 0.0461, 0.1159], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,812][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1807, 0.0595, 0.0841, 0.0507, 0.0665, 0.0535, 0.0449, 0.0852, 0.0405,
        0.0403, 0.0875, 0.0496, 0.0710, 0.0860], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:54,813][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2465, 0.0531, 0.0307, 0.0300, 0.0697, 0.0267, 0.0599, 0.0187, 0.0308,
        0.1028, 0.0268, 0.0357, 0.1915, 0.0282, 0.0490], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,814][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([6.2512e-04, 4.0383e-04, 5.1222e-04, 3.6753e-04, 4.3847e-03, 4.6100e-04,
        3.5028e-05, 7.7514e-04, 2.1334e-04, 8.4881e-05, 1.6726e-04, 2.0770e-04,
        1.3264e-03, 5.6386e-04, 9.8987e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,816][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1911, 0.0340, 0.0521, 0.0328, 0.0880, 0.0413, 0.0583, 0.0781, 0.0509,
        0.0420, 0.0336, 0.0300, 0.1079, 0.1103, 0.0497], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,817][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([8.9531e-04, 1.0287e-06, 4.9628e-06, 4.3407e-06, 3.2006e-05, 3.7199e-05,
        4.1196e-05, 6.5339e-05, 2.1119e-04, 6.8426e-04, 9.0824e-04, 6.8073e-04,
        8.8002e-03, 8.6010e-03, 9.7903e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,818][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0402, 0.0186, 0.0057, 0.0076, 0.0090, 0.0087, 0.0087, 0.0213, 0.0147,
        0.0493, 0.0252, 0.0554, 0.1184, 0.1115, 0.5056], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,819][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([9.2316e-03, 1.7495e-04, 5.0153e-05, 4.1974e-04, 1.4835e-03, 4.0196e-05,
        2.9485e-05, 3.3140e-05, 2.2233e-05, 5.8795e-06, 3.1432e-06, 1.2208e-04,
        1.6475e-04, 8.3961e-06, 9.8821e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,821][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1192, 0.1115, 0.0129, 0.1167, 0.0293, 0.0144, 0.1217, 0.0122, 0.0124,
        0.1583, 0.0124, 0.1521, 0.0905, 0.0114, 0.0249], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,822][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0252, 0.0033, 0.0057, 0.0046, 0.0086, 0.0122, 0.0041, 0.0241, 0.0314,
        0.0259, 0.0865, 0.0791, 0.1450, 0.3104, 0.2340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,824][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0765, 0.0225, 0.0906, 0.0238, 0.0751, 0.0743, 0.0383, 0.0658, 0.0945,
        0.0662, 0.0985, 0.0303, 0.0425, 0.1565, 0.0447], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,824][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1294, 0.0406, 0.0749, 0.0489, 0.0603, 0.0640, 0.0568, 0.0621, 0.0646,
        0.0564, 0.0700, 0.0543, 0.0704, 0.0923, 0.0550], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,824][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1066, 0.0258, 0.0693, 0.0376, 0.0761, 0.0603, 0.0339, 0.0667, 0.0574,
        0.0360, 0.0605, 0.0369, 0.0619, 0.0809, 0.1903], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,825][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2757, 0.0423, 0.0943, 0.0375, 0.0546, 0.0277, 0.0348, 0.0828, 0.0213,
        0.0340, 0.0665, 0.0321, 0.0520, 0.0653, 0.0793], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:54,825][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.2947, 0.0861, 0.0216, 0.0377, 0.0513, 0.0134, 0.0265, 0.0174, 0.0198,
        0.0692, 0.0244, 0.0482, 0.1562, 0.0151, 0.0789, 0.0397],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,826][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([3.1327e-03, 4.7549e-04, 2.0973e-03, 5.9184e-04, 2.5788e-04, 3.3394e-03,
        7.3815e-05, 6.0153e-04, 1.0979e-02, 2.6630e-05, 7.2914e-04, 3.7764e-04,
        1.1508e-04, 3.1587e-03, 4.1414e-04, 9.7363e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,826][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1681, 0.0220, 0.0802, 0.0322, 0.1087, 0.0244, 0.0251, 0.0661, 0.0253,
        0.0385, 0.0444, 0.0308, 0.1308, 0.0968, 0.0739, 0.0325],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,827][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([8.5056e-04, 8.4260e-06, 1.4901e-05, 2.3821e-05, 5.9045e-05, 1.0275e-04,
        8.3964e-05, 2.5913e-04, 8.7182e-04, 3.7613e-04, 3.2423e-03, 3.7098e-03,
        9.4130e-03, 1.8024e-02, 7.2666e-02, 8.9030e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,828][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0457, 0.0032, 0.0056, 0.0026, 0.0159, 0.0062, 0.0097, 0.0131, 0.0134,
        0.0187, 0.0248, 0.0181, 0.2733, 0.0922, 0.1940, 0.2635],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,829][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([2.6629e-02, 2.0813e-03, 4.1785e-03, 6.7388e-04, 8.1012e-03, 6.5796e-03,
        1.4380e-03, 1.8962e-03, 8.3118e-03, 1.2117e-03, 4.4965e-04, 1.5094e-04,
        1.0281e-03, 1.9165e-03, 5.6431e-04, 9.3479e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,831][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.1121, 0.1224, 0.0057, 0.0883, 0.0422, 0.0055, 0.1756, 0.0061, 0.0037,
        0.0988, 0.0047, 0.1338, 0.1349, 0.0078, 0.0509, 0.0073],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,832][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0258, 0.0021, 0.0041, 0.0026, 0.0060, 0.0067, 0.0039, 0.0162, 0.0188,
        0.0197, 0.0607, 0.0391, 0.0691, 0.1731, 0.2954, 0.2568],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,833][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0304, 0.0034, 0.0840, 0.0078, 0.0327, 0.1295, 0.0237, 0.0401, 0.1794,
        0.0239, 0.1196, 0.0099, 0.0144, 0.1096, 0.0253, 0.1663],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,835][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.1543, 0.0470, 0.0753, 0.0432, 0.0502, 0.0574, 0.0407, 0.0599, 0.0641,
        0.0411, 0.0658, 0.0457, 0.0457, 0.0843, 0.0571, 0.0683],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,836][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1106, 0.0334, 0.0694, 0.0328, 0.0378, 0.0676, 0.0305, 0.0512, 0.0852,
        0.0213, 0.0554, 0.0277, 0.0399, 0.0674, 0.0423, 0.2275],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,838][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.2180, 0.0512, 0.0620, 0.0430, 0.0459, 0.0378, 0.0440, 0.0695, 0.0329,
        0.0391, 0.0736, 0.0401, 0.0581, 0.0651, 0.0685, 0.0514],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:54,839][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2017, 0.0699, 0.0181, 0.0319, 0.0648, 0.0181, 0.0879, 0.0155, 0.0246,
        0.0502, 0.0209, 0.0427, 0.1941, 0.0129, 0.0761, 0.0553, 0.0154],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,840][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8642e-03, 2.3287e-05, 1.7570e-02, 4.1684e-05, 2.1397e-04, 7.1508e-04,
        8.8103e-06, 8.8272e-03, 8.9409e-04, 4.1683e-05, 4.6306e-03, 2.3598e-05,
        1.4758e-05, 4.6290e-01, 4.0144e-04, 6.5269e-04, 5.0017e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,841][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1533, 0.0184, 0.0767, 0.0259, 0.0437, 0.0200, 0.0171, 0.1057, 0.0221,
        0.0250, 0.0484, 0.0250, 0.0549, 0.1351, 0.0567, 0.0275, 0.1445],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,842][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6395e-03, 3.1394e-06, 4.0773e-05, 4.9626e-06, 8.5012e-05, 1.4144e-04,
        1.2911e-04, 2.4134e-04, 9.9453e-04, 3.8112e-04, 2.5220e-03, 2.7207e-04,
        6.2115e-03, 4.7912e-02, 4.0163e-01, 9.8658e-02, 4.3913e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,844][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0134, 0.0005, 0.0012, 0.0008, 0.0147, 0.0025, 0.0074, 0.0045, 0.0035,
        0.0068, 0.0050, 0.0061, 0.4296, 0.0497, 0.2329, 0.0619, 0.1594],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,846][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0268, 0.0005, 0.0610, 0.0037, 0.0355, 0.1536, 0.0012, 0.0153, 0.1246,
        0.0063, 0.0113, 0.0014, 0.0039, 0.2569, 0.0090, 0.0521, 0.2368],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,847][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0710, 0.0412, 0.0036, 0.0319, 0.0332, 0.0030, 0.0533, 0.0137, 0.0024,
        0.0610, 0.0030, 0.0513, 0.1042, 0.2096, 0.0564, 0.0079, 0.2533],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,849][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0208, 0.0037, 0.0032, 0.0036, 0.0042, 0.0045, 0.0052, 0.0079, 0.0126,
        0.0112, 0.0333, 0.0402, 0.0956, 0.0704, 0.1463, 0.2592, 0.2780],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,850][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0118, 0.0020, 0.0689, 0.0036, 0.0118, 0.0912, 0.0079, 0.0334, 0.1436,
        0.0157, 0.1238, 0.0052, 0.0054, 0.1701, 0.0138, 0.0880, 0.2036],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,852][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1184, 0.0314, 0.0704, 0.0407, 0.0425, 0.0572, 0.0409, 0.0585, 0.0613,
        0.0407, 0.0594, 0.0430, 0.0456, 0.0793, 0.0538, 0.0699, 0.0869],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,853][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0888, 0.0256, 0.0787, 0.0314, 0.0499, 0.0696, 0.0401, 0.0659, 0.0656,
        0.0343, 0.0639, 0.0289, 0.0402, 0.0965, 0.0481, 0.0746, 0.0980],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,855][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1611, 0.0501, 0.0725, 0.0439, 0.0578, 0.0461, 0.0359, 0.0704, 0.0341,
        0.0321, 0.0686, 0.0397, 0.0567, 0.0692, 0.0553, 0.0363, 0.0703],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:54,856][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:22:54,858][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14261],
        [   15],
        [35006],
        [ 4849],
        [43208],
        [43753],
        [38377],
        [40256],
        [45279],
        [32074],
        [21911],
        [ 4226],
        [43917],
        [25136],
        [24631],
        [30061],
        [25485]], device='cuda:0')
[2024-07-24 10:22:54,859][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[48273],
        [    1],
        [47461],
        [ 1467],
        [49804],
        [47056],
        [45103],
        [47069],
        [45902],
        [40399],
        [48138],
        [  552],
        [47439],
        [47534],
        [46691],
        [39532],
        [45860]], device='cuda:0')
[2024-07-24 10:22:54,861][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 4893],
        [ 3761],
        [ 3302],
        [ 5540],
        [ 5885],
        [ 3718],
        [13645],
        [ 6338],
        [ 7018],
        [15065],
        [ 5982],
        [ 7780],
        [ 3322],
        [ 3532],
        [ 3891],
        [ 3160],
        [ 4678]], device='cuda:0')
[2024-07-24 10:22:54,862][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20973],
        [20765],
        [31676],
        [17543],
        [42326],
        [46751],
        [20119],
        [35536],
        [48711],
        [ 9219],
        [10973],
        [15388],
        [39603],
        [26459],
        [36152],
        [47749],
        [25875]], device='cuda:0')
[2024-07-24 10:22:54,864][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12098],
        [12352],
        [24379],
        [14961],
        [18391],
        [20098],
        [26105],
        [22949],
        [20750],
        [27360],
        [12879],
        [23931],
        [31257],
        [21036],
        [22194],
        [21214],
        [22343]], device='cuda:0')
[2024-07-24 10:22:54,866][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30694],
        [26077],
        [31585],
        [22257],
        [ 1040],
        [23054],
        [ 7367],
        [41078],
        [33323],
        [ 5807],
        [27094],
        [24127],
        [31408],
        [29732],
        [ 2739],
        [34697],
        [17180]], device='cuda:0')
[2024-07-24 10:22:54,867][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[25801],
        [  553],
        [ 5526],
        [18953],
        [33637],
        [32342],
        [32805],
        [24280],
        [19660],
        [38476],
        [17528],
        [31788],
        [25621],
        [25005],
        [25057],
        [25738],
        [23400]], device='cuda:0')
[2024-07-24 10:22:54,868][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[22979],
        [ 3718],
        [24409],
        [ 9429],
        [35853],
        [18797],
        [27218],
        [25860],
        [22416],
        [45687],
        [22016],
        [10093],
        [34865],
        [20047],
        [37439],
        [27687],
        [19434]], device='cuda:0')
[2024-07-24 10:22:54,870][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45282],
        [23306],
        [ 4601],
        [  961],
        [ 1722],
        [ 1399],
        [ 3366],
        [  809],
        [  727],
        [  230],
        [ 2483],
        [ 1294],
        [ 2714],
        [ 5504],
        [ 4571],
        [ 4545],
        [ 5464]], device='cuda:0')
[2024-07-24 10:22:54,871][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40852],
        [40688],
        [38090],
        [41256],
        [38364],
        [42246],
        [43337],
        [36941],
        [40676],
        [42826],
        [33283],
        [26887],
        [21369],
        [18560],
        [31376],
        [36994],
        [37752]], device='cuda:0')
[2024-07-24 10:22:54,873][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[33222],
        [31467],
        [26029],
        [27157],
        [31440],
        [35345],
        [39091],
        [32698],
        [29686],
        [36597],
        [26570],
        [33223],
        [33952],
        [27919],
        [33307],
        [29410],
        [28105]], device='cuda:0')
[2024-07-24 10:22:54,874][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40649],
        [39342],
        [42734],
        [40450],
        [42557],
        [41173],
        [40217],
        [38184],
        [37214],
        [26671],
        [39001],
        [31854],
        [35709],
        [39706],
        [38790],
        [38382],
        [39384]], device='cuda:0')
[2024-07-24 10:22:54,876][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 6523],
        [31970],
        [ 6312],
        [36365],
        [ 5923],
        [19066],
        [38282],
        [10951],
        [26719],
        [36867],
        [17128],
        [46356],
        [16866],
        [10767],
        [14735],
        [36808],
        [12888]], device='cuda:0')
[2024-07-24 10:22:54,877][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[37601],
        [38885],
        [40121],
        [41797],
        [40497],
        [43278],
        [43984],
        [45125],
        [47197],
        [45359],
        [45695],
        [42020],
        [44894],
        [44157],
        [43757],
        [45314],
        [44819]], device='cuda:0')
[2024-07-24 10:22:54,879][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18741],
        [   12],
        [27102],
        [ 8710],
        [49408],
        [46050],
        [37796],
        [22313],
        [49219],
        [23150],
        [ 9227],
        [ 7202],
        [48396],
        [15220],
        [33462],
        [42194],
        [15509]], device='cuda:0')
[2024-07-24 10:22:54,880][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23687],
        [21868],
        [18741],
        [14933],
        [15993],
        [16505],
        [17542],
        [15824],
        [18657],
        [26321],
        [20761],
        [14831],
        [15937],
        [17048],
        [16611],
        [15174],
        [14881]], device='cuda:0')
[2024-07-24 10:22:54,881][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19901],
        [10061],
        [ 9429],
        [18812],
        [16172],
        [10671],
        [15426],
        [12966],
        [12308],
        [26872],
        [18997],
        [21142],
        [11015],
        [10941],
        [11011],
        [ 8366],
        [ 9989]], device='cuda:0')
[2024-07-24 10:22:54,882][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[39728],
        [39038],
        [37997],
        [33225],
        [37057],
        [36425],
        [35500],
        [33822],
        [32607],
        [32495],
        [19838],
        [29701],
        [34315],
        [26780],
        [31965],
        [33197],
        [25308]], device='cuda:0')
[2024-07-24 10:22:54,883][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8577],
        [ 4574],
        [15076],
        [ 8428],
        [17588],
        [22510],
        [23105],
        [33578],
        [26413],
        [26315],
        [31754],
        [18991],
        [26305],
        [31548],
        [27562],
        [18744],
        [26787]], device='cuda:0')
[2024-07-24 10:22:54,884][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14229],
        [42550],
        [26913],
        [26739],
        [22922],
        [24560],
        [36188],
        [26461],
        [22428],
        [30140],
        [22783],
        [19731],
        [34300],
        [34647],
        [33901],
        [29396],
        [33509]], device='cuda:0')
[2024-07-24 10:22:54,886][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11466],
        [ 7447],
        [17456],
        [10834],
        [ 4675],
        [18305],
        [ 2438],
        [14031],
        [15826],
        [ 1983],
        [15305],
        [10799],
        [ 6443],
        [15965],
        [ 4507],
        [ 5980],
        [15238]], device='cuda:0')
[2024-07-24 10:22:54,887][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47495],
        [42422],
        [26991],
        [11923],
        [12676],
        [13229],
        [39694],
        [39960],
        [41318],
        [16704],
        [36786],
        [19376],
        [18077],
        [47232],
        [21627],
        [29320],
        [47401]], device='cuda:0')
[2024-07-24 10:22:54,889][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26556],
        [26245],
        [18519],
        [15591],
        [11791],
        [ 9862],
        [11845],
        [ 9851],
        [11499],
        [11159],
        [ 8972],
        [12193],
        [15002],
        [15255],
        [12901],
        [15088],
        [17754]], device='cuda:0')
[2024-07-24 10:22:54,890][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44394],
        [45721],
        [30138],
        [44616],
        [40268],
        [22268],
        [37724],
        [25809],
        [19018],
        [36232],
        [14452],
        [39756],
        [31596],
        [17929],
        [30016],
        [25248],
        [21254]], device='cuda:0')
[2024-07-24 10:22:54,892][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[7168],
        [6461],
        [4695],
        [4429],
        [5597],
        [6100],
        [6115],
        [5828],
        [6365],
        [6586],
        [5259],
        [5403],
        [5239],
        [5326],
        [5348],
        [5373],
        [5398]], device='cuda:0')
[2024-07-24 10:22:54,893][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44277],
        [42132],
        [46699],
        [41248],
        [46448],
        [44720],
        [42261],
        [46253],
        [45004],
        [42652],
        [46056],
        [39117],
        [45449],
        [45785],
        [46875],
        [44956],
        [45998]], device='cuda:0')
[2024-07-24 10:22:54,895][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[31844],
        [37481],
        [37408],
        [44356],
        [41970],
        [40506],
        [39342],
        [37551],
        [30038],
        [31818],
        [34381],
        [33661],
        [35308],
        [34245],
        [35855],
        [30733],
        [30828]], device='cuda:0')
[2024-07-24 10:22:54,896][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6857],
        [10068],
        [14069],
        [16211],
        [14392],
        [18817],
        [13747],
        [14045],
        [15975],
        [14898],
        [15846],
        [18149],
        [16015],
        [15491],
        [15442],
        [18264],
        [15796]], device='cuda:0')
[2024-07-24 10:22:54,898][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26662],
        [50220],
        [20942],
        [38903],
        [  907],
        [ 3699],
        [11911],
        [26136],
        [  928],
        [25182],
        [38190],
        [40644],
        [ 1567],
        [32370],
        [14860],
        [ 7216],
        [31967]], device='cuda:0')
[2024-07-24 10:22:54,899][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472],
        [39472]], device='cuda:0')
[2024-07-24 10:22:54,926][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:54,926][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,926][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,927][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,927][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,927][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,928][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,928][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,928][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,929][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,929][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,929][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,930][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:54,930][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.0391, 0.9609], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,930][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.8709, 0.1291], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,931][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.9030, 0.0970], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,932][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.4929, 0.5071], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,933][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.7764, 0.2236], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,935][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.4727, 0.5273], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,936][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,937][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0466, 0.9534], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,938][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.8438, 0.1562], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,940][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([1.0000e+00, 1.3057e-08], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,940][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([2.0378e-04, 9.9980e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,941][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([3.4444e-04, 9.9966e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:54,943][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0131, 0.9782, 0.0087], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,943][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.2987e-01, 7.6975e-01, 3.8249e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,945][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6306, 0.0891, 0.2803], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,946][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3981, 0.4669, 0.1350], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,948][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5736, 0.2508, 0.1755], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,949][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4998, 0.0364, 0.4638], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,950][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.9866e-01, 6.9060e-04, 6.5393e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,951][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0408, 0.9249, 0.0343], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,952][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8493, 0.1316, 0.0191], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,952][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9961e-01, 1.6234e-07, 3.9190e-04], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,953][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([4.5003e-04, 5.0430e-01, 4.9525e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,953][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.9575e-03, 1.8235e-07, 9.9804e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:54,953][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0480, 0.5659, 0.0495, 0.3366], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,954][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.6121, 0.2849, 0.0813, 0.0217], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,954][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.4734, 0.0939, 0.2945, 0.1382], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,954][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.3275, 0.2873, 0.1293, 0.2560], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,955][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.4566, 0.1449, 0.2112, 0.1873], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,955][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0170, 0.9246, 0.0105, 0.0480], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,956][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ William] are: tensor([9.9591e-01, 1.4191e-03, 9.6263e-04, 1.7115e-03], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,957][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0267, 0.7155, 0.0419, 0.2159], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,958][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.8051, 0.1147, 0.0176, 0.0626], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,959][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ William] are: tensor([9.9987e-01, 1.0905e-08, 1.0079e-04, 2.4757e-05], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,960][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ William] are: tensor([3.9273e-04, 3.3135e-01, 4.7020e-01, 1.9806e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,961][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ William] are: tensor([4.4350e-02, 9.0223e-05, 7.2183e-01, 2.3373e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:54,962][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0338, 0.3783, 0.0226, 0.4370, 0.1283], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,963][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.4403, 0.4177, 0.0080, 0.1243, 0.0097], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,965][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.4192, 0.0883, 0.2117, 0.1337, 0.1471], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,966][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.2684, 0.2053, 0.0859, 0.2010, 0.2395], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,968][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.3550, 0.1263, 0.1670, 0.1542, 0.1974], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,969][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.3820, 0.2428, 0.1372, 0.0406, 0.1974], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,970][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.9850, 0.0048, 0.0042, 0.0035, 0.0025], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,972][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0035, 0.4571, 0.0108, 0.0886, 0.4400], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,973][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.7508, 0.0969, 0.0106, 0.0560, 0.0856], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,974][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ got] are: tensor([9.9993e-01, 1.1121e-08, 1.0051e-05, 5.8751e-05, 2.2048e-07],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,975][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0005, 0.2295, 0.3091, 0.1629, 0.2979], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,976][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ got] are: tensor([3.2770e-03, 5.6391e-07, 9.1198e-01, 3.4736e-07, 8.4741e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:54,977][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0106, 0.3206, 0.0141, 0.3184, 0.2779, 0.0582], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,978][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.1110e-01, 1.1552e-01, 4.3398e-03, 5.5909e-02, 1.2850e-02, 2.8129e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,980][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3599, 0.0691, 0.1871, 0.1116, 0.1157, 0.1566], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,981][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2177, 0.1874, 0.0659, 0.1987, 0.2045, 0.1257], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,983][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2560, 0.0988, 0.1217, 0.1290, 0.1830, 0.2115], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,984][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3304, 0.1697, 0.0422, 0.0572, 0.3218, 0.0788], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,985][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9528, 0.0146, 0.0135, 0.0078, 0.0056, 0.0058], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,987][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0103, 0.5154, 0.0091, 0.0928, 0.3497, 0.0227], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,988][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6331, 0.1495, 0.0184, 0.0703, 0.1190, 0.0097], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,989][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.6810e-01, 3.5182e-07, 1.0789e-04, 3.5838e-04, 4.0419e-06, 3.1427e-02],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,991][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0006, 0.1849, 0.2160, 0.1347, 0.2265, 0.2373], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,992][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.9012e-05, 1.3708e-07, 5.7233e-03, 6.6661e-08, 2.4094e-07, 9.9420e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:54,993][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0005, 0.3419, 0.0045, 0.4059, 0.0217, 0.1457, 0.0798],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,995][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.5724, 0.2766, 0.0184, 0.0918, 0.0279, 0.0123, 0.0006],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,996][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.3370, 0.0612, 0.1839, 0.0974, 0.1136, 0.1170, 0.0898],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,997][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.1907, 0.1833, 0.0712, 0.1548, 0.1944, 0.1012, 0.1045],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:54,999][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.1983, 0.0851, 0.1149, 0.1107, 0.1503, 0.1497, 0.1909],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,000][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0671, 0.0112, 0.0168, 0.0216, 0.3867, 0.0663, 0.4302],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,002][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.5971, 0.0580, 0.0557, 0.0380, 0.0282, 0.0221, 0.2009],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,003][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0034, 0.5742, 0.0164, 0.1126, 0.2558, 0.0272, 0.0104],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,005][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.6913, 0.0929, 0.0073, 0.0421, 0.1174, 0.0046, 0.0444],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,005][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([9.8399e-01, 3.0149e-07, 4.5317e-04, 1.8733e-04, 3.6612e-06, 1.5355e-02,
        8.9368e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,005][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0004, 0.1491, 0.2261, 0.1017, 0.1859, 0.1635, 0.1734],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,006][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([9.0292e-04, 5.5464e-06, 4.7485e-02, 4.8883e-07, 2.1610e-07, 2.9412e-05,
        9.5158e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,006][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0074, 0.3392, 0.0196, 0.2992, 0.1750, 0.0955, 0.0578, 0.0064],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,007][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.2527, 0.3947, 0.0072, 0.2438, 0.0712, 0.0115, 0.0185, 0.0005],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,007][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2821, 0.0661, 0.1395, 0.0929, 0.0999, 0.1111, 0.0873, 0.1210],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,007][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1803, 0.1513, 0.0553, 0.1435, 0.1782, 0.0883, 0.0984, 0.1047],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,008][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1699, 0.0715, 0.0812, 0.0918, 0.1221, 0.1270, 0.1542, 0.1823],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,008][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([2.3427e-03, 3.5956e-04, 2.7376e-04, 1.1036e-04, 9.9584e-04, 4.1032e-03,
        4.2368e-03, 9.8758e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,010][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.6672, 0.0327, 0.0270, 0.0095, 0.0124, 0.0142, 0.1760, 0.0610],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,011][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0103, 0.4566, 0.0084, 0.1224, 0.2368, 0.0255, 0.1209, 0.0192],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,012][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.5814, 0.1051, 0.0133, 0.0455, 0.0958, 0.0068, 0.0662, 0.0859],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,013][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([8.4578e-01, 1.7926e-06, 4.8210e-04, 1.3547e-03, 7.1920e-06, 1.5227e-01,
        2.9516e-05, 6.8538e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,015][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0006, 0.1274, 0.1395, 0.0872, 0.1532, 0.1313, 0.1630, 0.1979],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,016][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([3.3680e-04, 1.1603e-07, 6.7539e-03, 2.4647e-07, 3.9136e-08, 9.8805e-08,
        1.1264e-06, 9.9291e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,017][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0183, 0.1462, 0.0149, 0.3498, 0.1310, 0.1711, 0.0198, 0.1218, 0.0271],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,018][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([6.0478e-01, 2.6740e-01, 1.2691e-02, 6.5548e-02, 3.2352e-02, 3.9328e-03,
        4.3908e-03, 8.4055e-03, 4.9841e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,019][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2218, 0.0586, 0.1194, 0.0893, 0.0916, 0.1059, 0.0839, 0.0961, 0.1334],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,021][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1530, 0.1472, 0.0478, 0.1521, 0.1636, 0.0884, 0.0941, 0.0895, 0.0642],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,022][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1333, 0.0658, 0.0696, 0.0761, 0.1000, 0.1153, 0.1307, 0.1433, 0.1658],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,024][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1412, 0.1675, 0.0132, 0.0367, 0.0933, 0.0571, 0.0585, 0.3997, 0.0328],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,025][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2837, 0.0680, 0.0787, 0.0313, 0.0250, 0.0189, 0.2128, 0.1340, 0.1474],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,027][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0060, 0.4374, 0.0044, 0.0496, 0.2710, 0.0188, 0.1775, 0.0178, 0.0176],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,028][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4625, 0.1224, 0.0166, 0.0524, 0.1487, 0.0077, 0.0668, 0.1145, 0.0084],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,029][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.3660e-01, 7.7060e-07, 2.6630e-04, 4.2778e-04, 6.7358e-06, 5.6102e-02,
        1.2847e-05, 8.4284e-05, 6.4998e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,030][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0007, 0.0947, 0.1133, 0.0736, 0.1218, 0.1249, 0.1345, 0.1615, 0.1751],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,031][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.7131e-03, 1.6024e-05, 1.3813e-01, 5.6715e-06, 6.3780e-07, 1.7139e-03,
        6.4554e-04, 1.1459e-05, 8.5777e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,032][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ house] are: tensor([3.2481e-04, 1.0041e-01, 1.5983e-03, 1.0572e-01, 1.2408e-01, 9.2995e-02,
        3.3928e-01, 1.5890e-01, 5.1315e-02, 2.5381e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,033][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ house] are: tensor([4.7225e-01, 3.8309e-01, 4.0361e-03, 8.3913e-02, 3.5538e-02, 6.8643e-03,
        3.1251e-03, 5.2484e-03, 5.7529e-03, 1.8082e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,035][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.2373, 0.0528, 0.1363, 0.0726, 0.0857, 0.0842, 0.0728, 0.0813, 0.0888,
        0.0882], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,036][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.1473, 0.1454, 0.0510, 0.1309, 0.1591, 0.0758, 0.0846, 0.0917, 0.0499,
        0.0644], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,037][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.1832, 0.0613, 0.0687, 0.0724, 0.0849, 0.0986, 0.0956, 0.1271, 0.1227,
        0.0855], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,039][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0262, 0.0390, 0.0168, 0.0042, 0.0193, 0.0798, 0.0647, 0.5858, 0.1011,
        0.0632], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,040][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.2121, 0.0524, 0.0423, 0.0185, 0.0155, 0.0155, 0.1766, 0.0701, 0.1202,
        0.2767], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,042][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0019, 0.2372, 0.0095, 0.1028, 0.2087, 0.0273, 0.3622, 0.0188, 0.0235,
        0.0081], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,043][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.5036, 0.0911, 0.0058, 0.0369, 0.1726, 0.0042, 0.0432, 0.0644, 0.0040,
        0.0741], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,044][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ house] are: tensor([9.5214e-01, 1.0961e-06, 6.4986e-04, 4.0668e-04, 1.5008e-05, 3.4644e-02,
        8.6842e-05, 1.1348e-04, 2.1858e-03, 9.7567e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,046][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0004, 0.0901, 0.1063, 0.0720, 0.1085, 0.1047, 0.1290, 0.1524, 0.1329,
        0.1037], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,047][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ house] are: tensor([2.7609e-05, 1.6230e-06, 2.0333e-02, 5.3364e-07, 5.4200e-08, 2.6665e-06,
        1.5857e-05, 4.5961e-05, 1.0156e-07, 9.7957e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,048][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0310, 0.2244, 0.0078, 0.3025, 0.0356, 0.1032, 0.0287, 0.1415, 0.0497,
        0.0698, 0.0059], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,049][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.7333e-01, 4.9068e-01, 3.1276e-03, 1.0092e-01, 2.4560e-02, 1.1778e-03,
        2.9792e-03, 1.6563e-03, 8.4551e-04, 5.4195e-04, 1.8250e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,050][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1667, 0.0465, 0.0836, 0.0711, 0.0839, 0.0706, 0.0627, 0.0803, 0.0832,
        0.0896, 0.1618], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,052][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1366, 0.1250, 0.0436, 0.1223, 0.1534, 0.0749, 0.0812, 0.0870, 0.0504,
        0.0713, 0.0543], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,053][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1078, 0.0595, 0.0623, 0.0663, 0.0884, 0.0746, 0.0998, 0.1024, 0.1051,
        0.0900, 0.1438], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,055][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0635, 0.0481, 0.0040, 0.0086, 0.0333, 0.0295, 0.0173, 0.0561, 0.0410,
        0.0167, 0.6819], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,056][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2310, 0.0139, 0.0179, 0.0116, 0.0077, 0.0069, 0.1243, 0.0397, 0.0609,
        0.1598, 0.3263], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,058][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0101, 0.3106, 0.0146, 0.0641, 0.1954, 0.0289, 0.2009, 0.0420, 0.0310,
        0.0819, 0.0204], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,058][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4470, 0.1242, 0.0076, 0.0448, 0.0953, 0.0070, 0.0914, 0.0488, 0.0066,
        0.1182, 0.0091], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,058][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.6621e-01, 5.9585e-08, 2.0987e-04, 1.0049e-04, 4.7664e-07, 2.9312e-02,
        3.3266e-06, 1.6833e-04, 8.0092e-04, 2.9929e-03, 2.0010e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,059][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0006, 0.0741, 0.0870, 0.0563, 0.1013, 0.0835, 0.1044, 0.1265, 0.1168,
        0.0842, 0.1653], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,059][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([3.4191e-02, 3.6199e-04, 7.9757e-01, 4.1105e-05, 6.7727e-06, 1.8947e-04,
        1.2524e-03, 5.4118e-03, 7.9795e-04, 2.6471e-05, 1.6015e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,060][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0148, 0.1580, 0.0184, 0.0990, 0.0643, 0.1393, 0.0436, 0.0852, 0.0612,
        0.1478, 0.0532, 0.1151], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,060][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.5962, 0.2295, 0.0308, 0.0179, 0.0550, 0.0069, 0.0152, 0.0161, 0.0101,
        0.0034, 0.0144, 0.0045], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,061][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.1398, 0.0439, 0.1080, 0.0571, 0.0806, 0.0743, 0.0612, 0.0694, 0.0744,
        0.0812, 0.1489, 0.0611], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,061][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.1263, 0.0999, 0.0455, 0.0929, 0.1517, 0.0701, 0.0786, 0.0796, 0.0504,
        0.0640, 0.0565, 0.0845], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,063][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.1033, 0.0399, 0.0723, 0.0480, 0.0684, 0.0936, 0.0628, 0.1170, 0.1119,
        0.0566, 0.1726, 0.0535], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,064][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ William] are: tensor([1.0128e-03, 7.8462e-01, 1.1033e-03, 2.4892e-02, 5.3562e-04, 4.8111e-03,
        6.0251e-04, 4.4206e-03, 2.5382e-03, 2.6155e-04, 4.4500e-02, 1.3070e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,065][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0919, 0.0144, 0.0147, 0.0121, 0.0079, 0.0053, 0.0770, 0.0330, 0.0337,
        0.2400, 0.2642, 0.2059], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,066][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0070, 0.1876, 0.0122, 0.0549, 0.2137, 0.0333, 0.2340, 0.0310, 0.0297,
        0.1188, 0.0111, 0.0667], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,067][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.4732, 0.0808, 0.0097, 0.0426, 0.1151, 0.0063, 0.0480, 0.1002, 0.0065,
        0.0618, 0.0041, 0.0517], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,068][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ William] are: tensor([9.4486e-01, 4.3468e-08, 3.3329e-04, 5.0546e-05, 1.5402e-06, 4.9836e-02,
        7.9223e-06, 3.6487e-05, 1.5371e-03, 3.0707e-03, 2.1484e-04, 4.9334e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,070][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0005, 0.0609, 0.0897, 0.0506, 0.0992, 0.0843, 0.0980, 0.1284, 0.1120,
        0.0742, 0.1497, 0.0526], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,071][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ William] are: tensor([1.6465e-02, 5.0698e-05, 2.4748e-01, 1.7326e-01, 4.1956e-07, 9.8906e-06,
        8.5674e-05, 1.6254e-04, 2.3569e-05, 2.2205e-06, 4.4187e-01, 1.2060e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,072][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0348, 0.0176, 0.0138, 0.0815, 0.4646, 0.1363, 0.0174, 0.0653, 0.0230,
        0.0108, 0.0179, 0.1009, 0.0161], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,074][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.5810, 0.2470, 0.0123, 0.1128, 0.0170, 0.0033, 0.0027, 0.0010, 0.0019,
        0.0011, 0.0037, 0.0144, 0.0018], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,075][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1449, 0.0390, 0.0803, 0.0577, 0.0640, 0.0597, 0.0473, 0.0672, 0.0656,
        0.0817, 0.1422, 0.0643, 0.0862], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,077][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.1211, 0.1004, 0.0393, 0.0979, 0.1274, 0.0632, 0.0705, 0.0726, 0.0446,
        0.0541, 0.0492, 0.0860, 0.0736], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,078][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1176, 0.0485, 0.0593, 0.0570, 0.0691, 0.0698, 0.0600, 0.0891, 0.0927,
        0.0584, 0.1502, 0.0693, 0.0591], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,079][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0712, 0.0417, 0.0025, 0.0314, 0.4339, 0.0652, 0.1749, 0.1176, 0.0164,
        0.0038, 0.0176, 0.0180, 0.0057], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,081][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.3250, 0.0071, 0.0063, 0.0037, 0.0029, 0.0025, 0.0386, 0.0132, 0.0322,
        0.0776, 0.2335, 0.2433, 0.0141], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,083][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0038, 0.2582, 0.0046, 0.0954, 0.2783, 0.0049, 0.0469, 0.0214, 0.0077,
        0.0655, 0.0050, 0.1380, 0.0703], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,084][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2732, 0.0656, 0.0021, 0.0285, 0.0918, 0.0028, 0.0447, 0.0397, 0.0025,
        0.0765, 0.0018, 0.0390, 0.3317], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,085][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([8.8357e-01, 7.5027e-06, 1.3028e-03, 1.8108e-03, 1.5076e-05, 6.2568e-02,
        2.3865e-04, 3.2594e-04, 2.4281e-02, 2.3087e-02, 1.1068e-03, 1.6734e-03,
        1.1487e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,086][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0003, 0.0623, 0.0768, 0.0518, 0.0921, 0.0663, 0.0978, 0.1146, 0.1013,
        0.0702, 0.1375, 0.0562, 0.0727], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,087][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([6.0054e-04, 4.4707e-06, 3.2585e-02, 3.6829e-06, 5.5774e-06, 4.1410e-06,
        1.1881e-05, 1.9341e-06, 5.0901e-06, 1.2018e-08, 2.9102e-02, 2.0976e-06,
        9.3767e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,088][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.4103e-03, 3.4139e-03, 2.7003e-04, 2.3452e-02, 9.4549e-02, 8.4357e-03,
        9.0613e-04, 9.0645e-03, 2.9720e-03, 6.0559e-03, 1.6749e-03, 3.1624e-02,
        8.1615e-01, 1.7968e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,089][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.6097e-01, 4.7514e-01, 3.7978e-03, 9.8502e-02, 2.5470e-02, 2.5881e-03,
        4.6689e-03, 1.8498e-03, 1.8143e-03, 9.1069e-04, 8.6434e-04, 1.1000e-02,
        1.2391e-02, 3.6302e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,091][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1127, 0.0400, 0.0572, 0.0509, 0.0608, 0.0577, 0.0502, 0.0627, 0.0661,
        0.0664, 0.1230, 0.0659, 0.0912, 0.0952], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,092][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1147, 0.0946, 0.0329, 0.0941, 0.1294, 0.0588, 0.0653, 0.0709, 0.0400,
        0.0549, 0.0436, 0.0843, 0.0703, 0.0462], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,094][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0858, 0.0448, 0.0473, 0.0501, 0.0648, 0.0658, 0.0767, 0.0813, 0.0835,
        0.0537, 0.1131, 0.0556, 0.0655, 0.1120], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,095][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.8738e-03, 4.6211e-02, 2.3594e-04, 1.1635e-02, 3.7373e-03, 3.4356e-03,
        1.0246e-02, 3.3655e-03, 3.3986e-03, 5.2168e-04, 8.0263e-04, 6.0768e-03,
        3.6677e-04, 9.0709e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,096][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1089, 0.0149, 0.0199, 0.0066, 0.0048, 0.0050, 0.0530, 0.0251, 0.0449,
        0.1650, 0.3338, 0.1795, 0.0205, 0.0181], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,098][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0094, 0.1555, 0.0096, 0.0430, 0.1329, 0.0127, 0.0943, 0.0152, 0.0103,
        0.0526, 0.0185, 0.0526, 0.3851, 0.0083], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,099][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3469, 0.0882, 0.0071, 0.0341, 0.0963, 0.0049, 0.0483, 0.0389, 0.0047,
        0.0761, 0.0077, 0.0395, 0.1866, 0.0207], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,100][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.6087e-01, 4.9879e-08, 7.9366e-05, 1.6825e-04, 9.0477e-07, 2.2913e-02,
        3.0242e-06, 2.8316e-04, 2.1378e-03, 9.7665e-04, 6.0956e-05, 1.4433e-04,
        5.0157e-07, 1.2360e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,102][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0008, 0.0492, 0.0646, 0.0437, 0.0788, 0.0719, 0.0816, 0.1024, 0.0918,
        0.0552, 0.1251, 0.0433, 0.0716, 0.1201], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,103][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.2160e-05, 3.9669e-09, 4.2593e-03, 1.9025e-09, 3.6785e-09, 6.1467e-07,
        4.0329e-09, 6.7146e-06, 3.5542e-08, 7.9301e-11, 8.0751e-04, 1.0394e-09,
        1.4727e-09, 9.9490e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,104][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0008, 0.0198, 0.0007, 0.0446, 0.0432, 0.0081, 0.0037, 0.0105, 0.0016,
        0.0065, 0.0054, 0.0499, 0.6423, 0.1431, 0.0197], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,105][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([3.0615e-01, 5.2905e-01, 2.9444e-03, 1.0678e-01, 1.5342e-02, 2.8510e-03,
        2.5109e-03, 1.6390e-03, 4.2990e-03, 7.5441e-04, 8.2385e-04, 1.1120e-02,
        1.4909e-02, 2.2500e-04, 5.9768e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,107][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1160, 0.0379, 0.0780, 0.0451, 0.0538, 0.0490, 0.0438, 0.0575, 0.0549,
        0.0587, 0.1297, 0.0504, 0.0851, 0.0800, 0.0601], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,108][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1209, 0.0832, 0.0346, 0.0824, 0.1156, 0.0559, 0.0611, 0.0689, 0.0390,
        0.0488, 0.0457, 0.0739, 0.0645, 0.0445, 0.0611], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,110][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0981, 0.0359, 0.0611, 0.0426, 0.0523, 0.0625, 0.0555, 0.0832, 0.0766,
        0.0460, 0.1212, 0.0455, 0.0615, 0.0998, 0.0581], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,110][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0549, 0.0031, 0.0098, 0.0158, 0.1227, 0.1208, 0.0939, 0.0695, 0.0789,
        0.0636, 0.1108, 0.0171, 0.0460, 0.0530, 0.1399], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,111][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1197, 0.0198, 0.0231, 0.0056, 0.0062, 0.0074, 0.0656, 0.0237, 0.0592,
        0.1030, 0.2691, 0.2230, 0.0193, 0.0280, 0.0274], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,111][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0013, 0.1555, 0.0027, 0.0352, 0.1581, 0.0023, 0.0375, 0.0088, 0.0038,
        0.0766, 0.0024, 0.0500, 0.4428, 0.0023, 0.0207], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,112][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.2628, 0.0604, 0.0028, 0.0288, 0.0747, 0.0029, 0.0385, 0.0325, 0.0028,
        0.0640, 0.0021, 0.0362, 0.2174, 0.0107, 0.1633], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,112][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([8.4261e-01, 1.5003e-07, 1.7624e-04, 2.7998e-04, 1.1694e-06, 1.0475e-01,
        9.5731e-06, 2.5490e-04, 2.5622e-02, 2.2234e-03, 1.7567e-04, 2.6882e-04,
        1.7096e-06, 2.3609e-02, 1.5973e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,113][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0004, 0.0420, 0.0614, 0.0393, 0.0792, 0.0616, 0.0806, 0.1000, 0.0860,
        0.0582, 0.1142, 0.0409, 0.0667, 0.1073, 0.0623], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,113][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([5.2083e-07, 3.3718e-11, 4.9000e-05, 6.3541e-10, 1.3623e-07, 7.7097e-09,
        4.2259e-09, 1.6304e-09, 2.2584e-10, 2.3615e-10, 5.9077e-05, 3.4078e-10,
        3.9691e-09, 1.3537e-05, 9.9988e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,114][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ it] are: tensor([6.7228e-03, 1.4094e-02, 9.8547e-04, 2.5456e-02, 5.1931e-02, 1.4209e-02,
        1.2211e-03, 5.5286e-04, 1.9621e-03, 4.7341e-03, 2.1118e-03, 3.0430e-02,
        1.3384e-01, 2.7079e-03, 7.0859e-01, 4.4965e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,115][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ it] are: tensor([5.2879e-01, 2.8378e-01, 1.2807e-02, 4.3464e-02, 5.2211e-02, 7.3849e-03,
        1.0025e-02, 5.1941e-03, 2.4693e-03, 1.2647e-03, 3.4618e-03, 8.9383e-03,
        2.9730e-02, 9.7181e-04, 9.3367e-03, 1.7750e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,116][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1085, 0.0342, 0.0612, 0.0471, 0.0486, 0.0512, 0.0416, 0.0545, 0.0624,
        0.0628, 0.1147, 0.0530, 0.0758, 0.0619, 0.0619, 0.0606],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,118][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.1074, 0.0839, 0.0315, 0.0857, 0.1058, 0.0543, 0.0568, 0.0599, 0.0386,
        0.0478, 0.0420, 0.0779, 0.0633, 0.0392, 0.0566, 0.0492],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,119][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0804, 0.0389, 0.0457, 0.0479, 0.0443, 0.0623, 0.0548, 0.0781, 0.0771,
        0.0420, 0.1080, 0.0566, 0.0501, 0.0924, 0.0557, 0.0655],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,120][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0055, 0.2622, 0.0014, 0.0058, 0.0012, 0.0139, 0.0014, 0.0030, 0.0202,
        0.0022, 0.0292, 0.0011, 0.0009, 0.0039, 0.0077, 0.6405],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,122][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0767, 0.0206, 0.0281, 0.0067, 0.0063, 0.0059, 0.0585, 0.0266, 0.0385,
        0.1470, 0.2479, 0.1512, 0.0222, 0.0224, 0.0296, 0.1117],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,123][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0018, 0.3334, 0.0037, 0.0529, 0.0822, 0.0089, 0.1888, 0.0095, 0.0092,
        0.0391, 0.0048, 0.0692, 0.1593, 0.0019, 0.0198, 0.0155],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,125][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.1683, 0.0493, 0.0031, 0.0213, 0.0912, 0.0023, 0.0245, 0.0285, 0.0023,
        0.0479, 0.0025, 0.0284, 0.2822, 0.0114, 0.2080, 0.0288],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,126][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ it] are: tensor([9.3193e-01, 3.5286e-07, 9.8954e-05, 3.6332e-04, 4.1356e-06, 4.5160e-02,
        6.7723e-06, 1.4815e-04, 5.5740e-03, 3.5150e-03, 1.0870e-04, 3.6235e-04,
        3.3129e-06, 1.2699e-02, 1.0668e-05, 1.6624e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,127][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0008, 0.0395, 0.0506, 0.0374, 0.0633, 0.0654, 0.0784, 0.0849, 0.0870,
        0.0544, 0.1128, 0.0402, 0.0593, 0.0977, 0.0599, 0.0685],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,128][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ it] are: tensor([5.7040e-06, 1.5146e-08, 1.3870e-03, 1.5297e-08, 7.8447e-09, 3.0020e-07,
        3.9406e-06, 8.9374e-09, 2.5892e-05, 3.8239e-10, 5.6919e-04, 9.3446e-09,
        3.4978e-09, 9.3749e-06, 2.6968e-08, 9.9800e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,129][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9209e-04, 2.1986e-03, 1.8679e-04, 1.6011e-02, 6.9948e-02, 5.8483e-03,
        6.1533e-04, 5.9707e-03, 2.0779e-03, 4.3611e-03, 1.1639e-03, 2.1587e-02,
        5.8370e-01, 1.2050e-05, 2.6650e-01, 1.8815e-02, 1.0119e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,130][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.1692e-01, 5.0899e-01, 4.3679e-03, 1.0114e-01, 2.7786e-02, 2.7497e-03,
        4.0837e-03, 2.0552e-03, 1.9582e-03, 9.1404e-04, 7.7525e-04, 1.1591e-02,
        1.3729e-02, 3.3302e-05, 2.2002e-03, 6.6838e-04, 3.1606e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,132][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0890, 0.0335, 0.0474, 0.0425, 0.0508, 0.0465, 0.0422, 0.0515, 0.0528,
        0.0550, 0.0985, 0.0541, 0.0755, 0.0750, 0.0631, 0.0527, 0.0699],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,133][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1008, 0.0798, 0.0286, 0.0780, 0.1106, 0.0501, 0.0556, 0.0608, 0.0343,
        0.0471, 0.0379, 0.0701, 0.0598, 0.0400, 0.0559, 0.0433, 0.0472],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,135][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0769, 0.0359, 0.0416, 0.0406, 0.0505, 0.0554, 0.0612, 0.0670, 0.0671,
        0.0412, 0.0865, 0.0429, 0.0487, 0.0872, 0.0583, 0.0553, 0.0838],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,136][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.3258e-04, 2.5802e-02, 5.1389e-05, 4.2641e-03, 1.0168e-03, 1.7182e-03,
        4.7245e-03, 1.6572e-03, 1.4778e-03, 2.3152e-04, 3.1623e-04, 2.5504e-03,
        6.0412e-05, 3.7718e-01, 2.5248e-04, 6.2987e-04, 5.7733e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,137][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0746, 0.0244, 0.0284, 0.0070, 0.0064, 0.0059, 0.0605, 0.0242, 0.0396,
        0.0984, 0.2321, 0.1297, 0.0199, 0.0198, 0.0267, 0.1053, 0.0970],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,139][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0088, 0.1454, 0.0091, 0.0405, 0.1218, 0.0115, 0.0886, 0.0145, 0.0092,
        0.0504, 0.0173, 0.0497, 0.3497, 0.0079, 0.0511, 0.0171, 0.0074],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,140][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2821, 0.0711, 0.0060, 0.0271, 0.0844, 0.0038, 0.0369, 0.0309, 0.0038,
        0.0600, 0.0065, 0.0311, 0.1595, 0.0170, 0.1270, 0.0334, 0.0192],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,141][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.5408e-01, 3.3828e-08, 7.2259e-05, 1.3209e-04, 6.0457e-07, 1.9580e-02,
        2.4150e-06, 2.4580e-04, 1.5626e-03, 8.5607e-04, 5.7059e-05, 1.1343e-04,
        3.4328e-07, 1.2326e-02, 3.4989e-06, 1.3006e-06, 1.0964e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,143][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0010, 0.0354, 0.0497, 0.0334, 0.0618, 0.0583, 0.0678, 0.0858, 0.0762,
        0.0438, 0.1037, 0.0330, 0.0571, 0.1006, 0.0554, 0.0600, 0.0769],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,144][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.2911e-06, 1.6440e-09, 1.9370e-03, 8.3079e-10, 1.6060e-09, 2.4576e-07,
        1.6229e-09, 2.9544e-06, 1.4950e-08, 3.3871e-11, 3.7152e-04, 4.5567e-10,
        6.7067e-10, 4.8560e-01, 4.2594e-09, 4.2480e-10, 5.1208e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,159][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:55,159][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,160][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,161][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,161][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,162][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,163][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,163][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,165][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,166][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,168][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,168][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,169][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,170][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.4998, 0.5002], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,170][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.7444, 0.2556], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,171][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.8674, 0.1326], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,172][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.6818, 0.3182], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,173][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.1963, 0.8037], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,173][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.9637, 0.0363], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,174][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.3658, 0.6342], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,175][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.3515, 0.6485], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,176][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,177][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([2.6603e-04, 9.9973e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,179][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.1674, 0.8326], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,180][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.6802, 0.3198], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,182][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3333, 0.3336, 0.3331], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,184][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2056, 0.7832, 0.0111], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,185][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5458, 0.1172, 0.3370], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,186][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4884, 0.2549, 0.2567], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,187][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1316, 0.5413, 0.3271], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,188][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5246, 0.0393, 0.4361], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,188][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3594, 0.6195, 0.0211], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,190][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2551, 0.4634, 0.2814], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,191][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([2.0887e-01, 1.2117e-04, 7.9101e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,192][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1649e-04, 9.9303e-01, 6.8536e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,193][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1020, 0.5322, 0.3658], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,195][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1189, 0.0013, 0.8798], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,196][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.2501, 0.2503, 0.2499, 0.2497], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,198][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.1713, 0.2653, 0.5456, 0.0177], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,200][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.4198, 0.1102, 0.3233, 0.1467], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,201][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.4328, 0.1765, 0.2214, 0.1694], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,203][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0794, 0.3667, 0.2376, 0.3163], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,205][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.6040, 0.0201, 0.3530, 0.0230], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,206][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.3852, 0.4420, 0.0686, 0.1042], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,208][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.1419, 0.3599, 0.1854, 0.3127], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,209][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.1835, 0.0037, 0.7961, 0.0167], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,210][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([9.1098e-04, 9.4593e-01, 2.7816e-02, 2.5345e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,212][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0766, 0.3560, 0.2553, 0.3120], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,214][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.2069, 0.0023, 0.7567, 0.0341], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,215][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.2001, 0.2003, 0.1999, 0.1998, 0.1999], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,217][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.2188, 0.4131, 0.1611, 0.1607, 0.0463], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,219][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.3567, 0.1043, 0.2301, 0.1458, 0.1632], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,220][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.3726, 0.1327, 0.1615, 0.1333, 0.1999], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,222][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0646, 0.2796, 0.1779, 0.2408, 0.2370], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,224][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.4079, 0.0216, 0.3065, 0.0287, 0.2353], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,225][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.5265, 0.2354, 0.0750, 0.0788, 0.0843], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,227][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0819, 0.2176, 0.1122, 0.1859, 0.4024], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,228][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([2.2687e-01, 7.2360e-04, 7.6333e-01, 6.9690e-03, 2.1060e-03],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,230][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0009, 0.4575, 0.0037, 0.0275, 0.5104], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,231][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0542, 0.2673, 0.1886, 0.2358, 0.2540], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,233][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([1.5083e-01, 7.6792e-04, 8.2409e-01, 1.7045e-03, 2.2605e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,234][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1667, 0.1669, 0.1666, 0.1665, 0.1666, 0.1667], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,236][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6223, 0.1598, 0.0468, 0.1240, 0.0441, 0.0029], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,237][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3086, 0.0821, 0.2071, 0.1166, 0.1226, 0.1629], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,238][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2851, 0.1297, 0.1296, 0.1334, 0.1700, 0.1521], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,239][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0594, 0.2192, 0.1490, 0.2024, 0.2054, 0.1646], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,240][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1911, 0.0171, 0.1842, 0.0241, 0.1496, 0.4339], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,240][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2621, 0.1380, 0.0167, 0.2229, 0.2519, 0.1084], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,242][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1032, 0.1655, 0.0938, 0.1489, 0.2623, 0.2263], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,243][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.0620e-02, 5.8660e-06, 4.1704e-02, 7.2742e-05, 3.0008e-05, 9.4757e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,244][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.7215e-04, 4.6205e-01, 2.8129e-03, 2.0414e-02, 5.1195e-01, 2.4964e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,246][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0452, 0.2276, 0.1589, 0.2005, 0.2176, 0.1502], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,247][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0823, 0.0010, 0.3832, 0.0020, 0.0025, 0.5290], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,249][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.1429, 0.1431, 0.1428, 0.1427, 0.1428, 0.1430, 0.1426],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,250][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.2160, 0.3175, 0.1594, 0.1452, 0.0827, 0.0777, 0.0015],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,252][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.3070, 0.0689, 0.2045, 0.0991, 0.1163, 0.1207, 0.0834],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,254][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.2742, 0.1080, 0.1352, 0.0931, 0.1562, 0.1196, 0.1138],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,255][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0449, 0.1849, 0.1242, 0.1612, 0.1632, 0.1285, 0.1931],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,257][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.2800, 0.0083, 0.1588, 0.0099, 0.1076, 0.4110, 0.0244],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,259][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.2714, 0.1233, 0.0604, 0.1081, 0.0431, 0.2406, 0.1532],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,260][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0456, 0.1635, 0.0778, 0.1422, 0.2666, 0.1743, 0.1299],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,262][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([6.1232e-03, 8.7153e-05, 5.4201e-02, 4.7028e-04, 1.4692e-04, 9.1380e-01,
        2.5176e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,263][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([2.1329e-05, 7.0537e-01, 3.1466e-03, 5.7981e-03, 2.7895e-01, 1.3258e-04,
        6.5763e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,264][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0376, 0.1895, 0.1355, 0.1632, 0.1818, 0.1225, 0.1699],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,266][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.2162, 0.0014, 0.6516, 0.0017, 0.0016, 0.0542, 0.0734],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,268][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1250, 0.1252, 0.1250, 0.1249, 0.1250, 0.1251, 0.1248, 0.1251],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,269][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2238, 0.2613, 0.0553, 0.2812, 0.1199, 0.0354, 0.0223, 0.0008],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,271][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2450, 0.0768, 0.1521, 0.0953, 0.1043, 0.1130, 0.0822, 0.1313],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,273][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.2305, 0.0988, 0.1052, 0.0924, 0.1408, 0.1031, 0.1108, 0.1183],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,275][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0418, 0.1622, 0.1030, 0.1481, 0.1439, 0.1118, 0.1721, 0.1170],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,276][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1417, 0.0109, 0.1207, 0.0154, 0.1023, 0.3026, 0.0362, 0.2703],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,278][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5745, 0.0131, 0.0299, 0.0452, 0.1227, 0.1522, 0.0392, 0.0232],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,280][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0626, 0.1203, 0.0653, 0.1136, 0.1828, 0.1579, 0.2089, 0.0886],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,281][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([3.7321e-03, 2.7099e-05, 1.3554e-02, 1.3183e-04, 7.4957e-05, 9.6736e-01,
        1.5112e-02, 1.1430e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,282][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.1733e-05, 4.3107e-01, 2.4625e-03, 1.7758e-02, 2.5812e-01, 2.5518e-03,
        6.6265e-03, 2.8134e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,284][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0337, 0.1652, 0.1150, 0.1460, 0.1577, 0.1063, 0.1563, 0.1199],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,285][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1452, 0.0012, 0.4365, 0.0035, 0.0024, 0.0309, 0.0185, 0.3618],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,287][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1112, 0.1113, 0.1111, 0.1110, 0.1111, 0.1112, 0.1109, 0.1112, 0.1111],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,289][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.4381, 0.2088, 0.1056, 0.1189, 0.0734, 0.0267, 0.0067, 0.0189, 0.0028],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,290][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2024, 0.0660, 0.1300, 0.0866, 0.0930, 0.1079, 0.0765, 0.1002, 0.1375],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,291][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1966, 0.0917, 0.0923, 0.0922, 0.1209, 0.1017, 0.1021, 0.0974, 0.1051],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,292][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0372, 0.1424, 0.0908, 0.1311, 0.1303, 0.0996, 0.1572, 0.1024, 0.1090],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,293][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0937, 0.0083, 0.0876, 0.0118, 0.0754, 0.2233, 0.0269, 0.1932, 0.2799],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,293][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3335, 0.1196, 0.0134, 0.1866, 0.0897, 0.0483, 0.0140, 0.0347, 0.1602],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,295][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0528, 0.1066, 0.0523, 0.0878, 0.1589, 0.1392, 0.1966, 0.0774, 0.1284],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,296][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.3639e-03, 1.8458e-06, 7.7586e-03, 1.3740e-05, 8.1194e-06, 2.8348e-01,
        1.5855e-03, 2.0951e-06, 7.0579e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,297][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([5.1027e-05, 4.1908e-01, 1.7890e-03, 9.5930e-03, 2.7468e-01, 8.7913e-04,
        3.7923e-03, 2.8000e-01, 1.0141e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,299][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0305, 0.1488, 0.1030, 0.1314, 0.1415, 0.0976, 0.1409, 0.1057, 0.1007],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,301][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1032, 0.0017, 0.4900, 0.0030, 0.0021, 0.0909, 0.0252, 0.0249, 0.2592],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,302][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.1000, 0.1001, 0.1000, 0.0999, 0.1000, 0.1001, 0.0998, 0.1001, 0.1000,
        0.1000], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,304][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.1681, 0.4195, 0.0497, 0.1626, 0.0999, 0.0462, 0.0109, 0.0174, 0.0245,
        0.0011], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,306][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.2089, 0.0564, 0.1434, 0.0729, 0.0874, 0.0866, 0.0674, 0.0935, 0.0976,
        0.0859], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,307][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.1926, 0.0770, 0.0965, 0.0720, 0.1168, 0.0854, 0.0905, 0.0955, 0.0793,
        0.0944], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,309][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0292, 0.1260, 0.0822, 0.1120, 0.1089, 0.0875, 0.1316, 0.0916, 0.0957,
        0.1353], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,311][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.1270, 0.0045, 0.0839, 0.0060, 0.0624, 0.2294, 0.0157, 0.1975, 0.2579,
        0.0157], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,312][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.1551, 0.0303, 0.1714, 0.0318, 0.0589, 0.1648, 0.0037, 0.0210, 0.2456,
        0.1173], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,314][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0291, 0.0937, 0.0446, 0.0918, 0.1812, 0.1212, 0.2031, 0.0676, 0.1126,
        0.0551], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,315][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([5.0366e-04, 5.2155e-06, 9.0646e-03, 3.6540e-05, 2.1272e-05, 2.4594e-01,
        3.7476e-03, 8.8547e-06, 7.4057e-01, 1.0499e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,317][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([2.2392e-05, 6.1372e-01, 2.5227e-03, 5.4124e-03, 2.6365e-01, 2.1083e-04,
        1.0341e-02, 1.0201e-01, 2.0704e-03, 4.1113e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,318][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0274, 0.1329, 0.0930, 0.1160, 0.1228, 0.0862, 0.1216, 0.0951, 0.0874,
        0.1176], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,320][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.1196, 0.0012, 0.7184, 0.0024, 0.0017, 0.0431, 0.0166, 0.0502, 0.0353,
        0.0116], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,322][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0909, 0.0910, 0.0909, 0.0908, 0.0909, 0.0910, 0.0908, 0.0910, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,323][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2250, 0.3292, 0.0774, 0.2116, 0.1007, 0.0154, 0.0107, 0.0080, 0.0105,
        0.0068, 0.0048], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,325][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1582, 0.0519, 0.0953, 0.0698, 0.0854, 0.0733, 0.0558, 0.0830, 0.0864,
        0.0801, 0.1608], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,327][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1706, 0.0731, 0.0800, 0.0698, 0.1039, 0.0810, 0.0779, 0.0877, 0.0744,
        0.0923, 0.0892], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,328][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0304, 0.1126, 0.0728, 0.1038, 0.1049, 0.0779, 0.1217, 0.0813, 0.0841,
        0.1256, 0.0847], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,330][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0716, 0.0068, 0.0637, 0.0091, 0.0538, 0.1561, 0.0190, 0.1336, 0.1930,
        0.0193, 0.2741], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,332][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1827, 0.2755, 0.0055, 0.0981, 0.0798, 0.0698, 0.0060, 0.0403, 0.1879,
        0.0274, 0.0270], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,333][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0418, 0.0785, 0.0486, 0.0735, 0.1094, 0.1153, 0.1681, 0.0671, 0.1148,
        0.0779, 0.1052], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,335][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.9597e-04, 2.0433e-06, 3.1943e-03, 1.0252e-05, 5.2251e-06, 3.1156e-01,
        4.3504e-03, 1.8926e-06, 6.3780e-01, 8.3402e-05, 4.1988e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,336][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.0194e-04, 1.5111e-01, 2.9205e-03, 9.5837e-03, 8.6525e-02, 9.0419e-04,
        3.3888e-03, 7.3193e-01, 6.3799e-03, 1.7229e-05, 7.1399e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,338][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0241, 0.1204, 0.0846, 0.1053, 0.1179, 0.0785, 0.1135, 0.0885, 0.0803,
        0.1116, 0.0754], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,339][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0524, 0.0010, 0.1874, 0.0017, 0.0012, 0.0227, 0.0120, 0.0238, 0.0354,
        0.0014, 0.6608], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,341][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0834, 0.0835, 0.0833, 0.0833, 0.0833, 0.0834, 0.0832, 0.0834, 0.0833,
        0.0834, 0.0834, 0.0831], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,343][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.1680, 0.1819, 0.2126, 0.0169, 0.1208, 0.0343, 0.0299, 0.0684, 0.0393,
        0.0206, 0.0967, 0.0106], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,344][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.1379, 0.0453, 0.1156, 0.0557, 0.0783, 0.0745, 0.0552, 0.0718, 0.0794,
        0.0749, 0.1522, 0.0594], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,345][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.1569, 0.0575, 0.0756, 0.0576, 0.1142, 0.0759, 0.0817, 0.0803, 0.0723,
        0.0828, 0.0899, 0.0553], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,345][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0231, 0.1050, 0.0691, 0.0912, 0.0915, 0.0720, 0.1064, 0.0746, 0.0783,
        0.1082, 0.0812, 0.0995], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,347][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.1114, 0.0039, 0.0664, 0.0046, 0.0446, 0.1686, 0.0098, 0.1329, 0.1815,
        0.0101, 0.2594, 0.0069], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,348][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.2163, 0.3039, 0.0442, 0.0622, 0.0047, 0.0400, 0.0162, 0.0251, 0.1507,
        0.0135, 0.0502, 0.0729], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,350][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0314, 0.0709, 0.0391, 0.0634, 0.1278, 0.1063, 0.1514, 0.0613, 0.1007,
        0.0761, 0.0812, 0.0905], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,351][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([1.3209e-03, 2.7653e-05, 8.5947e-03, 1.0239e-04, 7.6158e-05, 2.4595e-01,
        1.5343e-02, 3.8554e-05, 6.6366e-01, 7.8091e-04, 6.4085e-02, 1.8548e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,352][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([1.3018e-04, 2.5007e-01, 7.3375e-03, 6.3368e-03, 3.4506e-01, 1.7471e-03,
        7.2475e-03, 3.5130e-01, 1.0651e-02, 4.0868e-05, 1.5766e-02, 4.3211e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,354][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0243, 0.1085, 0.0784, 0.0963, 0.1052, 0.0731, 0.1009, 0.0786, 0.0740,
        0.0988, 0.0700, 0.0918], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,355][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([3.4568e-02, 3.2928e-04, 1.1251e-01, 4.7213e-03, 2.9581e-04, 7.3228e-03,
        3.2803e-03, 6.7518e-03, 1.0399e-02, 2.5960e-04, 8.1236e-01, 7.2059e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,357][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0770, 0.0770, 0.0769, 0.0769, 0.0769, 0.0770, 0.0768, 0.0770, 0.0769,
        0.0770, 0.0770, 0.0767, 0.0769], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,358][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.2580, 0.1844, 0.1582, 0.1673, 0.0763, 0.0291, 0.0093, 0.0042, 0.0115,
        0.0093, 0.0469, 0.0416, 0.0037], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,360][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1358, 0.0416, 0.0872, 0.0579, 0.0647, 0.0603, 0.0422, 0.0720, 0.0687,
        0.0758, 0.1434, 0.0625, 0.0880], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,362][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1529, 0.0566, 0.0681, 0.0562, 0.0929, 0.0707, 0.0717, 0.0740, 0.0692,
        0.0706, 0.0824, 0.0538, 0.0807], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,364][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0226, 0.0978, 0.0617, 0.0843, 0.0834, 0.0638, 0.0983, 0.0686, 0.0707,
        0.1038, 0.0733, 0.0916, 0.0802], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,365][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0961, 0.0037, 0.0617, 0.0046, 0.0451, 0.1628, 0.0109, 0.1391, 0.1835,
        0.0109, 0.2563, 0.0068, 0.0184], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,366][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([2.5647e-02, 4.0057e-02, 5.9797e-03, 1.8214e-02, 5.4410e-03, 3.4246e-03,
        5.0708e-04, 1.7506e-03, 9.4825e-03, 3.6488e-03, 3.0590e-03, 2.3872e-02,
        8.5892e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,368][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0274, 0.0701, 0.0331, 0.0676, 0.1354, 0.0732, 0.1173, 0.0550, 0.0802,
        0.0731, 0.0710, 0.0969, 0.0997], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,370][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([5.8863e-04, 8.0960e-06, 6.7688e-03, 3.3246e-05, 3.6379e-05, 1.9988e-01,
        8.2299e-03, 5.3706e-06, 7.1045e-01, 2.7754e-04, 7.3710e-02, 3.9715e-06,
        4.2047e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,371][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([2.3674e-05, 4.5182e-01, 1.6957e-03, 5.8833e-03, 1.1331e-01, 2.6414e-04,
        5.9654e-03, 1.2170e-01, 4.9572e-03, 1.9978e-05, 4.7969e-03, 4.4129e-03,
        2.8515e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,373][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0197, 0.1020, 0.0713, 0.0891, 0.0959, 0.0648, 0.0922, 0.0732, 0.0674,
        0.0913, 0.0621, 0.0852, 0.0858], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,374][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([3.1921e-02, 2.7249e-04, 1.3169e-01, 7.0116e-04, 8.0891e-04, 9.9431e-03,
        3.9775e-03, 5.3512e-03, 1.2238e-02, 1.7504e-04, 7.9637e-01, 1.1908e-03,
        5.3512e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,376][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0715, 0.0715, 0.0714, 0.0714, 0.0714, 0.0715, 0.0713, 0.0715, 0.0714,
        0.0715, 0.0715, 0.0713, 0.0714, 0.0714], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,377][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.2380e-01, 2.6817e-01, 5.1516e-02, 1.9934e-01, 7.1367e-02, 1.6244e-02,
        8.7553e-03, 3.8042e-03, 7.5500e-03, 3.3863e-03, 1.1604e-02, 2.3475e-02,
        1.0854e-02, 1.3778e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,379][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1188, 0.0432, 0.0684, 0.0499, 0.0602, 0.0605, 0.0454, 0.0636, 0.0711,
        0.0600, 0.1274, 0.0577, 0.0842, 0.0896], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,381][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1383, 0.0556, 0.0584, 0.0551, 0.0888, 0.0641, 0.0640, 0.0731, 0.0615,
        0.0738, 0.0746, 0.0540, 0.0765, 0.0622], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,382][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0242, 0.0854, 0.0556, 0.0785, 0.0797, 0.0624, 0.0948, 0.0632, 0.0667,
        0.0959, 0.0666, 0.0854, 0.0776, 0.0639], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,384][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0391, 0.0044, 0.0387, 0.0063, 0.0371, 0.0994, 0.0156, 0.0897, 0.1253,
        0.0145, 0.1682, 0.0098, 0.0216, 0.3302], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,385][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.8153e-01, 5.8585e-04, 2.2377e-03, 4.5329e-03, 4.3466e-02, 3.1779e-02,
        8.8896e-04, 3.2493e-03, 3.2391e-02, 4.1054e-04, 2.3243e-03, 5.8548e-03,
        6.8750e-01, 3.2467e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,387][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0375, 0.0561, 0.0361, 0.0560, 0.0869, 0.0880, 0.1212, 0.0479, 0.0836,
        0.0587, 0.0814, 0.0741, 0.1028, 0.0695], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,388][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.9176e-04, 2.2166e-06, 2.2689e-03, 1.6119e-05, 9.3977e-06, 2.7414e-01,
        4.5829e-03, 3.0834e-06, 6.7639e-01, 8.7844e-05, 4.1593e-02, 1.6566e-06,
        1.3730e-06, 1.1756e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,390][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.4678e-05, 1.0737e-01, 1.4917e-03, 7.3347e-03, 1.0542e-01, 9.3620e-04,
        2.8328e-03, 5.6907e-01, 6.3117e-03, 1.3377e-05, 4.1301e-03, 5.4346e-03,
        1.8912e-01, 4.4033e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,391][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0188, 0.0937, 0.0652, 0.0832, 0.0899, 0.0613, 0.0878, 0.0692, 0.0625,
        0.0860, 0.0591, 0.0805, 0.0829, 0.0598], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,392][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.4617e-02, 2.0353e-04, 1.0949e-01, 4.4995e-04, 4.6108e-04, 1.4953e-02,
        2.0476e-03, 1.1672e-02, 1.1080e-02, 2.1667e-04, 4.2421e-01, 7.2516e-04,
        3.5639e-04, 3.9952e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,394][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0667, 0.0668, 0.0667, 0.0666, 0.0667, 0.0667, 0.0666, 0.0667, 0.0667,
        0.0667, 0.0667, 0.0665, 0.0666, 0.0667, 0.0668], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,396][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1650, 0.3959, 0.0541, 0.1675, 0.0759, 0.0255, 0.0080, 0.0072, 0.0230,
        0.0052, 0.0120, 0.0285, 0.0279, 0.0017, 0.0024], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,397][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1113, 0.0379, 0.0832, 0.0440, 0.0521, 0.0490, 0.0385, 0.0613, 0.0581,
        0.0544, 0.1326, 0.0489, 0.0847, 0.0797, 0.0643], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,398][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1414, 0.0459, 0.0587, 0.0469, 0.0811, 0.0582, 0.0601, 0.0674, 0.0574,
        0.0644, 0.0747, 0.0459, 0.0699, 0.0571, 0.0710], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,398][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0201, 0.0811, 0.0526, 0.0709, 0.0723, 0.0556, 0.0827, 0.0596, 0.0607,
        0.0881, 0.0632, 0.0768, 0.0750, 0.0586, 0.0827], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,400][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0498, 0.0032, 0.0381, 0.0041, 0.0312, 0.0928, 0.0097, 0.0852, 0.1103,
        0.0093, 0.1552, 0.0060, 0.0148, 0.3054, 0.0848], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,402][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0878, 0.0076, 0.0561, 0.0312, 0.0722, 0.0134, 0.0008, 0.0374, 0.0218,
        0.0080, 0.0105, 0.0454, 0.1012, 0.0268, 0.4797], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,403][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0269, 0.0580, 0.0314, 0.0551, 0.1142, 0.0660, 0.1083, 0.0447, 0.0678,
        0.0612, 0.0581, 0.0763, 0.1239, 0.0539, 0.0542], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,405][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([5.4382e-04, 1.2173e-06, 4.3085e-03, 1.2331e-05, 1.2342e-05, 1.6996e-01,
        3.2751e-03, 6.8235e-06, 7.6236e-01, 5.7372e-05, 5.9217e-02, 1.5993e-06,
        1.7808e-06, 2.4251e-04, 1.1293e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,406][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.0513e-04, 1.4967e-01, 1.8144e-03, 7.3159e-03, 9.6046e-02, 1.4062e-03,
        3.1041e-03, 3.3493e-01, 1.6111e-02, 1.5265e-05, 4.6620e-03, 5.3725e-03,
        2.8739e-01, 3.9153e-04, 9.1664e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,408][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0178, 0.0860, 0.0608, 0.0775, 0.0854, 0.0567, 0.0805, 0.0634, 0.0580,
        0.0802, 0.0548, 0.0746, 0.0771, 0.0547, 0.0723], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,409][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([2.9309e-02, 1.3232e-04, 1.1937e-01, 5.6561e-04, 1.3829e-03, 9.7604e-03,
        3.1205e-03, 3.9697e-03, 7.2483e-03, 2.8635e-04, 5.9776e-01, 8.2427e-04,
        5.4444e-04, 1.6565e-01, 6.0076e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,411][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0625, 0.0626, 0.0625, 0.0624, 0.0625, 0.0625, 0.0624, 0.0626, 0.0625,
        0.0625, 0.0625, 0.0623, 0.0625, 0.0625, 0.0627, 0.0625],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,412][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.2434, 0.1575, 0.1907, 0.0460, 0.1233, 0.0583, 0.0164, 0.0163, 0.0139,
        0.0062, 0.0453, 0.0157, 0.0342, 0.0074, 0.0244, 0.0011],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,414][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1074, 0.0341, 0.0653, 0.0441, 0.0467, 0.0517, 0.0372, 0.0565, 0.0678,
        0.0574, 0.1194, 0.0496, 0.0720, 0.0648, 0.0621, 0.0638],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,416][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.1236, 0.0486, 0.0534, 0.0505, 0.0738, 0.0578, 0.0571, 0.0580, 0.0570,
        0.0619, 0.0674, 0.0493, 0.0675, 0.0482, 0.0640, 0.0619],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,418][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0195, 0.0765, 0.0488, 0.0696, 0.0687, 0.0531, 0.0800, 0.0549, 0.0580,
        0.0830, 0.0590, 0.0758, 0.0689, 0.0530, 0.0774, 0.0538],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,419][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0405, 0.0033, 0.0359, 0.0046, 0.0291, 0.0855, 0.0105, 0.0770, 0.1066,
        0.0103, 0.1443, 0.0067, 0.0144, 0.2640, 0.0712, 0.0961],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,421][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.2655, 0.0603, 0.0081, 0.0107, 0.0189, 0.0127, 0.0023, 0.0116, 0.0755,
        0.0588, 0.0057, 0.0156, 0.3266, 0.0045, 0.0714, 0.0518],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,423][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0276, 0.0580, 0.0299, 0.0541, 0.0810, 0.0795, 0.1263, 0.0420, 0.0774,
        0.0470, 0.0652, 0.0747, 0.0870, 0.0510, 0.0496, 0.0496],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,424][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([4.4536e-04, 2.3470e-06, 2.7743e-03, 1.2569e-05, 1.0504e-05, 2.2255e-01,
        5.7484e-03, 8.6835e-06, 6.9338e-01, 1.0755e-04, 7.4352e-02, 1.8265e-06,
        1.9717e-06, 3.5586e-04, 7.2335e-07, 2.4261e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,426][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([7.1263e-05, 1.7580e-01, 1.1573e-03, 7.5581e-03, 1.2140e-01, 6.7484e-04,
        2.1874e-03, 2.7934e-01, 6.5873e-03, 1.1634e-05, 3.3693e-03, 5.7451e-03,
        3.0283e-01, 2.8246e-04, 5.8938e-02, 3.4051e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,427][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0185, 0.0808, 0.0570, 0.0728, 0.0771, 0.0540, 0.0771, 0.0588, 0.0554,
        0.0749, 0.0517, 0.0703, 0.0713, 0.0512, 0.0674, 0.0617],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,429][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([2.7102e-02, 2.6842e-04, 1.3271e-01, 6.0188e-04, 5.3196e-04, 1.1862e-02,
        5.3143e-03, 3.9523e-03, 2.8181e-02, 2.3939e-04, 5.6373e-01, 1.0203e-03,
        3.7022e-04, 1.0267e-01, 2.1337e-03, 1.1932e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,430][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0588, 0.0589, 0.0588, 0.0588, 0.0588, 0.0589, 0.0587, 0.0589, 0.0588,
        0.0588, 0.0588, 0.0587, 0.0588, 0.0588, 0.0590, 0.0588, 0.0589],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,432][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.4540e-01, 2.9334e-01, 6.6732e-02, 1.8631e-01, 8.5682e-02, 2.0976e-02,
        8.7328e-03, 5.6847e-03, 1.0979e-02, 4.9912e-03, 1.3207e-02, 2.9829e-02,
        1.7116e-02, 2.2883e-04, 6.1065e-03, 4.3628e-03, 3.2362e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,433][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0978, 0.0355, 0.0565, 0.0412, 0.0494, 0.0493, 0.0379, 0.0519, 0.0578,
        0.0497, 0.1038, 0.0475, 0.0697, 0.0729, 0.0578, 0.0514, 0.0700],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,435][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1156, 0.0459, 0.0483, 0.0456, 0.0738, 0.0530, 0.0530, 0.0607, 0.0510,
        0.0613, 0.0622, 0.0447, 0.0636, 0.0518, 0.0641, 0.0548, 0.0506],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,437][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0203, 0.0704, 0.0458, 0.0649, 0.0659, 0.0517, 0.0782, 0.0521, 0.0552,
        0.0792, 0.0549, 0.0705, 0.0640, 0.0527, 0.0754, 0.0505, 0.0484],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,439][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0229, 0.0030, 0.0227, 0.0042, 0.0230, 0.0589, 0.0107, 0.0549, 0.0773,
        0.0097, 0.1008, 0.0066, 0.0139, 0.1908, 0.0499, 0.0707, 0.2800],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,440][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([7.1395e-02, 1.9532e-04, 8.5920e-04, 1.5676e-03, 1.5593e-02, 1.1766e-02,
        3.1367e-04, 1.1444e-03, 1.2058e-02, 1.2997e-04, 8.6086e-04, 2.0162e-03,
        2.4751e-01, 1.1991e-03, 5.9886e-01, 3.3392e-02, 1.1390e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,442][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0343, 0.0444, 0.0307, 0.0463, 0.0696, 0.0762, 0.1015, 0.0406, 0.0740,
        0.0481, 0.0711, 0.0614, 0.0830, 0.0625, 0.0499, 0.0478, 0.0584],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,443][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.4745e-04, 2.3527e-06, 2.2382e-03, 1.8904e-05, 7.3460e-06, 2.4306e-01,
        6.5049e-03, 4.4561e-06, 7.1329e-01, 1.2432e-04, 3.2943e-02, 2.1774e-06,
        1.3584e-06, 1.9615e-04, 2.8421e-07, 5.3641e-04, 3.1797e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,444][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.1121e-04, 6.9262e-02, 1.2724e-03, 6.4271e-03, 7.9672e-02, 1.0196e-03,
        2.1861e-03, 5.9988e-01, 6.1532e-03, 1.0479e-05, 3.5886e-03, 4.7457e-03,
        1.5045e-01, 4.3498e-04, 6.3399e-02, 1.0986e-02, 3.9428e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,446][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0160, 0.0774, 0.0540, 0.0691, 0.0743, 0.0508, 0.0727, 0.0572, 0.0518,
        0.0711, 0.0490, 0.0668, 0.0686, 0.0496, 0.0652, 0.0588, 0.0476],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,448][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.4800e-02, 1.4289e-04, 7.0017e-02, 3.1153e-04, 3.1638e-04, 1.0158e-02,
        1.2838e-03, 7.8629e-03, 7.8350e-03, 1.5408e-04, 2.7108e-01, 4.9894e-04,
        2.6108e-04, 2.5752e-01, 1.1091e-03, 3.7793e-03, 3.5287e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,451][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:22:55,453][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21508],
        [ 3544],
        [10484],
        [12732],
        [30109],
        [33197],
        [27669],
        [19920],
        [29742],
        [24048],
        [13497],
        [15929],
        [29740],
        [19526],
        [13858],
        [13990],
        [15697]], device='cuda:0')
[2024-07-24 10:22:55,454][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8471],
        [  150],
        [37757],
        [ 5289],
        [44863],
        [41967],
        [36354],
        [38872],
        [41536],
        [26302],
        [27645],
        [ 3750],
        [43757],
        [29911],
        [20169],
        [14541],
        [31639]], device='cuda:0')
[2024-07-24 10:22:55,456][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[33177],
        [47190],
        [47144],
        [46365],
        [42814],
        [37265],
        [43758],
        [41416],
        [40714],
        [43631],
        [44221],
        [38167],
        [17024],
        [19981],
        [21830],
        [ 7012],
        [12192]], device='cuda:0')
[2024-07-24 10:22:55,458][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43170],
        [40542],
        [ 7253],
        [33735],
        [22326],
        [40226],
        [32650],
        [17551],
        [33626],
        [25734],
        [17707],
        [35628],
        [32991],
        [17549],
        [13932],
        [31225],
        [15064]], device='cuda:0')
[2024-07-24 10:22:55,460][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[33534],
        [34860],
        [35449],
        [37714],
        [37961],
        [39413],
        [39940],
        [39432],
        [39481],
        [37894],
        [37603],
        [38194],
        [37832],
        [38511],
        [38040],
        [37986],
        [38386]], device='cuda:0')
[2024-07-24 10:22:55,461][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[9046],
        [6512],
        [6259],
        [6980],
        [7376],
        [6596],
        [5411],
        [4943],
        [4801],
        [4510],
        [4637],
        [4793],
        [5031],
        [5293],
        [5276],
        [5282],
        [5548]], device='cuda:0')
[2024-07-24 10:22:55,463][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13288],
        [24836],
        [35318],
        [35945],
        [39407],
        [40582],
        [42352],
        [41958],
        [41241],
        [39969],
        [41276],
        [40799],
        [39585],
        [40160],
        [39841],
        [40050],
        [39950]], device='cuda:0')
[2024-07-24 10:22:55,465][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31072],
        [48250],
        [ 9697],
        [47985],
        [42351],
        [39154],
        [23881],
        [ 6591],
        [32098],
        [13977],
        [22858],
        [48608],
        [24891],
        [26157],
        [18634],
        [48952],
        [23530]], device='cuda:0')
[2024-07-24 10:22:55,467][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13570],
        [13517],
        [13551],
        [13517],
        [13382],
        [13040],
        [13528],
        [14816],
        [16532],
        [17506],
        [19543],
        [18671],
        [17087],
        [19068],
        [18343],
        [18648],
        [18639]], device='cuda:0')
[2024-07-24 10:22:55,469][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38575],
        [   70],
        [   64],
        [   51],
        [ 1760],
        [  862],
        [  348],
        [  737],
        [ 1565],
        [ 6263],
        [ 2658],
        [ 5620],
        [ 1853],
        [11415],
        [13328],
        [ 1657],
        [11663]], device='cuda:0')
[2024-07-24 10:22:55,471][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[8909],
        [9310],
        [9044],
        [9276],
        [8211],
        [7948],
        [8219],
        [8363],
        [7725],
        [7684],
        [9784],
        [8543],
        [6995],
        [7577],
        [7026],
        [6651],
        [7150]], device='cuda:0')
[2024-07-24 10:22:55,472][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[35400],
        [35400],
        [35407],
        [35401],
        [35399],
        [36017],
        [35717],
        [38193],
        [36661],
        [36293],
        [36057],
        [36454],
        [37689],
        [36020],
        [38241],
        [36591],
        [36037]], device='cuda:0')
[2024-07-24 10:22:55,474][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22677],
        [29293],
        [22069],
        [20742],
        [17418],
        [13170],
        [12153],
        [ 7123],
        [ 8812],
        [ 7950],
        [ 9805],
        [10129],
        [ 9969],
        [10109],
        [ 9905],
        [10630],
        [10796]], device='cuda:0')
[2024-07-24 10:22:55,476][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16793],
        [17941],
        [ 2083],
        [ 2620],
        [ 2060],
        [ 5919],
        [ 7887],
        [ 5946],
        [ 8055],
        [20664],
        [ 2155],
        [ 2295],
        [ 5844],
        [ 3375],
        [ 6260],
        [ 4205],
        [ 3451]], device='cuda:0')
[2024-07-24 10:22:55,478][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15608],
        [ 3710],
        [10405],
        [ 7911],
        [25933],
        [17755],
        [28305],
        [26137],
        [20934],
        [22001],
        [ 8607],
        [32283],
        [ 7355],
        [14919],
        [16573],
        [24140],
        [18205]], device='cuda:0')
[2024-07-24 10:22:55,480][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[28912],
        [28914],
        [28919],
        [28910],
        [28925],
        [28926],
        [28938],
        [28933],
        [28926],
        [28925],
        [28928],
        [28924],
        [28935],
        [28936],
        [28938],
        [28941],
        [28941]], device='cuda:0')
[2024-07-24 10:22:55,481][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 6190],
        [ 7055],
        [28184],
        [10914],
        [14294],
        [ 6701],
        [ 9013],
        [10279],
        [ 7469],
        [12619],
        [11480],
        [ 6906],
        [ 8512],
        [10212],
        [13411],
        [ 5980],
        [10705]], device='cuda:0')
[2024-07-24 10:22:55,483][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23759],
        [23268],
        [22164],
        [20596],
        [21752],
        [20008],
        [20438],
        [20678],
        [19968],
        [21403],
        [20057],
        [19514],
        [19217],
        [18544],
        [18386],
        [18619],
        [18234]], device='cuda:0')
[2024-07-24 10:22:55,485][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13672],
        [14386],
        [13827],
        [14455],
        [14539],
        [15034],
        [15852],
        [15838],
        [15943],
        [15969],
        [15430],
        [15546],
        [15538],
        [15429],
        [15529],
        [15502],
        [15355]], device='cuda:0')
[2024-07-24 10:22:55,487][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15572],
        [17974],
        [16523],
        [18422],
        [17473],
        [17441],
        [17849],
        [17824],
        [18114],
        [18272],
        [18302],
        [18761],
        [18900],
        [18800],
        [18315],
        [18128],
        [18071]], device='cuda:0')
[2024-07-24 10:22:55,489][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5144],
        [ 5186],
        [ 8422],
        [ 7721],
        [10360],
        [12819],
        [11787],
        [15071],
        [16017],
        [15466],
        [16741],
        [15894],
        [16235],
        [18221],
        [18081],
        [18291],
        [19886]], device='cuda:0')
[2024-07-24 10:22:55,491][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10586],
        [ 5691],
        [ 4414],
        [ 1103],
        [ 1757],
        [ 1343],
        [ 5331],
        [ 7102],
        [ 1817],
        [ 6539],
        [  775],
        [  815],
        [25391],
        [17994],
        [ 5140],
        [ 5725],
        [15257]], device='cuda:0')
[2024-07-24 10:22:55,492][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18225],
        [31705],
        [28078],
        [31650],
        [24563],
        [23533],
        [20950],
        [19255],
        [16656],
        [16629],
        [15457],
        [16711],
        [16790],
        [14769],
        [15439],
        [14721],
        [13726]], device='cuda:0')
[2024-07-24 10:22:55,494][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27139],
        [27129],
        [38059],
        [38211],
        [38034],
        [39446],
        [39605],
        [39378],
        [33469],
        [33133],
        [34151],
        [33862],
        [33377],
        [33778],
        [32938],
        [33558],
        [33359]], device='cuda:0')
[2024-07-24 10:22:55,496][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24416],
        [23023],
        [23386],
        [24820],
        [32075],
        [31875],
        [29369],
        [41153],
        [41007],
        [34045],
        [45841],
        [43575],
        [42700],
        [46469],
        [46487],
        [46500],
        [46184]], device='cuda:0')
[2024-07-24 10:22:55,498][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17252],
        [15879],
        [15297],
        [15374],
        [15722],
        [15761],
        [15975],
        [16141],
        [15936],
        [16406],
        [16271],
        [16161],
        [16448],
        [16310],
        [16369],
        [16287],
        [16166]], device='cuda:0')
[2024-07-24 10:22:55,500][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18866],
        [14516],
        [16235],
        [15991],
        [16156],
        [14658],
        [15506],
        [15826],
        [15362],
        [15555],
        [16271],
        [16631],
        [16665],
        [16588],
        [16212],
        [15526],
        [16929]], device='cuda:0')
[2024-07-24 10:22:55,501][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35784],
        [39081],
        [34994],
        [40029],
        [38281],
        [39767],
        [37883],
        [34831],
        [38661],
        [35465],
        [40514],
        [41455],
        [32111],
        [32999],
        [37436],
        [38092],
        [34509]], device='cuda:0')
[2024-07-24 10:22:55,503][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27037],
        [48884],
        [33667],
        [42000],
        [14312],
        [27934],
        [17614],
        [18366],
        [24882],
        [23231],
        [37702],
        [14603],
        [35765],
        [30286],
        [24448],
        [20220],
        [24714]], device='cuda:0')
[2024-07-24 10:22:55,505][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560],
        [29560]], device='cuda:0')
[2024-07-24 10:22:55,535][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:55,536][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,537][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,537][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,538][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,539][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,540][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,540][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,541][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,542][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,542][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,543][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,543][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,544][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.5620, 0.4380], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,545][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,546][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,546][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.2080, 0.7920], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,547][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0280, 0.9720], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,548][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.0767, 0.9233], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,548][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.3951, 0.6049], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,549][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.1299, 0.8701], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,551][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9744, 0.0256], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,552][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0126, 0.9874], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,554][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.1585, 0.8415], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,555][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7737, 0.2263], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,557][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2815, 0.4329, 0.2856], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,559][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0046, 0.9915, 0.0039], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,560][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([4.5629e-05, 3.2442e-01, 6.7554e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,561][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0771, 0.1946, 0.7283], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,563][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0043, 0.6419, 0.3537], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,565][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0049, 0.1704, 0.8246], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,566][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3455, 0.4121, 0.2424], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,568][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0882, 0.5419, 0.3698], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,569][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6027, 0.3078, 0.0894], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,571][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.8085e-04, 2.6163e-01, 7.3779e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,572][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1297, 0.6227, 0.2475], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,574][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4019, 0.1718, 0.4263], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,575][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.2169, 0.2779, 0.2684, 0.2368], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,577][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0028, 0.5974, 0.0177, 0.3821], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,578][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ William] are: tensor([2.1966e-06, 2.1263e-02, 4.7975e-01, 4.9899e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,580][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0293, 0.0663, 0.3447, 0.5597], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,581][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ William] are: tensor([2.8481e-04, 1.0378e-01, 2.3166e-01, 6.6428e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,581][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ William] are: tensor([4.7276e-04, 3.4523e-02, 6.3971e-01, 3.2530e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,582][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.1843, 0.3513, 0.1810, 0.2834], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,583][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0513, 0.3242, 0.2206, 0.4040], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,584][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.6764, 0.0983, 0.1746, 0.0508], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,585][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ William] are: tensor([9.4200e-05, 4.9750e-02, 7.0823e-01, 2.4192e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,587][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0384, 0.4966, 0.1529, 0.3120], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,588][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.2531, 0.1681, 0.3175, 0.2612], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,590][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.1296, 0.2451, 0.2186, 0.2634, 0.1434], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,591][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ got] are: tensor([3.5357e-04, 4.9408e-01, 3.3605e-03, 1.4266e-02, 4.8794e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,592][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ got] are: tensor([8.3683e-07, 1.1052e-03, 5.8504e-02, 2.5224e-01, 6.8815e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,593][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0189, 0.0459, 0.1903, 0.3164, 0.4285], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,595][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ got] are: tensor([2.1456e-04, 1.1361e-02, 1.0385e-01, 1.6811e-01, 7.1647e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,596][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ got] are: tensor([1.4366e-04, 1.2088e-02, 1.7285e-01, 2.4357e-01, 5.7135e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,597][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.1332, 0.1956, 0.1020, 0.1817, 0.3875], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,599][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0304, 0.2658, 0.1667, 0.3427, 0.1944], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,600][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.4468, 0.1072, 0.1840, 0.1811, 0.0808], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,602][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ got] are: tensor([1.4436e-05, 1.3521e-02, 1.0461e-01, 2.9815e-01, 5.8370e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,603][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0317, 0.3079, 0.1096, 0.1973, 0.3534], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,605][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.2994, 0.0810, 0.3327, 0.1348, 0.1521], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,606][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1339, 0.1668, 0.1948, 0.2287, 0.1500, 0.1256], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,608][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0020, 0.5243, 0.0126, 0.2787, 0.1800, 0.0025], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,609][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.1575e-07, 1.3344e-04, 8.0282e-03, 2.1548e-02, 6.2609e-01, 3.4420e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,611][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0124, 0.0287, 0.1338, 0.2045, 0.3307, 0.2900], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,612][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([5.8397e-05, 8.3544e-03, 1.9000e-02, 5.8211e-02, 7.3189e-01, 1.8249e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,613][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.1373e-04, 5.1292e-03, 5.4302e-02, 8.0464e-02, 3.6529e-01, 4.9470e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,615][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1224, 0.1659, 0.1065, 0.1631, 0.3315, 0.1105], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,616][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0261, 0.2351, 0.1479, 0.3023, 0.1928, 0.0958], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,618][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2780, 0.2117, 0.1318, 0.0643, 0.2921, 0.0220], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,619][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.7758e-06, 2.9565e-03, 2.2174e-02, 6.1999e-02, 4.8758e-01, 4.2528e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,621][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0478, 0.2579, 0.1108, 0.1631, 0.2805, 0.1399], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,623][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1136, 0.0295, 0.3490, 0.0737, 0.1370, 0.2972], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,624][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.1000, 0.1468, 0.1538, 0.1761, 0.1634, 0.1141, 0.1458],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,625][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([4.0339e-04, 5.2918e-01, 2.6756e-03, 3.1685e-02, 4.2051e-01, 9.8456e-04,
        1.4561e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,626][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([2.5750e-08, 2.2877e-05, 3.2943e-04, 2.2246e-03, 2.1012e-02, 1.7275e-01,
        8.0366e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,628][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0046, 0.0102, 0.0615, 0.0926, 0.1665, 0.1395, 0.5250],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,629][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([4.0042e-05, 7.1624e-03, 8.0602e-03, 1.9334e-02, 8.8004e-02, 1.8956e-01,
        6.8784e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,630][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([3.6798e-05, 1.1586e-03, 1.2286e-02, 1.0346e-02, 2.0723e-01, 4.6338e-01,
        3.0557e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,632][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0911, 0.1554, 0.0766, 0.1498, 0.2877, 0.0838, 0.1556],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,633][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0271, 0.2175, 0.1393, 0.2747, 0.1777, 0.0921, 0.0715],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,634][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.4869, 0.0865, 0.1050, 0.0364, 0.1856, 0.0447, 0.0550],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,634][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([4.0498e-06, 7.1327e-04, 7.8741e-03, 1.2474e-02, 1.5636e-01, 4.0112e-01,
        4.2145e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,635][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0236, 0.2148, 0.0846, 0.1308, 0.2833, 0.1296, 0.1333],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,636][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0911, 0.0213, 0.2828, 0.0544, 0.1343, 0.3207, 0.0955],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,638][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0733, 0.1517, 0.1156, 0.1481, 0.1135, 0.0980, 0.1360, 0.1638],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,639][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0162, 0.2383, 0.0261, 0.2287, 0.2715, 0.0198, 0.1083, 0.0910],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,640][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.5191e-08, 1.4494e-06, 7.2846e-05, 2.1110e-04, 4.6903e-03, 3.8968e-02,
        3.9014e-01, 5.6591e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,642][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0053, 0.0116, 0.0512, 0.0742, 0.1208, 0.1064, 0.4225, 0.2082],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,643][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([1.8160e-05, 1.1503e-03, 2.2610e-03, 1.2800e-02, 8.7197e-02, 5.2640e-02,
        5.8650e-01, 2.5743e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,644][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.4929e-05, 1.6615e-04, 2.6926e-03, 3.6484e-03, 2.9437e-02, 1.0517e-01,
        4.0814e-01, 4.5073e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,646][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1003, 0.1205, 0.0779, 0.1277, 0.2647, 0.0817, 0.1557, 0.0715],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,647][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0230, 0.2009, 0.1253, 0.2586, 0.1748, 0.0890, 0.0670, 0.0615],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,649][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1543, 0.0357, 0.0692, 0.0755, 0.4219, 0.0909, 0.1145, 0.0381],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,650][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([9.3867e-07, 1.8604e-04, 1.7051e-03, 3.6036e-03, 3.1357e-02, 8.8230e-02,
        4.4575e-01, 4.2917e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,652][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0264, 0.2093, 0.0716, 0.1139, 0.2195, 0.1046, 0.1173, 0.1375],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,654][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0760, 0.0162, 0.2160, 0.0397, 0.1047, 0.2844, 0.0751, 0.1881],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,655][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0703, 0.1115, 0.1076, 0.1222, 0.0893, 0.0746, 0.1332, 0.2165, 0.0748],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,657][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([4.6436e-04, 4.9616e-01, 4.2275e-03, 1.4047e-01, 2.2278e-01, 7.3194e-04,
        5.5613e-02, 7.7400e-02, 2.1465e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,658][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([6.0093e-10, 7.4992e-08, 3.7126e-06, 1.3159e-05, 2.5411e-04, 5.5721e-04,
        2.0912e-02, 8.3809e-01, 1.4017e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,659][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0033, 0.0072, 0.0373, 0.0536, 0.0943, 0.0774, 0.3373, 0.1728, 0.2168],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,660][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([8.2476e-06, 7.5171e-04, 7.7391e-04, 4.2520e-03, 1.6158e-02, 9.4616e-03,
        5.4170e-01, 2.1362e-01, 2.1327e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,662][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([5.9462e-06, 6.5828e-05, 9.2637e-04, 9.3389e-04, 7.4791e-03, 2.0908e-02,
        1.1221e-01, 3.1851e-01, 5.3897e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,663][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0943, 0.1110, 0.0765, 0.1112, 0.2378, 0.0745, 0.1474, 0.0764, 0.0709],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,665][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0224, 0.1887, 0.1190, 0.2413, 0.1620, 0.0817, 0.0620, 0.0567, 0.0662],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,667][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1204, 0.0937, 0.0938, 0.0466, 0.1623, 0.0352, 0.1017, 0.3379, 0.0083],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,668][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.6768e-07, 7.7304e-05, 3.8168e-04, 1.4598e-03, 1.0455e-02, 7.3730e-03,
        1.5731e-01, 2.6444e-01, 5.5850e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,669][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0296, 0.1680, 0.0896, 0.1071, 0.2022, 0.1054, 0.0945, 0.1273, 0.0764],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,671][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1253, 0.0179, 0.1921, 0.0364, 0.0789, 0.1946, 0.0610, 0.1214, 0.1725],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,673][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0646, 0.0886, 0.0921, 0.0890, 0.0887, 0.0704, 0.1094, 0.1690, 0.0821,
        0.1461], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,674][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ house] are: tensor([6.7759e-05, 1.2673e-01, 4.7618e-04, 1.1988e-02, 8.4926e-02, 6.2495e-04,
        1.1425e-01, 6.9629e-02, 1.1845e-03, 5.9012e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,675][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ house] are: tensor([2.7203e-11, 2.0907e-08, 6.4494e-07, 3.5507e-06, 2.0595e-04, 7.9403e-04,
        2.0367e-02, 2.4921e-01, 6.2522e-01, 1.0420e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,677][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0032, 0.0065, 0.0322, 0.0406, 0.0750, 0.0575, 0.2110, 0.1269, 0.1531,
        0.2940], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,678][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ house] are: tensor([5.7212e-07, 6.8885e-05, 2.1006e-04, 1.6520e-03, 9.1301e-03, 6.1329e-03,
        1.4290e-01, 1.3316e-01, 2.9786e-01, 4.0889e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,679][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ house] are: tensor([5.2807e-07, 1.7751e-05, 2.0596e-04, 3.3531e-04, 2.8209e-03, 5.7821e-03,
        2.4364e-02, 1.5317e-01, 5.7182e-01, 2.4148e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,681][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0665, 0.0988, 0.0588, 0.1024, 0.2336, 0.0673, 0.1156, 0.0601, 0.0623,
        0.1345], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,683][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0228, 0.1794, 0.1132, 0.2246, 0.1504, 0.0784, 0.0604, 0.0556, 0.0649,
        0.0504], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,685][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.2207, 0.0354, 0.0504, 0.0225, 0.0948, 0.0244, 0.0316, 0.4781, 0.0299,
        0.0123], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,686][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ house] are: tensor([5.1218e-08, 1.9462e-05, 1.5646e-04, 4.4486e-04, 3.0811e-03, 7.3487e-03,
        2.6429e-02, 1.8192e-01, 5.6477e-01, 2.1582e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,688][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0169, 0.1574, 0.0634, 0.0847, 0.1814, 0.0870, 0.0972, 0.0820, 0.0575,
        0.1726], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,689][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0514, 0.0124, 0.1840, 0.0281, 0.0614, 0.1971, 0.0390, 0.1124, 0.1870,
        0.1271], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,690][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0550, 0.0881, 0.0798, 0.0925, 0.0856, 0.0682, 0.0952, 0.1446, 0.0679,
        0.1434, 0.0798], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,691][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0045, 0.2427, 0.0031, 0.1067, 0.1626, 0.0033, 0.0253, 0.3034, 0.0158,
        0.1223, 0.0103], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,692][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.7487e-11, 6.8875e-09, 1.8251e-07, 7.8654e-07, 1.0026e-05, 5.4761e-05,
        1.1037e-03, 7.2623e-03, 5.6034e-02, 8.4285e-02, 8.5125e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,693][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0029, 0.0060, 0.0250, 0.0338, 0.0564, 0.0451, 0.1758, 0.0914, 0.1139,
        0.2455, 0.2042], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,694][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([4.8582e-06, 3.0482e-04, 3.4572e-04, 3.5644e-03, 4.0428e-03, 8.2417e-03,
        6.6514e-02, 3.3875e-02, 1.9252e-01, 1.2120e-01, 5.6939e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,695][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([4.6950e-07, 2.8544e-06, 5.2190e-05, 4.1235e-05, 6.2037e-04, 1.7442e-03,
        5.7066e-03, 2.8819e-02, 1.1623e-01, 1.1741e-01, 7.2938e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,696][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0747, 0.0827, 0.0573, 0.0945, 0.1716, 0.0612, 0.1102, 0.0623, 0.0592,
        0.1237, 0.1026], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,698][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0234, 0.1613, 0.1055, 0.2037, 0.1524, 0.0812, 0.0634, 0.0587, 0.0668,
        0.0526, 0.0310], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,699][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2449, 0.0795, 0.0637, 0.0337, 0.0939, 0.0636, 0.0660, 0.2544, 0.0361,
        0.0389, 0.0251], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,701][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([3.7040e-08, 5.4900e-06, 3.7596e-05, 8.8678e-05, 8.7373e-04, 2.4334e-03,
        9.4008e-03, 2.8909e-02, 1.3079e-01, 2.0658e-01, 6.2088e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,702][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0280, 0.1411, 0.0688, 0.0818, 0.1534, 0.0744, 0.0801, 0.0952, 0.0613,
        0.1480, 0.0680], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,704][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0656, 0.0125, 0.1381, 0.0240, 0.0602, 0.1725, 0.0499, 0.1076, 0.1305,
        0.1017, 0.1373], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:55,706][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0556, 0.0704, 0.0677, 0.0559, 0.0848, 0.0739, 0.0745, 0.1582, 0.0796,
        0.1231, 0.0901, 0.0663], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,707][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ William] are: tensor([1.5698e-04, 7.5160e-02, 1.5468e-03, 3.4613e-02, 3.1574e-02, 1.1713e-03,
        1.2660e-02, 1.0249e-01, 1.3500e-03, 6.6923e-01, 1.2755e-02, 5.7292e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,708][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ William] are: tensor([1.2533e-11, 1.1322e-09, 1.4147e-08, 1.5434e-08, 1.7699e-06, 6.0026e-06,
        7.6368e-05, 4.0373e-04, 6.3234e-03, 1.0278e-02, 3.2240e-01, 6.6051e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,710][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0015, 0.0027, 0.0148, 0.0192, 0.0384, 0.0292, 0.1311, 0.0694, 0.0879,
        0.1882, 0.1839, 0.2336], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,711][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ William] are: tensor([4.1202e-07, 2.2614e-05, 3.7208e-05, 7.9621e-05, 1.4371e-04, 9.9071e-04,
        3.6520e-03, 8.9669e-03, 2.9914e-02, 6.6978e-02, 1.8564e-01, 7.0357e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,712][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ William] are: tensor([7.8117e-08, 7.2610e-07, 1.0426e-05, 3.9650e-06, 1.1951e-04, 4.8725e-04,
        2.4121e-03, 7.6560e-03, 3.1882e-02, 5.4988e-02, 6.7046e-01, 2.3198e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,714][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0498, 0.0911, 0.0506, 0.0760, 0.1899, 0.0443, 0.1032, 0.0493, 0.0432,
        0.1210, 0.0899, 0.0916], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,716][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0204, 0.1653, 0.1047, 0.2102, 0.1443, 0.0740, 0.0575, 0.0518, 0.0602,
        0.0472, 0.0270, 0.0373], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,717][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.1815, 0.0295, 0.0468, 0.0143, 0.0887, 0.0327, 0.0594, 0.4149, 0.0302,
        0.0572, 0.0343, 0.0105], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,719][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ William] are: tensor([2.1047e-08, 1.0054e-06, 1.2958e-05, 4.2477e-06, 3.1098e-04, 7.6249e-04,
        1.8330e-03, 1.2483e-02, 5.0381e-02, 6.9208e-02, 6.1903e-01, 2.4597e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,720][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0101, 0.1283, 0.0461, 0.0801, 0.1913, 0.0661, 0.0870, 0.0694, 0.0494,
        0.1632, 0.0466, 0.0624], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,722][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0497, 0.0089, 0.0492, 0.0177, 0.0395, 0.1653, 0.0571, 0.1139, 0.1613,
        0.1263, 0.1746, 0.0365], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:55,724][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0430, 0.0627, 0.0658, 0.0714, 0.0604, 0.0530, 0.0834, 0.1520, 0.0616,
        0.1292, 0.0889, 0.0856, 0.0431], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,725][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([2.4898e-04, 2.2860e-01, 7.0951e-03, 2.1426e-02, 2.3491e-01, 7.1725e-05,
        1.3644e-03, 7.3827e-02, 5.2400e-04, 5.3303e-02, 5.4859e-03, 2.3474e-02,
        3.4967e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,727][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([5.1662e-12, 2.5488e-11, 2.6990e-09, 3.2095e-09, 2.8910e-07, 7.5449e-07,
        1.2568e-05, 2.8276e-04, 1.0739e-03, 1.6468e-03, 1.2321e-01, 2.6448e-01,
        6.0930e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,728][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0015, 0.0029, 0.0143, 0.0190, 0.0326, 0.0260, 0.1086, 0.0571, 0.0691,
        0.1551, 0.1362, 0.2004, 0.1774], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,729][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([1.2781e-06, 2.9023e-06, 3.9774e-05, 1.9510e-05, 6.5876e-04, 8.7784e-04,
        6.8927e-03, 4.1778e-03, 1.7132e-02, 1.2281e-02, 2.0433e-01, 1.3834e-01,
        6.1524e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,731][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([2.3114e-08, 2.0719e-07, 3.1701e-06, 2.1284e-06, 3.6219e-05, 1.6090e-04,
        5.9570e-04, 1.6594e-03, 1.0260e-02, 1.0215e-02, 3.1321e-01, 2.4763e-01,
        4.1623e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,733][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0558, 0.0711, 0.0352, 0.0700, 0.1559, 0.0393, 0.0846, 0.0382, 0.0407,
        0.1043, 0.0715, 0.0844, 0.1491], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,734][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0199, 0.1523, 0.0992, 0.1943, 0.1436, 0.0767, 0.0597, 0.0552, 0.0635,
        0.0496, 0.0291, 0.0399, 0.0169], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,736][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1866, 0.0473, 0.0419, 0.0557, 0.0849, 0.0456, 0.0475, 0.1509, 0.0368,
        0.0588, 0.0623, 0.0476, 0.1341], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,737][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([5.8339e-09, 2.9954e-07, 2.7240e-06, 4.7160e-06, 3.2151e-05, 1.7120e-04,
        8.0765e-04, 2.2134e-03, 9.6699e-03, 2.6656e-02, 2.3499e-01, 4.3461e-01,
        2.9084e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,739][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0120, 0.1143, 0.0446, 0.0677, 0.1290, 0.0603, 0.0655, 0.0728, 0.0435,
        0.1480, 0.0542, 0.0538, 0.1342], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,741][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0566, 0.0188, 0.1564, 0.0339, 0.0490, 0.1375, 0.0415, 0.0780, 0.1230,
        0.1081, 0.1439, 0.0307, 0.0226], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:55,742][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0490, 0.0664, 0.0599, 0.0581, 0.0556, 0.0476, 0.0840, 0.1326, 0.0496,
        0.1250, 0.0695, 0.0704, 0.0586, 0.0737], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,743][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0037, 0.1179, 0.0038, 0.0677, 0.0583, 0.0026, 0.0080, 0.0398, 0.0081,
        0.1217, 0.0271, 0.0711, 0.4676, 0.0027], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,744][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.2016e-12, 2.1361e-12, 6.9476e-11, 7.5915e-11, 4.8845e-09, 3.0278e-08,
        4.5726e-07, 3.5526e-06, 3.1588e-05, 4.0297e-05, 1.9319e-03, 3.8968e-03,
        8.1333e-02, 9.1276e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,745][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0015, 0.0033, 0.0128, 0.0168, 0.0280, 0.0204, 0.0895, 0.0418, 0.0516,
        0.1247, 0.0966, 0.1766, 0.1502, 0.1862], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,746][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.4174e-08, 3.5817e-07, 1.1370e-06, 2.2392e-06, 7.1645e-05, 1.9165e-05,
        1.2298e-04, 1.8213e-04, 4.4845e-04, 1.5363e-03, 5.2947e-03, 1.3200e-02,
        7.6576e-01, 2.1336e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,747][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.0478e-08, 4.4235e-08, 5.2805e-07, 4.1647e-07, 2.3898e-06, 1.3672e-05,
        6.4763e-05, 1.4591e-04, 1.0107e-03, 9.8431e-04, 2.8119e-02, 3.5085e-02,
        9.8869e-02, 8.3570e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,749][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0550, 0.0626, 0.0466, 0.0659, 0.1180, 0.0498, 0.0900, 0.0446, 0.0473,
        0.0930, 0.0847, 0.0781, 0.1295, 0.0349], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,751][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0193, 0.1427, 0.0933, 0.1838, 0.1437, 0.0778, 0.0598, 0.0556, 0.0639,
        0.0494, 0.0288, 0.0405, 0.0169, 0.0243], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,752][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0512, 0.0363, 0.0400, 0.0374, 0.1777, 0.0240, 0.0908, 0.0842, 0.0200,
        0.0115, 0.0396, 0.0305, 0.3537, 0.0029], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,753][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.1034e-09, 5.5445e-08, 3.0458e-07, 5.3666e-07, 3.9866e-06, 1.5995e-05,
        1.0779e-04, 8.6644e-05, 8.5995e-04, 2.0106e-03, 2.0422e-02, 3.1319e-02,
        8.3156e-02, 8.6202e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,754][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0294, 0.0899, 0.0648, 0.0561, 0.1275, 0.0629, 0.0603, 0.0808, 0.0517,
        0.0954, 0.0667, 0.0461, 0.1191, 0.0493], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,755][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0553, 0.0107, 0.1568, 0.0221, 0.0645, 0.1529, 0.0459, 0.0968, 0.1102,
        0.0848, 0.1175, 0.0230, 0.0270, 0.0326], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:55,756][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0389, 0.0696, 0.0535, 0.0571, 0.0509, 0.0449, 0.0699, 0.1077, 0.0531,
        0.1101, 0.0605, 0.0661, 0.0816, 0.1061, 0.0300], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,758][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([8.9668e-05, 7.7257e-02, 9.5452e-04, 1.3803e-02, 5.1608e-02, 6.7375e-05,
        4.1775e-03, 1.1476e-02, 6.6783e-04, 2.1631e-01, 2.0310e-03, 1.9904e-02,
        4.0104e-01, 1.5688e-04, 2.0045e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,759][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([1.0565e-13, 1.8623e-13, 3.6662e-12, 7.4322e-12, 5.5799e-11, 7.3902e-10,
        1.3525e-08, 1.9224e-07, 9.9963e-07, 2.3774e-06, 1.0870e-04, 3.3811e-04,
        3.1034e-03, 8.7465e-01, 1.2180e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,761][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0015, 0.0029, 0.0117, 0.0149, 0.0243, 0.0191, 0.0756, 0.0374, 0.0459,
        0.1080, 0.0865, 0.1329, 0.1197, 0.1605, 0.1591], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,762][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([1.0034e-07, 5.6316e-07, 2.0987e-06, 3.0413e-06, 1.4749e-05, 4.5764e-05,
        2.3865e-04, 2.1510e-04, 9.8176e-04, 7.6376e-04, 1.0669e-02, 1.9395e-02,
        6.3072e-02, 4.7999e-01, 4.2461e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,763][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([6.4360e-09, 1.9092e-08, 1.8591e-07, 2.0523e-07, 4.6620e-07, 6.0211e-06,
        3.2138e-05, 4.0817e-05, 4.0667e-04, 3.4439e-04, 1.2467e-02, 1.4445e-02,
        4.5535e-02, 7.0042e-01, 2.2630e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,765][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0465, 0.0629, 0.0333, 0.0579, 0.1260, 0.0364, 0.0794, 0.0395, 0.0339,
        0.0865, 0.0691, 0.0707, 0.1348, 0.0301, 0.0932], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,767][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0200, 0.1442, 0.0948, 0.1834, 0.1370, 0.0732, 0.0567, 0.0528, 0.0602,
        0.0469, 0.0276, 0.0378, 0.0166, 0.0237, 0.0253], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,769][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.1290, 0.0411, 0.0285, 0.0513, 0.0289, 0.0250, 0.0328, 0.0543, 0.0284,
        0.0248, 0.0251, 0.0381, 0.4276, 0.0426, 0.0225], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,770][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.1579e-09, 2.7368e-08, 1.7855e-07, 2.9180e-07, 1.5317e-06, 9.2594e-06,
        3.6772e-05, 1.4034e-04, 5.4696e-04, 1.1183e-03, 1.0848e-02, 1.5614e-02,
        2.4842e-02, 6.6409e-01, 2.8275e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,772][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0153, 0.0860, 0.0480, 0.0557, 0.1234, 0.0567, 0.0564, 0.0748, 0.0436,
        0.0975, 0.0561, 0.0467, 0.1314, 0.0343, 0.0739], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,773][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0611, 0.0131, 0.1385, 0.0254, 0.0578, 0.1367, 0.0387, 0.0918, 0.1082,
        0.0776, 0.1146, 0.0260, 0.0264, 0.0329, 0.0511], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:55,775][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0337, 0.0594, 0.0551, 0.0622, 0.0585, 0.0417, 0.0586, 0.1101, 0.0422,
        0.0996, 0.0652, 0.0731, 0.0638, 0.0934, 0.0608, 0.0225],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,777][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0005, 0.2854, 0.0004, 0.0254, 0.1957, 0.0004, 0.0117, 0.0250, 0.0008,
        0.1253, 0.0020, 0.0250, 0.2226, 0.0004, 0.0710, 0.0085],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,778][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ it] are: tensor([4.9410e-14, 8.8431e-14, 1.0725e-12, 1.0031e-12, 6.3355e-11, 4.3685e-10,
        5.3196e-09, 7.1948e-08, 3.7012e-07, 7.1593e-07, 2.3753e-05, 3.7960e-05,
        1.0822e-03, 1.2220e-01, 7.0706e-01, 1.6960e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,780][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0011, 0.0021, 0.0089, 0.0114, 0.0199, 0.0139, 0.0598, 0.0303, 0.0355,
        0.0852, 0.0691, 0.1149, 0.1045, 0.1372, 0.1421, 0.1642],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,781][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ it] are: tensor([3.7319e-08, 1.0936e-07, 4.7743e-07, 3.3116e-07, 4.2502e-06, 5.1853e-06,
        2.0602e-05, 6.0324e-05, 1.2584e-04, 9.5619e-05, 1.7269e-03, 1.8134e-03,
        5.2845e-02, 7.0754e-02, 7.1766e-01, 1.5489e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,783][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ it] are: tensor([1.9255e-09, 3.7524e-09, 5.9064e-08, 2.6133e-08, 2.2674e-07, 1.0317e-06,
        4.2093e-06, 9.2604e-06, 6.9799e-05, 9.4971e-05, 3.0351e-03, 1.7231e-03,
        8.5423e-03, 2.0806e-01, 2.7144e-01, 5.0702e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,784][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0494, 0.0534, 0.0354, 0.0555, 0.1182, 0.0372, 0.0741, 0.0386, 0.0342,
        0.0767, 0.0668, 0.0667, 0.1090, 0.0296, 0.0945, 0.0605],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,786][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0190, 0.1419, 0.0930, 0.1803, 0.1337, 0.0707, 0.0547, 0.0507, 0.0579,
        0.0451, 0.0266, 0.0364, 0.0161, 0.0231, 0.0245, 0.0263],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,788][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0790, 0.0330, 0.0388, 0.0246, 0.0596, 0.0222, 0.0236, 0.1744, 0.0130,
        0.0348, 0.0321, 0.0193, 0.2479, 0.0489, 0.1468, 0.0019],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,789][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ it] are: tensor([1.8753e-10, 4.7585e-09, 3.5545e-08, 7.7957e-08, 4.3868e-07, 1.2775e-06,
        8.0771e-06, 1.2536e-05, 7.1412e-05, 1.3490e-04, 2.0686e-03, 4.2542e-03,
        7.2578e-03, 1.4366e-01, 3.5191e-01, 4.9062e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,791][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0170, 0.0831, 0.0480, 0.0565, 0.1139, 0.0587, 0.0473, 0.0820, 0.0473,
        0.0911, 0.0529, 0.0457, 0.1128, 0.0369, 0.0626, 0.0442],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,793][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0658, 0.0108, 0.1315, 0.0218, 0.0482, 0.1158, 0.0375, 0.0866, 0.0980,
        0.0638, 0.1114, 0.0231, 0.0264, 0.0333, 0.0558, 0.0700],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:55,795][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0432, 0.0575, 0.0528, 0.0499, 0.0485, 0.0414, 0.0714, 0.1174, 0.0425,
        0.1086, 0.0609, 0.0606, 0.0509, 0.0649, 0.0453, 0.0268, 0.0574],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,797][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0020, 0.1000, 0.0021, 0.0518, 0.0460, 0.0015, 0.0052, 0.0318, 0.0063,
        0.0885, 0.0177, 0.0547, 0.4541, 0.0014, 0.1177, 0.0179, 0.0012],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,798][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.3902e-14, 3.5724e-15, 6.8759e-14, 5.7598e-14, 3.5049e-12, 1.9948e-11,
        3.2985e-10, 1.8932e-09, 1.7904e-08, 2.4849e-08, 9.5253e-07, 1.7487e-06,
        3.1902e-05, 3.8948e-04, 4.0566e-02, 1.3171e-01, 8.2730e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,799][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0012, 0.0025, 0.0088, 0.0112, 0.0184, 0.0127, 0.0553, 0.0251, 0.0300,
        0.0747, 0.0557, 0.1026, 0.0879, 0.1028, 0.1150, 0.1369, 0.1592],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,800][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([6.2181e-09, 1.2316e-08, 3.7336e-08, 5.9458e-08, 1.6704e-06, 4.9336e-07,
        3.4820e-06, 5.0238e-06, 1.1776e-05, 3.8775e-05, 1.3807e-04, 2.6371e-04,
        1.1924e-02, 4.7500e-03, 1.2486e-01, 6.6787e-01, 1.9013e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,801][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.0703e-09, 7.9632e-10, 9.0957e-09, 4.9186e-09, 2.7007e-08, 1.6414e-07,
        8.4889e-07, 1.4893e-06, 1.0864e-05, 1.0638e-05, 3.5501e-04, 2.8890e-04,
        9.0828e-04, 7.7987e-03, 2.7855e-02, 1.9272e-01, 7.7005e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,802][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0471, 0.0510, 0.0386, 0.0544, 0.0966, 0.0411, 0.0755, 0.0377, 0.0395,
        0.0771, 0.0720, 0.0649, 0.1062, 0.0298, 0.0772, 0.0648, 0.0266],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,804][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0193, 0.1337, 0.0888, 0.1689, 0.1304, 0.0705, 0.0548, 0.0513, 0.0580,
        0.0454, 0.0269, 0.0368, 0.0163, 0.0232, 0.0248, 0.0265, 0.0243],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,806][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0309, 0.0219, 0.0237, 0.0220, 0.1114, 0.0142, 0.0533, 0.0504, 0.0123,
        0.0067, 0.0237, 0.0179, 0.2092, 0.0017, 0.3928, 0.0065, 0.0013],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,807][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.4808e-11, 1.0095e-09, 4.3000e-09, 7.2702e-09, 4.6409e-08, 1.7744e-07,
        1.2585e-06, 9.0627e-07, 8.8291e-06, 2.1158e-05, 2.3913e-04, 3.0825e-04,
        7.5641e-04, 7.3780e-03, 3.9118e-02, 1.8960e-01, 7.6257e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,809][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0247, 0.0735, 0.0557, 0.0465, 0.1060, 0.0538, 0.0501, 0.0713, 0.0452,
        0.0808, 0.0586, 0.0393, 0.0981, 0.0441, 0.0630, 0.0531, 0.0363],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,811][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0583, 0.0102, 0.1237, 0.0198, 0.0526, 0.1197, 0.0413, 0.0851, 0.0891,
        0.0658, 0.0898, 0.0202, 0.0250, 0.0308, 0.0507, 0.0678, 0.0500],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:55,849][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:55,850][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,851][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,853][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,854][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,854][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,855][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,856][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,856][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,857][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,858][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,858][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,859][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:55,860][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.6888, 0.3112], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,861][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.1259, 0.8741], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,861][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.4381, 0.5619], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,862][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([1.0919e-18, 1.0000e+00], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,863][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.4905, 0.5095], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,864][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.4013, 0.5987], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,866][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.4082, 0.5918], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,867][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.1654, 0.8346], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,868][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.8703, 0.1297], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,869][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.1668, 0.8332], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,870][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.4162, 0.5838], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,870][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.7472, 0.2528], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:55,872][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2908, 0.4353, 0.2739], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,873][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1543, 0.8013, 0.0444], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,875][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1723, 0.2235, 0.6042], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,876][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.2269e-13, 9.9625e-01, 3.7534e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,877][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3740, 0.4303, 0.1956], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,879][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2465, 0.3525, 0.4010], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,880][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2228, 0.3583, 0.4189], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,882][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0964, 0.4538, 0.4498], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,884][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4035, 0.2758, 0.3207], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,885][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0424, 0.8049, 0.1527], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,887][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2413, 0.3376, 0.4211], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,889][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6639, 0.1950, 0.1411], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:55,890][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.2438, 0.2539, 0.2902, 0.2121], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,892][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0731, 0.4278, 0.1013, 0.3978], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,893][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0675, 0.0732, 0.2917, 0.5675], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,894][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([1.8954e-09, 9.5860e-01, 2.1552e-02, 1.9847e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,896][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.2775, 0.4102, 0.2167, 0.0956], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,898][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.1362, 0.2060, 0.2685, 0.3894], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,899][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.1039, 0.1371, 0.1810, 0.5781], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,901][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0563, 0.2684, 0.2707, 0.4046], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,903][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.3880, 0.1371, 0.3119, 0.1630], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,904][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0391, 0.5319, 0.2080, 0.2210], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,906][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.1503, 0.2171, 0.2811, 0.3515], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,907][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.4261, 0.1315, 0.1028, 0.3395], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:55,909][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.1320, 0.2383, 0.2222, 0.2873, 0.1202], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,911][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0149, 0.3948, 0.0210, 0.0214, 0.5480], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,912][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0400, 0.0444, 0.1522, 0.3151, 0.4484], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,913][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([9.3315e-12, 8.3065e-01, 9.0233e-03, 2.6710e-02, 1.3362e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,915][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.2572, 0.4238, 0.1693, 0.0927, 0.0569], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,916][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0878, 0.1373, 0.1699, 0.2405, 0.3644], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,918][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0851, 0.1226, 0.1495, 0.4082, 0.2346], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,920][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0320, 0.2029, 0.1975, 0.3177, 0.2499], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,921][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.2227, 0.0953, 0.2411, 0.2132, 0.2276], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,922][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0144, 0.4477, 0.1232, 0.3200, 0.0946], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,923][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.1086, 0.1618, 0.2124, 0.2743, 0.2428], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,923][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.3541, 0.0983, 0.0748, 0.2767, 0.1961], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:55,924][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1371, 0.1481, 0.2112, 0.2570, 0.1348, 0.1117], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,926][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0385, 0.3997, 0.0508, 0.3041, 0.1855, 0.0214], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,927][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0239, 0.0290, 0.0948, 0.2062, 0.3040, 0.3421], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,928][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.6146e-08, 1.0411e-01, 7.4165e-03, 6.4875e-02, 1.8338e-01, 6.4022e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,930][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2176, 0.3798, 0.1675, 0.0797, 0.0544, 0.1011], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,931][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0705, 0.1106, 0.1322, 0.1794, 0.2667, 0.2405], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,933][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0485, 0.0931, 0.1241, 0.3335, 0.2214, 0.1795], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,934][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0264, 0.1685, 0.1659, 0.2675, 0.2306, 0.1411], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,936][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1451, 0.1257, 0.1807, 0.1108, 0.3248, 0.1129], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,938][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0203, 0.3161, 0.1196, 0.2627, 0.1481, 0.1331], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,939][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0854, 0.1271, 0.1668, 0.2104, 0.1839, 0.2265], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,941][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3438, 0.0866, 0.0668, 0.2491, 0.1863, 0.0674], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:55,943][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.1089, 0.1199, 0.1730, 0.1900, 0.1744, 0.1137, 0.1201],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,944][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0557, 0.3030, 0.0322, 0.0483, 0.4546, 0.0271, 0.0790],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,946][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0080, 0.0086, 0.0408, 0.0821, 0.1437, 0.1895, 0.5272],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,947][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([9.7391e-05, 7.6733e-02, 1.0345e-02, 1.1121e-01, 1.4795e-01, 6.3684e-01,
        1.6826e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,949][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.2242, 0.3626, 0.1519, 0.0893, 0.0592, 0.0944, 0.0184],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,950][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0471, 0.0732, 0.0975, 0.1370, 0.2339, 0.2130, 0.1983],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,952][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0368, 0.0658, 0.0775, 0.2314, 0.1286, 0.1224, 0.3375],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,954][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0257, 0.1564, 0.1520, 0.2394, 0.2075, 0.1299, 0.0891],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,955][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.1661, 0.0669, 0.1380, 0.0786, 0.2436, 0.1330, 0.1739],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,957][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0105, 0.2517, 0.0911, 0.2021, 0.1538, 0.1771, 0.1138],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,959][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0676, 0.1003, 0.1347, 0.1662, 0.1445, 0.1802, 0.2064],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,960][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.3024, 0.0781, 0.0605, 0.2176, 0.1653, 0.0636, 0.1124],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:55,962][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0700, 0.1599, 0.1212, 0.1774, 0.1104, 0.0916, 0.1176, 0.1518],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,964][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1312, 0.0770, 0.0855, 0.1567, 0.1793, 0.1000, 0.2251, 0.0452],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,965][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0077, 0.0094, 0.0328, 0.0714, 0.1078, 0.1225, 0.4193, 0.2290],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,967][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([8.5094e-06, 3.3222e-02, 3.4915e-03, 1.0720e-01, 9.5348e-02, 6.3507e-01,
        7.9866e-03, 1.1768e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,968][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2118, 0.3194, 0.1411, 0.0858, 0.0585, 0.0974, 0.0184, 0.0675],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,970][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0451, 0.0695, 0.0849, 0.1115, 0.1718, 0.1548, 0.1659, 0.1965],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,972][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0224, 0.0559, 0.0648, 0.1844, 0.1180, 0.1035, 0.2903, 0.1607],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,973][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0211, 0.1385, 0.1332, 0.2168, 0.1952, 0.1203, 0.0807, 0.0942],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,974][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0825, 0.0409, 0.0966, 0.0817, 0.2495, 0.1390, 0.1565, 0.1534],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,975][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0095, 0.1839, 0.0738, 0.1662, 0.1182, 0.1788, 0.2143, 0.0553],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,976][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0539, 0.0807, 0.1084, 0.1366, 0.1182, 0.1479, 0.1712, 0.1832],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,977][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.3024, 0.0707, 0.0536, 0.2079, 0.1571, 0.0575, 0.1061, 0.0446],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:55,978][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0697, 0.1016, 0.1166, 0.1371, 0.0820, 0.0678, 0.1222, 0.2443, 0.0588],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,980][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0217, 0.2541, 0.0341, 0.1430, 0.1602, 0.0160, 0.3092, 0.0397, 0.0220],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,982][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0053, 0.0065, 0.0249, 0.0535, 0.0839, 0.0953, 0.3402, 0.1898, 0.2006],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,983][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0204e-06, 7.1740e-03, 9.6478e-04, 8.6976e-02, 1.0035e-01, 5.4736e-01,
        3.8450e-03, 1.5954e-01, 9.3786e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,984][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1839, 0.3112, 0.1393, 0.0735, 0.0497, 0.0910, 0.0143, 0.0625, 0.0747],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,986][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0393, 0.0607, 0.0728, 0.0970, 0.1489, 0.1325, 0.1433, 0.1684, 0.1371],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,988][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0147, 0.0426, 0.0544, 0.1564, 0.1073, 0.0832, 0.2614, 0.1378, 0.1423],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,989][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0203, 0.1259, 0.1225, 0.1964, 0.1743, 0.1073, 0.0727, 0.0843, 0.0964],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,991][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0600, 0.0530, 0.0948, 0.0573, 0.1511, 0.0830, 0.1381, 0.3186, 0.0442],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,993][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0127, 0.1917, 0.0777, 0.1822, 0.1085, 0.0898, 0.1529, 0.1294, 0.0552],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,994][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0467, 0.0695, 0.0929, 0.1148, 0.0991, 0.1238, 0.1427, 0.1521, 0.1585],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,996][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2910, 0.0660, 0.0507, 0.1963, 0.1508, 0.0543, 0.1005, 0.0422, 0.0483],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:55,998][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0776, 0.0786, 0.1044, 0.0925, 0.0903, 0.0690, 0.1016, 0.1960, 0.0777,
        0.1121], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:55,999][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0231, 0.0878, 0.0109, 0.0181, 0.1338, 0.0211, 0.4544, 0.0471, 0.0263,
        0.1773], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,001][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0045, 0.0048, 0.0220, 0.0402, 0.0707, 0.0885, 0.2427, 0.1749, 0.1747,
        0.1771], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,002][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([1.8660e-07, 4.6633e-02, 4.7746e-03, 3.6294e-02, 8.6139e-02, 4.5350e-01,
        1.9496e-03, 9.4205e-02, 1.9440e-01, 8.2098e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,004][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.1843, 0.3250, 0.1238, 0.0703, 0.0482, 0.0786, 0.0131, 0.0529, 0.0616,
        0.0423], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,006][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.0318, 0.0476, 0.0611, 0.0810, 0.1335, 0.1171, 0.1166, 0.1524, 0.1199,
        0.1391], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,007][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0191, 0.0397, 0.0476, 0.1349, 0.0802, 0.0755, 0.2027, 0.1188, 0.1439,
        0.1376], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,009][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0191, 0.1199, 0.1138, 0.1818, 0.1612, 0.1004, 0.0686, 0.0792, 0.0907,
        0.0653], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,011][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0771, 0.0300, 0.0712, 0.0425, 0.1193, 0.0683, 0.0892, 0.3663, 0.0656,
        0.0706], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,012][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0061, 0.1825, 0.0711, 0.1537, 0.0739, 0.1180, 0.1294, 0.0868, 0.0865,
        0.0920], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,014][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0409, 0.0607, 0.0809, 0.1009, 0.0878, 0.1090, 0.1255, 0.1344, 0.1390,
        0.1209], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,016][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.2501, 0.0600, 0.0472, 0.1736, 0.1343, 0.0510, 0.0895, 0.0396, 0.0457,
        0.1089], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,018][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0566, 0.0900, 0.0881, 0.1114, 0.0903, 0.0737, 0.0820, 0.1575, 0.0643,
        0.1173, 0.0686], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,019][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0690, 0.1446, 0.0295, 0.1317, 0.1021, 0.0478, 0.1850, 0.0918, 0.0913,
        0.0737, 0.0335], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,021][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0035, 0.0041, 0.0157, 0.0351, 0.0543, 0.0605, 0.2203, 0.1211, 0.1286,
        0.1705, 0.1862], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,022][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.4583e-06, 9.9599e-03, 5.0706e-04, 6.2581e-02, 6.2462e-02, 3.4262e-01,
        2.7717e-03, 9.9713e-02, 8.4898e-02, 2.9770e-01, 3.6785e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,024][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1740, 0.2717, 0.1174, 0.0606, 0.0415, 0.0758, 0.0118, 0.0516, 0.0622,
        0.0349, 0.0985], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,026][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0324, 0.0460, 0.0554, 0.0695, 0.1093, 0.0978, 0.1027, 0.1266, 0.1021,
        0.1237, 0.1345], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,027][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0130, 0.0339, 0.0436, 0.1111, 0.0824, 0.0678, 0.1864, 0.1030, 0.1124,
        0.1260, 0.1204], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,028][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0195, 0.1118, 0.1054, 0.1648, 0.1550, 0.0977, 0.0686, 0.0783, 0.0877,
        0.0653, 0.0459], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,028][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0715, 0.0425, 0.0647, 0.0456, 0.1112, 0.0875, 0.1055, 0.2363, 0.0663,
        0.1035, 0.0653], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,029][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0085, 0.1324, 0.0581, 0.1077, 0.0646, 0.1255, 0.1197, 0.0940, 0.0842,
        0.1592, 0.0460], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,030][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0367, 0.0549, 0.0725, 0.0897, 0.0782, 0.0965, 0.1116, 0.1182, 0.1228,
        0.1071, 0.1119], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,032][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2528, 0.0552, 0.0410, 0.1652, 0.1283, 0.0453, 0.0839, 0.0349, 0.0401,
        0.1035, 0.0496], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,033][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0646, 0.0659, 0.0747, 0.0539, 0.0958, 0.0806, 0.0611, 0.1847, 0.0807,
        0.0952, 0.0835, 0.0593], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,035][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0205, 0.0921, 0.0303, 0.0824, 0.0547, 0.0289, 0.0780, 0.0706, 0.0196,
        0.3662, 0.0527, 0.1039], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,037][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0021, 0.0021, 0.0111, 0.0206, 0.0400, 0.0494, 0.1625, 0.1051, 0.1094,
        0.1266, 0.1713, 0.1997], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,038][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.0004, 0.0073, 0.0017, 0.0233, 0.0566, 0.2931, 0.0316, 0.1606, 0.1655,
        0.1655, 0.0915, 0.0030], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,040][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.1537, 0.2633, 0.1233, 0.0600, 0.0446, 0.0697, 0.0128, 0.0489, 0.0580,
        0.0428, 0.0883, 0.0346], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,042][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0209, 0.0296, 0.0405, 0.0517, 0.0964, 0.0862, 0.0860, 0.1155, 0.0910,
        0.1103, 0.1254, 0.1464], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,043][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0146, 0.0240, 0.0311, 0.0888, 0.0506, 0.0507, 0.1361, 0.0805, 0.1035,
        0.0878, 0.1220, 0.2103], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,045][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0164, 0.1093, 0.1029, 0.1665, 0.1497, 0.0916, 0.0633, 0.0711, 0.0813,
        0.0592, 0.0407, 0.0480], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,047][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0636, 0.0245, 0.0517, 0.0282, 0.0986, 0.0718, 0.0885, 0.3091, 0.0642,
        0.0973, 0.0713, 0.0312], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,049][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0079, 0.1040, 0.0460, 0.0427, 0.0820, 0.1066, 0.1171, 0.0992, 0.0846,
        0.2047, 0.0580, 0.0473], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,050][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0329, 0.0490, 0.0653, 0.0795, 0.0688, 0.0857, 0.0985, 0.1050, 0.1094,
        0.0950, 0.1000, 0.1109], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,052][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.2138, 0.0509, 0.0394, 0.1443, 0.1114, 0.0424, 0.0750, 0.0330, 0.0380,
        0.0918, 0.0466, 0.1135], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,054][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0491, 0.0566, 0.0716, 0.0776, 0.0604, 0.0495, 0.0780, 0.1819, 0.0561,
        0.1138, 0.0839, 0.0884, 0.0330], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,056][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0122, 0.2324, 0.0711, 0.0370, 0.3621, 0.0024, 0.0148, 0.0453, 0.0060,
        0.0353, 0.0141, 0.0435, 0.1239], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,057][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0024, 0.0024, 0.0104, 0.0210, 0.0337, 0.0421, 0.1332, 0.0875, 0.0917,
        0.1067, 0.1380, 0.1794, 0.1514], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,059][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([3.0119e-08, 4.6873e-02, 3.7025e-03, 4.1674e-02, 1.7504e-01, 4.1064e-01,
        1.0584e-03, 6.9250e-02, 1.1430e-01, 8.7322e-02, 3.4544e-02, 3.7892e-05,
        1.5564e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,060][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.1545, 0.2479, 0.1144, 0.0661, 0.0454, 0.0693, 0.0133, 0.0488, 0.0543,
        0.0399, 0.0771, 0.0290, 0.0399], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,062][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0190, 0.0270, 0.0357, 0.0469, 0.0787, 0.0701, 0.0754, 0.0923, 0.0729,
        0.0949, 0.1021, 0.1284, 0.1567], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,064][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0135, 0.0253, 0.0319, 0.0809, 0.0528, 0.0481, 0.1233, 0.0762, 0.0875,
        0.0825, 0.1046, 0.1867, 0.0867], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,065][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0156, 0.1018, 0.0960, 0.1542, 0.1461, 0.0912, 0.0636, 0.0727, 0.0820,
        0.0607, 0.0422, 0.0501, 0.0239], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,067][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0537, 0.0247, 0.0448, 0.0462, 0.0812, 0.0636, 0.0695, 0.1550, 0.0571,
        0.0936, 0.0797, 0.0521, 0.1789], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,069][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0058, 0.0850, 0.0454, 0.0789, 0.0552, 0.1096, 0.0838, 0.0839, 0.0728,
        0.1711, 0.0579, 0.0873, 0.0633], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,071][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0302, 0.0438, 0.0586, 0.0729, 0.0640, 0.0789, 0.0905, 0.0973, 0.1003,
        0.0872, 0.0913, 0.1013, 0.0838], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,073][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.1975, 0.0444, 0.0340, 0.1343, 0.1039, 0.0375, 0.0694, 0.0295, 0.0342,
        0.0875, 0.0434, 0.1106, 0.0739], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,074][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0551, 0.0656, 0.0681, 0.0675, 0.0544, 0.0463, 0.0827, 0.1593, 0.0428,
        0.1095, 0.0651, 0.0738, 0.0465, 0.0633], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,076][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0959, 0.0770, 0.0418, 0.1060, 0.0516, 0.0561, 0.0783, 0.0145, 0.0685,
        0.0781, 0.0627, 0.1137, 0.1382, 0.0175], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,078][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0022, 0.0024, 0.0091, 0.0194, 0.0310, 0.0340, 0.1238, 0.0697, 0.0750,
        0.0957, 0.1115, 0.1705, 0.1465, 0.1094], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,079][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.9831e-05, 3.7024e-03, 5.4993e-04, 6.1834e-02, 3.6755e-02, 2.5554e-01,
        1.0384e-02, 1.2660e-01, 1.0866e-01, 2.3628e-01, 6.5578e-02, 6.1589e-04,
        7.8518e-02, 1.4973e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,080][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1629, 0.2110, 0.0969, 0.0559, 0.0397, 0.0643, 0.0127, 0.0470, 0.0541,
        0.0343, 0.0767, 0.0270, 0.0379, 0.0796], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,081][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0214, 0.0317, 0.0386, 0.0475, 0.0713, 0.0625, 0.0698, 0.0809, 0.0654,
        0.0840, 0.0886, 0.1079, 0.1361, 0.0942], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,082][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0088, 0.0208, 0.0280, 0.0689, 0.0536, 0.0391, 0.1137, 0.0628, 0.0722,
        0.0789, 0.0810, 0.1830, 0.0950, 0.0942], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,083][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0152, 0.0952, 0.0902, 0.1449, 0.1421, 0.0893, 0.0619, 0.0712, 0.0799,
        0.0591, 0.0411, 0.0494, 0.0237, 0.0367], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,085][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0321, 0.0247, 0.0501, 0.0402, 0.1069, 0.0504, 0.1003, 0.1223, 0.0442,
        0.0543, 0.0678, 0.0393, 0.2329, 0.0346], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,087][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0061, 0.1177, 0.0358, 0.0928, 0.0454, 0.0930, 0.0946, 0.0410, 0.0656,
        0.1432, 0.0454, 0.0970, 0.1097, 0.0125], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,089][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0263, 0.0399, 0.0533, 0.0663, 0.0575, 0.0718, 0.0830, 0.0884, 0.0920,
        0.0796, 0.0836, 0.0933, 0.0766, 0.0883], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,090][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2059, 0.0462, 0.0334, 0.1361, 0.1030, 0.0355, 0.0679, 0.0275, 0.0314,
        0.0828, 0.0389, 0.1028, 0.0700, 0.0185], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,092][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0457, 0.0690, 0.0537, 0.0627, 0.0488, 0.0414, 0.0661, 0.1190, 0.0480,
        0.1009, 0.0520, 0.0680, 0.0890, 0.1119, 0.0239], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,094][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0091, 0.0974, 0.0235, 0.0414, 0.1393, 0.0038, 0.0441, 0.0104, 0.0125,
        0.1644, 0.0133, 0.0583, 0.2349, 0.0019, 0.1456], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,095][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0024, 0.0024, 0.0092, 0.0180, 0.0270, 0.0322, 0.1066, 0.0658, 0.0690,
        0.0847, 0.0990, 0.1392, 0.1167, 0.1061, 0.1217], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,097][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([1.0394e-06, 1.0420e-02, 1.6923e-03, 5.4321e-02, 6.0777e-02, 3.1746e-01,
        6.4766e-03, 9.9941e-02, 1.7398e-01, 1.2845e-01, 7.2924e-02, 3.1198e-04,
        5.8745e-02, 1.3126e-02, 1.3731e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,098][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.1413, 0.2209, 0.0976, 0.0568, 0.0372, 0.0648, 0.0109, 0.0423, 0.0516,
        0.0318, 0.0740, 0.0250, 0.0373, 0.0740, 0.0345], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,100][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0195, 0.0291, 0.0347, 0.0430, 0.0637, 0.0573, 0.0653, 0.0735, 0.0597,
        0.0772, 0.0791, 0.0980, 0.1217, 0.0850, 0.0931], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,102][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0115, 0.0225, 0.0270, 0.0651, 0.0438, 0.0407, 0.1026, 0.0617, 0.0716,
        0.0694, 0.0828, 0.1455, 0.0721, 0.1118, 0.0719], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,104][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0156, 0.0941, 0.0902, 0.1424, 0.1358, 0.0848, 0.0587, 0.0676, 0.0757,
        0.0556, 0.0391, 0.0457, 0.0228, 0.0353, 0.0367], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,106][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0463, 0.0225, 0.0391, 0.0416, 0.0494, 0.0474, 0.0546, 0.0993, 0.0474,
        0.0562, 0.0549, 0.0426, 0.2647, 0.0730, 0.0611], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,107][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0066, 0.0967, 0.0309, 0.0786, 0.0407, 0.0869, 0.0726, 0.0828, 0.0631,
        0.1614, 0.0401, 0.0874, 0.1061, 0.0186, 0.0274], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,109][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0242, 0.0364, 0.0489, 0.0611, 0.0531, 0.0662, 0.0766, 0.0819, 0.0850,
        0.0735, 0.0771, 0.0860, 0.0705, 0.0815, 0.0780], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,111][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1966, 0.0456, 0.0338, 0.1284, 0.0986, 0.0357, 0.0651, 0.0279, 0.0315,
        0.0785, 0.0386, 0.0977, 0.0665, 0.0190, 0.0367], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,113][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0335, 0.0578, 0.0624, 0.0737, 0.0643, 0.0397, 0.0494, 0.1238, 0.0347,
        0.0830, 0.0605, 0.0794, 0.0620, 0.0939, 0.0669, 0.0151],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,114][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0340, 0.1965, 0.0110, 0.0413, 0.2405, 0.0173, 0.1051, 0.0215, 0.0156,
        0.0678, 0.0153, 0.0447, 0.1062, 0.0060, 0.0467, 0.0304],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,116][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0017, 0.0018, 0.0073, 0.0145, 0.0234, 0.0272, 0.0940, 0.0563, 0.0592,
        0.0757, 0.0878, 0.1275, 0.1112, 0.0944, 0.1188, 0.0993],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,118][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([9.7591e-06, 1.0995e-02, 1.8998e-03, 5.4368e-02, 7.1131e-02, 2.9751e-01,
        8.2842e-03, 1.2658e-01, 1.1984e-01, 1.4388e-01, 6.1286e-02, 3.5820e-04,
        8.5086e-02, 1.4820e-02, 3.3414e-03, 6.1477e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,119][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.1325, 0.2150, 0.0932, 0.0482, 0.0325, 0.0604, 0.0096, 0.0417, 0.0515,
        0.0307, 0.0758, 0.0239, 0.0338, 0.0753, 0.0321, 0.0438],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,121][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0169, 0.0247, 0.0302, 0.0383, 0.0606, 0.0523, 0.0569, 0.0673, 0.0541,
        0.0694, 0.0741, 0.0907, 0.1186, 0.0794, 0.0912, 0.0754],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,123][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0087, 0.0192, 0.0244, 0.0586, 0.0423, 0.0371, 0.0923, 0.0561, 0.0613,
        0.0657, 0.0712, 0.1415, 0.0726, 0.0951, 0.0729, 0.0808],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,125][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0148, 0.0899, 0.0870, 0.1382, 0.1306, 0.0811, 0.0560, 0.0644, 0.0726,
        0.0531, 0.0375, 0.0439, 0.0219, 0.0341, 0.0353, 0.0396],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,126][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0303, 0.0203, 0.0420, 0.0288, 0.0641, 0.0464, 0.0487, 0.1523, 0.0354,
        0.0588, 0.0551, 0.0304, 0.1769, 0.0725, 0.1223, 0.0156],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,128][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0048, 0.0891, 0.0398, 0.0821, 0.0469, 0.0897, 0.0838, 0.0524, 0.0540,
        0.1045, 0.0501, 0.0872, 0.0908, 0.0218, 0.0732, 0.0298],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,130][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0214, 0.0330, 0.0450, 0.0564, 0.0488, 0.0613, 0.0710, 0.0762, 0.0792,
        0.0681, 0.0717, 0.0801, 0.0654, 0.0760, 0.0727, 0.0736],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,132][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.1884, 0.0422, 0.0317, 0.1212, 0.0948, 0.0344, 0.0632, 0.0271, 0.0308,
        0.0768, 0.0379, 0.0952, 0.0659, 0.0187, 0.0361, 0.0356],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,133][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0506, 0.0560, 0.0621, 0.0572, 0.0478, 0.0409, 0.0701, 0.1481, 0.0371,
        0.0984, 0.0595, 0.0629, 0.0407, 0.0572, 0.0401, 0.0200, 0.0512],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,134][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0828, 0.0679, 0.0375, 0.0912, 0.0452, 0.0477, 0.0696, 0.0132, 0.0575,
        0.0692, 0.0566, 0.0981, 0.1184, 0.0153, 0.0660, 0.0489, 0.0150],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,135][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0017, 0.0018, 0.0068, 0.0141, 0.0223, 0.0252, 0.0877, 0.0507, 0.0557,
        0.0687, 0.0817, 0.1221, 0.1049, 0.0798, 0.1123, 0.0963, 0.0682],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,136][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.6103e-05, 2.5261e-03, 4.0513e-04, 6.6532e-02, 3.3650e-02, 2.2931e-01,
        1.7259e-02, 1.2529e-01, 1.2805e-01, 2.0471e-01, 7.7180e-02, 7.6284e-04,
        8.1690e-02, 1.6548e-02, 3.7491e-03, 9.8908e-04, 1.1312e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,138][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1250, 0.1882, 0.0863, 0.0472, 0.0327, 0.0584, 0.0099, 0.0399, 0.0487,
        0.0283, 0.0701, 0.0225, 0.0328, 0.0719, 0.0314, 0.0431, 0.0635],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,139][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0185, 0.0277, 0.0321, 0.0393, 0.0568, 0.0495, 0.0562, 0.0629, 0.0511,
        0.0653, 0.0676, 0.0828, 0.1050, 0.0720, 0.0809, 0.0698, 0.0625],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,141][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0065, 0.0165, 0.0218, 0.0537, 0.0422, 0.0306, 0.0905, 0.0490, 0.0551,
        0.0622, 0.0599, 0.1432, 0.0738, 0.0692, 0.0736, 0.0864, 0.0656],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,143][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0150, 0.0859, 0.0827, 0.1289, 0.1246, 0.0785, 0.0548, 0.0632, 0.0702,
        0.0522, 0.0367, 0.0429, 0.0216, 0.0333, 0.0346, 0.0386, 0.0363],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,145][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0247, 0.0200, 0.0378, 0.0303, 0.0865, 0.0377, 0.0802, 0.0939, 0.0333,
        0.0435, 0.0517, 0.0298, 0.1739, 0.0261, 0.1837, 0.0256, 0.0213],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,147][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0056, 0.1012, 0.0317, 0.0784, 0.0406, 0.0827, 0.0833, 0.0367, 0.0593,
        0.1213, 0.0399, 0.0821, 0.0938, 0.0114, 0.0645, 0.0594, 0.0082],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,148][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0201, 0.0309, 0.0419, 0.0523, 0.0452, 0.0568, 0.0658, 0.0705, 0.0734,
        0.0630, 0.0664, 0.0741, 0.0606, 0.0703, 0.0672, 0.0679, 0.0737],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,150][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1922, 0.0437, 0.0313, 0.1243, 0.0944, 0.0328, 0.0622, 0.0256, 0.0288,
        0.0746, 0.0352, 0.0923, 0.0629, 0.0171, 0.0335, 0.0325, 0.0165],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,154][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:22:56,155][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16992],
        [17939],
        [30348],
        [16181],
        [31771],
        [20221],
        [18578],
        [21059],
        [21501],
        [29651],
        [23199],
        [16615],
        [33539],
        [17514],
        [14729],
        [24069],
        [16560]], device='cuda:0')
[2024-07-24 10:22:56,157][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16116],
        [33023],
        [26443],
        [33320],
        [39884],
        [41467],
        [38983],
        [28066],
        [37021],
        [29297],
        [21713],
        [27657],
        [36598],
        [22336],
        [17549],
        [21902],
        [17544]], device='cuda:0')
[2024-07-24 10:22:56,159][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[4667],
        [4495],
        [3586],
        [3323],
        [3451],
        [3248],
        [3635],
        [3584],
        [3639],
        [3801],
        [3681],
        [3599],
        [3441],
        [3253],
        [3190],
        [3298],
        [3243]], device='cuda:0')
[2024-07-24 10:22:56,161][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33316],
        [  112],
        [  112],
        [   83],
        [  423],
        [   68],
        [  264],
        [  313],
        [  105],
        [ 4394],
        [  315],
        [ 4231],
        [  411],
        [  389],
        [  782],
        [  251],
        [  499]], device='cuda:0')
[2024-07-24 10:22:56,163][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[47126],
        [ 3101],
        [32104],
        [23216],
        [21127],
        [22185],
        [ 4922],
        [ 8962],
        [17682],
        [26497],
        [49340],
        [20137],
        [25358],
        [40923],
        [41018],
        [34808],
        [41050]], device='cuda:0')
[2024-07-24 10:22:56,165][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25660],
        [24442],
        [25491],
        [24246],
        [22219],
        [22828],
        [21760],
        [22144],
        [23135],
        [22524],
        [23725],
        [21940],
        [22186],
        [22908],
        [22757],
        [24027],
        [24461]], device='cuda:0')
[2024-07-24 10:22:56,166][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6625],
        [43882],
        [40647],
        [46095],
        [23071],
        [12889],
        [22028],
        [14024],
        [12925],
        [14834],
        [ 7622],
        [45069],
        [19802],
        [13112],
        [18198],
        [34297],
        [ 7861]], device='cuda:0')
[2024-07-24 10:22:56,168][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[36805],
        [34981],
        [38291],
        [31394],
        [28170],
        [36617],
        [46953],
        [48630],
        [44832],
        [47027],
        [35646],
        [27064],
        [20793],
        [35757],
        [32448],
        [42476],
        [40946]], device='cuda:0')
[2024-07-24 10:22:56,170][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27313],
        [29225],
        [29833],
        [27089],
        [26860],
        [26959],
        [27506],
        [28433],
        [28936],
        [29444],
        [29516],
        [28487],
        [30277],
        [30462],
        [31580],
        [31513],
        [31545]], device='cuda:0')
[2024-07-24 10:22:56,172][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[36452],
        [35172],
        [35174],
        [33937],
        [34177],
        [34360],
        [34453],
        [34417],
        [34323],
        [34317],
        [34347],
        [34211],
        [34260],
        [34331],
        [34323],
        [34397],
        [34458]], device='cuda:0')
[2024-07-24 10:22:56,174][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38682],
        [38658],
        [38606],
        [38931],
        [35624],
        [28949],
        [34578],
        [23542],
        [30689],
        [32881],
        [35056],
        [32619],
        [33297],
        [27719],
        [34448],
        [33470],
        [30138]], device='cuda:0')
[2024-07-24 10:22:56,176][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 5721],
        [20795],
        [ 3556],
        [ 2860],
        [  811],
        [ 1227],
        [ 1896],
        [ 2474],
        [ 3600],
        [ 5686],
        [ 4086],
        [ 3054],
        [ 1606],
        [ 1301],
        [  994],
        [ 1045],
        [ 1524]], device='cuda:0')
[2024-07-24 10:22:56,177][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[26894],
        [24398],
        [37517],
        [28693],
        [34189],
        [32813],
        [31792],
        [34417],
        [34574],
        [34601],
        [36583],
        [34334],
        [35173],
        [37826],
        [36899],
        [36325],
        [37809]], device='cuda:0')
[2024-07-24 10:22:56,179][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[47930],
        [40076],
        [38242],
        [30259],
        [33019],
        [29302],
        [26971],
        [26564],
        [27641],
        [25072],
        [24889],
        [22742],
        [24735],
        [24254],
        [23621],
        [23951],
        [23364]], device='cuda:0')
[2024-07-24 10:22:56,181][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14881],
        [18429],
        [35227],
        [22095],
        [25649],
        [11479],
        [11234],
        [19463],
        [16431],
        [16546],
        [22424],
        [10967],
        [22112],
        [31035],
        [21028],
        [20911],
        [30883]], device='cuda:0')
[2024-07-24 10:22:56,183][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[37418],
        [35401],
        [31653],
        [31644],
        [29112],
        [30859],
        [29455],
        [29212],
        [30429],
        [30411],
        [30048],
        [30706],
        [30383],
        [30566],
        [30796],
        [29605],
        [30086]], device='cuda:0')
[2024-07-24 10:22:56,185][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12550],
        [42479],
        [40654],
        [25964],
        [35708],
        [34500],
        [30416],
        [24610],
        [30165],
        [33541],
        [29177],
        [37038],
        [41098],
        [36450],
        [44256],
        [39133],
        [35693]], device='cuda:0')
[2024-07-24 10:22:56,187][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[46624],
        [47202],
        [47272],
        [47327],
        [47041],
        [47256],
        [47402],
        [47298],
        [47264],
        [47349],
        [47437],
        [47360],
        [47123],
        [47129],
        [47076],
        [47097],
        [47128]], device='cuda:0')
[2024-07-24 10:22:56,188][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18656],
        [22602],
        [22627],
        [22924],
        [23285],
        [25719],
        [26148],
        [25895],
        [25355],
        [25402],
        [27629],
        [26239],
        [25669],
        [27225],
        [26148],
        [26340],
        [27044]], device='cuda:0')
[2024-07-24 10:22:56,189][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20691],
        [20112],
        [18717],
        [18181],
        [18420],
        [17992],
        [18222],
        [18636],
        [18422],
        [18950],
        [18780],
        [19133],
        [19356],
        [19529],
        [19533],
        [19589],
        [19990]], device='cuda:0')
[2024-07-24 10:22:56,191][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[1839],
        [1983],
        [2093],
        [2195],
        [2147],
        [2209],
        [2292],
        [2243],
        [2278],
        [2328],
        [2372],
        [2471],
        [2510],
        [2500],
        [2465],
        [2513],
        [2508]], device='cuda:0')
[2024-07-24 10:22:56,193][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 6619],
        [ 8950],
        [ 9031],
        [10408],
        [10585],
        [10292],
        [10086],
        [ 9289],
        [ 8147],
        [ 8094],
        [ 7333],
        [ 7361],
        [ 7521],
        [ 7409],
        [ 7164],
        [ 6922],
        [ 6818]], device='cuda:0')
[2024-07-24 10:22:56,195][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10173],
        [10441],
        [10668],
        [10598],
        [10486],
        [10349],
        [10268],
        [10192],
        [10125],
        [10101],
        [10098],
        [10141],
        [10135],
        [10129],
        [10138],
        [10120],
        [10115]], device='cuda:0')
[2024-07-24 10:22:56,196][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25122],
        [25467],
        [25769],
        [25472],
        [26036],
        [26052],
        [25061],
        [23623],
        [21715],
        [21720],
        [22839],
        [22035],
        [22895],
        [22542],
        [22791],
        [23120],
        [24017]], device='cuda:0')
[2024-07-24 10:22:56,198][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32819],
        [33792],
        [34936],
        [35116],
        [33609],
        [32877],
        [32757],
        [33618],
        [34709],
        [34565],
        [34958],
        [35074],
        [34338],
        [33590],
        [33918],
        [33080],
        [32956]], device='cuda:0')
[2024-07-24 10:22:56,200][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[43750],
        [44023],
        [43799],
        [43457],
        [43206],
        [42968],
        [42931],
        [42572],
        [42376],
        [42329],
        [42220],
        [42233],
        [42170],
        [42067],
        [41987],
        [41967],
        [41823]], device='cuda:0')
[2024-07-24 10:22:56,202][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[40420],
        [40178],
        [40270],
        [40729],
        [40789],
        [41027],
        [40823],
        [40893],
        [41018],
        [40882],
        [40977],
        [41375],
        [41556],
        [41607],
        [41713],
        [41788],
        [41815]], device='cuda:0')
[2024-07-24 10:22:56,203][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23030],
        [17416],
        [17819],
        [18162],
        [17398],
        [16925],
        [17025],
        [18663],
        [18102],
        [17761],
        [17293],
        [15930],
        [15614],
        [16149],
        [15160],
        [16183],
        [16295]], device='cuda:0')
[2024-07-24 10:22:56,205][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26007],
        [ 9414],
        [19547],
        [21363],
        [26091],
        [30121],
        [32529],
        [33069],
        [32529],
        [29789],
        [34854],
        [30818],
        [33468],
        [29046],
        [27417],
        [34880],
        [29317]], device='cuda:0')
[2024-07-24 10:22:56,207][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685],
        [35685]], device='cuda:0')
[2024-07-24 10:22:56,259][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:56,260][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,262][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,262][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,263][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,264][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,264][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,265][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,266][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,267][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,267][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,268][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,269][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,271][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.6215, 0.3785], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,272][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.4711, 0.5289], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,274][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.5122, 0.4878], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,274][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.1937, 0.8063], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,276][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.7410, 0.2590], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,276][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.8167, 0.1833], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,277][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1624, 0.8376], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,279][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.5580, 0.4420], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,280][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0687, 0.9313], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,282][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0781, 0.9219], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,284][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.8043, 0.1957], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,285][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.9328, 0.0672], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,287][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4792, 0.2840, 0.2368], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,288][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3002, 0.3581, 0.3417], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,290][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2336, 0.3775, 0.3889], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,291][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0643e-05, 9.9994e-01, 4.6572e-05], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,293][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5417, 0.2111, 0.2472], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,294][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8893, 0.0606, 0.0501], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,295][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([3.6557e-04, 9.9605e-01, 3.5872e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,297][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0024, 0.9748, 0.0228], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,299][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0296, 0.4853, 0.4851], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,300][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0373, 0.3940, 0.5687], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,302][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6141, 0.1008, 0.2851], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,303][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4079, 0.5099, 0.0822], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,305][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.3919, 0.2290, 0.1910, 0.1880], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,307][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.2209, 0.2690, 0.2770, 0.2332], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,308][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.1436, 0.2591, 0.3943, 0.2030], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,309][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ William] are: tensor([1.0798e-04, 9.9878e-01, 1.2508e-04, 9.8398e-04], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,310][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.4906, 0.1830, 0.2019, 0.1246], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,310][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.5914, 0.1651, 0.2069, 0.0366], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,311][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ William] are: tensor([4.7254e-05, 9.7704e-01, 3.3156e-03, 1.9600e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,312][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ William] are: tensor([1.9071e-04, 9.6552e-01, 3.3677e-02, 6.1241e-04], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,314][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0125, 0.2713, 0.2850, 0.4311], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,315][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0182, 0.2431, 0.4269, 0.3118], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,317][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.4254, 0.2191, 0.0999, 0.2556], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,319][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0285, 0.9045, 0.0620, 0.0050], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,320][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.3304, 0.1921, 0.1621, 0.1558, 0.1596], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,322][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.1722, 0.2191, 0.2216, 0.1854, 0.2017], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,323][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1275, 0.2311, 0.3292, 0.2134, 0.0988], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,325][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ got] are: tensor([5.7093e-04, 9.7160e-01, 1.0986e-04, 2.0074e-03, 2.5714e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,326][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.4032, 0.1603, 0.1762, 0.1253, 0.1351], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,328][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.6373, 0.0807, 0.1449, 0.0250, 0.1121], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,329][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ got] are: tensor([9.6628e-05, 8.4468e-01, 3.4921e-02, 9.9531e-02, 2.0767e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,330][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ got] are: tensor([2.0171e-04, 9.5428e-01, 3.7265e-02, 1.5430e-03, 6.7118e-03],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,332][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0115, 0.2061, 0.2128, 0.3191, 0.2504], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,333][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0159, 0.1623, 0.2329, 0.1850, 0.4039], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,335][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.4404, 0.1299, 0.1485, 0.1376, 0.1437], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,336][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.1545, 0.5706, 0.2075, 0.0051, 0.0622], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,338][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2881, 0.1674, 0.1409, 0.1352, 0.1366, 0.1318], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,340][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1478, 0.1810, 0.1801, 0.1536, 0.1752, 0.1623], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,341][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0685, 0.2112, 0.2629, 0.1454, 0.1288, 0.1832], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,343][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.9032e-07, 7.9018e-01, 6.2601e-05, 1.3602e-03, 2.0838e-01, 1.9883e-05],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,344][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3402, 0.1375, 0.1534, 0.1091, 0.1232, 0.1367], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,346][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7337, 0.0443, 0.0736, 0.0177, 0.0788, 0.0518], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,347][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([4.0616e-07, 7.6218e-01, 2.1224e-02, 1.1877e-01, 9.7768e-02, 6.1733e-05],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,348][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.1374e-08, 7.0455e-01, 3.6457e-02, 2.6553e-03, 2.5634e-01, 1.5768e-06],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,350][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0206, 0.1842, 0.1707, 0.2529, 0.2060, 0.1657], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,351][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0034, 0.0798, 0.1181, 0.0889, 0.2985, 0.4113], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,353][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2085, 0.1552, 0.1924, 0.1363, 0.1081, 0.1996], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,354][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.1364e-04, 5.2828e-01, 1.3793e-01, 9.0187e-03, 3.2419e-01, 2.6417e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,356][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.2539, 0.1468, 0.1243, 0.1180, 0.1207, 0.1165, 0.1198],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,357][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.1167, 0.1555, 0.1616, 0.1336, 0.1511, 0.1450, 0.1366],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,359][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0582, 0.1171, 0.1806, 0.1068, 0.0949, 0.3719, 0.0705],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,360][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([5.6260e-07, 6.9782e-01, 6.5446e-05, 1.4830e-03, 3.0058e-01, 4.5028e-05,
        8.3677e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,361][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.3557, 0.1350, 0.1330, 0.0932, 0.0994, 0.1138, 0.0699],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,362][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.4915, 0.0560, 0.0751, 0.0147, 0.1225, 0.0760, 0.1642],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,362][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([1.2206e-07, 7.9201e-01, 4.4569e-03, 1.3671e-01, 6.6475e-02, 1.4663e-04,
        1.9637e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,363][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([2.1778e-08, 5.8614e-01, 2.6734e-02, 1.7308e-03, 3.8539e-01, 3.5066e-06,
        4.7946e-07], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,364][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0156, 0.1461, 0.1410, 0.2074, 0.1697, 0.1417, 0.1785],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,366][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0027, 0.0682, 0.1126, 0.0935, 0.2750, 0.3923, 0.0557],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,367][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.3671, 0.0859, 0.1850, 0.0409, 0.0829, 0.0558, 0.1824],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,368][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([1.9913e-04, 5.2209e-01, 1.5438e-01, 1.5430e-02, 3.0709e-01, 6.3450e-04,
        1.8006e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,370][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2297, 0.1322, 0.1118, 0.1067, 0.1093, 0.1053, 0.1081, 0.0969],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,372][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1132, 0.1378, 0.1393, 0.1171, 0.1387, 0.1286, 0.1293, 0.0959],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,373][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0474, 0.0960, 0.1660, 0.1102, 0.0649, 0.3337, 0.1093, 0.0723],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,374][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([2.8114e-06, 5.0744e-01, 2.2279e-04, 4.4682e-03, 4.8769e-01, 7.5288e-05,
        1.9100e-05, 9.0346e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,376][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2945, 0.1143, 0.1276, 0.0831, 0.1014, 0.1127, 0.0846, 0.0818],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,377][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.4680, 0.0396, 0.0562, 0.0118, 0.0705, 0.0493, 0.2261, 0.0785],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,379][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.2958e-07, 7.4374e-01, 7.4023e-03, 1.7751e-01, 7.0621e-02, 1.5482e-04,
        3.5733e-04, 2.1516e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,380][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.9238e-08, 5.8181e-01, 6.7369e-02, 1.4931e-03, 3.4932e-01, 1.9584e-06,
        2.4860e-06, 3.4440e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,382][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0169, 0.1345, 0.1274, 0.1815, 0.1519, 0.1264, 0.1565, 0.1051],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,383][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0043, 0.0572, 0.0785, 0.0628, 0.1984, 0.2208, 0.0426, 0.3355],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,385][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2631, 0.0793, 0.1853, 0.0799, 0.0372, 0.0373, 0.0791, 0.2388],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,386][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([8.0591e-05, 2.4706e-01, 1.2425e-01, 5.0264e-03, 6.2290e-01, 2.9946e-04,
        1.9202e-04, 1.8379e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,388][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2089, 0.1214, 0.1027, 0.0983, 0.1002, 0.0968, 0.0991, 0.0886, 0.0840],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,389][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0991, 0.1197, 0.1211, 0.1004, 0.1192, 0.1077, 0.1165, 0.0864, 0.1298],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,391][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0344, 0.1181, 0.1352, 0.0945, 0.0953, 0.1587, 0.0737, 0.1347, 0.1553],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,392][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.4935e-05, 9.2518e-01, 4.5133e-05, 1.5121e-03, 7.1607e-02, 7.7777e-06,
        5.4558e-06, 2.4643e-05, 1.5996e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,394][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2669, 0.1020, 0.1180, 0.0826, 0.0877, 0.1049, 0.0725, 0.0727, 0.0925],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,396][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.5955, 0.0324, 0.0519, 0.0100, 0.0467, 0.0365, 0.1221, 0.0501, 0.0548],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,397][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.3369e-06, 9.2006e-01, 3.7326e-03, 4.4612e-02, 2.9777e-02, 3.2726e-05,
        6.4397e-05, 6.3327e-05, 1.6514e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,398][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.5553e-06, 8.8869e-01, 1.6833e-02, 9.2956e-04, 9.3204e-02, 3.2784e-07,
        2.2939e-07, 4.5518e-07, 3.3954e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,400][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0147, 0.1182, 0.1153, 0.1796, 0.1442, 0.1072, 0.1324, 0.0896, 0.0988],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,402][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0025, 0.0420, 0.0575, 0.0431, 0.1484, 0.1774, 0.0278, 0.2939, 0.2073],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,403][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1609, 0.0827, 0.0657, 0.0657, 0.0890, 0.0600, 0.0595, 0.0359, 0.3806],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,404][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.4772e-03, 7.1138e-01, 1.1570e-01, 7.5528e-03, 1.5735e-01, 1.7257e-04,
        1.1624e-04, 1.1675e-04, 4.1328e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,406][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.1933, 0.1114, 0.0939, 0.0902, 0.0923, 0.0895, 0.0914, 0.0820, 0.0774,
        0.0785], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,408][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0795, 0.1058, 0.1119, 0.0919, 0.1074, 0.1030, 0.1054, 0.0793, 0.1272,
        0.0886], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,409][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0270, 0.0538, 0.0850, 0.0657, 0.0465, 0.2140, 0.0570, 0.1457, 0.2780,
        0.0273], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,410][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ house] are: tensor([1.2457e-05, 6.9743e-01, 2.5752e-04, 1.5023e-03, 2.8874e-01, 8.9533e-05,
        1.6960e-05, 4.7039e-05, 1.1837e-02, 6.1363e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,412][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.2657, 0.0923, 0.1077, 0.0715, 0.0832, 0.0942, 0.0705, 0.0682, 0.0860,
        0.0606], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,413][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.2952, 0.0371, 0.0597, 0.0113, 0.0761, 0.0504, 0.2215, 0.0834, 0.0758,
        0.0895], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,414][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ house] are: tensor([4.6113e-07, 9.1476e-01, 1.9128e-03, 5.2778e-02, 2.1748e-02, 1.1128e-04,
        1.1467e-04, 1.0986e-04, 8.2442e-03, 2.1583e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,415][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ house] are: tensor([4.8335e-08, 9.2102e-01, 1.2227e-02, 5.7768e-04, 6.5401e-02, 1.9256e-07,
        1.5235e-07, 2.2860e-07, 7.6318e-04, 1.2452e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,416][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0124, 0.1020, 0.1043, 0.1610, 0.1286, 0.0967, 0.1192, 0.0838, 0.0921,
        0.1000], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,417][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0021, 0.0335, 0.0542, 0.0401, 0.1301, 0.1680, 0.0245, 0.2847, 0.2096,
        0.0533], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,419][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.2775, 0.0809, 0.0416, 0.0401, 0.0584, 0.0260, 0.1085, 0.0777, 0.0590,
        0.2303], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,420][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ house] are: tensor([8.1782e-04, 6.7745e-01, 1.0719e-01, 5.9114e-03, 1.9562e-01, 1.6758e-04,
        9.1997e-05, 1.8577e-04, 1.0310e-02, 2.2550e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,422][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1823, 0.1044, 0.0877, 0.0839, 0.0859, 0.0827, 0.0849, 0.0758, 0.0716,
        0.0726, 0.0683], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,424][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0845, 0.0975, 0.1003, 0.0810, 0.0938, 0.0903, 0.0911, 0.0698, 0.1092,
        0.0770, 0.1055], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,425][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0345, 0.0664, 0.0955, 0.0686, 0.0563, 0.1762, 0.0586, 0.1131, 0.2286,
        0.0450, 0.0572], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,426][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([3.7409e-07, 9.2637e-01, 3.7081e-05, 4.6414e-03, 6.4599e-02, 1.9814e-05,
        6.2015e-06, 2.6555e-05, 4.1332e-03, 6.9595e-05, 9.4793e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,428][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2300, 0.0848, 0.0987, 0.0646, 0.0756, 0.0882, 0.0639, 0.0631, 0.0791,
        0.0610, 0.0909], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,430][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3658, 0.0337, 0.0549, 0.0107, 0.0602, 0.0500, 0.1356, 0.0621, 0.0864,
        0.0785, 0.0622], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,431][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([3.2059e-07, 8.2515e-01, 6.0154e-03, 1.2054e-01, 3.4187e-02, 1.2574e-04,
        1.4741e-04, 2.1553e-04, 1.1036e-02, 4.6012e-04, 2.1165e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,432][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([2.8446e-07, 8.6389e-01, 1.8296e-02, 7.6462e-04, 1.1556e-01, 3.2765e-07,
        2.8512e-07, 7.8951e-07, 9.0396e-04, 9.4690e-05, 4.9079e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,434][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0135, 0.1012, 0.0975, 0.1530, 0.1242, 0.0913, 0.1101, 0.0731, 0.0836,
        0.0909, 0.0616], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,435][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0023, 0.0295, 0.0443, 0.0321, 0.1063, 0.1289, 0.0194, 0.2160, 0.1572,
        0.0448, 0.2192], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,437][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1524, 0.0270, 0.1812, 0.0334, 0.0504, 0.0323, 0.0682, 0.0593, 0.1458,
        0.0470, 0.2030], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,438][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([8.9985e-04, 4.9577e-01, 1.8376e-01, 5.3844e-03, 2.9131e-01, 1.9133e-04,
        1.1813e-04, 1.8663e-04, 9.1454e-03, 2.8306e-03, 1.0401e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,440][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.1753, 0.0974, 0.0813, 0.0773, 0.0787, 0.0760, 0.0776, 0.0694, 0.0656,
        0.0669, 0.0624, 0.0720], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,442][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0701, 0.0865, 0.0906, 0.0735, 0.0898, 0.0832, 0.0840, 0.0696, 0.1010,
        0.0757, 0.1030, 0.0728], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,444][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0237, 0.0540, 0.0821, 0.0421, 0.0350, 0.2289, 0.0541, 0.0833, 0.2623,
        0.0279, 0.0660, 0.0407], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,445][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ William] are: tensor([9.3082e-06, 7.6622e-01, 1.4245e-04, 6.2193e-04, 2.2216e-01, 6.3979e-05,
        1.4244e-05, 4.7413e-05, 8.6651e-03, 2.8034e-04, 1.5746e-03, 2.0745e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,447][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.2386, 0.0812, 0.0932, 0.0566, 0.0709, 0.0836, 0.0626, 0.0553, 0.0736,
        0.0536, 0.0827, 0.0481], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,448][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.1505, 0.0355, 0.0723, 0.0094, 0.0788, 0.0883, 0.1238, 0.1275, 0.1380,
        0.0816, 0.0808, 0.0135], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,450][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ William] are: tensor([9.3302e-07, 9.4510e-01, 1.2187e-03, 1.1894e-02, 1.5081e-02, 1.3932e-04,
        5.2404e-05, 1.4317e-04, 8.0813e-03, 4.1924e-04, 2.5992e-03, 1.5273e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,451][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ William] are: tensor([4.3108e-07, 5.5981e-01, 1.1829e-02, 8.3273e-05, 4.2242e-01, 1.6284e-06,
        3.9071e-07, 1.2884e-06, 2.9796e-03, 2.3182e-04, 2.6044e-03, 4.4309e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,452][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0087, 0.0834, 0.0875, 0.1320, 0.1103, 0.0838, 0.1029, 0.0719, 0.0772,
        0.0828, 0.0594, 0.1002], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,454][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0020, 0.0256, 0.0432, 0.0314, 0.1035, 0.1220, 0.0188, 0.2049, 0.1445,
        0.0427, 0.1898, 0.0716], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,456][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.1423, 0.0848, 0.0293, 0.0922, 0.0980, 0.0392, 0.0409, 0.0408, 0.2329,
        0.0434, 0.0282, 0.1279], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,457][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ William] are: tensor([7.1229e-04, 7.2970e-01, 6.9513e-02, 2.9307e-03, 1.6743e-01, 2.4256e-04,
        1.4478e-04, 1.4853e-04, 1.2238e-02, 2.9929e-03, 1.2751e-02, 1.1989e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,459][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.1567, 0.0903, 0.0758, 0.0720, 0.0741, 0.0706, 0.0732, 0.0649, 0.0615,
        0.0626, 0.0586, 0.0675, 0.0722], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,461][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0695, 0.0798, 0.0848, 0.0650, 0.0771, 0.0767, 0.0801, 0.0599, 0.0979,
        0.0662, 0.0924, 0.0644, 0.0861], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,462][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0381, 0.0554, 0.0649, 0.0565, 0.0309, 0.1767, 0.0497, 0.1117, 0.2406,
        0.0304, 0.0600, 0.0593, 0.0258], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,464][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([3.0961e-04, 7.5028e-01, 8.6114e-04, 1.7555e-03, 2.2648e-01, 4.2170e-05,
        1.2312e-05, 3.2843e-05, 9.5094e-03, 9.9112e-05, 4.7245e-03, 2.7717e-04,
        5.6224e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,465][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.2161, 0.0767, 0.0864, 0.0602, 0.0683, 0.0787, 0.0557, 0.0550, 0.0686,
        0.0510, 0.0764, 0.0519, 0.0549], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,466][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.2170, 0.0315, 0.0760, 0.0080, 0.0713, 0.0635, 0.1307, 0.0786, 0.0865,
        0.0734, 0.0709, 0.0080, 0.0847], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,467][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([6.9727e-06, 8.2751e-01, 1.5249e-02, 7.5027e-02, 2.1458e-02, 1.4223e-05,
        7.7021e-05, 5.4653e-05, 1.4837e-03, 3.1823e-04, 3.2948e-03, 2.6059e-02,
        2.9450e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,468][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([5.7482e-06, 9.4814e-01, 2.6284e-02, 1.1188e-03, 2.2566e-02, 1.7734e-07,
        1.1694e-07, 3.6973e-07, 2.7047e-04, 3.6452e-05, 5.6593e-04, 9.5307e-05,
        9.1583e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,469][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0141, 0.0787, 0.0818, 0.1180, 0.0953, 0.0762, 0.0917, 0.0646, 0.0741,
        0.0776, 0.0594, 0.0967, 0.0716], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,470][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0020, 0.0287, 0.0415, 0.0303, 0.0852, 0.1079, 0.0211, 0.1792, 0.1287,
        0.0405, 0.1795, 0.0712, 0.0843], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,472][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1220, 0.0413, 0.0864, 0.0797, 0.0341, 0.0309, 0.0693, 0.0363, 0.1214,
        0.0865, 0.0985, 0.1394, 0.0543], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,473][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([2.4517e-02, 4.6392e-01, 3.3858e-01, 6.5576e-03, 1.0610e-01, 2.1863e-04,
        1.6605e-04, 1.9427e-04, 7.1561e-03, 1.9757e-03, 1.8354e-02, 9.3539e-04,
        3.1327e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,475][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1515, 0.0854, 0.0711, 0.0677, 0.0692, 0.0660, 0.0680, 0.0606, 0.0572,
        0.0582, 0.0545, 0.0629, 0.0674, 0.0603], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,477][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0633, 0.0739, 0.0762, 0.0647, 0.0747, 0.0698, 0.0738, 0.0567, 0.0834,
        0.0646, 0.0841, 0.0625, 0.0872, 0.0653], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,478][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0201, 0.0614, 0.0719, 0.0597, 0.0481, 0.1445, 0.0618, 0.0713, 0.2231,
        0.0379, 0.0602, 0.0584, 0.0601, 0.0215], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,480][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.8025e-04, 6.2616e-01, 8.9666e-05, 1.4284e-03, 3.4621e-01, 1.9687e-05,
        3.2946e-06, 1.8383e-05, 3.1581e-03, 7.9140e-05, 2.6329e-04, 1.8342e-04,
        1.3889e-02, 8.3182e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,481][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1857, 0.0695, 0.0820, 0.0548, 0.0664, 0.0747, 0.0540, 0.0548, 0.0666,
        0.0481, 0.0760, 0.0479, 0.0558, 0.0636], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,483][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5480, 0.0179, 0.0378, 0.0047, 0.0259, 0.0238, 0.0679, 0.0328, 0.0394,
        0.0466, 0.0293, 0.0063, 0.0328, 0.0867], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,484][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.7189e-05, 8.6102e-01, 1.0194e-02, 1.8194e-02, 1.6055e-02, 1.5777e-05,
        3.9680e-05, 3.5557e-05, 1.2248e-03, 2.0800e-04, 1.7049e-03, 6.5292e-03,
        2.5337e-02, 5.9415e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,486][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.5395e-05, 9.1915e-01, 2.4842e-02, 7.4414e-04, 3.9202e-02, 4.3750e-07,
        3.2985e-07, 4.8221e-07, 2.9542e-04, 5.8052e-05, 5.6022e-04, 6.3276e-05,
        5.8076e-03, 9.2418e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,487][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0127, 0.0768, 0.0783, 0.1137, 0.0956, 0.0717, 0.0858, 0.0600, 0.0682,
        0.0731, 0.0534, 0.0877, 0.0681, 0.0547], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,489][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0020, 0.0216, 0.0305, 0.0219, 0.0794, 0.0783, 0.0133, 0.1326, 0.0957,
        0.0304, 0.1544, 0.0568, 0.0858, 0.1972], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,491][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1287, 0.0103, 0.0550, 0.0344, 0.0486, 0.0147, 0.0359, 0.1260, 0.0673,
        0.0575, 0.1057, 0.0562, 0.0190, 0.2407], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,492][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.2269e-02, 3.4976e-01, 2.0583e-01, 3.7319e-03, 1.8901e-01, 1.7783e-04,
        1.4557e-04, 2.4503e-04, 5.6085e-03, 2.5904e-03, 1.1791e-02, 5.5523e-04,
        1.1830e-01, 8.9990e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,494][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.1387, 0.0799, 0.0672, 0.0636, 0.0652, 0.0624, 0.0641, 0.0572, 0.0543,
        0.0552, 0.0516, 0.0591, 0.0637, 0.0570, 0.0607], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,496][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0541, 0.0674, 0.0713, 0.0588, 0.0674, 0.0653, 0.0654, 0.0537, 0.0815,
        0.0557, 0.0810, 0.0585, 0.0851, 0.0628, 0.0719], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,497][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0302, 0.0407, 0.0615, 0.0428, 0.0242, 0.1670, 0.0394, 0.1195, 0.2323,
        0.0273, 0.0566, 0.0432, 0.0349, 0.0678, 0.0126], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,499][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([9.8547e-04, 8.8204e-01, 2.0172e-04, 1.7551e-03, 4.6827e-02, 1.0717e-05,
        9.0484e-06, 1.5900e-05, 2.5259e-03, 1.3682e-04, 5.4570e-04, 2.7532e-04,
        6.4214e-03, 1.1438e-02, 4.6813e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,501][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1812, 0.0699, 0.0790, 0.0549, 0.0615, 0.0690, 0.0484, 0.0491, 0.0617,
        0.0443, 0.0683, 0.0472, 0.0572, 0.0599, 0.0484], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,502][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.4655, 0.0201, 0.0565, 0.0059, 0.0271, 0.0242, 0.0848, 0.0373, 0.0300,
        0.0537, 0.0281, 0.0070, 0.0338, 0.0862, 0.0398], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,503][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([9.0931e-05, 6.4476e-01, 1.8032e-02, 3.9549e-02, 1.7694e-02, 2.9680e-05,
        9.0953e-05, 1.2073e-04, 1.9252e-03, 6.4646e-04, 4.5729e-03, 1.3126e-02,
        5.0306e-02, 1.7982e-01, 2.9234e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,505][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([8.8023e-05, 9.2553e-01, 1.7490e-02, 3.9808e-04, 4.9258e-03, 4.8381e-08,
        2.5604e-08, 4.1868e-08, 4.6030e-05, 6.7481e-06, 1.4581e-04, 9.2741e-06,
        6.5595e-04, 3.6612e-03, 4.7042e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,506][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0105, 0.0719, 0.0740, 0.1104, 0.0882, 0.0664, 0.0820, 0.0565, 0.0639,
        0.0706, 0.0507, 0.0850, 0.0661, 0.0526, 0.0511], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,508][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0021, 0.0209, 0.0289, 0.0232, 0.0621, 0.0733, 0.0148, 0.1248, 0.0894,
        0.0299, 0.1292, 0.0561, 0.0634, 0.1839, 0.0980], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,510][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1243, 0.0336, 0.0619, 0.0288, 0.1069, 0.0519, 0.0247, 0.0439, 0.0920,
        0.0491, 0.0673, 0.0443, 0.0459, 0.0717, 0.1538], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,511][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([3.9947e-02, 4.7331e-01, 1.5871e-01, 3.7111e-03, 7.4181e-02, 5.3660e-05,
        7.1066e-05, 6.7287e-05, 1.7094e-03, 1.3434e-03, 5.9431e-03, 2.6373e-04,
        5.1680e-02, 8.1431e-02, 1.0758e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,513][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.1352, 0.0760, 0.0635, 0.0600, 0.0616, 0.0587, 0.0605, 0.0537, 0.0509,
        0.0517, 0.0483, 0.0556, 0.0600, 0.0535, 0.0571, 0.0536],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,515][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0509, 0.0646, 0.0660, 0.0538, 0.0633, 0.0589, 0.0646, 0.0474, 0.0743,
        0.0549, 0.0741, 0.0534, 0.0738, 0.0560, 0.0678, 0.0763],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,516][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0330, 0.0512, 0.0759, 0.0403, 0.0453, 0.1099, 0.0456, 0.1383, 0.1456,
        0.0458, 0.0531, 0.0410, 0.0610, 0.0540, 0.0355, 0.0246],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,518][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ it] are: tensor([1.8491e-03, 5.6008e-01, 6.5811e-05, 6.8671e-04, 1.0851e-01, 6.7233e-06,
        1.5719e-06, 1.1062e-05, 1.3027e-03, 1.8016e-05, 1.0388e-04, 9.2017e-05,
        5.1968e-03, 5.8104e-03, 1.0006e-01, 2.1620e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,519][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.1689, 0.0628, 0.0752, 0.0536, 0.0556, 0.0673, 0.0467, 0.0450, 0.0590,
        0.0405, 0.0682, 0.0463, 0.0520, 0.0536, 0.0469, 0.0583],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,520][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.3771, 0.0214, 0.0564, 0.0063, 0.0266, 0.0308, 0.0587, 0.0329, 0.0416,
        0.0388, 0.0303, 0.0083, 0.0443, 0.1003, 0.0649, 0.0614],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,521][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ it] are: tensor([2.8748e-05, 6.7266e-01, 3.6543e-03, 1.4705e-02, 1.0337e-02, 7.8374e-06,
        1.8764e-05, 2.3688e-05, 5.1180e-04, 1.3738e-04, 7.7527e-04, 4.4329e-03,
        2.4482e-02, 5.6963e-02, 1.8124e-02, 1.9314e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,522][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ it] are: tensor([1.0948e-04, 7.2381e-01, 3.2299e-03, 1.6513e-04, 6.4513e-03, 2.6235e-08,
        1.9630e-08, 2.1529e-08, 2.5114e-05, 1.6465e-06, 2.6431e-05, 7.5315e-06,
        8.7348e-04, 1.6725e-03, 9.7236e-02, 1.6639e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,523][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0107, 0.0683, 0.0672, 0.1006, 0.0838, 0.0629, 0.0762, 0.0538, 0.0606,
        0.0658, 0.0478, 0.0810, 0.0624, 0.0504, 0.0501, 0.0583],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,525][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0009, 0.0153, 0.0200, 0.0157, 0.0543, 0.0685, 0.0098, 0.1166, 0.0832,
        0.0226, 0.1205, 0.0439, 0.0643, 0.1824, 0.1133, 0.0686],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,527][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.1413, 0.0336, 0.0543, 0.0387, 0.0354, 0.0222, 0.0287, 0.0427, 0.1895,
        0.0450, 0.0471, 0.0598, 0.0431, 0.0420, 0.0708, 0.1058],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,528][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ it] are: tensor([6.4009e-02, 4.4072e-01, 9.6879e-02, 3.0552e-03, 5.2693e-02, 5.0469e-05,
        2.4647e-05, 3.4347e-05, 9.9811e-04, 2.5668e-04, 2.2261e-03, 2.1149e-04,
        1.8307e-02, 5.2613e-02, 1.7637e-01, 9.1547e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,530][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1276, 0.0719, 0.0600, 0.0572, 0.0585, 0.0561, 0.0576, 0.0515, 0.0485,
        0.0492, 0.0462, 0.0532, 0.0572, 0.0513, 0.0545, 0.0511, 0.0483],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,532][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0508, 0.0591, 0.0618, 0.0516, 0.0605, 0.0566, 0.0607, 0.0461, 0.0677,
        0.0528, 0.0681, 0.0501, 0.0711, 0.0529, 0.0659, 0.0733, 0.0508],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,533][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0180, 0.0543, 0.0619, 0.0538, 0.0408, 0.1285, 0.0587, 0.0636, 0.2015,
        0.0356, 0.0533, 0.0533, 0.0512, 0.0180, 0.0328, 0.0622, 0.0124],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,535][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.0978e-04, 2.6238e-01, 4.0941e-05, 5.7434e-04, 1.3383e-01, 7.8265e-06,
        1.2146e-06, 6.1116e-06, 1.0882e-03, 3.3768e-05, 8.4769e-05, 6.3399e-05,
        5.1888e-03, 2.6973e-03, 1.0021e-01, 4.8287e-01, 1.0714e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,536][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1560, 0.0579, 0.0693, 0.0469, 0.0558, 0.0633, 0.0454, 0.0467, 0.0567,
        0.0410, 0.0646, 0.0413, 0.0474, 0.0544, 0.0452, 0.0551, 0.0528],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,538][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5237, 0.0151, 0.0282, 0.0038, 0.0174, 0.0162, 0.0522, 0.0218, 0.0259,
        0.0321, 0.0193, 0.0049, 0.0228, 0.0608, 0.0343, 0.0370, 0.0841],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,540][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.5189e-05, 3.8380e-01, 2.9234e-03, 5.7360e-03, 5.8383e-03, 4.6311e-06,
        1.0962e-05, 9.3274e-06, 3.4343e-04, 7.7224e-05, 4.9210e-04, 1.7556e-03,
        7.3679e-03, 1.4983e-02, 8.4448e-03, 4.3125e-01, 1.3693e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,541][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.2526e-05, 2.2818e-01, 4.3815e-03, 9.5419e-05, 4.6914e-03, 2.8846e-08,
        1.9613e-08, 2.4762e-08, 1.9250e-05, 3.4829e-06, 3.2092e-05, 3.1911e-06,
        5.3165e-04, 9.5508e-04, 1.3465e-01, 5.8695e-01, 3.9462e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,543][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0102, 0.0660, 0.0666, 0.0971, 0.0809, 0.0609, 0.0737, 0.0509, 0.0580,
        0.0627, 0.0450, 0.0752, 0.0591, 0.0470, 0.0474, 0.0558, 0.0436],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,545][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0017, 0.0159, 0.0218, 0.0160, 0.0553, 0.0572, 0.0095, 0.0957, 0.0694,
        0.0209, 0.1098, 0.0409, 0.0611, 0.1357, 0.0972, 0.0546, 0.1372],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,546][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0912, 0.0071, 0.0354, 0.0234, 0.0330, 0.0095, 0.0247, 0.0829, 0.0445,
        0.0394, 0.0691, 0.0378, 0.0124, 0.1551, 0.0991, 0.0469, 0.1884],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,548][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.8046e-02, 1.9246e-01, 8.2799e-02, 1.4081e-03, 6.4482e-02, 4.4132e-05,
        3.0087e-05, 4.9831e-05, 1.3268e-03, 5.1488e-04, 2.5332e-03, 1.1935e-04,
        3.4181e-02, 2.5991e-02, 2.8639e-01, 1.1727e-01, 1.6235e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:56,586][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:56,587][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,588][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,588][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,589][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,590][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,591][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,591][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,592][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,593][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,593][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,594][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,595][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:56,595][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.7059, 0.2941], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,596][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.7361, 0.2639], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,597][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,599][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.1425, 0.8575], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,603][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.4357, 0.5643], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,607][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.6032, 0.3968], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,611][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.7988, 0.2012], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,614][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.3609, 0.6391], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,616][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.3586, 0.6414], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,617][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.8688, 0.1312], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,617][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.2995, 0.7005], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,618][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.1587, 0.8413], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:56,619][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5990, 0.1935, 0.2074], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,621][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1773, 0.8184, 0.0043], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,623][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0016, 0.4834, 0.5151], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,627][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0238, 0.0494, 0.9268], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,632][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2845, 0.3732, 0.3423], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,635][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5031, 0.3451, 0.1518], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,639][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0493, 0.9180, 0.0327], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,641][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2121, 0.3917, 0.3961], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,642][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1632, 0.5537, 0.2830], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,643][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3418, 0.5467, 0.1115], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,643][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1507, 0.2707, 0.5786], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,645][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0271, 0.1783, 0.7946], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:56,648][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.5978, 0.1568, 0.1460, 0.0994], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,652][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.4979, 0.3953, 0.0785, 0.0283], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,656][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0007, 0.2421, 0.3058, 0.4513], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,658][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([1.5371e-04, 1.5450e-02, 9.8330e-01, 1.0950e-03], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,662][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.2097, 0.2762, 0.2525, 0.2616], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,666][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.3454, 0.2611, 0.2846, 0.1088], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,666][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0086, 0.9274, 0.0548, 0.0092], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,667][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.1518, 0.2779, 0.2885, 0.2818], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,668][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.1310, 0.3891, 0.3806, 0.0993], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,669][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0248, 0.8660, 0.0979, 0.0113], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,671][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.1234, 0.2899, 0.3594, 0.2273], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,674][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0032, 0.1231, 0.7150, 0.1587], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:56,678][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.5782, 0.1414, 0.1442, 0.0681, 0.0681], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,682][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.1972, 0.7048, 0.0714, 0.0204, 0.0061], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,686][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0004, 0.2072, 0.2522, 0.4228, 0.1173], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,688][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([1.8528e-03, 7.6834e-03, 9.4731e-01, 8.2183e-04, 4.2329e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,691][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.1681, 0.2195, 0.2014, 0.2089, 0.2021], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,691][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.2666, 0.2135, 0.1868, 0.1127, 0.2204], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,692][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0055, 0.8427, 0.1130, 0.0156, 0.0232], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,693][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.1147, 0.2154, 0.2211, 0.2183, 0.2305], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,695][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0930, 0.2696, 0.3501, 0.1356, 0.1518], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,697][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.1528, 0.6558, 0.1454, 0.0058, 0.0401], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,702][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.1160, 0.2284, 0.3596, 0.1769, 0.1189], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,706][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0093, 0.0805, 0.4666, 0.1191, 0.3246], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:56,709][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4675, 0.1242, 0.1265, 0.0677, 0.0514, 0.1627], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,713][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2220, 0.6397, 0.0406, 0.0474, 0.0246, 0.0256], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,715][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.6392e-04, 1.9152e-01, 2.1440e-01, 4.0572e-01, 1.0083e-01, 8.7365e-02],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,716][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0033, 0.0089, 0.6378, 0.0009, 0.1116, 0.2375], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,717][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1382, 0.1828, 0.1670, 0.1733, 0.1674, 0.1714], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,718][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2743, 0.2246, 0.1035, 0.1299, 0.1618, 0.1059], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,718][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.2120e-05, 6.5799e-01, 1.2338e-01, 2.2539e-02, 1.9599e-01, 8.7563e-05],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,720][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0883, 0.1745, 0.1783, 0.1776, 0.1913, 0.1901], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,724][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0699, 0.2986, 0.2179, 0.1066, 0.2035, 0.1035], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,726][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.3455e-04, 6.2399e-01, 1.2827e-01, 1.2098e-02, 2.3488e-01, 4.2048e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,729][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0595, 0.1634, 0.2781, 0.1294, 0.0899, 0.2799], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,733][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0016, 0.0733, 0.2490, 0.0701, 0.2109, 0.3951], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:56,738][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.5029, 0.1339, 0.1107, 0.0511, 0.0376, 0.1041, 0.0597],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,740][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.1053, 0.7182, 0.0839, 0.0381, 0.0188, 0.0344, 0.0013],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,741][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([2.5133e-04, 1.4852e-01, 1.9305e-01, 3.0399e-01, 7.5244e-02, 6.9981e-02,
        2.0896e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,742][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0007, 0.0058, 0.4884, 0.0006, 0.1338, 0.3133, 0.0573],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,742][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1178, 0.1562, 0.1429, 0.1485, 0.1431, 0.1464, 0.1451],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,745][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.1658, 0.1903, 0.0971, 0.0702, 0.2463, 0.1134, 0.1169],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,746][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([7.7875e-06, 6.5747e-01, 1.0350e-01, 2.4967e-02, 2.1387e-01, 1.2672e-04,
        5.0902e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,751][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0745, 0.1454, 0.1525, 0.1479, 0.1637, 0.1676, 0.1485],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,755][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0564, 0.2254, 0.2358, 0.0859, 0.2055, 0.1354, 0.0556],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,757][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([1.9239e-04, 6.2912e-01, 1.2809e-01, 1.4786e-02, 2.2700e-01, 5.4458e-04,
        2.6519e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,760][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0817, 0.1480, 0.2825, 0.0820, 0.0773, 0.1993, 0.1292],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,764][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0006, 0.0370, 0.1935, 0.0515, 0.1278, 0.5016, 0.0880],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:56,765][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.4001, 0.1258, 0.1099, 0.0487, 0.0401, 0.1057, 0.0573, 0.1125],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,766][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2042, 0.5025, 0.0492, 0.0555, 0.0887, 0.0859, 0.0118, 0.0023],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,767][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0003, 0.1383, 0.1627, 0.2444, 0.0696, 0.0566, 0.1856, 0.1427],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,768][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.6120e-03, 1.2307e-03, 2.8177e-01, 4.6367e-04, 3.2882e-02, 8.6250e-02,
        1.7145e-02, 5.7864e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,771][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1036, 0.1358, 0.1244, 0.1293, 0.1250, 0.1280, 0.1268, 0.1271],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,775][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.2223, 0.1911, 0.0859, 0.0921, 0.1447, 0.0924, 0.1268, 0.0448],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,777][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([8.7000e-06, 6.0899e-01, 1.0856e-01, 2.2564e-02, 2.5956e-01, 1.1993e-04,
        5.4682e-05, 1.3761e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,781][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0660, 0.1286, 0.1296, 0.1274, 0.1372, 0.1361, 0.1300, 0.1452],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,785][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0467, 0.2053, 0.1448, 0.0612, 0.1243, 0.1039, 0.0616, 0.2524],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,787][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([3.9258e-04, 3.1774e-01, 2.3272e-01, 1.0490e-02, 4.3690e-01, 8.8536e-04,
        6.0582e-04, 2.7330e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,789][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0578, 0.1345, 0.2185, 0.1063, 0.0565, 0.1536, 0.1128, 0.1601],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,790][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0015, 0.0296, 0.1439, 0.0301, 0.1388, 0.2489, 0.0438, 0.3634],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:56,791][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3537, 0.1008, 0.1017, 0.0510, 0.0405, 0.1059, 0.0515, 0.0713, 0.1236],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,792][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1413, 0.6175, 0.0415, 0.0489, 0.0528, 0.0205, 0.0312, 0.0042, 0.0421],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,793][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.8547e-04, 1.2944e-01, 1.3436e-01, 2.3032e-01, 6.2312e-02, 5.0200e-02,
        1.8803e-01, 1.3019e-01, 7.4965e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,795][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.2607e-03, 1.1590e-03, 5.2445e-02, 1.4635e-04, 6.1102e-03, 1.7490e-02,
        1.0876e-02, 3.1407e-01, 5.9644e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,800][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0917, 0.1211, 0.1107, 0.1151, 0.1108, 0.1136, 0.1126, 0.1127, 0.1117],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,803][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2099, 0.1842, 0.0768, 0.0889, 0.1035, 0.0771, 0.1156, 0.0486, 0.0954],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,805][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.5913e-04, 8.6856e-01, 5.0305e-02, 1.2034e-02, 6.7029e-02, 3.5166e-05,
        1.4518e-05, 5.1607e-05, 1.8079e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,809][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0579, 0.1124, 0.1134, 0.1124, 0.1211, 0.1199, 0.1143, 0.1284, 0.1202],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,813][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0328, 0.1614, 0.1206, 0.0579, 0.1212, 0.0775, 0.0666, 0.3023, 0.0597],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,814][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.3840e-03, 7.4708e-01, 1.0115e-01, 7.1314e-03, 1.3426e-01, 2.0632e-04,
        1.3762e-04, 1.2127e-04, 6.5312e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,815][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0456, 0.1081, 0.1731, 0.0788, 0.0635, 0.1563, 0.0855, 0.0902, 0.1989],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,816][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0005, 0.0212, 0.0959, 0.0175, 0.0761, 0.1326, 0.0200, 0.2239, 0.4124],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:56,817][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.3947, 0.0936, 0.0925, 0.0438, 0.0311, 0.0915, 0.0399, 0.0675, 0.0984,
        0.0471], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,819][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0419, 0.5841, 0.0749, 0.0447, 0.0188, 0.0564, 0.0069, 0.0042, 0.1640,
        0.0042], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,821][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0002, 0.1144, 0.1305, 0.2099, 0.0574, 0.0535, 0.1502, 0.1257, 0.0778,
        0.0806], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,823][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([8.3890e-06, 8.3492e-05, 1.7182e-02, 1.5399e-05, 2.5224e-03, 1.7003e-02,
        4.4653e-03, 1.9818e-01, 7.5946e-01, 1.0837e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,827][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0819, 0.1092, 0.0997, 0.1038, 0.1002, 0.1025, 0.1017, 0.1018, 0.1008,
        0.0983], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,831][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.1489, 0.1433, 0.0955, 0.0610, 0.1411, 0.0807, 0.1153, 0.0435, 0.1207,
        0.0499], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,834][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([1.8304e-05, 8.2649e-01, 5.4132e-02, 1.2725e-02, 1.0272e-01, 3.8488e-05,
        1.3889e-05, 4.6195e-05, 3.5341e-03, 2.7818e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,837][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0504, 0.0994, 0.1022, 0.0988, 0.1086, 0.1103, 0.0994, 0.1186, 0.1109,
        0.1014], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,839][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0311, 0.1194, 0.1176, 0.0541, 0.1081, 0.0782, 0.0493, 0.3134, 0.0627,
        0.0661], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,840][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([8.5236e-04, 7.1931e-01, 9.7706e-02, 8.3165e-03, 1.6160e-01, 2.2947e-04,
        1.0179e-04, 3.0687e-04, 1.0380e-02, 1.2001e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,840][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0493, 0.1144, 0.1490, 0.0700, 0.0526, 0.1344, 0.0887, 0.1119, 0.1375,
        0.0922], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,841][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([2.2676e-04, 9.8755e-03, 5.5039e-02, 1.4392e-02, 4.1552e-02, 1.3001e-01,
        2.3969e-02, 2.2856e-01, 4.8014e-01, 1.6244e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:56,843][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2888, 0.0906, 0.0903, 0.0465, 0.0354, 0.0894, 0.0453, 0.0667, 0.0983,
        0.0406, 0.1082], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,846][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2905, 0.3738, 0.0450, 0.0371, 0.0200, 0.0425, 0.0203, 0.0026, 0.1497,
        0.0037, 0.0146], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,850][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0002, 0.1137, 0.1023, 0.1748, 0.0440, 0.0315, 0.1130, 0.0839, 0.0526,
        0.0622, 0.2217], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,852][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.1634e-03, 4.3401e-04, 3.0102e-02, 1.2009e-04, 2.5444e-03, 1.8275e-02,
        5.5908e-03, 8.3754e-02, 5.5227e-01, 4.1366e-03, 3.0161e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,856][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0748, 0.1000, 0.0911, 0.0948, 0.0912, 0.0935, 0.0930, 0.0928, 0.0920,
        0.0898, 0.0871], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,859][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2049, 0.1440, 0.0697, 0.0642, 0.1040, 0.0776, 0.0935, 0.0354, 0.1184,
        0.0461, 0.0424], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,862][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.6788e-05, 8.1414e-01, 6.1905e-02, 1.7364e-02, 9.9079e-02, 4.3286e-05,
        1.1666e-05, 6.9801e-05, 4.9920e-03, 3.7411e-04, 1.9928e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,864][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0491, 0.0932, 0.0929, 0.0906, 0.0983, 0.0980, 0.0909, 0.1044, 0.0979,
        0.0921, 0.0927], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,864][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0293, 0.1051, 0.0797, 0.0371, 0.0992, 0.0745, 0.0471, 0.1973, 0.0606,
        0.1263, 0.1436], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,865][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.1233e-03, 8.3622e-01, 8.0188e-02, 1.5214e-02, 5.2673e-02, 2.0799e-04,
        8.6085e-05, 5.8870e-05, 9.3535e-03, 1.3629e-03, 2.5138e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,866][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0395, 0.0691, 0.1581, 0.0586, 0.0433, 0.1023, 0.0753, 0.0828, 0.1268,
        0.0663, 0.1780], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,869][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0005, 0.0124, 0.0682, 0.0143, 0.0592, 0.1071, 0.0160, 0.1478, 0.3341,
        0.0130, 0.2275], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:56,872][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.3632, 0.0860, 0.0769, 0.0514, 0.0251, 0.0727, 0.0320, 0.0517, 0.0829,
        0.0267, 0.0896, 0.0417], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,876][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.3029, 0.2107, 0.0590, 0.0163, 0.0417, 0.0580, 0.0124, 0.0405, 0.1573,
        0.0248, 0.0564, 0.0200], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,879][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([2.0629e-04, 8.7772e-02, 9.4298e-02, 1.4250e-01, 3.6518e-02, 2.8705e-02,
        8.2461e-02, 7.9294e-02, 4.7333e-02, 5.0548e-02, 2.1286e-01, 1.3751e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,881][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([9.3066e-06, 1.8929e-04, 1.5619e-02, 8.8592e-06, 4.2684e-03, 1.1277e-02,
        2.4831e-03, 7.4500e-02, 4.3306e-01, 9.7837e-03, 4.4833e-01, 4.7521e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,885][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0676, 0.0917, 0.0834, 0.0869, 0.0834, 0.0856, 0.0852, 0.0850, 0.0843,
        0.0822, 0.0798, 0.0849], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,888][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.1488, 0.0842, 0.0966, 0.0373, 0.1275, 0.0973, 0.0818, 0.0657, 0.1196,
        0.0382, 0.0710, 0.0319], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,888][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([1.0326e-04, 8.9829e-01, 4.0248e-02, 4.7371e-03, 4.1924e-02, 6.6694e-05,
        1.0924e-05, 1.1754e-04, 3.8241e-03, 7.1864e-04, 6.5049e-03, 3.4576e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,889][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0425, 0.0817, 0.0845, 0.0812, 0.0911, 0.0916, 0.0825, 0.0983, 0.0914,
        0.0848, 0.0873, 0.0832], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,890][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0222, 0.0716, 0.0770, 0.0197, 0.0855, 0.0565, 0.0368, 0.2733, 0.0510,
        0.1020, 0.1742, 0.0304], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,892][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([8.7112e-04, 8.2786e-01, 7.5655e-02, 6.3886e-03, 6.6512e-02, 3.0092e-04,
        8.2485e-05, 4.9518e-05, 1.1922e-02, 1.9294e-03, 5.0506e-03, 3.3795e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,894][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0365, 0.0842, 0.1046, 0.0687, 0.0491, 0.1107, 0.0587, 0.0733, 0.1521,
        0.0547, 0.1128, 0.0946], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,897][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([2.6120e-04, 1.0073e-02, 5.2754e-02, 1.0171e-02, 4.0443e-02, 1.0808e-01,
        1.7125e-02, 1.7293e-01, 2.7514e-01, 1.1803e-02, 2.3210e-01, 6.9118e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:56,901][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.3261, 0.0776, 0.0798, 0.0343, 0.0317, 0.0747, 0.0334, 0.0572, 0.0870,
        0.0269, 0.0958, 0.0287, 0.0469], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,905][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.2325, 0.0976, 0.0914, 0.0093, 0.0131, 0.0781, 0.0275, 0.0057, 0.3806,
        0.0036, 0.0438, 0.0101, 0.0067], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,907][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([1.8962e-04, 7.4235e-02, 8.0173e-02, 1.2724e-01, 3.3535e-02, 2.9063e-02,
        8.1273e-02, 7.2850e-02, 4.4586e-02, 5.0301e-02, 1.9736e-01, 1.3263e-01,
        7.6562e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,910][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([1.2844e-04, 1.2316e-04, 2.6001e-02, 1.3285e-05, 1.1871e-03, 5.4715e-03,
        1.9310e-03, 3.5778e-02, 3.0669e-01, 1.9145e-03, 6.0889e-01, 4.5039e-04,
        1.1426e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,913][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0627, 0.0840, 0.0767, 0.0798, 0.0768, 0.0786, 0.0782, 0.0780, 0.0775,
        0.0756, 0.0735, 0.0779, 0.0808], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,915][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.1306, 0.0564, 0.0987, 0.0403, 0.1019, 0.0658, 0.1105, 0.0483, 0.1069,
        0.0559, 0.0495, 0.0332, 0.1020], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,915][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([3.6001e-04, 8.9143e-01, 6.0856e-02, 1.1690e-02, 2.3184e-02, 1.5308e-05,
        8.4302e-06, 2.2101e-05, 1.1288e-03, 1.9063e-04, 3.0042e-03, 2.6757e-03,
        5.4358e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,916][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0411, 0.0768, 0.0780, 0.0758, 0.0812, 0.0829, 0.0754, 0.0889, 0.0830,
        0.0774, 0.0798, 0.0775, 0.0821], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,917][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0304, 0.0820, 0.0804, 0.0303, 0.0702, 0.0567, 0.0396, 0.2277, 0.0436,
        0.0884, 0.1513, 0.0436, 0.0557], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,919][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([2.5267e-02, 6.2129e-01, 2.0523e-01, 3.9978e-03, 1.1271e-01, 2.4315e-04,
        1.7091e-04, 1.3471e-04, 8.4459e-03, 1.0491e-03, 8.9397e-03, 6.3252e-04,
        1.1886e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,921][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0364, 0.0698, 0.1222, 0.0608, 0.0334, 0.0911, 0.0611, 0.0675, 0.1091,
        0.0574, 0.1326, 0.0879, 0.0707], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,926][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0006, 0.0098, 0.0455, 0.0115, 0.0314, 0.0863, 0.0142, 0.1629, 0.2933,
        0.0105, 0.2524, 0.0678, 0.0137], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:56,930][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2555, 0.0740, 0.0726, 0.0401, 0.0311, 0.0763, 0.0370, 0.0560, 0.0813,
        0.0320, 0.0873, 0.0339, 0.0350, 0.0879], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,933][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1567, 0.1929, 0.0183, 0.0591, 0.0315, 0.0315, 0.0253, 0.0045, 0.0690,
        0.0185, 0.0196, 0.0673, 0.3038, 0.0019], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,935][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.5246e-04, 7.3662e-02, 7.3760e-02, 1.1806e-01, 3.0374e-02, 2.2886e-02,
        7.5713e-02, 6.2909e-02, 3.8263e-02, 3.9758e-02, 1.8476e-01, 1.2006e-01,
        7.4511e-02, 8.5134e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,937][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.6684e-04, 5.5787e-06, 1.2943e-03, 4.9330e-07, 3.2390e-04, 6.8638e-04,
        5.4662e-05, 2.7887e-03, 1.7273e-02, 1.3230e-04, 1.9235e-02, 1.5690e-05,
        4.3425e-03, 9.5338e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,939][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0582, 0.0780, 0.0710, 0.0740, 0.0710, 0.0728, 0.0725, 0.0723, 0.0717,
        0.0700, 0.0680, 0.0722, 0.0747, 0.0737], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,940][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1776, 0.1045, 0.0583, 0.0482, 0.0897, 0.0682, 0.0867, 0.0312, 0.0934,
        0.0353, 0.0458, 0.0417, 0.0930, 0.0266], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,941][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4974e-03, 7.6841e-01, 9.8789e-02, 8.4921e-03, 5.3306e-02, 3.7332e-05,
        1.9568e-05, 5.1304e-05, 2.1636e-03, 3.4948e-04, 3.3156e-03, 1.5374e-03,
        1.4224e-02, 4.7806e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,942][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0382, 0.0727, 0.0725, 0.0705, 0.0757, 0.0752, 0.0702, 0.0803, 0.0754,
        0.0711, 0.0717, 0.0702, 0.0761, 0.0801], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,944][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0156, 0.0799, 0.0682, 0.0316, 0.0657, 0.0481, 0.0438, 0.1224, 0.0496,
        0.1133, 0.1652, 0.0477, 0.0895, 0.0594], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,946][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.6106e-02, 4.6332e-01, 1.5137e-01, 9.0778e-03, 1.7976e-01, 2.5870e-04,
        8.4484e-05, 7.3667e-05, 6.1442e-03, 7.2077e-04, 4.0615e-03, 1.8513e-03,
        1.0749e-01, 4.9686e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,950][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0313, 0.0521, 0.1021, 0.0532, 0.0352, 0.0736, 0.0550, 0.0850, 0.0848,
        0.0630, 0.1327, 0.0776, 0.0519, 0.1025], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,953][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0005, 0.0153, 0.0510, 0.0113, 0.0512, 0.0733, 0.0166, 0.1170, 0.2341,
        0.0135, 0.2196, 0.0652, 0.0203, 0.1113], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:56,957][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2632, 0.0603, 0.0737, 0.0360, 0.0303, 0.0723, 0.0288, 0.0512, 0.0736,
        0.0319, 0.0865, 0.0301, 0.0268, 0.0831, 0.0520], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,962][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0734, 0.2756, 0.0503, 0.0513, 0.0169, 0.0513, 0.0052, 0.0114, 0.1557,
        0.0018, 0.0473, 0.0485, 0.1850, 0.0181, 0.0083], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,964][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0002, 0.0678, 0.0690, 0.1075, 0.0285, 0.0239, 0.0693, 0.0594, 0.0369,
        0.0416, 0.1547, 0.1097, 0.0681, 0.0921, 0.0714], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,965][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([1.3099e-04, 4.6946e-06, 1.2860e-03, 3.6959e-07, 6.3468e-05, 2.6653e-04,
        7.8840e-05, 1.7673e-03, 1.1172e-02, 9.3199e-05, 2.0314e-02, 9.7930e-06,
        9.9554e-04, 9.0326e-01, 6.0558e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,966][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0540, 0.0727, 0.0662, 0.0689, 0.0663, 0.0680, 0.0677, 0.0675, 0.0670,
        0.0654, 0.0634, 0.0673, 0.0697, 0.0686, 0.0672], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,967][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1091, 0.0964, 0.0749, 0.0426, 0.1192, 0.0581, 0.0592, 0.0345, 0.0740,
        0.0408, 0.0418, 0.0359, 0.1048, 0.0325, 0.0762], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,968][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([1.9986e-03, 7.6447e-01, 6.6027e-02, 5.9050e-03, 1.8749e-02, 8.6751e-06,
        3.4927e-06, 1.6234e-05, 6.5594e-04, 1.3558e-04, 1.3480e-03, 7.0948e-04,
        9.1232e-03, 6.5573e-02, 6.5276e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,971][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0368, 0.0671, 0.0671, 0.0650, 0.0690, 0.0696, 0.0642, 0.0743, 0.0698,
        0.0657, 0.0669, 0.0650, 0.0697, 0.0745, 0.0753], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,975][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0226, 0.0602, 0.0567, 0.0241, 0.0706, 0.0403, 0.0352, 0.1797, 0.0374,
        0.0787, 0.1293, 0.0371, 0.1076, 0.0842, 0.0364], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,977][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([2.9220e-02, 5.2075e-01, 1.2298e-01, 6.0344e-03, 7.5345e-02, 1.1369e-04,
        4.6647e-05, 5.3341e-05, 3.0378e-03, 5.3973e-04, 2.3540e-03, 7.8468e-04,
        9.2151e-02, 1.0388e-01, 4.2717e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,980][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0341, 0.0590, 0.1014, 0.0423, 0.0398, 0.0897, 0.0404, 0.0612, 0.0871,
        0.0435, 0.1107, 0.0567, 0.0601, 0.0815, 0.0926], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,984][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0008, 0.0079, 0.0354, 0.0096, 0.0269, 0.0532, 0.0109, 0.1127, 0.2038,
        0.0093, 0.2011, 0.0502, 0.0128, 0.2384, 0.0269], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:56,989][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.2501, 0.0606, 0.0691, 0.0315, 0.0261, 0.0723, 0.0294, 0.0443, 0.0829,
        0.0257, 0.0810, 0.0270, 0.0287, 0.0703, 0.0309, 0.0703],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,990][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0598, 0.2746, 0.0458, 0.0224, 0.0187, 0.0189, 0.0204, 0.0046, 0.1416,
        0.0079, 0.0582, 0.0274, 0.0405, 0.0047, 0.0132, 0.2415],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,990][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([1.1151e-04, 6.0810e-02, 6.0316e-02, 1.0499e-01, 2.7113e-02, 2.2492e-02,
        7.2602e-02, 5.6766e-02, 3.4569e-02, 4.1481e-02, 1.4386e-01, 1.1720e-01,
        6.9392e-02, 8.4871e-02, 6.9234e-02, 3.4178e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,991][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([1.2827e-04, 2.6900e-06, 6.2925e-04, 1.7690e-07, 1.4169e-04, 2.7811e-04,
        2.1819e-05, 1.8771e-03, 6.8272e-03, 2.4614e-05, 8.5886e-03, 4.4750e-06,
        1.8039e-03, 6.0238e-01, 1.8180e-01, 1.9550e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,993][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0507, 0.0685, 0.0621, 0.0648, 0.0620, 0.0635, 0.0632, 0.0630, 0.0626,
        0.0610, 0.0593, 0.0630, 0.0652, 0.0643, 0.0629, 0.0640],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,996][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.1048, 0.1084, 0.0596, 0.0412, 0.0589, 0.0599, 0.0594, 0.0285, 0.0977,
        0.0459, 0.0410, 0.0380, 0.0735, 0.0248, 0.0545, 0.1039],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:56,998][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([3.2704e-03, 8.0044e-01, 3.4504e-02, 5.3779e-03, 1.0534e-02, 8.3921e-06,
        2.4762e-06, 1.0806e-05, 3.7996e-04, 6.0307e-05, 6.1415e-04, 5.7381e-04,
        4.2855e-03, 2.5781e-02, 3.6297e-02, 7.7859e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,002][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0336, 0.0626, 0.0622, 0.0605, 0.0658, 0.0652, 0.0608, 0.0697, 0.0650,
        0.0617, 0.0621, 0.0608, 0.0664, 0.0695, 0.0715, 0.0626],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,006][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0158, 0.0717, 0.0525, 0.0259, 0.0565, 0.0394, 0.0314, 0.1623, 0.0281,
        0.0800, 0.1222, 0.0400, 0.0899, 0.0815, 0.0842, 0.0186],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,009][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([5.5403e-02, 5.9149e-01, 4.9214e-02, 2.9830e-03, 5.6566e-02, 7.3401e-05,
        2.2323e-05, 2.1572e-05, 2.0375e-03, 2.6915e-04, 8.7194e-04, 4.0306e-04,
        2.1349e-02, 2.7048e-02, 1.2498e-01, 6.7266e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,013][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0250, 0.0468, 0.0914, 0.0409, 0.0285, 0.0733, 0.0396, 0.0590, 0.1067,
        0.0441, 0.0994, 0.0597, 0.0577, 0.0706, 0.0744, 0.0829],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,014][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([2.2604e-04, 9.0648e-03, 3.1295e-02, 9.5700e-03, 2.4244e-02, 6.0747e-02,
        9.1762e-03, 1.0948e-01, 2.3074e-01, 7.5351e-03, 1.7240e-01, 5.1841e-02,
        1.0983e-02, 2.3040e-01, 2.5885e-02, 1.6413e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,015][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2096, 0.0623, 0.0615, 0.0333, 0.0264, 0.0644, 0.0311, 0.0476, 0.0691,
        0.0272, 0.0740, 0.0282, 0.0305, 0.0743, 0.0335, 0.0473, 0.0797],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,016][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0618, 0.0696, 0.0066, 0.0212, 0.0122, 0.0119, 0.0103, 0.0016, 0.0272,
        0.0070, 0.0073, 0.0240, 0.1076, 0.0007, 0.0186, 0.6117, 0.0006],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,017][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.2163e-04, 6.2680e-02, 6.0887e-02, 1.0112e-01, 2.5781e-02, 1.9520e-02,
        6.6502e-02, 5.1824e-02, 3.1960e-02, 3.4349e-02, 1.5219e-01, 1.0595e-01,
        6.5286e-02, 6.9261e-02, 6.5896e-02, 3.5224e-02, 5.1449e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,019][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.0901e-04, 2.2341e-07, 5.9473e-05, 1.3655e-08, 1.5040e-05, 2.5749e-05,
        1.5158e-06, 1.0068e-04, 6.6572e-04, 4.1123e-06, 7.5179e-04, 3.3816e-07,
        1.4296e-04, 4.0055e-02, 2.8654e-02, 5.8636e-02, 8.7078e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,023][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0474, 0.0640, 0.0583, 0.0606, 0.0581, 0.0597, 0.0595, 0.0592, 0.0589,
        0.0574, 0.0558, 0.0593, 0.0616, 0.0606, 0.0592, 0.0603, 0.0601],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,027][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1514, 0.0892, 0.0447, 0.0402, 0.0693, 0.0549, 0.0702, 0.0249, 0.0759,
        0.0298, 0.0363, 0.0349, 0.0718, 0.0208, 0.0604, 0.1041, 0.0213],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,029][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.3552e-03, 4.4887e-01, 3.7205e-02, 3.1386e-03, 1.7933e-02, 8.5323e-06,
        4.2319e-06, 9.9226e-06, 4.7513e-04, 8.8972e-05, 6.2873e-04, 3.2761e-04,
        3.7079e-03, 1.3472e-02, 4.5297e-02, 2.7773e-01, 1.4875e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,033][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0313, 0.0591, 0.0587, 0.0572, 0.0610, 0.0606, 0.0570, 0.0646, 0.0608,
        0.0576, 0.0579, 0.0568, 0.0616, 0.0646, 0.0668, 0.0591, 0.0651],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,037][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0129, 0.0704, 0.0559, 0.0273, 0.0578, 0.0420, 0.0411, 0.1015, 0.0424,
        0.1029, 0.1382, 0.0415, 0.0748, 0.0502, 0.0620, 0.0359, 0.0430],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,038][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.2454e-02, 2.5730e-01, 7.7172e-02, 3.8858e-03, 6.6243e-02, 7.8585e-05,
        2.0468e-05, 1.9056e-05, 1.8275e-03, 1.8904e-04, 1.1094e-03, 4.8477e-04,
        3.3035e-02, 1.5411e-02, 2.6191e-01, 1.6313e-01, 8.5730e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,039][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0257, 0.0405, 0.0813, 0.0422, 0.0274, 0.0578, 0.0431, 0.0677, 0.0674,
        0.0498, 0.1049, 0.0616, 0.0403, 0.0822, 0.0715, 0.0585, 0.0782],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,040][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0005, 0.0136, 0.0429, 0.0095, 0.0453, 0.0568, 0.0132, 0.0943, 0.2037,
        0.0119, 0.1750, 0.0509, 0.0183, 0.0910, 0.0430, 0.0154, 0.1146],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,044][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:22:57,046][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15637],
        [ 6539],
        [14814],
        [ 3929],
        [10909],
        [ 5593],
        [ 9978],
        [12733],
        [ 7089],
        [ 9269],
        [10640],
        [ 6639],
        [17748],
        [ 5116],
        [ 5973],
        [ 9135],
        [ 6773]], device='cuda:0')
[2024-07-24 10:22:57,048][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16145],
        [13725],
        [23851],
        [12105],
        [30804],
        [17354],
        [17060],
        [18502],
        [18674],
        [29641],
        [19975],
        [14866],
        [33714],
        [15175],
        [14436],
        [18967],
        [14908]], device='cuda:0')
[2024-07-24 10:22:57,051][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[24519],
        [23871],
        [24141],
        [24428],
        [24271],
        [24255],
        [24080],
        [24060],
        [23964],
        [23846],
        [23808],
        [23821],
        [23850],
        [24004],
        [24032],
        [24091],
        [24127]], device='cuda:0')
[2024-07-24 10:22:57,053][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20818],
        [18369],
        [21205],
        [18812],
        [18928],
        [17765],
        [17474],
        [18209],
        [18119],
        [17670],
        [18520],
        [17769],
        [18852],
        [19225],
        [20022],
        [19447],
        [19749]], device='cuda:0')
[2024-07-24 10:22:57,056][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[38177],
        [31919],
        [25956],
        [24375],
        [24289],
        [24844],
        [26118],
        [27664],
        [27399],
        [28018],
        [27317],
        [26539],
        [27308],
        [25838],
        [28719],
        [28839],
        [25718]], device='cuda:0')
[2024-07-24 10:22:57,059][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[20467],
        [ 8887],
        [ 8610],
        [ 8617],
        [ 8753],
        [10032],
        [10804],
        [13023],
        [ 9026],
        [10851],
        [ 9040],
        [10230],
        [10351],
        [11614],
        [ 9984],
        [13456],
        [17100]], device='cuda:0')
[2024-07-24 10:22:57,061][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[25058],
        [25581],
        [25812],
        [26316],
        [27555],
        [28530],
        [27903],
        [28370],
        [28398],
        [28620],
        [28280],
        [28388],
        [28460],
        [28579],
        [28876],
        [28861],
        [28966]], device='cuda:0')
[2024-07-24 10:22:57,064][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[11229],
        [15482],
        [12601],
        [20627],
        [17280],
        [14414],
        [21346],
        [22956],
        [17244],
        [25616],
        [21031],
        [25450],
        [23878],
        [13621],
        [14200],
        [11734],
        [ 9554]], device='cuda:0')
[2024-07-24 10:22:57,066][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15532],
        [42878],
        [43526],
        [43522],
        [43529],
        [43336],
        [43351],
        [43279],
        [43492],
        [43539],
        [43488],
        [43478],
        [43288],
        [43364],
        [42845],
        [43883],
        [43537]], device='cuda:0')
[2024-07-24 10:22:57,068][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[5557],
        [3719],
        [5259],
        [5258],
        [5200],
        [4301],
        [4366],
        [4519],
        [4767],
        [4915],
        [4656],
        [4356],
        [5116],
        [4956],
        [5168],
        [4442],
        [5290]], device='cuda:0')
[2024-07-24 10:22:57,069][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14322],
        [ 8253],
        [ 7883],
        [ 7404],
        [ 7739],
        [ 7342],
        [ 7644],
        [ 7528],
        [ 7432],
        [ 7532],
        [ 7472],
        [ 7366],
        [ 7444],
        [ 7398],
        [ 7359],
        [ 7269],
        [ 7282]], device='cuda:0')
[2024-07-24 10:22:57,071][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[45485],
        [48574],
        [48144],
        [48299],
        [48180],
        [47873],
        [47845],
        [47759],
        [47704],
        [47712],
        [47929],
        [48015],
        [47970],
        [47848],
        [47895],
        [47813],
        [47824]], device='cuda:0')
[2024-07-24 10:22:57,074][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[7023],
        [6002],
        [2053],
        [5101],
        [2774],
        [2603],
        [2418],
        [2602],
        [4374],
        [4426],
        [3033],
        [5364],
        [5304],
        [3195],
        [4466],
        [4863],
        [2979]], device='cuda:0')
[2024-07-24 10:22:57,076][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[40566],
        [40358],
        [38202],
        [32470],
        [38001],
        [31572],
        [32266],
        [27097],
        [32634],
        [31945],
        [33500],
        [31244],
        [38742],
        [32593],
        [34911],
        [32434],
        [32045]], device='cuda:0')
[2024-07-24 10:22:57,079][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25262],
        [22669],
        [ 9885],
        [ 3290],
        [ 5139],
        [ 9166],
        [14579],
        [12654],
        [10135],
        [ 2942],
        [ 6363],
        [ 9219],
        [12522],
        [ 7679],
        [ 9000],
        [14907],
        [ 9355]], device='cuda:0')
[2024-07-24 10:22:57,082][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26346],
        [26395],
        [28194],
        [28256],
        [28348],
        [29040],
        [28435],
        [29114],
        [29764],
        [29544],
        [30487],
        [30140],
        [30334],
        [30605],
        [30502],
        [30657],
        [30656]], device='cuda:0')
[2024-07-24 10:22:57,084][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26037],
        [32866],
        [47042],
        [36076],
        [45243],
        [44063],
        [46380],
        [39893],
        [44664],
        [44348],
        [38172],
        [33603],
        [29639],
        [28420],
        [34027],
        [40074],
        [42498]], device='cuda:0')
[2024-07-24 10:22:57,087][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28349],
        [34381],
        [32679],
        [35279],
        [35425],
        [35155],
        [34721],
        [33557],
        [33029],
        [32542],
        [31933],
        [32039],
        [31704],
        [32286],
        [32336],
        [32007],
        [32025]], device='cuda:0')
[2024-07-24 10:22:57,089][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[19792],
        [24851],
        [12514],
        [11763],
        [11748],
        [14687],
        [16873],
        [18968],
        [16642],
        [16367],
        [16620],
        [16689],
        [16597],
        [18040],
        [18043],
        [14445],
        [16851]], device='cuda:0')
[2024-07-24 10:22:57,092][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30136],
        [30797],
        [31700],
        [32261],
        [32711],
        [33045],
        [33210],
        [33503],
        [33710],
        [33831],
        [33912],
        [34048],
        [34007],
        [34119],
        [34155],
        [34161],
        [34171]], device='cuda:0')
[2024-07-24 10:22:57,095][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[2324],
        [4035],
        [6116],
        [9898],
        [6933],
        [6278],
        [6113],
        [6867],
        [6751],
        [6622],
        [6389],
        [6801],
        [7155],
        [6716],
        [7255],
        [6465],
        [5781]], device='cuda:0')
[2024-07-24 10:22:57,096][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40930],
        [39806],
        [23459],
        [23208],
        [25645],
        [31751],
        [31863],
        [33124],
        [25369],
        [26888],
        [27082],
        [24315],
        [24482],
        [28423],
        [29891],
        [27174],
        [33554]], device='cuda:0')
[2024-07-24 10:22:57,098][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27205],
        [24044],
        [24039],
        [23962],
        [23570],
        [23365],
        [23212],
        [23158],
        [23094],
        [22984],
        [22986],
        [23021],
        [22964],
        [22986],
        [22972],
        [22962],
        [22985]], device='cuda:0')
[2024-07-24 10:22:57,099][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10217],
        [21622],
        [19601],
        [17046],
        [15861],
        [16650],
        [16533],
        [18379],
        [17782],
        [17782],
        [17329],
        [16879],
        [16436],
        [15788],
        [15946],
        [16815],
        [16393]], device='cuda:0')
[2024-07-24 10:22:57,102][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[3960],
        [4487],
        [2653],
        [2724],
        [2098],
        [1692],
        [1702],
        [1435],
        [2083],
        [1977],
        [2514],
        [2465],
        [1460],
        [ 818],
        [1111],
        [2456],
        [1607]], device='cuda:0')
[2024-07-24 10:22:57,105][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[16136],
        [22840],
        [20641],
        [23800],
        [23682],
        [25245],
        [24075],
        [24147],
        [23865],
        [24148],
        [22447],
        [24297],
        [24237],
        [23715],
        [23860],
        [23687],
        [23549]], device='cuda:0')
[2024-07-24 10:22:57,107][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[38276],
        [43884],
        [46677],
        [46786],
        [46154],
        [46377],
        [46488],
        [47141],
        [47174],
        [47159],
        [48008],
        [48082],
        [48147],
        [48052],
        [47980],
        [47812],
        [47692]], device='cuda:0')
[2024-07-24 10:22:57,110][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22894],
        [16350],
        [22163],
        [21807],
        [22622],
        [21711],
        [20974],
        [20484],
        [21192],
        [21367],
        [20517],
        [20905],
        [22126],
        [23837],
        [22261],
        [21450],
        [20456]], device='cuda:0')
[2024-07-24 10:22:57,112][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33939],
        [21009],
        [29261],
        [25197],
        [19333],
        [16848],
        [18942],
        [27913],
        [20007],
        [18371],
        [35091],
        [22042],
        [24627],
        [28617],
        [25357],
        [24471],
        [25530]], device='cuda:0')
[2024-07-24 10:22:57,115][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180],
        [10180]], device='cuda:0')
[2024-07-24 10:22:57,160][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:57,161][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,161][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,162][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,163][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,164][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,164][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,165][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,167][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,170][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,172][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,176][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,178][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,182][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.3680, 0.6320], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,185][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.3553, 0.6447], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,186][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.7219, 0.2781], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,187][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.2245, 0.7755], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,187][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.6612, 0.3388], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,188][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.7853, 0.2147], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,190][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.3086, 0.6914], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,193][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.2315, 0.7685], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,197][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.5597, 0.4403], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,201][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0451, 0.9549], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,205][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.5674, 0.4326], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,208][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.8127, 0.1873], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,210][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1642, 0.3907, 0.4450], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,210][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2139, 0.4074, 0.3787], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,211][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4487, 0.2459, 0.3054], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,212][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0678, 0.5337, 0.3985], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,213][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4817, 0.2528, 0.2655], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,216][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6278, 0.2030, 0.1693], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,219][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1672, 0.4215, 0.4113], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,223][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1251, 0.4546, 0.4203], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,227][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4186, 0.3016, 0.2798], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,230][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0181, 0.6224, 0.3595], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,234][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4014, 0.2780, 0.3206], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,235][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.0666e-12, 1.0000e+00, 1.7261e-06], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,236][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.1125, 0.2390, 0.3174, 0.3311], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,236][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.1536, 0.2938, 0.2724, 0.2801], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,237][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.4337, 0.1694, 0.2097, 0.1872], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,239][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0590, 0.3450, 0.2547, 0.3413], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,243][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.3776, 0.1985, 0.2086, 0.2153], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,246][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.5859, 0.1689, 0.1414, 0.1038], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,250][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.1194, 0.2982, 0.3010, 0.2813], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,254][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0915, 0.3086, 0.2851, 0.3148], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,257][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.3016, 0.2013, 0.1779, 0.3192], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,259][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0194, 0.3806, 0.2346, 0.3655], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,260][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.3068, 0.2077, 0.2328, 0.2527], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,261][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ William] are: tensor([5.2516e-11, 1.0000e+00, 2.3103e-07, 2.8728e-08], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,262][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.1063, 0.1731, 0.2299, 0.2712, 0.2196], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,263][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.1219, 0.2316, 0.2155, 0.2219, 0.2091], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,266][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.2865, 0.1402, 0.1883, 0.1639, 0.2211], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,270][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0305, 0.2727, 0.2026, 0.2607, 0.2334], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,274][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.3148, 0.1644, 0.1727, 0.1783, 0.1698], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,277][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.5183, 0.1538, 0.1265, 0.0921, 0.1093], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,282][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0947, 0.2295, 0.2314, 0.2240, 0.2203], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,284][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0715, 0.2360, 0.2185, 0.2410, 0.2330], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,285][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.2068, 0.1442, 0.1372, 0.2430, 0.2686], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,285][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0102, 0.2888, 0.1900, 0.3273, 0.1837], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,286][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.2378, 0.1496, 0.1746, 0.1904, 0.2475], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,287][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ got] are: tensor([6.0023e-14, 9.9998e-01, 5.8881e-07, 1.4528e-05, 4.0664e-07],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,289][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0639, 0.1553, 0.1886, 0.2195, 0.2032, 0.1695], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,291][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1023, 0.1902, 0.1760, 0.1813, 0.1714, 0.1788], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,296][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1987, 0.1570, 0.1754, 0.1555, 0.2148, 0.0985], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,300][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0450, 0.2022, 0.1539, 0.1912, 0.1695, 0.2382], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,303][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2722, 0.1414, 0.1489, 0.1536, 0.1461, 0.1377], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,307][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4625, 0.1426, 0.1166, 0.0871, 0.1029, 0.0883], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,309][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0736, 0.1861, 0.1882, 0.1850, 0.1826, 0.1844], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,310][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0609, 0.1894, 0.1746, 0.1918, 0.1855, 0.1978], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,311][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1728, 0.1282, 0.1175, 0.2022, 0.2283, 0.1510], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,312][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0082, 0.2536, 0.1411, 0.2814, 0.1694, 0.1462], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,314][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1692, 0.1550, 0.1496, 0.1933, 0.1863, 0.1465], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,316][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.3780e-17, 9.9988e-01, 4.4739e-08, 4.0656e-07, 1.1509e-04, 2.9806e-16],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,320][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0635, 0.1201, 0.1593, 0.1869, 0.1593, 0.1614, 0.1495],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,324][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0863, 0.1615, 0.1499, 0.1534, 0.1453, 0.1522, 0.1515],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,327][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.1932, 0.1347, 0.1552, 0.1339, 0.1859, 0.0875, 0.1097],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,331][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0331, 0.1574, 0.1235, 0.1538, 0.1367, 0.1988, 0.1966],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,334][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.2359, 0.1230, 0.1294, 0.1336, 0.1269, 0.1194, 0.1319],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,334][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.4288, 0.1305, 0.1057, 0.0784, 0.0924, 0.0798, 0.0845],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,335][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0629, 0.1561, 0.1589, 0.1511, 0.1547, 0.1566, 0.1597],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,336][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0502, 0.1578, 0.1453, 0.1607, 0.1550, 0.1628, 0.1682],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,338][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.1545, 0.0974, 0.0939, 0.1633, 0.1831, 0.1190, 0.1889],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,341][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0109, 0.1988, 0.1258, 0.2083, 0.1480, 0.1552, 0.1530],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,345][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.1484, 0.1178, 0.1135, 0.1479, 0.1529, 0.1223, 0.1972],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,347][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([1.2024e-20, 9.9963e-01, 4.5313e-09, 3.7646e-07, 3.7049e-04, 3.1048e-14,
        1.6260e-16], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,351][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0528, 0.1022, 0.1275, 0.1518, 0.1412, 0.1454, 0.1404, 0.1387],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,354][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0792, 0.1400, 0.1301, 0.1333, 0.1267, 0.1322, 0.1309, 0.1277],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,358][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1499, 0.1239, 0.1370, 0.1258, 0.1726, 0.0853, 0.1023, 0.1032],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,359][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0226, 0.1363, 0.1060, 0.1333, 0.1180, 0.1641, 0.1634, 0.1563],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,360][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2086, 0.1097, 0.1153, 0.1190, 0.1132, 0.1061, 0.1173, 0.1107],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,361][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.3654, 0.1242, 0.1036, 0.0770, 0.0909, 0.0803, 0.0850, 0.0736],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,363][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0543, 0.1352, 0.1360, 0.1312, 0.1334, 0.1366, 0.1421, 0.1312],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,366][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0474, 0.1346, 0.1246, 0.1354, 0.1316, 0.1400, 0.1416, 0.1447],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,370][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1139, 0.0873, 0.0858, 0.1421, 0.1635, 0.1070, 0.1632, 0.1371],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,374][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0043, 0.1958, 0.1042, 0.1814, 0.1346, 0.1276, 0.1376, 0.1145],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,377][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1419, 0.1139, 0.1087, 0.1393, 0.1073, 0.1054, 0.1448, 0.1385],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,379][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.4299e-17, 9.9994e-01, 2.6260e-07, 6.1304e-07, 5.9267e-05, 5.1016e-17,
        4.7511e-16, 7.0581e-15], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,383][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0416, 0.1007, 0.1148, 0.1403, 0.1233, 0.1041, 0.1159, 0.1444, 0.1148],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,384][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0700, 0.1245, 0.1148, 0.1187, 0.1122, 0.1165, 0.1158, 0.1123, 0.1150],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,385][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1431, 0.1117, 0.1263, 0.1155, 0.1582, 0.0769, 0.0907, 0.0924, 0.0853],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,386][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0250, 0.1160, 0.0905, 0.1137, 0.1032, 0.1403, 0.1410, 0.1375, 0.1328],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,388][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1874, 0.0976, 0.1028, 0.1060, 0.1008, 0.0947, 0.1047, 0.0987, 0.1072],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,391][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3552, 0.1155, 0.0941, 0.0703, 0.0828, 0.0730, 0.0774, 0.0676, 0.0640],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,395][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0463, 0.1187, 0.1195, 0.1158, 0.1174, 0.1199, 0.1257, 0.1185, 0.1183],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,399][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0415, 0.1175, 0.1080, 0.1184, 0.1148, 0.1228, 0.1240, 0.1262, 0.1267],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,402][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1035, 0.0774, 0.0746, 0.1247, 0.1427, 0.0955, 0.1449, 0.1215, 0.1152],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,406][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0059, 0.1666, 0.0947, 0.1786, 0.1125, 0.1030, 0.1294, 0.1188, 0.0903],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,408][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1284, 0.0914, 0.1012, 0.1196, 0.1291, 0.0972, 0.1181, 0.1116, 0.1034],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,409][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.3044e-13, 9.9992e-01, 1.2343e-07, 2.2438e-07, 7.5376e-05, 2.8445e-17,
        4.6601e-18, 1.2483e-14, 6.5338e-10], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,410][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0472, 0.0893, 0.1016, 0.1252, 0.0968, 0.1046, 0.0954, 0.1326, 0.1107,
        0.0966], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,411][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0614, 0.1117, 0.1034, 0.1060, 0.1010, 0.1049, 0.1042, 0.1015, 0.1038,
        0.1021], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,413][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.1312, 0.0978, 0.1198, 0.1095, 0.1532, 0.0689, 0.0854, 0.0851, 0.0775,
        0.0716], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,416][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0197, 0.1003, 0.0772, 0.0989, 0.0891, 0.1256, 0.1241, 0.1194, 0.1183,
        0.1274], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,420][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.1704, 0.0878, 0.0928, 0.0956, 0.0909, 0.0855, 0.0944, 0.0892, 0.0969,
        0.0965], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,424][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.3405, 0.1076, 0.0876, 0.0655, 0.0769, 0.0675, 0.0703, 0.0618, 0.0586,
        0.0636], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,427][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0426, 0.1045, 0.1074, 0.1032, 0.1053, 0.1065, 0.1127, 0.1051, 0.1074,
        0.1054], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,431][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0363, 0.1038, 0.0954, 0.1052, 0.1017, 0.1069, 0.1101, 0.1119, 0.1112,
        0.1175], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,433][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0932, 0.0603, 0.0635, 0.1057, 0.1199, 0.0791, 0.1188, 0.1001, 0.0934,
        0.1660], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,434][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0065, 0.1344, 0.0864, 0.1470, 0.0951, 0.1076, 0.1204, 0.1119, 0.0916,
        0.0990], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,435][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.1099, 0.0932, 0.0816, 0.1099, 0.0943, 0.0943, 0.1105, 0.0808, 0.0887,
        0.1368], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,435][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ house] are: tensor([6.3028e-15, 1.0000e+00, 6.5566e-09, 6.0705e-08, 1.7106e-06, 2.5282e-17,
        3.2287e-18, 2.6331e-16, 9.0395e-10, 4.7609e-12], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,437][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0326, 0.0790, 0.0892, 0.1140, 0.0981, 0.0946, 0.0959, 0.1136, 0.1031,
        0.0953, 0.0846], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,440][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0573, 0.1016, 0.0933, 0.0965, 0.0912, 0.0945, 0.0941, 0.0914, 0.0938,
        0.0924, 0.0940], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,444][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1092, 0.0940, 0.1019, 0.0936, 0.1202, 0.0673, 0.0762, 0.0799, 0.0753,
        0.0686, 0.1138], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,448][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0170, 0.0939, 0.0719, 0.0920, 0.0831, 0.1112, 0.1092, 0.1062, 0.1052,
        0.1141, 0.0960], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,451][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1522, 0.0803, 0.0843, 0.0870, 0.0828, 0.0777, 0.0859, 0.0810, 0.0879,
        0.0876, 0.0933], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,455][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2966, 0.1015, 0.0835, 0.0632, 0.0742, 0.0656, 0.0690, 0.0608, 0.0571,
        0.0620, 0.0666], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,458][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0387, 0.0939, 0.0953, 0.0936, 0.0947, 0.0962, 0.1016, 0.0949, 0.0963,
        0.0969, 0.0979], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,458][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0314, 0.0930, 0.0854, 0.0936, 0.0909, 0.0970, 0.0982, 0.1002, 0.1005,
        0.1047, 0.1051], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,459][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0790, 0.0585, 0.0567, 0.0941, 0.1045, 0.0724, 0.1061, 0.0922, 0.0876,
        0.1464, 0.1025], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,460][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0032, 0.1481, 0.0819, 0.1487, 0.0969, 0.0912, 0.1081, 0.0951, 0.0805,
        0.0976, 0.0486], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,462][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1097, 0.0763, 0.0803, 0.1035, 0.0925, 0.0797, 0.1000, 0.0875, 0.0799,
        0.1081, 0.0824], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,464][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.2318e-14, 1.0000e+00, 2.2761e-09, 6.8884e-07, 1.2682e-06, 1.2967e-17,
        2.5380e-17, 3.0807e-15, 2.5628e-10, 2.4591e-09, 3.7147e-09],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,468][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0353, 0.0631, 0.0845, 0.0848, 0.0793, 0.0921, 0.0807, 0.1161, 0.0967,
        0.0757, 0.0886, 0.1030], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,471][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0510, 0.0919, 0.0851, 0.0874, 0.0832, 0.0862, 0.0858, 0.0835, 0.0855,
        0.0844, 0.0854, 0.0907], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,475][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.1259, 0.0823, 0.0921, 0.0814, 0.1033, 0.0547, 0.0678, 0.0667, 0.0650,
        0.0587, 0.1019, 0.1004], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,480][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0197, 0.0770, 0.0590, 0.0761, 0.0707, 0.1001, 0.0989, 0.0954, 0.0948,
        0.1017, 0.0868, 0.1198], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,482][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.1405, 0.0727, 0.0767, 0.0792, 0.0751, 0.0707, 0.0783, 0.0739, 0.0802,
        0.0798, 0.0851, 0.0878], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,483][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.3062, 0.0926, 0.0768, 0.0564, 0.0675, 0.0595, 0.0615, 0.0555, 0.0519,
        0.0561, 0.0613, 0.0547], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,484][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0350, 0.0870, 0.0884, 0.0824, 0.0868, 0.0880, 0.0919, 0.0870, 0.0879,
        0.0895, 0.0916, 0.0845], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,485][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0323, 0.0844, 0.0770, 0.0850, 0.0822, 0.0871, 0.0888, 0.0905, 0.0903,
        0.0941, 0.0947, 0.0936], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,487][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0760, 0.0540, 0.0487, 0.0835, 0.0916, 0.0636, 0.0941, 0.0806, 0.0768,
        0.1292, 0.0879, 0.1141], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,490][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0058, 0.1192, 0.0736, 0.1149, 0.0905, 0.0859, 0.0996, 0.0844, 0.0722,
        0.0944, 0.0504, 0.1093], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,493][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.1038, 0.0656, 0.0779, 0.0808, 0.0890, 0.0759, 0.0980, 0.0785, 0.0762,
        0.0935, 0.0806, 0.0802], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,496][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ William] are: tensor([9.2995e-11, 1.0000e+00, 1.1258e-09, 1.0532e-10, 2.3983e-06, 3.4464e-16,
        1.2464e-18, 1.8730e-15, 1.5890e-08, 1.1913e-09, 9.4328e-07, 2.9190e-08],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:57,500][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0337, 0.0587, 0.0770, 0.0914, 0.0694, 0.0759, 0.0758, 0.1056, 0.0814,
        0.0757, 0.0776, 0.1077, 0.0700], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,504][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0487, 0.0842, 0.0777, 0.0801, 0.0759, 0.0790, 0.0785, 0.0764, 0.0784,
        0.0773, 0.0786, 0.0836, 0.0818], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,506][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1112, 0.0674, 0.0885, 0.0719, 0.0984, 0.0472, 0.0634, 0.0613, 0.0546,
        0.0500, 0.0921, 0.0906, 0.1034], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,507][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0137, 0.0744, 0.0584, 0.0693, 0.0626, 0.0881, 0.0880, 0.0869, 0.0858,
        0.0925, 0.0810, 0.1075, 0.0918], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,508][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1311, 0.0677, 0.0712, 0.0735, 0.0699, 0.0656, 0.0724, 0.0683, 0.0742,
        0.0740, 0.0788, 0.0813, 0.0720], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,509][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.2832, 0.0871, 0.0731, 0.0538, 0.0639, 0.0562, 0.0596, 0.0519, 0.0491,
        0.0534, 0.0589, 0.0518, 0.0580], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,511][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0355, 0.0788, 0.0793, 0.0776, 0.0769, 0.0793, 0.0853, 0.0792, 0.0802,
        0.0814, 0.0827, 0.0801, 0.0838], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,514][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0266, 0.0770, 0.0710, 0.0780, 0.0754, 0.0796, 0.0819, 0.0832, 0.0827,
        0.0869, 0.0872, 0.0856, 0.0850], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,518][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0670, 0.0468, 0.0448, 0.0760, 0.0812, 0.0575, 0.0886, 0.0745, 0.0691,
        0.1186, 0.0794, 0.1016, 0.0949], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,522][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0042, 0.1053, 0.0708, 0.1149, 0.0762, 0.0748, 0.0885, 0.0867, 0.0676,
        0.0786, 0.0457, 0.1085, 0.0783], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,525][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0867, 0.0632, 0.0740, 0.0753, 0.0895, 0.0671, 0.0869, 0.0850, 0.0740,
        0.0728, 0.0691, 0.0734, 0.0829], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,527][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([7.4102e-12, 1.0000e+00, 1.0544e-08, 1.3300e-08, 5.4405e-07, 4.4665e-18,
        2.2476e-19, 7.3636e-17, 4.9271e-11, 1.6677e-12, 3.3959e-08, 4.6332e-08,
        2.3175e-07], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:57,531][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0255, 0.0549, 0.0661, 0.0810, 0.0760, 0.0737, 0.0740, 0.0781, 0.0789,
        0.0672, 0.0670, 0.0951, 0.0836, 0.0789], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,532][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0451, 0.0777, 0.0717, 0.0738, 0.0701, 0.0729, 0.0723, 0.0706, 0.0725,
        0.0714, 0.0729, 0.0773, 0.0757, 0.0761], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,533][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0967, 0.0691, 0.0816, 0.0677, 0.0902, 0.0471, 0.0580, 0.0585, 0.0530,
        0.0513, 0.0818, 0.0789, 0.0927, 0.0735], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,534][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0133, 0.0690, 0.0543, 0.0665, 0.0594, 0.0805, 0.0800, 0.0783, 0.0760,
        0.0838, 0.0725, 0.0972, 0.0837, 0.0855], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,536][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1210, 0.0633, 0.0664, 0.0686, 0.0652, 0.0611, 0.0675, 0.0636, 0.0691,
        0.0689, 0.0733, 0.0756, 0.0670, 0.0695], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,539][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2522, 0.0860, 0.0708, 0.0526, 0.0608, 0.0542, 0.0565, 0.0495, 0.0475,
        0.0511, 0.0553, 0.0502, 0.0557, 0.0577], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,543][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0299, 0.0722, 0.0738, 0.0719, 0.0726, 0.0739, 0.0783, 0.0742, 0.0742,
        0.0756, 0.0762, 0.0736, 0.0795, 0.0742], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,547][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0246, 0.0710, 0.0656, 0.0711, 0.0692, 0.0742, 0.0748, 0.0765, 0.0768,
        0.0792, 0.0803, 0.0778, 0.0777, 0.0813], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,551][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0604, 0.0441, 0.0415, 0.0703, 0.0766, 0.0555, 0.0809, 0.0690, 0.0667,
        0.1109, 0.0759, 0.0969, 0.0907, 0.0606], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,556][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0028, 0.1080, 0.0602, 0.1120, 0.0657, 0.0736, 0.0863, 0.0749, 0.0608,
        0.0722, 0.0395, 0.1046, 0.0865, 0.0528], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,556][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0812, 0.0565, 0.0647, 0.0783, 0.0727, 0.0629, 0.0737, 0.0760, 0.0636,
        0.0792, 0.0607, 0.0796, 0.0681, 0.0827], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,557][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.5896e-12, 9.9994e-01, 4.3039e-09, 7.0647e-08, 8.3916e-07, 9.3631e-20,
        9.3822e-19, 1.9262e-18, 2.0606e-12, 2.4578e-11, 5.8250e-09, 2.4647e-08,
        5.7612e-05, 2.0714e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:57,558][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0309, 0.0477, 0.0626, 0.0723, 0.0672, 0.0699, 0.0575, 0.0857, 0.0745,
        0.0621, 0.0648, 0.0856, 0.0694, 0.0856, 0.0642], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,560][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0413, 0.0725, 0.0670, 0.0686, 0.0653, 0.0678, 0.0673, 0.0657, 0.0675,
        0.0664, 0.0678, 0.0718, 0.0705, 0.0708, 0.0695], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,563][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0851, 0.0580, 0.0733, 0.0573, 0.0813, 0.0409, 0.0546, 0.0542, 0.0488,
        0.0462, 0.0799, 0.0754, 0.0868, 0.0686, 0.0895], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,567][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0124, 0.0654, 0.0507, 0.0615, 0.0540, 0.0732, 0.0735, 0.0722, 0.0702,
        0.0760, 0.0668, 0.0892, 0.0760, 0.0786, 0.0804], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,571][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1140, 0.0590, 0.0621, 0.0641, 0.0608, 0.0571, 0.0630, 0.0594, 0.0646,
        0.0643, 0.0687, 0.0708, 0.0625, 0.0651, 0.0643], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,574][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.2489, 0.0809, 0.0661, 0.0492, 0.0564, 0.0500, 0.0523, 0.0456, 0.0436,
        0.0471, 0.0518, 0.0462, 0.0515, 0.0540, 0.0564], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,578][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0291, 0.0677, 0.0690, 0.0665, 0.0670, 0.0689, 0.0728, 0.0685, 0.0692,
        0.0696, 0.0714, 0.0682, 0.0739, 0.0698, 0.0682], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,580][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0240, 0.0655, 0.0608, 0.0659, 0.0641, 0.0681, 0.0691, 0.0709, 0.0707,
        0.0736, 0.0745, 0.0721, 0.0718, 0.0749, 0.0740], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,581][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0577, 0.0405, 0.0397, 0.0669, 0.0733, 0.0508, 0.0760, 0.0639, 0.0602,
        0.1039, 0.0681, 0.0875, 0.0821, 0.0521, 0.0772], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,582][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0037, 0.0895, 0.0570, 0.0997, 0.0648, 0.0654, 0.0764, 0.0718, 0.0587,
        0.0639, 0.0399, 0.0945, 0.0923, 0.0560, 0.0664], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,583][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0868, 0.0570, 0.0615, 0.0592, 0.0782, 0.0627, 0.0670, 0.0682, 0.0627,
        0.0732, 0.0562, 0.0609, 0.0569, 0.0755, 0.0740], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,585][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.2471e-12, 9.9659e-01, 1.6522e-07, 7.2579e-08, 9.2551e-08, 1.4864e-21,
        1.4862e-20, 1.0029e-17, 3.1138e-13, 1.0892e-12, 5.6641e-09, 4.2190e-09,
        2.9966e-07, 2.4060e-05, 3.3806e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:57,587][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0222, 0.0486, 0.0571, 0.0718, 0.0656, 0.0562, 0.0582, 0.0773, 0.0602,
        0.0620, 0.0582, 0.0835, 0.0731, 0.0787, 0.0688, 0.0585],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,591][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0395, 0.0680, 0.0626, 0.0647, 0.0611, 0.0635, 0.0629, 0.0613, 0.0629,
        0.0620, 0.0632, 0.0671, 0.0656, 0.0660, 0.0648, 0.0648],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,596][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0821, 0.0561, 0.0708, 0.0561, 0.0760, 0.0376, 0.0472, 0.0469, 0.0429,
        0.0389, 0.0725, 0.0669, 0.0805, 0.0657, 0.0813, 0.0784],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,600][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0131, 0.0566, 0.0436, 0.0542, 0.0481, 0.0678, 0.0665, 0.0649, 0.0643,
        0.0710, 0.0607, 0.0820, 0.0691, 0.0723, 0.0750, 0.0908],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,604][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.1055, 0.0553, 0.0581, 0.0598, 0.0569, 0.0533, 0.0589, 0.0556, 0.0603,
        0.0602, 0.0640, 0.0660, 0.0585, 0.0606, 0.0601, 0.0667],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,605][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.2434, 0.0753, 0.0625, 0.0464, 0.0541, 0.0476, 0.0495, 0.0436, 0.0419,
        0.0449, 0.0499, 0.0442, 0.0499, 0.0516, 0.0543, 0.0409],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,606][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0264, 0.0645, 0.0641, 0.0636, 0.0636, 0.0643, 0.0685, 0.0638, 0.0638,
        0.0660, 0.0661, 0.0651, 0.0696, 0.0649, 0.0664, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,607][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0221, 0.0615, 0.0562, 0.0617, 0.0597, 0.0642, 0.0646, 0.0660, 0.0663,
        0.0685, 0.0692, 0.0676, 0.0672, 0.0698, 0.0689, 0.0663],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,609][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0515, 0.0388, 0.0364, 0.0597, 0.0664, 0.0472, 0.0706, 0.0600, 0.0581,
        0.0973, 0.0668, 0.0822, 0.0810, 0.0531, 0.0761, 0.0548],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,613][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0036, 0.0881, 0.0550, 0.0967, 0.0637, 0.0638, 0.0659, 0.0668, 0.0545,
        0.0625, 0.0359, 0.0905, 0.0751, 0.0524, 0.0685, 0.0570],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,616][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0767, 0.0397, 0.0568, 0.0618, 0.0735, 0.0554, 0.0634, 0.0682, 0.0577,
        0.0654, 0.0561, 0.0620, 0.0653, 0.0744, 0.0630, 0.0606],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,618][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ it] are: tensor([3.8500e-09, 7.7883e-01, 6.8065e-10, 8.2262e-09, 2.1667e-06, 6.1538e-19,
        1.2182e-20, 3.1330e-17, 4.1062e-12, 2.1176e-13, 3.0523e-09, 1.3503e-08,
        1.7864e-05, 3.1400e-06, 1.8263e-01, 3.8517e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:57,622][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0192, 0.0444, 0.0527, 0.0653, 0.0615, 0.0600, 0.0600, 0.0621, 0.0638,
        0.0543, 0.0534, 0.0765, 0.0676, 0.0629, 0.0703, 0.0661, 0.0598],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,627][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0369, 0.0637, 0.0587, 0.0604, 0.0573, 0.0595, 0.0590, 0.0576, 0.0592,
        0.0582, 0.0595, 0.0631, 0.0618, 0.0621, 0.0611, 0.0611, 0.0608],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,629][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0743, 0.0558, 0.0632, 0.0548, 0.0707, 0.0374, 0.0449, 0.0454, 0.0417,
        0.0405, 0.0657, 0.0641, 0.0761, 0.0601, 0.0748, 0.0730, 0.0576],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,630][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0105, 0.0541, 0.0419, 0.0519, 0.0462, 0.0622, 0.0615, 0.0603, 0.0588,
        0.0647, 0.0563, 0.0756, 0.0648, 0.0661, 0.0704, 0.0867, 0.0680],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,631][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0993, 0.0520, 0.0546, 0.0564, 0.0535, 0.0501, 0.0553, 0.0522, 0.0567,
        0.0565, 0.0602, 0.0621, 0.0549, 0.0570, 0.0564, 0.0626, 0.0604],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,632][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2121, 0.0713, 0.0607, 0.0447, 0.0521, 0.0468, 0.0484, 0.0427, 0.0415,
        0.0444, 0.0479, 0.0430, 0.0487, 0.0505, 0.0539, 0.0414, 0.0499],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,634][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0250, 0.0593, 0.0604, 0.0591, 0.0597, 0.0606, 0.0643, 0.0610, 0.0607,
        0.0620, 0.0624, 0.0605, 0.0652, 0.0607, 0.0620, 0.0574, 0.0598],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,637][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0208, 0.0576, 0.0531, 0.0575, 0.0559, 0.0600, 0.0604, 0.0618, 0.0620,
        0.0639, 0.0647, 0.0628, 0.0626, 0.0656, 0.0645, 0.0619, 0.0649],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,641][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0489, 0.0368, 0.0347, 0.0579, 0.0646, 0.0459, 0.0668, 0.0587, 0.0560,
        0.0906, 0.0636, 0.0791, 0.0761, 0.0513, 0.0732, 0.0529, 0.0431],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,644][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0026, 0.0902, 0.0504, 0.0940, 0.0545, 0.0621, 0.0715, 0.0632, 0.0514,
        0.0598, 0.0335, 0.0881, 0.0723, 0.0445, 0.0606, 0.0571, 0.0442],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,648][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0673, 0.0456, 0.0542, 0.0642, 0.0600, 0.0525, 0.0593, 0.0633, 0.0532,
        0.0637, 0.0504, 0.0651, 0.0553, 0.0696, 0.0553, 0.0507, 0.0704],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,651][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.8986e-11, 5.7074e-01, 1.3613e-09, 1.9290e-08, 1.8989e-07, 4.1195e-21,
        1.8931e-20, 4.2032e-20, 8.1653e-14, 4.7421e-13, 2.2563e-10, 8.0741e-10,
        1.9580e-06, 1.2136e-07, 1.2627e-01, 3.0282e-01, 1.6673e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:57,704][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:57,708][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,709][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,709][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,710][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,711][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,712][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,715][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,717][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,720][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,723][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,726][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,729][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:57,733][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.3315, 0.6685], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,733][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0751, 0.9249], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,734][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.9780, 0.0220], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,735][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.4437, 0.5563], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,737][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.5092, 0.4908], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,739][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.2600, 0.7400], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,743][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.7981, 0.2019], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,747][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,750][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.6172, 0.3828], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,754][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.8475, 0.1525], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,756][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.9977, 0.0023], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,757][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.8127, 0.1873], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:57,758][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0134, 0.9167, 0.0699], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,759][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0372, 0.5329, 0.4299], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,759][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4656, 0.3029, 0.2315], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,761][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0340, 0.5976, 0.3684], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,765][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2494, 0.1431, 0.6076], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,768][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0062, 0.9197, 0.0741], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,772][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0511, 0.8713, 0.0777], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,776][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0014, 0.4625, 0.5361], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,779][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4733, 0.2529, 0.2738], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,781][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2668, 0.6580, 0.0752], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,782][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9281, 0.0077, 0.0642], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,782][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.0666e-12, 1.0000e+00, 1.7261e-06], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:57,783][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0018, 0.9663, 0.0221, 0.0098], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,785][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0290, 0.3609, 0.2917, 0.3185], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,787][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.1896, 0.4130, 0.3485, 0.0489], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,791][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.0070, 0.6171, 0.3368, 0.0392], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,795][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.3088, 0.5021, 0.1321, 0.0569], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,798][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0067, 0.8859, 0.0786, 0.0288], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,802][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.2084, 0.7202, 0.0327, 0.0386], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,805][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0019, 0.8067, 0.0382, 0.1532], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,805][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.4673, 0.1986, 0.1953, 0.1388], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,806][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.2102, 0.5953, 0.1325, 0.0620], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,807][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.9633, 0.0040, 0.0291, 0.0036], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,808][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([5.2516e-11, 1.0000e+00, 2.3103e-07, 2.8728e-08], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:57,810][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0070, 0.6678, 0.0357, 0.0094, 0.2800], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,813][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0209, 0.2794, 0.2237, 0.2454, 0.2305], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,816][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.1933, 0.3609, 0.3565, 0.0241, 0.0652], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,820][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0035, 0.4835, 0.3339, 0.0225, 0.1567], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,824][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.3618, 0.1253, 0.2347, 0.0311, 0.2471], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,827][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0055, 0.7491, 0.0967, 0.0358, 0.1128], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,829][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0831, 0.5360, 0.0074, 0.1012, 0.2723], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,830][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0013, 0.4753, 0.0721, 0.0915, 0.3598], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,831][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3887, 0.1508, 0.1579, 0.1200, 0.1826], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,831][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.2160, 0.5131, 0.0604, 0.0498, 0.1607], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,833][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.9400, 0.0028, 0.0479, 0.0018, 0.0076], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,835][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([6.0023e-14, 9.9998e-01, 5.8881e-07, 1.4528e-05, 4.0664e-07],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:57,837][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.3863e-05, 5.7430e-01, 1.7359e-02, 1.2702e-02, 3.9469e-01, 9.3171e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,841][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0146, 0.2288, 0.1831, 0.2006, 0.1875, 0.1854], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,845][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0063, 0.3603, 0.4811, 0.0350, 0.1119, 0.0054], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,847][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.0599e-04, 3.8342e-01, 2.3854e-01, 3.0381e-02, 3.4601e-01, 1.3422e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,851][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1690, 0.1470, 0.2603, 0.0528, 0.0923, 0.2787], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,853][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.1299e-04, 6.4471e-01, 4.5034e-02, 4.0625e-02, 2.6730e-01, 2.2143e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,854][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.2284e-04, 2.0822e-01, 1.7966e-03, 5.4729e-02, 7.3363e-01, 1.5027e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,855][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0006, 0.5174, 0.0343, 0.1080, 0.2049, 0.1348], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,855][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4298, 0.1175, 0.1209, 0.0834, 0.1306, 0.1178], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,857][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0086, 0.3073, 0.0603, 0.0500, 0.5688, 0.0051], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,860][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9564, 0.0030, 0.0242, 0.0035, 0.0054, 0.0075], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,862][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.3780e-17, 9.9988e-01, 4.4739e-08, 4.0656e-07, 1.1509e-04, 2.9806e-16],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:57,864][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([4.6402e-06, 4.4081e-01, 1.4797e-02, 1.1173e-02, 5.3209e-01, 9.6846e-04,
        1.5709e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,868][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0118, 0.1947, 0.1552, 0.1700, 0.1589, 0.1575, 0.1519],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,871][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0091, 0.3545, 0.4611, 0.0396, 0.1253, 0.0059, 0.0046],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,874][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([1.9797e-05, 3.4543e-01, 2.4156e-01, 3.4763e-02, 3.7636e-01, 1.7892e-03,
        7.3908e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,878][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.2039, 0.0543, 0.1182, 0.0210, 0.0646, 0.0509, 0.4872],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,878][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([4.2734e-05, 6.9750e-01, 4.6290e-02, 5.2967e-02, 1.9960e-01, 2.6498e-03,
        9.4983e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,879][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0014, 0.4476, 0.0024, 0.0628, 0.4542, 0.0010, 0.0306],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,880][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0006, 0.5314, 0.0250, 0.0830, 0.1703, 0.0828, 0.1069],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,882][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.3757, 0.1070, 0.1009, 0.0772, 0.1195, 0.1152, 0.1046],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,885][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0066, 0.2900, 0.0688, 0.0389, 0.5783, 0.0101, 0.0073],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,889][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.9360, 0.0051, 0.0299, 0.0043, 0.0082, 0.0114, 0.0051],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,891][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([1.2024e-20, 9.9963e-01, 4.5313e-09, 3.7646e-07, 3.7049e-04, 3.1048e-14,
        1.6260e-16], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:57,893][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([1.7994e-05, 3.7377e-01, 1.2348e-02, 8.6216e-03, 6.0359e-01, 9.6221e-04,
        2.1526e-04, 4.7806e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,897][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0096, 0.1674, 0.1334, 0.1468, 0.1374, 0.1359, 0.1317, 0.1377],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,901][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0049, 0.4324, 0.4209, 0.0380, 0.0868, 0.0060, 0.0052, 0.0058],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,902][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([5.5404e-05, 2.9938e-01, 2.4664e-01, 3.1719e-02, 4.1996e-01, 1.6752e-03,
        6.5976e-05, 4.9503e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,903][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1668, 0.0585, 0.2711, 0.0065, 0.0454, 0.0500, 0.0938, 0.3078],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,903][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([6.6981e-05, 5.8398e-01, 6.2663e-02, 3.3935e-02, 3.1200e-01, 3.9219e-03,
        1.3717e-03, 2.0672e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,904][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([2.8019e-04, 3.3654e-01, 1.9743e-03, 4.4608e-02, 5.3580e-01, 1.6132e-03,
        7.3266e-02, 5.9180e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,906][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0013, 0.1984, 0.0603, 0.0480, 0.2821, 0.0942, 0.1390, 0.1766],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,909][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.4091, 0.0858, 0.0884, 0.0604, 0.1013, 0.0862, 0.0919, 0.0768],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,913][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0048, 0.3765, 0.0492, 0.0360, 0.5036, 0.0077, 0.0065, 0.0156],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,917][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.9008, 0.0052, 0.0446, 0.0041, 0.0063, 0.0098, 0.0047, 0.0245],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,919][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.4299e-17, 9.9994e-01, 2.6260e-07, 6.1304e-07, 5.9267e-05, 5.1016e-17,
        4.7511e-16, 7.0581e-15], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:57,921][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.8135e-04, 6.0445e-01, 1.8518e-02, 6.4136e-03, 3.4226e-01, 3.0408e-04,
        5.0639e-05, 4.1325e-04, 2.7303e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,924][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0091, 0.1474, 0.1173, 0.1292, 0.1196, 0.1186, 0.1150, 0.1206, 0.1232],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,926][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0151, 0.4216, 0.3967, 0.0360, 0.0982, 0.0049, 0.0046, 0.0051, 0.0178],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,927][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.6459e-03, 3.8759e-01, 2.9230e-01, 3.4389e-02, 2.6528e-01, 8.1415e-04,
        3.3129e-05, 3.3084e-04, 1.6611e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,928][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1962, 0.2248, 0.2451, 0.0690, 0.0282, 0.0275, 0.0624, 0.0714, 0.0755],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,929][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([6.3317e-04, 7.2142e-01, 5.3621e-02, 2.7101e-02, 1.5448e-01, 1.3262e-03,
        4.7258e-04, 1.2433e-03, 3.9707e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,930][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([3.4599e-04, 3.8091e-01, 1.6155e-03, 8.1296e-02, 4.7798e-01, 9.1416e-04,
        4.5794e-02, 4.1210e-03, 7.0302e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,933][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0009, 0.3461, 0.0175, 0.0531, 0.1097, 0.0728, 0.1032, 0.0553, 0.2415],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,937][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3581, 0.0795, 0.0815, 0.0571, 0.0954, 0.0860, 0.0867, 0.0755, 0.0801],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,941][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0322, 0.3896, 0.0586, 0.0397, 0.4080, 0.0034, 0.0051, 0.0164, 0.0471],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,944][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9518, 0.0018, 0.0192, 0.0018, 0.0043, 0.0050, 0.0018, 0.0077, 0.0067],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,946][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.3044e-13, 9.9992e-01, 1.2343e-07, 2.2438e-07, 7.5376e-05, 2.8445e-17,
        4.6601e-18, 1.2483e-14, 6.5338e-10], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:57,948][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([1.3832e-04, 5.1485e-01, 2.0627e-02, 7.3645e-03, 4.2955e-01, 1.9132e-04,
        2.6776e-05, 4.2005e-04, 2.0422e-02, 6.4028e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,950][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0083, 0.1317, 0.1044, 0.1146, 0.1062, 0.1047, 0.1012, 0.1064, 0.1089,
        0.1134], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,951][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0131, 0.4348, 0.3949, 0.0415, 0.0838, 0.0040, 0.0031, 0.0045, 0.0128,
        0.0074], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,952][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([1.5151e-04, 4.0163e-01, 2.5186e-01, 2.8111e-02, 2.9966e-01, 6.4632e-04,
        2.2533e-05, 1.9998e-04, 1.6252e-02, 1.4650e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,953][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0808, 0.0367, 0.1046, 0.0041, 0.0033, 0.0216, 0.0353, 0.0353, 0.0222,
        0.6561], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,954][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([4.0997e-04, 7.0140e-01, 5.0991e-02, 2.7487e-02, 1.6420e-01, 1.2607e-03,
        2.8268e-04, 7.9770e-04, 4.4482e-02, 8.6916e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,956][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([6.7326e-03, 4.7018e-01, 2.5203e-03, 8.7430e-02, 3.2297e-01, 1.3973e-04,
        7.7506e-03, 7.6304e-04, 1.1544e-03, 1.0035e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,959][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0011, 0.3227, 0.0180, 0.0453, 0.1065, 0.0418, 0.0613, 0.0371, 0.1358,
        0.2304], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,963][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.2715, 0.0782, 0.0754, 0.0646, 0.0877, 0.0894, 0.0866, 0.0793, 0.0868,
        0.0805], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,967][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0209, 0.4836, 0.0457, 0.0509, 0.3062, 0.0044, 0.0033, 0.0090, 0.0432,
        0.0327], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,971][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.9426, 0.0030, 0.0137, 0.0022, 0.0041, 0.0061, 0.0021, 0.0094, 0.0109,
        0.0061], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,973][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([6.3028e-15, 1.0000e+00, 6.5566e-09, 6.0705e-08, 1.7106e-06, 2.5282e-17,
        3.2287e-18, 2.6331e-16, 9.0395e-10, 4.7609e-12], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:57,975][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([5.9722e-04, 5.3962e-01, 1.4527e-02, 5.7380e-03, 3.4226e-01, 4.9426e-04,
        6.9363e-05, 7.2889e-04, 4.3729e-02, 7.6797e-03, 4.4551e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,975][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0078, 0.1191, 0.0944, 0.1040, 0.0962, 0.0960, 0.0929, 0.0977, 0.0997,
        0.1038, 0.0884], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,976][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0074, 0.4947, 0.3038, 0.0396, 0.0897, 0.0062, 0.0061, 0.0055, 0.0185,
        0.0121, 0.0166], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,978][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.8638e-03, 4.0751e-01, 2.1339e-01, 3.5413e-02, 2.8492e-01, 1.3307e-03,
        6.0552e-05, 5.5457e-04, 2.4128e-02, 2.5737e-03, 2.7252e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,980][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0855, 0.0517, 0.2136, 0.0120, 0.0154, 0.0111, 0.0384, 0.0508, 0.0184,
        0.2367, 0.2663], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,983][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.1805e-03, 6.6404e-01, 6.3244e-02, 2.7152e-02, 1.3193e-01, 1.9873e-03,
        4.6844e-04, 2.1368e-03, 5.3817e-02, 1.3148e-02, 4.0901e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,985][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.5553e-04, 2.7413e-01, 6.8307e-04, 4.1064e-02, 1.5780e-01, 8.2953e-04,
        3.9608e-02, 3.5819e-03, 7.5989e-03, 4.7218e-01, 2.3668e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,989][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0003, 0.1306, 0.0235, 0.0315, 0.1045, 0.0487, 0.0765, 0.0709, 0.1399,
        0.1808, 0.1926], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,992][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3216, 0.0690, 0.0711, 0.0514, 0.0816, 0.0721, 0.0759, 0.0647, 0.0678,
        0.0670, 0.0578], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,996][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0338, 0.4173, 0.0442, 0.0324, 0.2857, 0.0055, 0.0051, 0.0160, 0.0567,
        0.0460, 0.0573], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,998][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8140, 0.0074, 0.0377, 0.0059, 0.0138, 0.0111, 0.0075, 0.0191, 0.0172,
        0.0090, 0.0574], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:57,999][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.2318e-14, 1.0000e+00, 2.2761e-09, 6.8884e-07, 1.2682e-06, 1.2967e-17,
        2.5380e-17, 3.0807e-15, 2.5628e-10, 2.4591e-09, 3.7147e-09],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,000][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([2.7709e-04, 4.5806e-01, 9.2697e-03, 1.4573e-03, 4.0354e-01, 4.9712e-04,
        6.2737e-05, 3.4897e-04, 3.9730e-02, 1.1570e-02, 6.5879e-02, 9.3099e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,001][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0076, 0.1080, 0.0854, 0.0935, 0.0872, 0.0871, 0.0840, 0.0883, 0.0905,
        0.0948, 0.0808, 0.0929], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,003][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0118, 0.4306, 0.3619, 0.0399, 0.0757, 0.0052, 0.0059, 0.0057, 0.0194,
        0.0150, 0.0204, 0.0083], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,005][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([3.7110e-04, 4.4336e-01, 1.6437e-01, 2.0508e-02, 2.7257e-01, 1.1229e-03,
        5.8421e-05, 6.7553e-04, 3.7191e-02, 6.2467e-03, 4.8727e-02, 4.7954e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,009][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.1944, 0.2672, 0.0867, 0.0279, 0.0292, 0.0095, 0.0390, 0.0119, 0.0198,
        0.0687, 0.2077, 0.0380], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,011][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([1.8987e-03, 5.4579e-01, 4.7570e-02, 1.5236e-02, 1.4113e-01, 2.4740e-03,
        3.5502e-04, 1.9128e-03, 7.5622e-02, 1.5085e-02, 1.0280e-01, 5.0132e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,014][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([8.2728e-03, 5.6680e-01, 3.0779e-03, 1.3079e-02, 1.3384e-01, 4.5335e-04,
        1.5416e-02, 1.9183e-03, 3.6006e-03, 2.3166e-01, 2.9196e-03, 1.8967e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,017][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0016, 0.2803, 0.0039, 0.0274, 0.0285, 0.0256, 0.0288, 0.0113, 0.0958,
        0.0661, 0.0635, 0.3673], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,021][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.2515, 0.0705, 0.0705, 0.0505, 0.0779, 0.0780, 0.0768, 0.0667, 0.0746,
        0.0766, 0.0582, 0.0481], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,023][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0263, 0.3005, 0.0437, 0.0172, 0.3983, 0.0026, 0.0031, 0.0123, 0.0361,
        0.0534, 0.0785, 0.0280], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,024][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.8315, 0.0034, 0.0242, 0.0026, 0.0118, 0.0089, 0.0042, 0.0113, 0.0188,
        0.0125, 0.0682, 0.0027], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,025][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([9.2995e-11, 1.0000e+00, 1.1258e-09, 1.0532e-10, 2.3983e-06, 3.4464e-16,
        1.2464e-18, 1.8730e-15, 1.5890e-08, 1.1913e-09, 9.4328e-07, 2.9190e-08],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,026][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([4.7797e-03, 3.5828e-01, 3.5852e-02, 4.4101e-03, 2.0244e-01, 1.4839e-04,
        2.4891e-05, 1.7874e-04, 1.8562e-02, 3.4706e-03, 5.9719e-02, 8.5809e-03,
        3.0355e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,028][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0063, 0.1001, 0.0792, 0.0868, 0.0806, 0.0796, 0.0767, 0.0808, 0.0823,
        0.0854, 0.0737, 0.0847, 0.0837], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,031][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0484, 0.2508, 0.5524, 0.0166, 0.0693, 0.0036, 0.0028, 0.0037, 0.0140,
        0.0061, 0.0157, 0.0030, 0.0136], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,034][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([3.7058e-04, 4.4223e-01, 3.5930e-01, 1.7134e-02, 1.3891e-01, 3.1400e-04,
        8.9567e-06, 1.6677e-04, 8.1364e-03, 7.4391e-04, 1.8935e-02, 8.8871e-04,
        1.2869e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,038][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0864, 0.0474, 0.0676, 0.0207, 0.0688, 0.0091, 0.0058, 0.0366, 0.0180,
        0.0096, 0.1129, 0.0262, 0.4906], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,040][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([2.2162e-03, 5.0796e-01, 7.2783e-02, 1.6371e-02, 1.1310e-01, 6.0108e-04,
        2.7016e-04, 2.5864e-04, 2.8819e-02, 3.7685e-03, 9.3662e-02, 2.4885e-02,
        1.3531e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,042][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([2.5832e-02, 2.7418e-01, 1.1047e-03, 3.3181e-02, 8.5678e-02, 9.9273e-05,
        7.0136e-03, 7.1803e-04, 8.0175e-04, 6.6623e-02, 1.2963e-03, 8.6311e-02,
        4.1716e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,046][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0004, 0.1624, 0.0165, 0.0240, 0.0780, 0.0262, 0.0392, 0.0269, 0.0978,
        0.1049, 0.1019, 0.1663, 0.1556], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,047][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1990, 0.0584, 0.0630, 0.0457, 0.0802, 0.0775, 0.0755, 0.0652, 0.0681,
        0.0680, 0.0609, 0.0469, 0.0917], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,048][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0597, 0.2762, 0.0445, 0.0205, 0.1876, 0.0012, 0.0019, 0.0061, 0.0304,
        0.0187, 0.0917, 0.0342, 0.2275], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,049][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([9.1497e-01, 1.4247e-03, 2.0225e-02, 1.1638e-03, 5.2787e-03, 5.1227e-03,
        1.3261e-03, 1.4266e-02, 7.1982e-03, 1.6925e-03, 2.3657e-02, 7.1791e-04,
        2.9587e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,050][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([7.4102e-12, 1.0000e+00, 1.0544e-08, 1.3300e-08, 5.4405e-07, 4.4665e-18,
        2.2476e-19, 7.3636e-17, 4.9271e-11, 1.6677e-12, 3.3959e-08, 4.6332e-08,
        2.3175e-07], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,052][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0522e-03, 2.3028e-01, 1.0991e-02, 3.3734e-03, 2.0209e-01, 9.5499e-05,
        2.3694e-05, 8.0718e-05, 8.2509e-03, 1.1848e-03, 1.4705e-02, 5.0298e-03,
        4.3360e-01, 8.9242e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,055][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0054, 0.0925, 0.0733, 0.0809, 0.0751, 0.0741, 0.0713, 0.0752, 0.0767,
        0.0802, 0.0684, 0.0792, 0.0784, 0.0694], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,059][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0134, 0.3473, 0.4262, 0.0301, 0.0882, 0.0032, 0.0034, 0.0036, 0.0150,
        0.0095, 0.0160, 0.0066, 0.0151, 0.0223], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,062][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.2063e-03, 3.2840e-01, 2.7763e-01, 3.0533e-02, 2.2325e-01, 1.0458e-03,
        4.5472e-05, 4.3817e-04, 1.6658e-02, 1.9562e-03, 3.5944e-02, 2.8917e-03,
        4.6687e-02, 3.2323e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,066][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1087, 0.0275, 0.1871, 0.0054, 0.0317, 0.0316, 0.0219, 0.0326, 0.0264,
        0.1646, 0.3218, 0.0059, 0.0265, 0.0080], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,068][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.6837e-03, 4.3935e-01, 5.6035e-02, 1.7904e-02, 8.6842e-02, 5.6066e-04,
        1.4248e-04, 4.0600e-04, 1.5318e-02, 4.8620e-03, 3.4667e-02, 1.6193e-02,
        2.4076e-01, 8.5278e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,070][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.6338e-03, 2.3967e-01, 9.7588e-04, 4.0518e-02, 8.6652e-02, 6.7936e-05,
        4.5548e-03, 3.2518e-04, 6.2125e-04, 9.1809e-02, 5.5901e-04, 5.1193e-02,
        4.1175e-01, 6.9670e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,071][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0003, 0.1176, 0.0135, 0.0189, 0.0533, 0.0220, 0.0441, 0.0288, 0.0863,
        0.0954, 0.1029, 0.1363, 0.0891, 0.1915], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,072][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2179, 0.0607, 0.0636, 0.0460, 0.0710, 0.0662, 0.0657, 0.0598, 0.0607,
        0.0573, 0.0486, 0.0365, 0.0802, 0.0657], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,073][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0452, 0.2103, 0.0299, 0.0176, 0.1107, 0.0012, 0.0017, 0.0058, 0.0135,
        0.0149, 0.0283, 0.0217, 0.3153, 0.1838], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,075][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8766, 0.0029, 0.0202, 0.0022, 0.0048, 0.0063, 0.0023, 0.0119, 0.0101,
        0.0040, 0.0301, 0.0020, 0.0026, 0.0238], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,077][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.5896e-12, 9.9994e-01, 4.3039e-09, 7.0647e-08, 8.3916e-07, 9.3631e-20,
        9.3822e-19, 1.9262e-18, 2.0606e-12, 2.4578e-11, 5.8250e-09, 2.4647e-08,
        5.7612e-05, 2.0714e-06], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,079][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([3.0083e-03, 1.2017e-01, 1.1579e-02, 9.5626e-04, 7.9497e-02, 2.9708e-05,
        3.6929e-06, 4.4114e-05, 3.3293e-03, 5.8241e-04, 1.1945e-02, 7.4591e-04,
        1.4359e-01, 1.4167e-01, 4.8285e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,083][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0052, 0.0858, 0.0683, 0.0753, 0.0697, 0.0682, 0.0660, 0.0693, 0.0710,
        0.0742, 0.0638, 0.0736, 0.0729, 0.0648, 0.0720], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,086][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0289, 0.4771, 0.3094, 0.0278, 0.0599, 0.0018, 0.0027, 0.0021, 0.0101,
        0.0049, 0.0115, 0.0054, 0.0120, 0.0162, 0.0303], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,088][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.3302e-04, 4.3413e-01, 3.0462e-01, 2.1309e-02, 1.2511e-01, 3.8885e-04,
        1.3616e-05, 2.1450e-04, 9.1923e-03, 9.1045e-04, 2.1957e-02, 1.2862e-03,
        1.8518e-02, 2.1573e-02, 4.0336e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,092][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0726, 0.0088, 0.1105, 0.0120, 0.0579, 0.0441, 0.0082, 0.0165, 0.0538,
        0.1568, 0.2287, 0.0150, 0.0441, 0.0186, 0.1523], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,094][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([2.9197e-03, 4.1674e-01, 3.9224e-02, 1.6268e-02, 2.4872e-02, 1.6874e-04,
        6.4071e-05, 1.4475e-04, 6.2692e-03, 1.5241e-03, 2.6248e-02, 1.0459e-02,
        6.8327e-02, 1.3165e-01, 2.5512e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,095][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([1.3287e-02, 1.8953e-01, 1.2795e-03, 5.6120e-02, 6.1879e-02, 4.8062e-05,
        2.3021e-03, 2.7002e-04, 3.0390e-04, 3.3044e-02, 7.0094e-04, 4.0707e-02,
        3.8104e-01, 3.8475e-02, 1.8101e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,096][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0004, 0.0681, 0.0220, 0.0121, 0.0438, 0.0151, 0.0217, 0.0259, 0.0609,
        0.0962, 0.1350, 0.0728, 0.0570, 0.1378, 0.2312], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,097][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1298, 0.0547, 0.0576, 0.0441, 0.0681, 0.0701, 0.0656, 0.0633, 0.0640,
        0.0631, 0.0518, 0.0411, 0.0837, 0.0684, 0.0746], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,099][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0495, 0.1968, 0.0166, 0.0124, 0.0496, 0.0006, 0.0005, 0.0014, 0.0054,
        0.0051, 0.0096, 0.0099, 0.2271, 0.1521, 0.2635], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,101][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.8908, 0.0026, 0.0159, 0.0012, 0.0055, 0.0042, 0.0020, 0.0096, 0.0071,
        0.0023, 0.0181, 0.0011, 0.0020, 0.0211, 0.0165], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,103][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([2.2471e-12, 9.9659e-01, 1.6522e-07, 7.2579e-08, 9.2551e-08, 1.4864e-21,
        1.4862e-20, 1.0029e-17, 3.1138e-13, 1.0892e-12, 5.6641e-09, 4.2190e-09,
        2.9966e-07, 2.4060e-05, 3.3806e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,106][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([2.6869e-03, 1.6561e-01, 5.0906e-03, 1.4435e-03, 4.3201e-02, 9.8660e-06,
        2.0753e-06, 2.0380e-05, 8.5552e-04, 2.5161e-04, 2.6159e-03, 1.1855e-03,
        8.6410e-02, 3.4466e-02, 3.4781e-01, 3.0835e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,110][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0053, 0.0799, 0.0634, 0.0699, 0.0646, 0.0636, 0.0617, 0.0647, 0.0661,
        0.0687, 0.0592, 0.0684, 0.0678, 0.0604, 0.0672, 0.0692],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,114][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0503, 0.3321, 0.3587, 0.0183, 0.0553, 0.0019, 0.0021, 0.0023, 0.0095,
        0.0055, 0.0123, 0.0035, 0.0115, 0.0173, 0.0427, 0.0768],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,116][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([2.5252e-03, 3.9076e-01, 1.9690e-01, 2.7150e-02, 1.4308e-01, 5.2301e-04,
        1.7180e-05, 1.7186e-04, 9.2383e-03, 1.3835e-03, 1.9359e-02, 1.5960e-03,
        1.5208e-02, 2.2872e-02, 5.2881e-02, 1.1634e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,119][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0943, 0.0404, 0.1049, 0.0145, 0.0329, 0.0054, 0.0118, 0.0111, 0.0294,
        0.0401, 0.1093, 0.0185, 0.0760, 0.0023, 0.0078, 0.4012],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,119][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([7.9491e-03, 1.5541e-01, 2.0426e-02, 4.8331e-03, 3.0647e-02, 1.1751e-04,
        1.9820e-05, 7.2940e-05, 3.2942e-03, 3.5721e-04, 1.5792e-02, 2.8142e-03,
        6.0115e-02, 4.3997e-02, 2.0405e-01, 4.5011e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,120][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([1.6409e-02, 2.4432e-01, 1.0156e-03, 5.2021e-02, 5.2358e-02, 5.9309e-05,
        2.4759e-03, 2.8105e-04, 3.8553e-04, 2.8519e-02, 8.0074e-04, 4.3737e-02,
        2.2363e-01, 4.0265e-02, 1.3861e-01, 1.5511e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,122][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([2.0037e-04, 2.0083e-01, 4.2300e-03, 2.0199e-02, 3.0208e-02, 2.5975e-02,
        2.8342e-02, 1.0448e-02, 7.0457e-02, 3.7019e-02, 5.0718e-02, 1.3744e-01,
        5.5890e-02, 5.9971e-02, 6.0140e-02, 2.0793e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,125][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.1785, 0.0488, 0.0518, 0.0361, 0.0615, 0.0567, 0.0584, 0.0513, 0.0548,
        0.0505, 0.0437, 0.0332, 0.0720, 0.0598, 0.0768, 0.0660],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,127][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([4.8768e-02, 6.4532e-02, 1.1136e-02, 5.7153e-03, 5.2538e-02, 3.1232e-04,
        3.2881e-04, 1.4171e-03, 3.8219e-03, 2.9438e-03, 8.9225e-03, 5.6370e-03,
        9.1227e-02, 1.0725e-01, 4.3028e-01, 1.6517e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,129][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([9.2863e-01, 6.5856e-04, 7.2918e-03, 6.3377e-04, 2.4058e-03, 2.5023e-03,
        7.3878e-04, 4.1882e-03, 3.8845e-03, 1.7816e-03, 1.5406e-02, 7.0805e-04,
        9.5748e-04, 1.1047e-02, 5.0641e-03, 1.4101e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,131][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([3.8500e-09, 7.7883e-01, 6.8065e-10, 8.2262e-09, 2.1667e-06, 6.1538e-19,
        1.2182e-20, 3.1330e-17, 4.1062e-12, 2.1176e-13, 3.0523e-09, 1.3503e-08,
        1.7864e-05, 3.1400e-06, 1.8263e-01, 3.8517e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,134][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.4366e-04, 4.5745e-02, 1.9259e-03, 5.2421e-04, 2.0599e-02, 8.5639e-06,
        1.7577e-06, 5.1145e-06, 6.9257e-04, 8.3903e-05, 1.4799e-03, 4.2468e-04,
        3.8938e-02, 7.7526e-03, 3.9276e-01, 4.0629e-01, 8.2222e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,138][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0045, 0.0745, 0.0596, 0.0654, 0.0610, 0.0597, 0.0576, 0.0609, 0.0619,
        0.0648, 0.0554, 0.0639, 0.0634, 0.0561, 0.0629, 0.0649, 0.0636],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,141][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0161, 0.3424, 0.3024, 0.0248, 0.0643, 0.0022, 0.0031, 0.0027, 0.0111,
        0.0088, 0.0130, 0.0051, 0.0131, 0.0165, 0.0517, 0.0888, 0.0337],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,143][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.7051e-03, 2.6082e-01, 1.7783e-01, 2.0926e-02, 1.4607e-01, 4.8490e-04,
        1.7428e-05, 1.8552e-04, 8.4658e-03, 8.7345e-04, 1.9682e-02, 1.4291e-03,
        2.2857e-02, 1.7818e-02, 6.1115e-02, 1.9336e-01, 6.5363e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,144][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1037, 0.0265, 0.1795, 0.0052, 0.0311, 0.0300, 0.0205, 0.0307, 0.0250,
        0.1552, 0.3032, 0.0058, 0.0238, 0.0077, 0.0054, 0.0385, 0.0080],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,144][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.2234e-04, 1.0129e-01, 1.0079e-02, 3.0670e-03, 1.1558e-02, 6.6131e-05,
        1.3418e-05, 3.4353e-05, 1.7504e-03, 4.6491e-04, 3.7632e-03, 1.7235e-03,
        2.5811e-02, 9.5224e-03, 1.8444e-01, 5.7971e-01, 6.5885e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,145][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.7711e-03, 1.6932e-01, 7.1798e-04, 3.7894e-02, 3.9878e-02, 3.0383e-05,
        1.8192e-03, 1.2211e-04, 2.4903e-04, 3.7209e-02, 2.7627e-04, 2.3762e-02,
        1.5211e-01, 2.3728e-02, 1.9397e-01, 2.7257e-01, 4.4567e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,147][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0002, 0.0989, 0.0070, 0.0129, 0.0306, 0.0143, 0.0265, 0.0148, 0.0538,
        0.0516, 0.0541, 0.0916, 0.0473, 0.1048, 0.0919, 0.1264, 0.1733],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,150][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1859, 0.0506, 0.0523, 0.0378, 0.0579, 0.0539, 0.0535, 0.0479, 0.0485,
        0.0468, 0.0386, 0.0298, 0.0642, 0.0536, 0.0662, 0.0583, 0.0543],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,152][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.9488e-02, 8.7582e-02, 1.0546e-02, 7.2081e-03, 3.0749e-02, 2.8395e-04,
        3.9220e-04, 1.1484e-03, 3.0452e-03, 3.6018e-03, 6.3655e-03, 6.0516e-03,
        6.7847e-02, 4.6445e-02, 3.5163e-01, 2.0965e-01, 1.3796e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,156][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8659, 0.0025, 0.0139, 0.0017, 0.0031, 0.0047, 0.0015, 0.0090, 0.0072,
        0.0026, 0.0201, 0.0015, 0.0016, 0.0162, 0.0068, 0.0207, 0.0209],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,158][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.8986e-11, 5.7074e-01, 1.3613e-09, 1.9290e-08, 1.8989e-07, 4.1195e-21,
        1.8931e-20, 4.2032e-20, 8.1653e-14, 4.7421e-13, 2.2563e-10, 8.0741e-10,
        1.9580e-06, 1.2136e-07, 1.2627e-01, 3.0282e-01, 1.6673e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,161][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:22:58,164][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14132],
        [17186],
        [ 8751],
        [ 3227],
        [ 9703],
        [ 3686],
        [ 4926],
        [ 8331],
        [ 4274],
        [ 5692],
        [ 6667],
        [ 3921],
        [12698],
        [ 3567],
        [ 3784],
        [ 5421],
        [ 4186]], device='cuda:0')
[2024-07-24 10:22:58,167][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14961],
        [19400],
        [15250],
        [ 5650],
        [13738],
        [ 8016],
        [12450],
        [15733],
        [ 9956],
        [12393],
        [12270],
        [10577],
        [21553],
        [ 6339],
        [ 7858],
        [10675],
        [ 9160]], device='cuda:0')
[2024-07-24 10:22:58,169][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25378],
        [31026],
        [30976],
        [28102],
        [28495],
        [28560],
        [28124],
        [27497],
        [27204],
        [27050],
        [27355],
        [26331],
        [26533],
        [27339],
        [28121],
        [27978],
        [28257]], device='cuda:0')
[2024-07-24 10:22:58,171][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[3082],
        [2762],
        [2714],
        [2976],
        [2964],
        [3012],
        [3028],
        [3037],
        [3015],
        [3008],
        [2999],
        [3046],
        [3036],
        [3054],
        [3017],
        [3038],
        [2989]], device='cuda:0')
[2024-07-24 10:22:58,172][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13721],
        [13473],
        [10324],
        [ 9684],
        [ 8319],
        [ 8139],
        [ 8517],
        [ 8380],
        [ 8524],
        [ 8737],
        [ 8864],
        [ 8840],
        [ 8470],
        [ 8350],
        [ 8567],
        [ 8601],
        [ 8619]], device='cuda:0')
[2024-07-24 10:22:58,174][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33695],
        [40090],
        [39426],
        [36355],
        [36064],
        [36247],
        [35869],
        [35936],
        [36159],
        [36250],
        [36196],
        [35670],
        [35495],
        [35612],
        [35815],
        [35788],
        [35901]], device='cuda:0')
[2024-07-24 10:22:58,176][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17769],
        [19405],
        [21201],
        [22541],
        [22827],
        [22893],
        [22627],
        [22732],
        [22551],
        [22527],
        [22115],
        [21706],
        [21395],
        [21013],
        [20745],
        [20239],
        [19910]], device='cuda:0')
[2024-07-24 10:22:58,179][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1761],
        [3317],
        [4287],
        [4982],
        [5531],
        [5896],
        [6019],
        [6452],
        [6510],
        [6477],
        [6673],
        [6816],
        [6927],
        [7145],
        [7073],
        [7137],
        [7277]], device='cuda:0')
[2024-07-24 10:22:58,181][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 9842],
        [ 9011],
        [ 9031],
        [ 9623],
        [ 9596],
        [ 9858],
        [10222],
        [10727],
        [10823],
        [10827],
        [10890],
        [10764],
        [10978],
        [10900],
        [11032],
        [10778],
        [10672]], device='cuda:0')
[2024-07-24 10:22:58,184][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[22667],
        [23166],
        [21496],
        [21145],
        [20609],
        [20745],
        [20102],
        [19825],
        [19890],
        [19730],
        [19810],
        [19663],
        [19594],
        [19491],
        [19302],
        [19310],
        [19291]], device='cuda:0')
[2024-07-24 10:22:58,187][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11156],
        [ 9241],
        [ 8684],
        [ 9727],
        [ 9884],
        [10260],
        [10242],
        [10412],
        [10562],
        [10721],
        [11062],
        [12120],
        [12535],
        [12764],
        [12941],
        [13203],
        [13495]], device='cuda:0')
[2024-07-24 10:22:58,189][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[42077],
        [47890],
        [47135],
        [47462],
        [47621],
        [47379],
        [47375],
        [47476],
        [47210],
        [46856],
        [46868],
        [46804],
        [46846],
        [46858],
        [46827],
        [46612],
        [46584]], device='cuda:0')
[2024-07-24 10:22:58,192][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18695],
        [ 9153],
        [ 8530],
        [ 7270],
        [ 6549],
        [ 5573],
        [ 3674],
        [ 3314],
        [ 3708],
        [ 3005],
        [ 2789],
        [ 2949],
        [ 3228],
        [ 2978],
        [ 2865],
        [ 3052],
        [ 2841]], device='cuda:0')
[2024-07-24 10:22:58,194][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41741],
        [36940],
        [13507],
        [13507],
        [13508],
        [13508],
        [13512],
        [13508],
        [13508],
        [13507],
        [13507],
        [13507],
        [13507],
        [13508],
        [13573],
        [18488],
        [21328]], device='cuda:0')
[2024-07-24 10:22:58,197][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7604],
        [ 8891],
        [ 8250],
        [ 5951],
        [ 8634],
        [ 7876],
        [ 6237],
        [11204],
        [ 8422],
        [22458],
        [19666],
        [10833],
        [11130],
        [22850],
        [ 3586],
        [ 7324],
        [ 7728]], device='cuda:0')
[2024-07-24 10:22:58,198][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21486],
        [15112],
        [13308],
        [13318],
        [14386],
        [14764],
        [14540],
        [14138],
        [14442],
        [14380],
        [14061],
        [14015],
        [14508],
        [12272],
        [ 4411],
        [ 6872],
        [ 6420]], device='cuda:0')
[2024-07-24 10:22:58,200][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19727],
        [23712],
        [24159],
        [24545],
        [24383],
        [24999],
        [25230],
        [25478],
        [25878],
        [26229],
        [26424],
        [26635],
        [26768],
        [26965],
        [26989],
        [27041],
        [27127]], device='cuda:0')
[2024-07-24 10:22:58,201][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[2883],
        [2864],
        [3746],
        [4222],
        [4830],
        [5788],
        [5854],
        [5212],
        [5343],
        [5156],
        [4901],
        [5082],
        [5856],
        [5415],
        [4709],
        [5551],
        [5579]], device='cuda:0')
[2024-07-24 10:22:58,204][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10094],
        [22701],
        [24005],
        [24526],
        [22689],
        [20121],
        [19397],
        [18180],
        [21112],
        [20765],
        [20925],
        [21098],
        [22566],
        [20720],
        [22436],
        [19955],
        [16846]], device='cuda:0')
[2024-07-24 10:22:58,207][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22747],
        [15153],
        [28334],
        [18187],
        [13526],
        [16735],
        [14190],
        [21378],
        [22979],
        [ 8188],
        [27955],
        [27236],
        [21127],
        [28980],
        [17934],
        [27725],
        [28971]], device='cuda:0')
[2024-07-24 10:22:58,209][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22812],
        [ 9700],
        [10212],
        [10193],
        [12291],
        [15614],
        [13875],
        [17139],
        [13338],
        [13834],
        [14138],
        [15540],
        [17305],
        [20195],
        [23690],
        [28008],
        [27551]], device='cuda:0')
[2024-07-24 10:22:58,212][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10827],
        [13551],
        [22465],
        [20616],
        [19868],
        [18465],
        [19539],
        [18093],
        [18332],
        [18066],
        [ 9324],
        [14970],
        [15749],
        [14723],
        [11968],
        [ 8865],
        [ 4813]], device='cuda:0')
[2024-07-24 10:22:58,215][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[39251],
        [40572],
        [37820],
        [40719],
        [39642],
        [40561],
        [40343],
        [37600],
        [39977],
        [37870],
        [35773],
        [40569],
        [37343],
        [36027],
        [33432],
        [36856],
        [34043]], device='cuda:0')
[2024-07-24 10:22:58,217][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18070],
        [26835],
        [26793],
        [23649],
        [19159],
        [18443],
        [17480],
        [16292],
        [15301],
        [14671],
        [14674],
        [14129],
        [13757],
        [13721],
        [13566],
        [13632],
        [13875]], device='cuda:0')
[2024-07-24 10:22:58,220][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22600],
        [24396],
        [22761],
        [20980],
        [18992],
        [15272],
        [15251],
        [15470],
        [16264],
        [17133],
        [17168],
        [15753],
        [16900],
        [15158],
        [13970],
        [15454],
        [18505]], device='cuda:0')
[2024-07-24 10:22:58,222][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10539],
        [10463],
        [10667],
        [10520],
        [10452],
        [10643],
        [10587],
        [10493],
        [10495],
        [10411],
        [ 9054],
        [ 8910],
        [ 9623],
        [ 9391],
        [ 9924],
        [10489],
        [10506]], device='cuda:0')
[2024-07-24 10:22:58,225][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[46597],
        [45338],
        [42015],
        [42015],
        [42015],
        [42016],
        [42018],
        [42015],
        [42015],
        [42015],
        [42015],
        [42015],
        [42015],
        [42015],
        [42050],
        [43187],
        [43868]], device='cuda:0')
[2024-07-24 10:22:58,226][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[38091],
        [35444],
        [30796],
        [32842],
        [33267],
        [32961],
        [33788],
        [32717],
        [33168],
        [34746],
        [34462],
        [34133],
        [33151],
        [33741],
        [36696],
        [34637],
        [35562]], device='cuda:0')
[2024-07-24 10:22:58,228][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38257],
        [29888],
        [38078],
        [36766],
        [43286],
        [42643],
        [43947],
        [41127],
        [41042],
        [29567],
        [36975],
        [35004],
        [39382],
        [29929],
        [48671],
        [41977],
        [41712]], device='cuda:0')
[2024-07-24 10:22:58,229][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211],
        [10211]], device='cuda:0')
[2024-07-24 10:22:58,287][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:58,291][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,293][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,297][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,297][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,298][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,299][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,299][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,301][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,301][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,302][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,303][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,303][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,304][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9398, 0.0602], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,305][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0105, 0.9895], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,305][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0197, 0.9803], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,306][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.8861, 0.1139], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,307][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.5536, 0.4464], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,308][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.6566, 0.3434], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,308][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,311][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0397, 0.9603], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,314][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9663, 0.0337], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,318][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.3393, 0.6607], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,321][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0287, 0.9713], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,325][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0813, 0.9187], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,328][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8927, 0.0558, 0.0515], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,329][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0090, 0.2960, 0.6950], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,330][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0092, 0.5132, 0.4776], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,331][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4528, 0.1859, 0.3613], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,332][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1889, 0.6777, 0.1334], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,333][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5061, 0.2866, 0.2073], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,336][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9478, 0.0116, 0.0406], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,339][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0171, 0.5211, 0.4618], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,343][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9163, 0.0393, 0.0445], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,346][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1958, 0.4015, 0.4027], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,350][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0162, 0.5684, 0.4155], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,353][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0447, 0.5044, 0.4509], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,353][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.8281, 0.0537, 0.0476, 0.0707], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,354][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ William] are: tensor([3.4249e-04, 4.8112e-02, 9.2889e-02, 8.5866e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,355][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0065, 0.3405, 0.3207, 0.3323], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,356][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.4772, 0.0968, 0.3557, 0.0703], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,358][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0820, 0.7672, 0.0533, 0.0975], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,361][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.3743, 0.2255, 0.1805, 0.2198], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,365][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.8440, 0.0081, 0.1145, 0.0334], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,368][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0156, 0.3664, 0.3158, 0.3021], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,372][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.8649, 0.0429, 0.0519, 0.0404], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,376][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.1414, 0.2888, 0.2914, 0.2785], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,379][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0079, 0.4729, 0.3665, 0.1526], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,379][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0281, 0.3470, 0.3130, 0.3119], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,380][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.8234, 0.0489, 0.0414, 0.0601, 0.0262], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,381][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ got] are: tensor([5.9930e-04, 4.0986e-02, 1.2111e-01, 6.6253e-01, 1.7477e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,382][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0043, 0.2588, 0.2441, 0.2548, 0.2379], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,385][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.4720, 0.0652, 0.2810, 0.1311, 0.0507], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,389][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.1059, 0.5721, 0.0474, 0.1030, 0.1716], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,392][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.3097, 0.1854, 0.1422, 0.1783, 0.1845], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,396][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.8803, 0.0059, 0.0588, 0.0378, 0.0172], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,400][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0102, 0.2916, 0.2547, 0.2482, 0.1953], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,402][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.8174, 0.0445, 0.0458, 0.0503, 0.0420], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,403][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.1117, 0.2306, 0.2314, 0.2225, 0.2039], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,404][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0107, 0.3572, 0.2625, 0.1202, 0.2494], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,405][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0210, 0.2591, 0.2320, 0.2335, 0.2545], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,406][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6978, 0.0616, 0.0552, 0.0753, 0.0349, 0.0752], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,408][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.9760e-04, 2.7407e-02, 4.7182e-02, 5.7985e-01, 7.2821e-02, 2.7255e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,411][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0036, 0.2053, 0.1955, 0.2012, 0.1907, 0.2037], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,415][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2305, 0.1205, 0.3044, 0.1616, 0.0672, 0.1158], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,418][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0018, 0.5695, 0.0217, 0.1003, 0.2937, 0.0129], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,422][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2789, 0.1606, 0.1135, 0.1521, 0.1526, 0.1424], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,426][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.8269, 0.0116, 0.0414, 0.0360, 0.0353, 0.0488], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,427][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0068, 0.2328, 0.2067, 0.1937, 0.1676, 0.1924], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,428][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5461, 0.0878, 0.0960, 0.0851, 0.1450, 0.0401], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,429][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0900, 0.1875, 0.1923, 0.1836, 0.1705, 0.1761], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,429][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0079, 0.2992, 0.2215, 0.1017, 0.2100, 0.1597], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,431][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0158, 0.2149, 0.1870, 0.1890, 0.2031, 0.1902], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,434][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.6965, 0.0532, 0.0439, 0.0599, 0.0287, 0.0614, 0.0563],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,436][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([3.5428e-04, 3.3052e-02, 5.5255e-02, 4.4349e-01, 8.6474e-02, 2.1435e-01,
        1.6702e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,442][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0032, 0.1709, 0.1620, 0.1676, 0.1578, 0.1692, 0.1693],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,448][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.2212, 0.0939, 0.3099, 0.0741, 0.0690, 0.1671, 0.0647],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,450][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0007, 0.5160, 0.0227, 0.1272, 0.3050, 0.0216, 0.0068],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,451][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.2204, 0.1607, 0.0965, 0.1337, 0.1366, 0.1067, 0.1455],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,451][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.7954, 0.0046, 0.0567, 0.0486, 0.0218, 0.0675, 0.0053],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,452][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0064, 0.1931, 0.1704, 0.1596, 0.1331, 0.1663, 0.1711],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,456][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.3863, 0.0910, 0.1381, 0.1108, 0.1948, 0.0521, 0.0269],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,461][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0779, 0.1595, 0.1638, 0.1556, 0.1455, 0.1502, 0.1475],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,467][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0069, 0.2711, 0.1958, 0.0882, 0.1837, 0.1389, 0.1154],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,471][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0128, 0.1680, 0.1516, 0.1543, 0.1643, 0.1527, 0.1963],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,472][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.5331, 0.0608, 0.0571, 0.0699, 0.0371, 0.0719, 0.0631, 0.1071],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,473][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([2.1497e-04, 2.1405e-02, 6.9509e-02, 4.3680e-01, 7.3909e-02, 2.4019e-01,
        8.6737e-02, 7.1237e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,474][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0024, 0.1465, 0.1392, 0.1433, 0.1356, 0.1446, 0.1450, 0.1434],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,477][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1558, 0.1121, 0.2101, 0.1049, 0.0605, 0.1147, 0.1226, 0.1193],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,482][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0047, 0.4938, 0.0292, 0.0758, 0.3512, 0.0197, 0.0082, 0.0174],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,487][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.1873, 0.1348, 0.0854, 0.1167, 0.1145, 0.0967, 0.1339, 0.1308],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,492][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.7486, 0.0115, 0.0382, 0.0427, 0.0353, 0.0772, 0.0207, 0.0259],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,494][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0047, 0.1661, 0.1472, 0.1371, 0.1171, 0.1428, 0.1480, 0.1368],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,495][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.5151, 0.0758, 0.1027, 0.0905, 0.1213, 0.0375, 0.0213, 0.0357],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,495][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0698, 0.1364, 0.1416, 0.1354, 0.1266, 0.1314, 0.1293, 0.1294],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,496][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0056, 0.2335, 0.1691, 0.0768, 0.1598, 0.1199, 0.1008, 0.1345],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,500][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0110, 0.1482, 0.1306, 0.1309, 0.1408, 0.1319, 0.1696, 0.1372],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,505][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4941, 0.0561, 0.0478, 0.0620, 0.0302, 0.0627, 0.0556, 0.0940, 0.0974],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,509][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.1953e-04, 3.0333e-02, 5.3298e-02, 3.9824e-01, 6.3914e-02, 2.1278e-01,
        9.4487e-02, 5.5833e-02, 9.0897e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,515][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0022, 0.1275, 0.1218, 0.1251, 0.1187, 0.1262, 0.1267, 0.1257, 0.1260],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,516][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1544, 0.0850, 0.1705, 0.0871, 0.0397, 0.0766, 0.0977, 0.1484, 0.1407],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,517][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0201, 0.5614, 0.0274, 0.0785, 0.2311, 0.0098, 0.0045, 0.0108, 0.0565],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,518][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1757, 0.1045, 0.0790, 0.1019, 0.1002, 0.0901, 0.1234, 0.1249, 0.1002],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,521][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.6732, 0.0114, 0.0397, 0.0447, 0.0404, 0.0608, 0.0224, 0.0747, 0.0327],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,526][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0040, 0.1460, 0.1292, 0.1218, 0.1028, 0.1222, 0.1278, 0.1233, 0.1229],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,531][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5581, 0.0701, 0.0757, 0.0770, 0.0999, 0.0283, 0.0154, 0.0304, 0.0452],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,537][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0614, 0.1229, 0.1257, 0.1207, 0.1118, 0.1150, 0.1133, 0.1152, 0.1140],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,538][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0050, 0.2045, 0.1510, 0.0683, 0.1433, 0.1077, 0.0884, 0.1184, 0.1134],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,539][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0088, 0.1320, 0.1156, 0.1172, 0.1253, 0.1160, 0.1491, 0.1198, 0.1162],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:58,540][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.5198, 0.0435, 0.0374, 0.0487, 0.0233, 0.0517, 0.0460, 0.0825, 0.0854,
        0.0617], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,543][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0007, 0.0409, 0.0716, 0.3099, 0.0891, 0.1978, 0.1006, 0.0388, 0.0731,
        0.0775], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,548][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0021, 0.1129, 0.1075, 0.1108, 0.1048, 0.1120, 0.1123, 0.1115, 0.1124,
        0.1136], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,553][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.1084, 0.0759, 0.1860, 0.0624, 0.0235, 0.0793, 0.0834, 0.1805, 0.1201,
        0.0805], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,559][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0112, 0.4607, 0.0405, 0.1265, 0.2330, 0.0088, 0.0026, 0.0092, 0.0633,
        0.0442], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,560][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.1338, 0.1137, 0.0701, 0.0969, 0.0978, 0.0778, 0.1059, 0.1019, 0.0878,
        0.1143], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,561][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.4292, 0.0081, 0.0569, 0.0684, 0.0469, 0.1604, 0.0199, 0.0995, 0.0952,
        0.0155], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,562][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0038, 0.1320, 0.1136, 0.1092, 0.0919, 0.1136, 0.1138, 0.1116, 0.1092,
        0.1014], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,566][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.3546, 0.0838, 0.1267, 0.1004, 0.1427, 0.0362, 0.0201, 0.0357, 0.0678,
        0.0320], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,571][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0552, 0.1113, 0.1128, 0.1083, 0.1006, 0.1040, 0.1024, 0.1039, 0.1028,
        0.0986], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,577][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0039, 0.1875, 0.1399, 0.0628, 0.1332, 0.0971, 0.0815, 0.1076, 0.1013,
        0.0852], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,581][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0085, 0.1144, 0.1031, 0.1043, 0.1114, 0.1038, 0.1314, 0.1065, 0.1024,
        0.1142], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:58,582][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4060, 0.0469, 0.0428, 0.0553, 0.0281, 0.0526, 0.0475, 0.0812, 0.0823,
        0.0613, 0.0960], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,583][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.1434e-04, 1.6127e-02, 6.1216e-02, 2.4079e-01, 4.7667e-02, 1.5852e-01,
        6.8708e-02, 5.4679e-02, 8.0589e-02, 5.3235e-02, 2.1826e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,584][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0019, 0.1021, 0.0972, 0.0998, 0.0947, 0.1005, 0.1010, 0.1002, 0.1007,
        0.1017, 0.1003], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,587][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1078, 0.0424, 0.0860, 0.0628, 0.0426, 0.0796, 0.0655, 0.0788, 0.1979,
        0.1031, 0.1335], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,591][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0598, 0.3760, 0.0374, 0.0435, 0.1908, 0.0154, 0.0079, 0.0217, 0.0865,
        0.0808, 0.0803], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,597][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1313, 0.0765, 0.0675, 0.0832, 0.0785, 0.0759, 0.1036, 0.1046, 0.0823,
        0.1169, 0.0798], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,603][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4285, 0.0119, 0.0267, 0.0829, 0.0600, 0.1341, 0.0304, 0.0512, 0.0917,
        0.0293, 0.0532], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,604][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0038, 0.1175, 0.1027, 0.0989, 0.0812, 0.1016, 0.1027, 0.0982, 0.1014,
        0.0939, 0.0982], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,605][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3867, 0.0813, 0.1043, 0.0920, 0.1073, 0.0333, 0.0176, 0.0384, 0.0573,
        0.0311, 0.0507], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,606][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0499, 0.1002, 0.1022, 0.0986, 0.0910, 0.0933, 0.0912, 0.0934, 0.0934,
        0.0900, 0.0970], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,609][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0035, 0.1759, 0.1265, 0.0572, 0.1211, 0.0904, 0.0729, 0.0993, 0.0951,
        0.0756, 0.0825], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,614][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0079, 0.1052, 0.0930, 0.0931, 0.0999, 0.0936, 0.1166, 0.0970, 0.0926,
        0.1014, 0.0997], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:58,619][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.4329, 0.0373, 0.0315, 0.0457, 0.0213, 0.0453, 0.0416, 0.0750, 0.0760,
        0.0556, 0.0843, 0.0537], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,623][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ William] are: tensor([1.1388e-04, 1.3323e-02, 3.9835e-02, 2.3138e-01, 5.1916e-02, 1.3460e-01,
        8.5843e-02, 3.9562e-02, 6.9635e-02, 5.1699e-02, 1.4327e-01, 1.3882e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,625][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0021, 0.0911, 0.0874, 0.0895, 0.0854, 0.0910, 0.0915, 0.0909, 0.0911,
        0.0922, 0.0911, 0.0968], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,626][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0988, 0.0270, 0.1169, 0.0278, 0.0185, 0.0847, 0.0548, 0.1155, 0.1367,
        0.1063, 0.1853, 0.0278], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,627][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0343, 0.4245, 0.0182, 0.0391, 0.1225, 0.0072, 0.0030, 0.0097, 0.0667,
        0.0807, 0.0696, 0.1245], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,628][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.1339, 0.0775, 0.0546, 0.0708, 0.0769, 0.0660, 0.0961, 0.0907, 0.0745,
        0.1070, 0.0677, 0.0844], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,632][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.4007, 0.0059, 0.0616, 0.0234, 0.0386, 0.1723, 0.0227, 0.0610, 0.1061,
        0.0142, 0.0763, 0.0172], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,638][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0039, 0.1101, 0.0924, 0.0904, 0.0726, 0.0910, 0.0965, 0.0868, 0.0896,
        0.0866, 0.0875, 0.0925], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,644][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.3511, 0.0668, 0.0820, 0.0633, 0.1401, 0.0360, 0.0182, 0.0331, 0.0610,
        0.0362, 0.0698, 0.0425], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,646][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0449, 0.0921, 0.0943, 0.0897, 0.0838, 0.0857, 0.0837, 0.0858, 0.0856,
        0.0820, 0.0888, 0.0837], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,647][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0032, 0.1641, 0.1208, 0.0527, 0.1136, 0.0836, 0.0685, 0.0920, 0.0865,
        0.0706, 0.0751, 0.0692], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,648][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0070, 0.0929, 0.0838, 0.0846, 0.0905, 0.0842, 0.1051, 0.0862, 0.0832,
        0.0921, 0.0893, 0.1009], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:58,649][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.3967, 0.0374, 0.0300, 0.0422, 0.0211, 0.0439, 0.0408, 0.0688, 0.0723,
        0.0535, 0.0810, 0.0512, 0.0609], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,653][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0003, 0.0211, 0.0617, 0.2002, 0.0684, 0.1588, 0.0714, 0.0425, 0.0636,
        0.0470, 0.1186, 0.0871, 0.0592], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,659][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0016, 0.0837, 0.0800, 0.0822, 0.0778, 0.0830, 0.0832, 0.0827, 0.0833,
        0.0842, 0.0834, 0.0891, 0.0859], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,665][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.1008, 0.0291, 0.1540, 0.0456, 0.0149, 0.0527, 0.0544, 0.1565, 0.1065,
        0.0729, 0.1762, 0.0283, 0.0081], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,667][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0395, 0.3570, 0.0322, 0.0546, 0.0891, 0.0039, 0.0015, 0.0054, 0.0315,
        0.0175, 0.0594, 0.0722, 0.2363], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,668][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.1380, 0.0690, 0.0437, 0.0637, 0.0624, 0.0542, 0.0783, 0.0765, 0.0602,
        0.0927, 0.0543, 0.0795, 0.1275], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,669][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.3569, 0.0071, 0.0667, 0.0509, 0.0220, 0.1140, 0.0234, 0.0685, 0.0890,
        0.0189, 0.1357, 0.0392, 0.0076], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,670][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0041, 0.0992, 0.0855, 0.0826, 0.0654, 0.0880, 0.0896, 0.0830, 0.0842,
        0.0771, 0.0814, 0.0856, 0.0744], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,674][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.4644, 0.0724, 0.0535, 0.0461, 0.0844, 0.0277, 0.0157, 0.0219, 0.0480,
        0.0261, 0.0495, 0.0376, 0.0527], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,680][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0416, 0.0835, 0.0853, 0.0819, 0.0762, 0.0784, 0.0772, 0.0791, 0.0787,
        0.0759, 0.0822, 0.0783, 0.0817], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,686][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0028, 0.1510, 0.1130, 0.0498, 0.1097, 0.0768, 0.0651, 0.0869, 0.0801,
        0.0676, 0.0698, 0.0657, 0.0616], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,688][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0066, 0.0843, 0.0758, 0.0762, 0.0820, 0.0766, 0.0969, 0.0794, 0.0759,
        0.0830, 0.0812, 0.0911, 0.0909], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:58,689][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3425, 0.0414, 0.0340, 0.0441, 0.0222, 0.0413, 0.0369, 0.0608, 0.0605,
        0.0442, 0.0697, 0.0455, 0.0519, 0.1050], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,690][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0002, 0.0189, 0.0689, 0.2169, 0.0551, 0.1974, 0.0482, 0.0495, 0.0598,
        0.0294, 0.1157, 0.0674, 0.0252, 0.0474], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,691][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0014, 0.0774, 0.0740, 0.0758, 0.0717, 0.0764, 0.0768, 0.0761, 0.0765,
        0.0775, 0.0766, 0.0818, 0.0793, 0.0788], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,696][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1044, 0.0368, 0.1192, 0.0412, 0.0232, 0.0655, 0.0554, 0.0855, 0.1097,
        0.0813, 0.1720, 0.0417, 0.0190, 0.0449], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,701][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0241, 0.2248, 0.0266, 0.0378, 0.1360, 0.0036, 0.0014, 0.0035, 0.0238,
        0.0202, 0.0315, 0.0350, 0.3773, 0.0543], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,707][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1286, 0.0607, 0.0449, 0.0597, 0.0596, 0.0513, 0.0697, 0.0698, 0.0564,
        0.0796, 0.0531, 0.0692, 0.1132, 0.0842], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,709][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3161, 0.0120, 0.0343, 0.0562, 0.0534, 0.1271, 0.0293, 0.0468, 0.0930,
        0.0253, 0.0793, 0.0507, 0.0194, 0.0571], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,710][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0028, 0.0898, 0.0771, 0.0778, 0.0646, 0.0774, 0.0782, 0.0740, 0.0770,
        0.0728, 0.0751, 0.0806, 0.0728, 0.0800], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,711][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5606, 0.0364, 0.0526, 0.0416, 0.0605, 0.0167, 0.0085, 0.0160, 0.0325,
        0.0174, 0.0379, 0.0262, 0.0397, 0.0535], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,713][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0395, 0.0760, 0.0790, 0.0762, 0.0712, 0.0729, 0.0718, 0.0730, 0.0728,
        0.0706, 0.0756, 0.0719, 0.0753, 0.0743], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,717][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0027, 0.1404, 0.1040, 0.0462, 0.0987, 0.0739, 0.0595, 0.0803, 0.0764,
        0.0618, 0.0659, 0.0612, 0.0560, 0.0730], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,723][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0056, 0.0800, 0.0698, 0.0704, 0.0757, 0.0694, 0.0889, 0.0720, 0.0695,
        0.0775, 0.0748, 0.0843, 0.0838, 0.0783], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:58,729][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.3546, 0.0329, 0.0268, 0.0364, 0.0170, 0.0349, 0.0323, 0.0573, 0.0578,
        0.0430, 0.0671, 0.0407, 0.0469, 0.1039, 0.0485], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,731][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0004, 0.0195, 0.0689, 0.1842, 0.0687, 0.1758, 0.0574, 0.0437, 0.0614,
        0.0446, 0.0986, 0.0676, 0.0401, 0.0459, 0.0232], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,732][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0014, 0.0717, 0.0685, 0.0704, 0.0664, 0.0707, 0.0710, 0.0705, 0.0708,
        0.0716, 0.0708, 0.0757, 0.0732, 0.0730, 0.0742], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,732][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0829, 0.0413, 0.1338, 0.0453, 0.0151, 0.0523, 0.0537, 0.0858, 0.1281,
        0.0718, 0.1660, 0.0383, 0.0149, 0.0573, 0.0134], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,734][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0431, 0.2255, 0.0297, 0.0487, 0.0700, 0.0016, 0.0008, 0.0024, 0.0153,
        0.0102, 0.0253, 0.0344, 0.1820, 0.0485, 0.2625], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,740][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0937, 0.0591, 0.0374, 0.0516, 0.0544, 0.0462, 0.0658, 0.0647, 0.0521,
        0.0732, 0.0447, 0.0625, 0.1194, 0.0890, 0.0863], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,746][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.4132, 0.0081, 0.0445, 0.0408, 0.0279, 0.0620, 0.0125, 0.0561, 0.0509,
        0.0183, 0.0900, 0.0324, 0.0106, 0.1176, 0.0151], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,752][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0031, 0.0817, 0.0741, 0.0706, 0.0606, 0.0743, 0.0728, 0.0726, 0.0723,
        0.0678, 0.0731, 0.0739, 0.0657, 0.0785, 0.0588], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,752][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.4316, 0.0448, 0.0518, 0.0442, 0.0556, 0.0217, 0.0129, 0.0217, 0.0378,
        0.0173, 0.0413, 0.0300, 0.0428, 0.0790, 0.0675], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,753][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0369, 0.0715, 0.0735, 0.0706, 0.0660, 0.0682, 0.0674, 0.0683, 0.0676,
        0.0651, 0.0703, 0.0667, 0.0699, 0.0690, 0.0692], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,754][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0036, 0.1279, 0.0945, 0.0439, 0.0883, 0.0659, 0.0546, 0.0721, 0.0680,
        0.0577, 0.0604, 0.0563, 0.0533, 0.0654, 0.0882], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,758][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0055, 0.0720, 0.0647, 0.0646, 0.0700, 0.0647, 0.0824, 0.0672, 0.0644,
        0.0718, 0.0692, 0.0778, 0.0772, 0.0726, 0.0759], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:58,763][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.2942, 0.0321, 0.0247, 0.0345, 0.0171, 0.0342, 0.0319, 0.0543, 0.0558,
        0.0416, 0.0635, 0.0414, 0.0476, 0.0975, 0.0482, 0.0815],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,767][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ it] are: tensor([1.3479e-04, 1.1226e-02, 5.5972e-02, 2.0732e-01, 5.9627e-02, 1.3830e-01,
        4.9657e-02, 4.1075e-02, 4.8659e-02, 3.2444e-02, 1.0379e-01, 7.2701e-02,
        4.2012e-02, 4.7192e-02, 2.1267e-02, 6.8623e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,773][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0012, 0.0667, 0.0639, 0.0654, 0.0620, 0.0658, 0.0660, 0.0655, 0.0659,
        0.0667, 0.0660, 0.0706, 0.0684, 0.0682, 0.0695, 0.0682],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,774][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0919, 0.0244, 0.1413, 0.0370, 0.0259, 0.0421, 0.0565, 0.1125, 0.0870,
        0.0613, 0.1542, 0.0296, 0.0193, 0.0463, 0.0324, 0.0382],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,775][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0290, 0.2214, 0.0184, 0.0378, 0.0762, 0.0014, 0.0006, 0.0017, 0.0079,
        0.0061, 0.0147, 0.0219, 0.1022, 0.0311, 0.2200, 0.2098],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,776][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0923, 0.0518, 0.0402, 0.0512, 0.0529, 0.0469, 0.0613, 0.0631, 0.0498,
        0.0687, 0.0469, 0.0591, 0.1029, 0.0773, 0.0791, 0.0566],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,779][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.4843, 0.0076, 0.0293, 0.0413, 0.0383, 0.0398, 0.0121, 0.0763, 0.0222,
        0.0211, 0.0594, 0.0410, 0.0177, 0.0703, 0.0263, 0.0132],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,785][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0028, 0.0803, 0.0700, 0.0674, 0.0550, 0.0654, 0.0693, 0.0652, 0.0669,
        0.0650, 0.0684, 0.0699, 0.0646, 0.0727, 0.0581, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,791][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.3869, 0.0537, 0.0515, 0.0413, 0.0658, 0.0191, 0.0108, 0.0170, 0.0325,
        0.0151, 0.0364, 0.0295, 0.0451, 0.0695, 0.0780, 0.0475],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,794][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0321, 0.0679, 0.0708, 0.0666, 0.0622, 0.0637, 0.0628, 0.0641, 0.0632,
        0.0610, 0.0656, 0.0619, 0.0655, 0.0652, 0.0653, 0.0622],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,795][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0028, 0.1189, 0.0873, 0.0403, 0.0821, 0.0616, 0.0508, 0.0689, 0.0639,
        0.0536, 0.0559, 0.0525, 0.0488, 0.0617, 0.0824, 0.0684],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,796][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0045, 0.0683, 0.0597, 0.0606, 0.0646, 0.0600, 0.0783, 0.0621, 0.0601,
        0.0671, 0.0644, 0.0737, 0.0721, 0.0669, 0.0697, 0.0679],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:58,797][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2601, 0.0314, 0.0260, 0.0336, 0.0180, 0.0339, 0.0315, 0.0512, 0.0523,
        0.0391, 0.0588, 0.0385, 0.0457, 0.0875, 0.0442, 0.0731, 0.0751],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,799][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3168e-04, 1.3036e-02, 5.6723e-02, 2.0763e-01, 4.5661e-02, 1.4529e-01,
        3.3010e-02, 4.2572e-02, 4.8768e-02, 2.4993e-02, 9.6551e-02, 6.3053e-02,
        2.8236e-02, 4.7806e-02, 1.6364e-02, 4.8043e-02, 8.2136e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,804][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0012, 0.0626, 0.0598, 0.0612, 0.0579, 0.0617, 0.0620, 0.0615, 0.0618,
        0.0626, 0.0619, 0.0660, 0.0640, 0.0636, 0.0649, 0.0642, 0.0631],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,810][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0915, 0.0312, 0.1072, 0.0372, 0.0180, 0.0581, 0.0554, 0.0773, 0.1018,
        0.0779, 0.1562, 0.0375, 0.0163, 0.0392, 0.0269, 0.0421, 0.0262],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,814][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.5593e-02, 9.3846e-02, 1.1423e-02, 1.4746e-02, 5.5086e-02, 1.0469e-03,
        3.3462e-04, 8.2020e-04, 6.5956e-03, 5.1806e-03, 9.3928e-03, 9.3311e-03,
        1.1489e-01, 1.6709e-02, 2.3276e-01, 3.4409e-01, 6.8159e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,816][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0849, 0.0471, 0.0397, 0.0488, 0.0499, 0.0439, 0.0578, 0.0584, 0.0473,
        0.0636, 0.0459, 0.0574, 0.0949, 0.0723, 0.0735, 0.0577, 0.0569],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,817][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3208, 0.0108, 0.0261, 0.0480, 0.0571, 0.0974, 0.0253, 0.0450, 0.0705,
        0.0262, 0.0622, 0.0454, 0.0164, 0.0437, 0.0247, 0.0426, 0.0379],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,818][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0023, 0.0734, 0.0640, 0.0635, 0.0538, 0.0637, 0.0649, 0.0615, 0.0636,
        0.0604, 0.0625, 0.0658, 0.0608, 0.0661, 0.0563, 0.0539, 0.0638],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,821][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4960, 0.0272, 0.0419, 0.0333, 0.0452, 0.0129, 0.0071, 0.0128, 0.0261,
        0.0140, 0.0310, 0.0210, 0.0319, 0.0426, 0.0641, 0.0551, 0.0377],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,827][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0309, 0.0630, 0.0663, 0.0625, 0.0591, 0.0603, 0.0594, 0.0601, 0.0596,
        0.0575, 0.0616, 0.0580, 0.0610, 0.0604, 0.0614, 0.0585, 0.0605],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,833][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0028, 0.1079, 0.0794, 0.0375, 0.0745, 0.0577, 0.0469, 0.0629, 0.0593,
        0.0485, 0.0522, 0.0489, 0.0455, 0.0570, 0.0751, 0.0635, 0.0802],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,836][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0048, 0.0644, 0.0562, 0.0568, 0.0613, 0.0562, 0.0707, 0.0582, 0.0563,
        0.0624, 0.0603, 0.0675, 0.0672, 0.0632, 0.0655, 0.0628, 0.0664],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:58,888][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:58,892][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,892][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,892][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,893][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,893][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,893][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,894][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,894][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,894][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,895][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,895][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,896][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:58,896][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.0962, 0.9038], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,896][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0215, 0.9785], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,897][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.9960, 0.0040], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,897][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.3467, 0.6533], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,897][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.8345, 0.1655], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,898][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.0475, 0.9525], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,898][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0234, 0.9766], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,898][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.9380, 0.0620], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,899][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.8344, 0.1656], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,899][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.1608, 0.8392], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,899][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.9973, 0.0027], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,900][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.9931, 0.0069], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:58,900][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2211, 0.5997, 0.1792], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,900][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0114, 0.0911, 0.8975], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,901][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9908, 0.0072, 0.0020], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,901][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2150, 0.4799, 0.3051], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,901][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5876, 0.3349, 0.0775], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,902][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0193, 0.4817, 0.4990], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,902][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0013, 0.9354, 0.0633], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,902][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6229, 0.1455, 0.2316], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,903][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4923, 0.4276, 0.0801], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,905][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0807, 0.4728, 0.4465], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,907][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9803, 0.0113, 0.0084], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,910][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9496, 0.0106, 0.0398], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:58,914][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.1098, 0.4418, 0.1917, 0.2567], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,918][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0163, 0.1791, 0.2536, 0.5510], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,921][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.9931, 0.0043, 0.0013, 0.0013], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,923][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.1477, 0.3676, 0.2653, 0.2194], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,923][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.2869, 0.1855, 0.4754, 0.0521], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,923][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0119, 0.3174, 0.3341, 0.3366], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,924][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0028, 0.6600, 0.0073, 0.3300], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,924][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.4811, 0.3587, 0.1124, 0.0478], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,925][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.5596, 0.2892, 0.1025, 0.0487], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,925][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0537, 0.3284, 0.3073, 0.3106], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,925][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.9830, 0.0071, 0.0049, 0.0050], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,926][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.9561, 0.0100, 0.0274, 0.0065], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:58,927][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.1016, 0.3437, 0.0911, 0.1302, 0.3333], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,929][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0019, 0.0520, 0.2014, 0.2138, 0.5309], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,933][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.9785, 0.0113, 0.0036, 0.0039, 0.0026], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,936][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.1347, 0.2791, 0.1995, 0.1839, 0.2028], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,940][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.2702, 0.1900, 0.4597, 0.0704, 0.0097], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,944][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0100, 0.2461, 0.2527, 0.2609, 0.2303], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,946][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0032, 0.5430, 0.0107, 0.3820, 0.0611], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,947][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.3967, 0.1696, 0.1390, 0.0405, 0.2542], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,947][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3460, 0.4289, 0.0648, 0.0821, 0.0782], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,947][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0363, 0.2517, 0.2350, 0.2418, 0.2352], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,948][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.8575, 0.0386, 0.0259, 0.0291, 0.0489], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,948][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.9202, 0.0108, 0.0374, 0.0068, 0.0248], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:58,948][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1307, 0.2909, 0.0889, 0.1158, 0.1945, 0.1792], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,949][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0007, 0.0423, 0.1993, 0.1038, 0.3935, 0.2604], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,950][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.9832, 0.0080, 0.0025, 0.0025, 0.0019, 0.0019], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,952][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1104, 0.2490, 0.1721, 0.1561, 0.1712, 0.1412], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,954][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4482, 0.2240, 0.1861, 0.0774, 0.0218, 0.0424], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,957][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0097, 0.2039, 0.2032, 0.2128, 0.1899, 0.1805], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,961][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0223, 0.5856, 0.0043, 0.2097, 0.0856, 0.0926], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,965][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0499, 0.2092, 0.1053, 0.0422, 0.5567, 0.0366], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,968][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0846, 0.4988, 0.0649, 0.0721, 0.2500, 0.0296], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,970][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0290, 0.2058, 0.1925, 0.1954, 0.1918, 0.1854], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,970][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6999, 0.0691, 0.0430, 0.0380, 0.0557, 0.0942], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,971][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.8488, 0.0324, 0.0516, 0.0124, 0.0230, 0.0318], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:58,971][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0890, 0.2545, 0.0485, 0.0808, 0.1365, 0.1587, 0.2319],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,971][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0017, 0.0469, 0.1316, 0.1645, 0.2315, 0.1043, 0.3194],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,972][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.9841, 0.0065, 0.0021, 0.0021, 0.0015, 0.0016, 0.0021],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,972][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0860, 0.2134, 0.1570, 0.1222, 0.1529, 0.1340, 0.1345],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,972][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1282, 0.2100, 0.2727, 0.0456, 0.0176, 0.2916, 0.0343],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,974][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0081, 0.1730, 0.1718, 0.1778, 0.1599, 0.1513, 0.1580],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,976][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0136, 0.3539, 0.0022, 0.1173, 0.0370, 0.0686, 0.4074],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,980][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0242, 0.3629, 0.0786, 0.0745, 0.4135, 0.0291, 0.0171],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,983][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0266, 0.3783, 0.0907, 0.1044, 0.3439, 0.0443, 0.0119],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,987][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0239, 0.1726, 0.1621, 0.1643, 0.1615, 0.1558, 0.1597],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,991][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.8732, 0.0166, 0.0119, 0.0101, 0.0281, 0.0307, 0.0293],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,993][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.8263, 0.0339, 0.0530, 0.0151, 0.0337, 0.0272, 0.0108],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:58,994][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0541, 0.1157, 0.0681, 0.0791, 0.1704, 0.1285, 0.1484, 0.2357],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,994][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([6.1482e-05, 6.2185e-03, 9.6192e-02, 2.8048e-02, 1.5543e-01, 6.0740e-02,
        1.0916e-01, 5.4415e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,995][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.9754, 0.0091, 0.0028, 0.0029, 0.0021, 0.0021, 0.0027, 0.0030],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,995][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0770, 0.1893, 0.1342, 0.1142, 0.1383, 0.1124, 0.1396, 0.0949],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,995][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2064, 0.2510, 0.1583, 0.0694, 0.0337, 0.2222, 0.0425, 0.0166],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,996][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0083, 0.1505, 0.1463, 0.1524, 0.1367, 0.1298, 0.1354, 0.1407],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,996][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0147, 0.2428, 0.0104, 0.1057, 0.0430, 0.0712, 0.4188, 0.0933],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:58,998][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0584, 0.2573, 0.0773, 0.0379, 0.4953, 0.0341, 0.0120, 0.0277],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,000][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1218, 0.4518, 0.0760, 0.0972, 0.2022, 0.0273, 0.0104, 0.0133],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,004][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0195, 0.1509, 0.1398, 0.1431, 0.1392, 0.1355, 0.1394, 0.1326],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,007][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.7197, 0.0498, 0.0251, 0.0274, 0.0430, 0.0607, 0.0397, 0.0345],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,010][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.8811, 0.0155, 0.0336, 0.0080, 0.0157, 0.0146, 0.0078, 0.0237],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,014][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0579, 0.1260, 0.0516, 0.0709, 0.1279, 0.1096, 0.1314, 0.1891, 0.1356],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,016][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([5.5158e-05, 7.5755e-03, 1.0211e-01, 2.5190e-02, 1.1653e-01, 6.5407e-02,
        7.6047e-02, 3.8224e-01, 2.2485e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,017][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.9805, 0.0065, 0.0020, 0.0020, 0.0015, 0.0015, 0.0020, 0.0022, 0.0018],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,017][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0639, 0.1801, 0.1232, 0.1062, 0.1202, 0.1007, 0.1230, 0.0913, 0.0914],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,018][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2284, 0.1858, 0.1850, 0.0645, 0.0554, 0.1080, 0.0669, 0.0757, 0.0303],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,018][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0070, 0.1319, 0.1296, 0.1351, 0.1209, 0.1141, 0.1188, 0.1250, 0.1177],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,019][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0060, 0.2434, 0.0025, 0.1158, 0.0389, 0.0564, 0.4455, 0.0601, 0.0313],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,019][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1846, 0.2159, 0.1007, 0.0294, 0.3129, 0.0222, 0.0089, 0.0286, 0.0968],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,019][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1429, 0.4492, 0.0596, 0.0824, 0.1714, 0.0210, 0.0066, 0.0149, 0.0520],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,020][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0187, 0.1319, 0.1224, 0.1260, 0.1229, 0.1191, 0.1231, 0.1176, 0.1182],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,022][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.6132, 0.0644, 0.0335, 0.0338, 0.0477, 0.0831, 0.0380, 0.0353, 0.0509],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,025][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8826, 0.0191, 0.0291, 0.0068, 0.0120, 0.0114, 0.0048, 0.0096, 0.0246],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,028][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0253, 0.1545, 0.0437, 0.0755, 0.1321, 0.1044, 0.1429, 0.1332, 0.1145,
        0.0738], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,030][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([2.9457e-04, 1.5997e-02, 5.3357e-02, 3.9060e-02, 8.8042e-02, 4.7424e-02,
        1.1182e-01, 3.0514e-01, 1.8466e-01, 1.5421e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,034][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.9813, 0.0060, 0.0018, 0.0018, 0.0013, 0.0013, 0.0017, 0.0019, 0.0015,
        0.0014], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,037][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0473, 0.1617, 0.1174, 0.0908, 0.0980, 0.0943, 0.1137, 0.0902, 0.0845,
        0.1022], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,041][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0629, 0.2592, 0.1661, 0.0386, 0.0167, 0.1991, 0.0406, 0.0849, 0.1148,
        0.0171], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,043][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.0056, 0.1166, 0.1169, 0.1216, 0.1081, 0.1014, 0.1060, 0.1094, 0.1047,
        0.1097], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,044][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0138, 0.2705, 0.0022, 0.0762, 0.0224, 0.0624, 0.3482, 0.0781, 0.0383,
        0.0878], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,044][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.1386, 0.2716, 0.0844, 0.0523, 0.2703, 0.0171, 0.0050, 0.0275, 0.0694,
        0.0638], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,045][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0662, 0.3691, 0.0896, 0.0935, 0.2217, 0.0231, 0.0069, 0.0131, 0.0922,
        0.0245], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,045][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0161, 0.1187, 0.1091, 0.1126, 0.1092, 0.1059, 0.1096, 0.1047, 0.1059,
        0.1082], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,045][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.8802, 0.0120, 0.0077, 0.0076, 0.0205, 0.0230, 0.0207, 0.0094, 0.0110,
        0.0078], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,046][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.8357, 0.0232, 0.0252, 0.0078, 0.0163, 0.0125, 0.0067, 0.0122, 0.0313,
        0.0293], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,046][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0642, 0.1451, 0.0264, 0.0656, 0.0942, 0.0793, 0.0938, 0.1456, 0.0978,
        0.1072, 0.0808], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,047][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.0512e-05, 2.3957e-03, 7.0777e-02, 9.5019e-03, 6.1602e-02, 2.8313e-02,
        2.9215e-02, 1.2431e-01, 1.0730e-01, 2.9413e-02, 5.3713e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,050][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9812, 0.0054, 0.0015, 0.0015, 0.0012, 0.0011, 0.0015, 0.0017, 0.0014,
        0.0013, 0.0021], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,052][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0611, 0.1379, 0.0935, 0.0856, 0.1038, 0.0854, 0.1008, 0.0688, 0.0805,
        0.0948, 0.0878], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,056][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2078, 0.1725, 0.0731, 0.0842, 0.0421, 0.2101, 0.0532, 0.0309, 0.0929,
        0.0231, 0.0101], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,059][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0051, 0.1045, 0.1040, 0.1082, 0.0954, 0.0905, 0.0940, 0.0986, 0.0938,
        0.0982, 0.1077], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,063][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0011, 0.1889, 0.0024, 0.0983, 0.0245, 0.0442, 0.4690, 0.0402, 0.0306,
        0.0986, 0.0022], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,067][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1718, 0.1525, 0.1214, 0.0259, 0.2241, 0.0190, 0.0075, 0.0380, 0.0751,
        0.0560, 0.1087], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,068][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0977, 0.3632, 0.0899, 0.0967, 0.1497, 0.0249, 0.0089, 0.0223, 0.0697,
        0.0355, 0.0415], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,068][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0142, 0.1068, 0.1001, 0.1021, 0.0994, 0.0965, 0.0993, 0.0955, 0.0957,
        0.0982, 0.0922], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,069][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6695, 0.0434, 0.0253, 0.0243, 0.0361, 0.0544, 0.0276, 0.0286, 0.0360,
        0.0179, 0.0370], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,069][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7973, 0.0203, 0.0319, 0.0073, 0.0152, 0.0106, 0.0065, 0.0122, 0.0190,
        0.0145, 0.0652], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,070][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0461, 0.0902, 0.0348, 0.0513, 0.0840, 0.1182, 0.1073, 0.1253, 0.1050,
        0.0708, 0.0760, 0.0910], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,070][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([1.1412e-04, 1.0386e-02, 4.5300e-02, 2.5056e-02, 4.1858e-02, 2.5582e-02,
        2.3137e-02, 8.3368e-02, 6.0359e-02, 4.3830e-02, 3.8538e-01, 2.5563e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,071][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([9.8644e-01, 3.3120e-03, 1.0811e-03, 1.0094e-03, 8.1216e-04, 8.0342e-04,
        1.0194e-03, 1.2174e-03, 9.4650e-04, 8.4328e-04, 1.4597e-03, 1.0530e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,073][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.0437, 0.1186, 0.0934, 0.0731, 0.0893, 0.0838, 0.0937, 0.0709, 0.0766,
        0.0907, 0.0920, 0.0741], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,076][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0839, 0.0598, 0.2271, 0.0175, 0.0175, 0.2954, 0.0330, 0.0905, 0.0997,
        0.0195, 0.0373, 0.0185], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,080][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0049, 0.0947, 0.0943, 0.0966, 0.0874, 0.0819, 0.0855, 0.0902, 0.0847,
        0.0903, 0.0976, 0.0920], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,083][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0082, 0.2669, 0.0007, 0.0344, 0.0184, 0.0550, 0.2152, 0.0230, 0.0224,
        0.0646, 0.0032, 0.2880], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,087][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.2337, 0.2722, 0.0450, 0.0250, 0.1929, 0.0108, 0.0058, 0.0175, 0.0433,
        0.0577, 0.0610, 0.0351], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,091][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0585, 0.1934, 0.0643, 0.0379, 0.3132, 0.0267, 0.0062, 0.0145, 0.0876,
        0.0420, 0.1024, 0.0532], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,092][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0131, 0.0977, 0.0914, 0.0917, 0.0906, 0.0880, 0.0904, 0.0865, 0.0876,
        0.0891, 0.0835, 0.0905], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,092][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.8808, 0.0120, 0.0067, 0.0066, 0.0149, 0.0205, 0.0151, 0.0086, 0.0113,
        0.0067, 0.0111, 0.0056], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,093][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.7952, 0.0163, 0.0171, 0.0050, 0.0089, 0.0072, 0.0056, 0.0071, 0.0239,
        0.0231, 0.0670, 0.0237], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,093][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0504, 0.0994, 0.0159, 0.0349, 0.0689, 0.0964, 0.1342, 0.1147, 0.0915,
        0.0602, 0.0595, 0.0951, 0.0789], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,093][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([5.3464e-05, 8.4023e-03, 4.0134e-02, 1.7619e-02, 6.2487e-02, 3.2840e-02,
        3.5879e-02, 9.7882e-02, 6.9646e-02, 2.9739e-02, 2.8246e-01, 1.1083e-01,
        2.1203e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,094][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([9.8229e-01, 4.5623e-03, 1.3323e-03, 1.3536e-03, 9.6717e-04, 9.1788e-04,
        1.1833e-03, 1.3636e-03, 1.1573e-03, 1.0369e-03, 1.8313e-03, 1.3624e-03,
        6.4321e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,094][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0540, 0.1158, 0.0849, 0.0713, 0.0780, 0.0734, 0.0862, 0.0666, 0.0676,
        0.0809, 0.0831, 0.0713, 0.0669], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,096][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.1142, 0.1367, 0.1988, 0.0452, 0.0130, 0.2069, 0.0320, 0.0729, 0.0754,
        0.0188, 0.0354, 0.0406, 0.0100], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,098][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0045, 0.0850, 0.0839, 0.0881, 0.0783, 0.0743, 0.0779, 0.0814, 0.0770,
        0.0809, 0.0889, 0.0859, 0.0939], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,102][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0195, 0.1983, 0.0016, 0.0544, 0.0132, 0.0200, 0.1322, 0.0260, 0.0208,
        0.0513, 0.0037, 0.2627, 0.1963], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,105][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.2146, 0.0894, 0.0712, 0.0168, 0.1043, 0.0047, 0.0023, 0.0104, 0.0257,
        0.0252, 0.0576, 0.0185, 0.3596], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,109][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1531, 0.3957, 0.0293, 0.0276, 0.1109, 0.0134, 0.0046, 0.0052, 0.0486,
        0.0232, 0.0467, 0.0430, 0.0988], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,113][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0122, 0.0899, 0.0836, 0.0857, 0.0831, 0.0806, 0.0826, 0.0791, 0.0796,
        0.0818, 0.0768, 0.0845, 0.0806], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,116][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.7149, 0.0342, 0.0145, 0.0153, 0.0307, 0.0480, 0.0282, 0.0192, 0.0270,
        0.0128, 0.0245, 0.0102, 0.0206], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,116][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.8035, 0.0173, 0.0208, 0.0060, 0.0156, 0.0110, 0.0038, 0.0107, 0.0199,
        0.0079, 0.0393, 0.0126, 0.0315], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,117][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0509, 0.1090, 0.0312, 0.0452, 0.0754, 0.0673, 0.0905, 0.1034, 0.0691,
        0.0672, 0.0761, 0.0812, 0.0595, 0.0738], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,117][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.5649e-06, 1.6871e-03, 5.4996e-02, 4.2714e-03, 9.8525e-02, 4.3913e-02,
        3.0445e-02, 1.8857e-01, 1.1796e-01, 1.6153e-02, 2.3765e-01, 1.4422e-02,
        6.2845e-02, 1.2855e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,118][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.7980e-01, 4.6792e-03, 1.3618e-03, 1.3978e-03, 1.0447e-03, 9.7876e-04,
        1.2448e-03, 1.4856e-03, 1.2916e-03, 1.1547e-03, 2.0053e-03, 1.4825e-03,
        7.1283e-04, 1.3576e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,118][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0408, 0.1150, 0.0817, 0.0673, 0.0778, 0.0676, 0.0801, 0.0580, 0.0613,
        0.0755, 0.0800, 0.0668, 0.0700, 0.0582], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,120][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0443, 0.1477, 0.1579, 0.0755, 0.0350, 0.1595, 0.0443, 0.0314, 0.1159,
        0.0496, 0.0312, 0.0604, 0.0414, 0.0057], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,122][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0045, 0.0796, 0.0758, 0.0810, 0.0720, 0.0685, 0.0710, 0.0746, 0.0702,
        0.0739, 0.0810, 0.0794, 0.0862, 0.0825], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,126][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0048, 0.2497, 0.0023, 0.0833, 0.0100, 0.0214, 0.0952, 0.0262, 0.0168,
        0.0504, 0.0029, 0.2340, 0.1891, 0.0139], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,129][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1030, 0.0758, 0.0422, 0.0156, 0.1334, 0.0052, 0.0018, 0.0099, 0.0248,
        0.0245, 0.0349, 0.0178, 0.4191, 0.0919], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,133][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2551, 0.2085, 0.0594, 0.0440, 0.0952, 0.0113, 0.0037, 0.0062, 0.0415,
        0.0189, 0.0521, 0.0353, 0.0967, 0.0722], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,137][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0112, 0.0831, 0.0777, 0.0784, 0.0771, 0.0745, 0.0763, 0.0732, 0.0739,
        0.0757, 0.0710, 0.0775, 0.0758, 0.0746], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,140][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6358, 0.0423, 0.0211, 0.0225, 0.0311, 0.0496, 0.0234, 0.0254, 0.0357,
        0.0127, 0.0262, 0.0154, 0.0277, 0.0310], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,140][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8116, 0.0174, 0.0255, 0.0070, 0.0142, 0.0091, 0.0037, 0.0087, 0.0129,
        0.0075, 0.0275, 0.0099, 0.0137, 0.0313], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,141][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0209, 0.0892, 0.0227, 0.0471, 0.0736, 0.0586, 0.0848, 0.1115, 0.0687,
        0.0488, 0.0672, 0.0769, 0.0654, 0.0750, 0.0896], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,141][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([5.3325e-06, 1.0698e-03, 2.7910e-02, 5.0077e-03, 5.0611e-02, 2.0424e-02,
        1.6767e-02, 8.4452e-02, 6.5258e-02, 1.2730e-02, 2.5266e-01, 2.7630e-02,
        5.8104e-02, 7.1209e-02, 3.0616e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,141][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([9.7444e-01, 5.6633e-03, 1.6891e-03, 1.7433e-03, 1.2233e-03, 1.1630e-03,
        1.5250e-03, 1.7347e-03, 1.5114e-03, 1.3678e-03, 2.4299e-03, 1.7985e-03,
        8.7613e-04, 1.6732e-03, 1.1657e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,142][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0339, 0.1041, 0.0761, 0.0632, 0.0715, 0.0634, 0.0732, 0.0539, 0.0621,
        0.0712, 0.0742, 0.0624, 0.0655, 0.0590, 0.0663], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,142][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0479, 0.1579, 0.1879, 0.0484, 0.0124, 0.1642, 0.0287, 0.0679, 0.1237,
        0.0191, 0.0453, 0.0412, 0.0231, 0.0217, 0.0106], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,144][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0036, 0.0724, 0.0705, 0.0753, 0.0665, 0.0634, 0.0664, 0.0689, 0.0654,
        0.0684, 0.0746, 0.0732, 0.0801, 0.0776, 0.0736], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,147][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0027, 0.1595, 0.0031, 0.0933, 0.0113, 0.0157, 0.1632, 0.0362, 0.0185,
        0.0559, 0.0040, 0.2206, 0.1598, 0.0297, 0.0265], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,150][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.2670, 0.0631, 0.0429, 0.0168, 0.0776, 0.0029, 0.0006, 0.0065, 0.0174,
        0.0181, 0.0382, 0.0129, 0.2153, 0.1188, 0.1019], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,154][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.2354, 0.2187, 0.0329, 0.0307, 0.0549, 0.0105, 0.0037, 0.0067, 0.0345,
        0.0102, 0.0419, 0.0327, 0.0858, 0.1182, 0.0833], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,157][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0104, 0.0758, 0.0711, 0.0721, 0.0711, 0.0690, 0.0709, 0.0682, 0.0687,
        0.0703, 0.0663, 0.0726, 0.0703, 0.0697, 0.0734], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,161][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.5415, 0.0494, 0.0249, 0.0218, 0.0399, 0.0555, 0.0354, 0.0267, 0.0396,
        0.0193, 0.0318, 0.0142, 0.0266, 0.0313, 0.0421], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,164][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.7833, 0.0143, 0.0234, 0.0046, 0.0115, 0.0085, 0.0033, 0.0060, 0.0123,
        0.0077, 0.0285, 0.0091, 0.0099, 0.0277, 0.0498], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,165][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0528, 0.0874, 0.0206, 0.0347, 0.0576, 0.0679, 0.0705, 0.0988, 0.0638,
        0.0584, 0.0564, 0.0710, 0.0550, 0.0611, 0.0637, 0.0803],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,165][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([6.0427e-06, 3.9588e-04, 1.8507e-02, 2.3938e-03, 1.3886e-02, 6.7424e-03,
        5.1433e-03, 4.5325e-02, 2.5308e-02, 6.1919e-03, 1.5548e-01, 1.8937e-02,
        4.5991e-02, 4.1226e-02, 1.6880e-01, 4.4567e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,165][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.9533, 0.0079, 0.0032, 0.0030, 0.0023, 0.0020, 0.0027, 0.0030, 0.0026,
        0.0024, 0.0040, 0.0029, 0.0016, 0.0031, 0.0022, 0.0040],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,166][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0382, 0.0989, 0.0734, 0.0600, 0.0692, 0.0580, 0.0716, 0.0533, 0.0533,
        0.0635, 0.0691, 0.0585, 0.0598, 0.0520, 0.0655, 0.0556],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,166][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0715, 0.1182, 0.1258, 0.0436, 0.0367, 0.1166, 0.0635, 0.0877, 0.0388,
        0.0681, 0.0424, 0.0430, 0.0644, 0.0467, 0.0274, 0.0057],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,168][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0034, 0.0673, 0.0655, 0.0698, 0.0619, 0.0590, 0.0612, 0.0650, 0.0605,
        0.0643, 0.0697, 0.0682, 0.0750, 0.0719, 0.0693, 0.0682],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,171][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0067, 0.1918, 0.0018, 0.0792, 0.0187, 0.0211, 0.0851, 0.0322, 0.0160,
        0.0400, 0.0030, 0.2244, 0.2387, 0.0139, 0.0192, 0.0083],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,175][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.1483, 0.0883, 0.0417, 0.0166, 0.1217, 0.0031, 0.0013, 0.0054, 0.0159,
        0.0136, 0.0236, 0.0120, 0.1878, 0.0834, 0.1033, 0.1340],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,179][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.2436, 0.2144, 0.0345, 0.0242, 0.0623, 0.0063, 0.0024, 0.0032, 0.0215,
        0.0073, 0.0288, 0.0272, 0.0730, 0.0780, 0.0977, 0.0756],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,182][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0097, 0.0716, 0.0668, 0.0681, 0.0664, 0.0643, 0.0661, 0.0636, 0.0640,
        0.0657, 0.0620, 0.0679, 0.0657, 0.0648, 0.0690, 0.0643],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,186][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.4622, 0.0538, 0.0247, 0.0283, 0.0431, 0.0585, 0.0368, 0.0270, 0.0403,
        0.0217, 0.0315, 0.0214, 0.0374, 0.0345, 0.0500, 0.0289],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,188][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.7233, 0.0263, 0.0233, 0.0098, 0.0114, 0.0083, 0.0046, 0.0074, 0.0142,
        0.0066, 0.0247, 0.0196, 0.0117, 0.0216, 0.0234, 0.0638],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,188][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0341, 0.0638, 0.0269, 0.0378, 0.0593, 0.0522, 0.0603, 0.0902, 0.0563,
        0.0572, 0.0653, 0.0598, 0.0478, 0.0656, 0.0758, 0.0657, 0.0817],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,189][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.6389e-06, 3.1341e-04, 1.6368e-02, 1.1244e-03, 2.5617e-02, 9.1612e-03,
        7.7795e-03, 4.9948e-02, 3.2985e-02, 4.7700e-03, 1.1264e-01, 5.6672e-03,
        1.9080e-02, 4.2310e-02, 1.4292e-01, 3.2307e-01, 2.0625e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,189][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.9612, 0.0060, 0.0022, 0.0022, 0.0016, 0.0015, 0.0019, 0.0023, 0.0020,
        0.0018, 0.0031, 0.0022, 0.0012, 0.0023, 0.0017, 0.0034, 0.0034],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,190][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0332, 0.0951, 0.0680, 0.0564, 0.0648, 0.0568, 0.0671, 0.0490, 0.0509,
        0.0627, 0.0668, 0.0555, 0.0574, 0.0487, 0.0615, 0.0556, 0.0507],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,190][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0266, 0.1103, 0.1553, 0.0594, 0.0380, 0.1813, 0.0453, 0.0322, 0.1248,
        0.0437, 0.0337, 0.0463, 0.0427, 0.0057, 0.0263, 0.0248, 0.0036],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,191][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0035, 0.0626, 0.0611, 0.0650, 0.0574, 0.0550, 0.0569, 0.0606, 0.0564,
        0.0594, 0.0647, 0.0627, 0.0684, 0.0659, 0.0638, 0.0637, 0.0730],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,192][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0029, 0.2465, 0.0031, 0.0900, 0.0112, 0.0229, 0.0968, 0.0239, 0.0183,
        0.0449, 0.0034, 0.2072, 0.1621, 0.0133, 0.0293, 0.0138, 0.0105],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,195][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1302, 0.0537, 0.0310, 0.0126, 0.0937, 0.0028, 0.0010, 0.0058, 0.0128,
        0.0146, 0.0215, 0.0119, 0.2058, 0.0552, 0.1050, 0.1296, 0.1127],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,199][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2576, 0.1327, 0.0353, 0.0250, 0.0489, 0.0052, 0.0017, 0.0028, 0.0197,
        0.0083, 0.0281, 0.0174, 0.0493, 0.0346, 0.0898, 0.1844, 0.0592],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,203][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0090, 0.0675, 0.0631, 0.0638, 0.0628, 0.0606, 0.0624, 0.0596, 0.0602,
        0.0617, 0.0579, 0.0632, 0.0619, 0.0607, 0.0647, 0.0612, 0.0599],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,206][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4313, 0.0562, 0.0282, 0.0308, 0.0395, 0.0549, 0.0308, 0.0296, 0.0415,
        0.0161, 0.0299, 0.0197, 0.0328, 0.0334, 0.0492, 0.0332, 0.0430],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,210][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7897, 0.0126, 0.0199, 0.0051, 0.0104, 0.0066, 0.0028, 0.0055, 0.0091,
        0.0051, 0.0194, 0.0069, 0.0085, 0.0204, 0.0236, 0.0239, 0.0307],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,211][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:22:59,214][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13969],
        [29329],
        [11035],
        [ 4653],
        [ 8442],
        [ 6957],
        [ 4401],
        [ 7292],
        [ 6486],
        [ 1591],
        [ 8036],
        [ 5621],
        [11715],
        [ 5888],
        [ 5519],
        [ 4804],
        [ 5296]], device='cuda:0')
[2024-07-24 10:22:59,215][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14261],
        [37505],
        [13276],
        [ 7427],
        [14920],
        [ 8343],
        [10690],
        [15602],
        [ 9784],
        [ 8588],
        [12216],
        [11238],
        [19333],
        [ 8971],
        [ 7994],
        [11237],
        [11230]], device='cuda:0')
[2024-07-24 10:22:59,216][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[8507],
        [7980],
        [7742],
        [7548],
        [7588],
        [7121],
        [7161],
        [6855],
        [6770],
        [6767],
        [6385],
        [6380],
        [6366],
        [6296],
        [6447],
        [6435],
        [6486]], device='cuda:0')
[2024-07-24 10:22:59,217][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[45156],
        [21438],
        [17586],
        [10585],
        [12053],
        [11194],
        [12676],
        [11989],
        [11788],
        [12460],
        [10574],
        [10331],
        [11014],
        [10844],
        [11465],
        [11786],
        [11936]], device='cuda:0')
[2024-07-24 10:22:59,218][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[15778],
        [22095],
        [23046],
        [22614],
        [22314],
        [22026],
        [22110],
        [22149],
        [22145],
        [22127],
        [22212],
        [21968],
        [21759],
        [21828],
        [21778],
        [21698],
        [21760]], device='cuda:0')
[2024-07-24 10:22:59,219][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[7062],
        [5365],
        [4178],
        [3732],
        [2790],
        [2337],
        [1918],
        [1533],
        [1911],
        [1969],
        [2504],
        [2777],
        [2762],
        [2719],
        [2795],
        [2485],
        [2551]], device='cuda:0')
[2024-07-24 10:22:59,221][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17825],
        [32669],
        [33405],
        [34395],
        [35415],
        [36713],
        [36472],
        [36897],
        [36517],
        [35456],
        [34585],
        [36004],
        [33399],
        [31441],
        [29938],
        [30654],
        [28846]], device='cuda:0')
[2024-07-24 10:22:59,222][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14656],
        [11408],
        [12714],
        [12058],
        [12723],
        [12629],
        [11178],
        [11987],
        [12228],
        [12050],
        [12188],
        [11503],
        [11697],
        [12270],
        [12617],
        [12787],
        [12990]], device='cuda:0')
[2024-07-24 10:22:59,225][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[47479],
        [47381],
        [45836],
        [39899],
        [42049],
        [39188],
        [36920],
        [35706],
        [33373],
        [24436],
        [22703],
        [21945],
        [20327],
        [19648],
        [20780],
        [24226],
        [19858]], device='cuda:0')
[2024-07-24 10:22:59,227][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[32419],
        [39127],
        [44164],
        [43437],
        [43711],
        [43992],
        [42523],
        [42695],
        [43099],
        [42594],
        [42769],
        [42821],
        [43668],
        [44203],
        [44175],
        [44323],
        [44694]], device='cuda:0')
[2024-07-24 10:22:59,230][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[46829],
        [46302],
        [44826],
        [43083],
        [38820],
        [12554],
        [ 7971],
        [10804],
        [12348],
        [ 7163],
        [ 7600],
        [ 6672],
        [ 8325],
        [10982],
        [ 6540],
        [ 5787],
        [ 7358]], device='cuda:0')
[2024-07-24 10:22:59,232][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[26857],
        [24898],
        [22187],
        [21701],
        [20654],
        [20456],
        [20166],
        [20167],
        [20194],
        [20035],
        [20253],
        [20442],
        [20391],
        [20217],
        [20277],
        [20058],
        [20025]], device='cuda:0')
[2024-07-24 10:22:59,235][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12131],
        [18212],
        [17407],
        [16769],
        [15966],
        [15542],
        [15475],
        [15248],
        [15110],
        [15130],
        [15032],
        [15016],
        [14892],
        [14800],
        [14812],
        [14617],
        [14514]], device='cuda:0')
[2024-07-24 10:22:59,237][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23038],
        [17665],
        [19871],
        [24037],
        [26190],
        [26953],
        [28715],
        [29190],
        [29371],
        [29989],
        [29711],
        [29712],
        [30182],
        [29889],
        [29848],
        [30091],
        [29592]], device='cuda:0')
[2024-07-24 10:22:59,240][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[30160],
        [ 8684],
        [22284],
        [ 7467],
        [ 9708],
        [15905],
        [ 7289],
        [ 7376],
        [14278],
        [  970],
        [16455],
        [ 4497],
        [ 8297],
        [14243],
        [ 7977],
        [11270],
        [ 8998]], device='cuda:0')
[2024-07-24 10:22:59,242][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[33393],
        [21527],
        [23424],
        [23523],
        [29317],
        [27815],
        [28324],
        [32308],
        [32100],
        [32509],
        [32083],
        [32625],
        [32730],
        [32615],
        [34161],
        [33225],
        [33801]], device='cuda:0')
[2024-07-24 10:22:59,243][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16211],
        [ 9696],
        [ 5042],
        [ 8826],
        [ 7175],
        [ 7890],
        [ 6934],
        [10980],
        [12487],
        [11631],
        [21324],
        [21231],
        [21412],
        [20417],
        [21708],
        [25188],
        [24167]], device='cuda:0')
[2024-07-24 10:22:59,244][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28600],
        [28483],
        [28328],
        [28403],
        [27880],
        [28098],
        [28123],
        [27855],
        [28040],
        [28058],
        [28053],
        [28215],
        [28093],
        [28038],
        [27874],
        [27278],
        [27511]], device='cuda:0')
[2024-07-24 10:22:59,245][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11550],
        [10329],
        [11479],
        [13428],
        [16263],
        [16984],
        [17028],
        [17401],
        [16562],
        [16035],
        [15700],
        [16028],
        [15631],
        [15456],
        [15583],
        [15466],
        [15366]], device='cuda:0')
[2024-07-24 10:22:59,246][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15281],
        [20728],
        [24024],
        [29014],
        [29526],
        [28842],
        [37565],
        [36782],
        [34356],
        [38088],
        [37578],
        [36837],
        [36554],
        [36278],
        [36526],
        [33793],
        [36230]], device='cuda:0')
[2024-07-24 10:22:59,247][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[43295],
        [38705],
        [38348],
        [38603],
        [38429],
        [38533],
        [38594],
        [38626],
        [38722],
        [38648],
        [38755],
        [38785],
        [38969],
        [39217],
        [39282],
        [39466],
        [39614]], device='cuda:0')
[2024-07-24 10:22:59,250][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14084],
        [45373],
        [45052],
        [47448],
        [47707],
        [47256],
        [47776],
        [47814],
        [47869],
        [48218],
        [48248],
        [48693],
        [48913],
        [48828],
        [48890],
        [48838],
        [48670]], device='cuda:0')
[2024-07-24 10:22:59,251][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[29580],
        [25265],
        [ 7999],
        [11269],
        [ 5096],
        [ 4675],
        [ 6230],
        [ 4891],
        [ 4304],
        [ 4325],
        [ 2295],
        [ 4329],
        [ 3009],
        [ 3366],
        [ 3370],
        [ 1865],
        [ 2139]], device='cuda:0')
[2024-07-24 10:22:59,253][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[43298],
        [42739],
        [16767],
        [18772],
        [14075],
        [17057],
        [18817],
        [16292],
        [16237],
        [18184],
        [17489],
        [22136],
        [19057],
        [21115],
        [23463],
        [22784],
        [23111]], device='cuda:0')
[2024-07-24 10:22:59,256][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8739],
        [22453],
        [25277],
        [26088],
        [26214],
        [26214],
        [25874],
        [25792],
        [25704],
        [25673],
        [25692],
        [25880],
        [25816],
        [25899],
        [25951],
        [25982],
        [26063]], device='cuda:0')
[2024-07-24 10:22:59,258][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[32146],
        [32556],
        [34808],
        [34580],
        [42759],
        [33225],
        [43746],
        [34517],
        [29421],
        [43431],
        [31704],
        [43167],
        [33664],
        [29590],
        [26475],
        [24491],
        [23765]], device='cuda:0')
[2024-07-24 10:22:59,261][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21535],
        [22952],
        [28172],
        [27772],
        [31883],
        [40499],
        [40840],
        [35366],
        [36781],
        [40324],
        [41143],
        [41900],
        [40758],
        [39837],
        [39398],
        [42069],
        [38283]], device='cuda:0')
[2024-07-24 10:22:59,263][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17216],
        [13249],
        [20119],
        [17086],
        [15334],
        [15223],
        [12147],
        [13969],
        [15381],
        [11977],
        [14711],
        [10998],
        [12891],
        [13663],
        [14327],
        [15293],
        [15502]], device='cuda:0')
[2024-07-24 10:22:59,266][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[22081],
        [26738],
        [23647],
        [28735],
        [31063],
        [39124],
        [38691],
        [37175],
        [34896],
        [41128],
        [27515],
        [33072],
        [32388],
        [24206],
        [31846],
        [24736],
        [23006]], device='cuda:0')
[2024-07-24 10:22:59,268][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183],
        [33183]], device='cuda:0')
[2024-07-24 10:22:59,303][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:59,305][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,306][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,306][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,306][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,307][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,307][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,307][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,308][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,308][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,308][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,309][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,309][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,310][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.8822, 0.1178], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,310][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0760, 0.9240], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,310][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.4436, 0.5564], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,311][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.4433, 0.5567], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,311][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.9838, 0.0162], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,311][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.2017, 0.7983], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,312][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.2359, 0.7641], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,314][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.8160, 0.1840], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,317][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.9092, 0.0908], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,317][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0356, 0.9644], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,317][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.8536, 0.1464], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,318][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7198, 0.2802], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,318][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3693, 0.5689, 0.0618], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,318][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0211, 0.8701, 0.1088], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,321][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2978, 0.3656, 0.3366], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,325][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2766, 0.3724, 0.3510], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,328][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9396, 0.0273, 0.0331], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,332][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2055, 0.6688, 0.1256], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,334][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1149, 0.4244, 0.4607], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,334][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3509, 0.4983, 0.1508], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,335][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0938, 0.8518, 0.0544], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,335][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0492, 0.1602, 0.7906], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,335][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7390, 0.1451, 0.1159], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,336][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6778, 0.2264, 0.0959], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,336][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.3586, 0.5233, 0.0470, 0.0711], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,336][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0384, 0.7016, 0.0743, 0.1857], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,338][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.2161, 0.2787, 0.2541, 0.2511], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,340][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.1917, 0.2994, 0.2715, 0.2374], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,344][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.7561, 0.0330, 0.0305, 0.1804], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,347][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0826, 0.5603, 0.3192, 0.0379], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,351][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0901, 0.3606, 0.1407, 0.4086], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,355][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.3879, 0.4424, 0.0552, 0.1145], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,357][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.2596, 0.6161, 0.0471, 0.0772], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,358][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0258, 0.1287, 0.5696, 0.2759], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,358][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.5970, 0.1235, 0.0833, 0.1963], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,358][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.5100, 0.2130, 0.1129, 0.1641], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,359][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.1521, 0.5899, 0.0555, 0.1516, 0.0509], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,359][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0189, 0.5969, 0.0611, 0.1725, 0.1507], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,359][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1773, 0.2228, 0.2029, 0.1995, 0.1976], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,360][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.1181, 0.2425, 0.2391, 0.2132, 0.1871], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,360][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.7382, 0.0247, 0.0259, 0.1472, 0.0640], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,362][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.1162, 0.5314, 0.2029, 0.0489, 0.1006], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,364][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0697, 0.1931, 0.1599, 0.2252, 0.3521], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,368][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.1905, 0.4761, 0.0765, 0.1438, 0.1131], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,371][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0898, 0.6102, 0.0488, 0.1372, 0.1140], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,375][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0143, 0.1413, 0.4731, 0.2538, 0.1175], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,379][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.4107, 0.1627, 0.0774, 0.2341, 0.1150], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,381][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.3707, 0.1783, 0.1035, 0.1602, 0.1873], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,382][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0231, 0.6516, 0.0328, 0.1926, 0.0892, 0.0107], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,382][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0019, 0.5425, 0.0665, 0.1725, 0.2015, 0.0152], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,382][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1447, 0.1915, 0.1722, 0.1711, 0.1694, 0.1510], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,383][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1249, 0.2032, 0.2076, 0.1716, 0.1816, 0.1111], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,383][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6968, 0.0286, 0.0260, 0.1388, 0.0427, 0.0672], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,383][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0473, 0.6476, 0.1386, 0.0335, 0.0772, 0.0558], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,385][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0700, 0.2345, 0.1139, 0.1756, 0.1530, 0.2529], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,387][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0406, 0.5193, 0.0503, 0.1647, 0.1760, 0.0491], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,390][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0051, 0.7021, 0.0217, 0.1299, 0.1365, 0.0047], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,394][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0328, 0.1265, 0.3237, 0.2398, 0.1947, 0.0824], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,398][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4348, 0.1311, 0.0501, 0.1756, 0.0870, 0.1214], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,401][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.4195, 0.1361, 0.0741, 0.0959, 0.1385, 0.1359], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,405][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0197, 0.6028, 0.0377, 0.1864, 0.1253, 0.0155, 0.0126],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,405][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0018, 0.5302, 0.0633, 0.1758, 0.2019, 0.0157, 0.0113],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,405][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.1295, 0.1674, 0.1503, 0.1491, 0.1459, 0.1303, 0.1275],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,406][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0801, 0.1643, 0.1745, 0.1443, 0.1672, 0.1206, 0.1490],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,406][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.6883, 0.0201, 0.0190, 0.0912, 0.0431, 0.0655, 0.0729],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,406][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0244, 0.4778, 0.2717, 0.0288, 0.0862, 0.0675, 0.0435],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,407][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0372, 0.1566, 0.1443, 0.1642, 0.1683, 0.0981, 0.2313],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,407][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0208, 0.5301, 0.0327, 0.1818, 0.1447, 0.0536, 0.0363],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,408][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0041, 0.6765, 0.0156, 0.1452, 0.1448, 0.0085, 0.0053],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,411][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0024, 0.1075, 0.3700, 0.3106, 0.1100, 0.0568, 0.0427],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,413][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.3890, 0.1211, 0.0584, 0.1680, 0.0848, 0.1029, 0.0758],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,417][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.2031, 0.1249, 0.0707, 0.1007, 0.1344, 0.1736, 0.1925],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,421][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0306, 0.6593, 0.0282, 0.1734, 0.0720, 0.0171, 0.0106, 0.0090],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,424][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0025, 0.5068, 0.0589, 0.1895, 0.1955, 0.0182, 0.0142, 0.0146],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,428][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1121, 0.1456, 0.1322, 0.1317, 0.1303, 0.1161, 0.1134, 0.1185],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,429][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0926, 0.1530, 0.1535, 0.1224, 0.1541, 0.1066, 0.1259, 0.0919],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,429][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.5616, 0.0240, 0.0257, 0.1296, 0.0346, 0.0732, 0.0829, 0.0684],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,430][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0333, 0.5490, 0.1522, 0.0336, 0.0898, 0.0589, 0.0569, 0.0263],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,430][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0201, 0.1344, 0.1093, 0.1249, 0.1133, 0.0824, 0.1110, 0.3045],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,430][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0376, 0.4645, 0.0548, 0.1609, 0.1501, 0.0441, 0.0351, 0.0529],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,431][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0077, 0.6687, 0.0278, 0.1083, 0.1626, 0.0092, 0.0044, 0.0112],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,431][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0315, 0.1801, 0.3035, 0.1467, 0.1552, 0.0369, 0.0859, 0.0602],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,431][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2445, 0.1103, 0.0660, 0.1725, 0.1084, 0.1112, 0.0931, 0.0940],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,433][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3119, 0.1019, 0.0502, 0.0723, 0.1036, 0.1062, 0.1549, 0.0990],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,436][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1132, 0.5676, 0.0332, 0.1621, 0.0627, 0.0063, 0.0052, 0.0064, 0.0433],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,440][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0034, 0.5182, 0.0586, 0.1806, 0.1809, 0.0156, 0.0119, 0.0130, 0.0178],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,443][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1040, 0.1309, 0.1182, 0.1178, 0.1161, 0.1037, 0.1010, 0.1064, 0.1018],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,447][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0795, 0.1365, 0.1445, 0.1182, 0.1384, 0.0893, 0.1092, 0.0907, 0.0937],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,451][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4866, 0.0267, 0.0285, 0.1477, 0.0530, 0.0832, 0.0711, 0.0686, 0.0346],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,453][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0689, 0.4516, 0.1675, 0.0286, 0.1009, 0.0516, 0.0474, 0.0335, 0.0500],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,453][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0344, 0.1324, 0.0883, 0.1212, 0.0989, 0.1169, 0.1133, 0.1030, 0.1916],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,454][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0853, 0.4417, 0.0361, 0.1237, 0.1172, 0.0240, 0.0211, 0.0321, 0.1188],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,454][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0505, 0.6027, 0.0295, 0.1030, 0.1580, 0.0031, 0.0021, 0.0083, 0.0426],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,454][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0306, 0.1593, 0.2332, 0.1296, 0.1254, 0.0450, 0.1089, 0.1123, 0.0556],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,455][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3064, 0.0938, 0.0444, 0.1336, 0.0720, 0.1010, 0.0800, 0.0734, 0.0953],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,455][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2629, 0.0902, 0.0492, 0.0673, 0.0969, 0.0938, 0.1375, 0.1124, 0.0898],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,455][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0514, 0.5805, 0.0379, 0.1585, 0.0535, 0.0070, 0.0037, 0.0061, 0.0544,
        0.0469], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,456][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0027, 0.5090, 0.0590, 0.1768, 0.1851, 0.0127, 0.0089, 0.0110, 0.0152,
        0.0197], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,457][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0901, 0.1175, 0.1075, 0.1070, 0.1051, 0.0938, 0.0920, 0.0965, 0.0928,
        0.0978], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,460][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0728, 0.1283, 0.1245, 0.1126, 0.1115, 0.0840, 0.1085, 0.0835, 0.0852,
        0.0891], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,463][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.5394, 0.0159, 0.0154, 0.0863, 0.0288, 0.0440, 0.0839, 0.0488, 0.0168,
        0.1207], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,467][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0409, 0.4234, 0.2769, 0.0313, 0.0779, 0.0389, 0.0297, 0.0217, 0.0341,
        0.0253], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,471][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0319, 0.1388, 0.1112, 0.1195, 0.0751, 0.0876, 0.0822, 0.1284, 0.0966,
        0.1287], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,475][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0505, 0.4564, 0.0300, 0.1520, 0.0885, 0.0170, 0.0120, 0.0169, 0.0856,
        0.0911], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,477][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0341, 0.5542, 0.0290, 0.1144, 0.1276, 0.0025, 0.0012, 0.0060, 0.0378,
        0.0933], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,478][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0055, 0.0690, 0.2940, 0.1935, 0.1191, 0.0574, 0.0571, 0.0631, 0.0974,
        0.0441], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,478][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.2632, 0.0768, 0.0486, 0.1262, 0.0668, 0.0888, 0.0674, 0.0718, 0.0800,
        0.1105], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,478][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.1417, 0.0937, 0.0455, 0.0589, 0.0764, 0.1045, 0.1338, 0.1258, 0.1037,
        0.1159], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,479][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0864, 0.5162, 0.0237, 0.1280, 0.0406, 0.0078, 0.0051, 0.0085, 0.0465,
        0.1068, 0.0303], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,479][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0046, 0.5027, 0.0523, 0.1700, 0.1683, 0.0167, 0.0124, 0.0137, 0.0191,
        0.0244, 0.0157], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,479][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0874, 0.1089, 0.0972, 0.0970, 0.0957, 0.0860, 0.0836, 0.0876, 0.0841,
        0.0892, 0.0833], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,480][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0838, 0.1096, 0.1037, 0.0905, 0.1104, 0.0745, 0.0909, 0.0732, 0.0824,
        0.0824, 0.0985], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,481][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3601, 0.0203, 0.0248, 0.1422, 0.0365, 0.0738, 0.0724, 0.0609, 0.0307,
        0.1134, 0.0649], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,484][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1960, 0.3169, 0.1055, 0.0279, 0.1036, 0.0547, 0.0362, 0.0274, 0.0535,
        0.0290, 0.0492], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,488][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0204, 0.1023, 0.0985, 0.1084, 0.0791, 0.0911, 0.0804, 0.1385, 0.0893,
        0.0727, 0.1193], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,492][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0544, 0.2933, 0.0324, 0.1051, 0.0947, 0.0238, 0.0243, 0.0364, 0.1206,
        0.1424, 0.0726], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,495][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0401, 0.4802, 0.0286, 0.0831, 0.1253, 0.0047, 0.0038, 0.0112, 0.0572,
        0.1281, 0.0377], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,499][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0141, 0.1566, 0.1514, 0.2656, 0.0688, 0.0416, 0.0773, 0.0312, 0.0350,
        0.0723, 0.0861], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,501][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2320, 0.0588, 0.0440, 0.0983, 0.0713, 0.0829, 0.0697, 0.0650, 0.0789,
        0.1002, 0.0991], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,502][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2440, 0.0704, 0.0334, 0.0593, 0.0786, 0.0797, 0.1143, 0.0786, 0.0809,
        0.1013, 0.0594], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,502][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.1337, 0.4640, 0.0284, 0.0613, 0.0352, 0.0049, 0.0035, 0.0068, 0.0619,
        0.0879, 0.0372, 0.0750], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,502][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0053, 0.5559, 0.0521, 0.1376, 0.1359, 0.0134, 0.0100, 0.0111, 0.0162,
        0.0212, 0.0154, 0.0261], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,503][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0764, 0.1011, 0.0899, 0.0895, 0.0890, 0.0794, 0.0783, 0.0797, 0.0777,
        0.0824, 0.0770, 0.0796], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,503][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0572, 0.0952, 0.0942, 0.0794, 0.0937, 0.0713, 0.0964, 0.0686, 0.0747,
        0.0852, 0.1002, 0.0839], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,503][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.2836, 0.0178, 0.0162, 0.0872, 0.0394, 0.0597, 0.0856, 0.0524, 0.0255,
        0.1224, 0.0652, 0.1449], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,504][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0330, 0.3230, 0.2405, 0.0245, 0.0625, 0.0512, 0.0468, 0.0349, 0.0525,
        0.0383, 0.0787, 0.0140], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,504][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0327, 0.1311, 0.0611, 0.1409, 0.0567, 0.0725, 0.0558, 0.0668, 0.0942,
        0.0587, 0.0723, 0.1571], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,506][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0723, 0.2609, 0.0143, 0.0580, 0.0504, 0.0145, 0.0134, 0.0175, 0.0811,
        0.1203, 0.0428, 0.2546], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,508][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0830, 0.4626, 0.0194, 0.0428, 0.0926, 0.0017, 0.0010, 0.0071, 0.0382,
        0.1184, 0.0554, 0.0779], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,512][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0022, 0.0685, 0.0922, 0.1079, 0.2097, 0.0433, 0.0616, 0.0436, 0.0645,
        0.0585, 0.1232, 0.1247], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,516][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.2743, 0.0579, 0.0338, 0.0812, 0.0495, 0.0583, 0.0411, 0.0416, 0.0553,
        0.0724, 0.0908, 0.1437], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,519][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.1626, 0.0634, 0.0376, 0.0490, 0.0627, 0.0848, 0.1048, 0.0935, 0.0858,
        0.0993, 0.0680, 0.0885], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,523][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0726, 0.4175, 0.0378, 0.0965, 0.0454, 0.0042, 0.0025, 0.0063, 0.0412,
        0.0647, 0.0359, 0.0913, 0.0840], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,526][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0047, 0.4814, 0.0560, 0.1678, 0.1743, 0.0120, 0.0089, 0.0096, 0.0150,
        0.0196, 0.0140, 0.0248, 0.0119], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,526][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0742, 0.0923, 0.0831, 0.0828, 0.0815, 0.0727, 0.0702, 0.0739, 0.0712,
        0.0752, 0.0704, 0.0743, 0.0779], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,526][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0579, 0.0827, 0.0947, 0.0792, 0.0746, 0.0667, 0.0694, 0.0680, 0.0728,
        0.0719, 0.0916, 0.0828, 0.0877], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,527][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1831, 0.0187, 0.0238, 0.1111, 0.0409, 0.0648, 0.0634, 0.0558, 0.0248,
        0.1063, 0.0619, 0.1465, 0.0988], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,527][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0514, 0.2464, 0.2807, 0.0380, 0.0683, 0.0517, 0.0361, 0.0219, 0.0445,
        0.0230, 0.0953, 0.0146, 0.0281], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,527][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0428, 0.0737, 0.0468, 0.1000, 0.0823, 0.0417, 0.0372, 0.0861, 0.0729,
        0.0516, 0.0658, 0.1347, 0.1643], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,528][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0425, 0.2997, 0.0239, 0.0776, 0.0601, 0.0156, 0.0071, 0.0156, 0.0597,
        0.0823, 0.0386, 0.1231, 0.1543], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,529][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0621, 0.3947, 0.0344, 0.0697, 0.1118, 0.0016, 0.0008, 0.0026, 0.0219,
        0.0288, 0.0360, 0.0346, 0.2010], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,532][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0074, 0.1705, 0.1382, 0.0892, 0.0809, 0.0622, 0.0760, 0.0469, 0.0510,
        0.0541, 0.0888, 0.0786, 0.0561], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,532][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.2553, 0.0625, 0.0288, 0.0769, 0.0448, 0.0594, 0.0464, 0.0400, 0.0531,
        0.0683, 0.0753, 0.1006, 0.0886], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,533][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.1376, 0.0519, 0.0374, 0.0531, 0.0570, 0.0703, 0.0902, 0.0831, 0.0692,
        0.0845, 0.0647, 0.0859, 0.1152], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,533][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1108, 0.3724, 0.0315, 0.1060, 0.0381, 0.0030, 0.0022, 0.0026, 0.0212,
        0.0564, 0.0196, 0.0856, 0.1279, 0.0228], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,534][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0022, 0.4409, 0.0493, 0.1757, 0.1778, 0.0148, 0.0118, 0.0104, 0.0175,
        0.0249, 0.0151, 0.0332, 0.0145, 0.0118], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,534][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0676, 0.0864, 0.0764, 0.0777, 0.0764, 0.0676, 0.0660, 0.0684, 0.0658,
        0.0699, 0.0654, 0.0690, 0.0730, 0.0705], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,534][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0552, 0.0824, 0.0850, 0.0700, 0.0855, 0.0580, 0.0765, 0.0603, 0.0631,
        0.0615, 0.0817, 0.0699, 0.0958, 0.0550], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,535][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2662, 0.0147, 0.0181, 0.0908, 0.0363, 0.0571, 0.0602, 0.0491, 0.0199,
        0.0866, 0.0500, 0.1253, 0.0766, 0.0491], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,539][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0756, 0.3479, 0.1460, 0.0239, 0.0776, 0.0460, 0.0351, 0.0231, 0.0383,
        0.0233, 0.0561, 0.0114, 0.0694, 0.0263], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,542][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0169, 0.0997, 0.0643, 0.0679, 0.0717, 0.0561, 0.0649, 0.0990, 0.0498,
        0.0558, 0.0629, 0.0715, 0.0538, 0.1657], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,546][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0606, 0.1955, 0.0288, 0.0714, 0.0595, 0.0122, 0.0123, 0.0191, 0.0568,
        0.0891, 0.0465, 0.1096, 0.1835, 0.0551], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,550][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0361, 0.3132, 0.0252, 0.0559, 0.0758, 0.0016, 0.0009, 0.0022, 0.0195,
        0.0459, 0.0183, 0.0264, 0.3163, 0.0628], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,552][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0128, 0.0572, 0.1340, 0.1066, 0.1023, 0.0262, 0.0522, 0.0266, 0.0386,
        0.0561, 0.1064, 0.1475, 0.0538, 0.0796], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,553][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2094, 0.0495, 0.0235, 0.0726, 0.0427, 0.0533, 0.0445, 0.0444, 0.0573,
        0.0698, 0.0739, 0.1022, 0.1001, 0.0566], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,553][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1409, 0.0623, 0.0328, 0.0447, 0.0591, 0.0606, 0.0881, 0.0609, 0.0574,
        0.0724, 0.0519, 0.0699, 0.1374, 0.0615], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,554][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.1367, 0.3445, 0.0276, 0.0745, 0.0320, 0.0016, 0.0010, 0.0018, 0.0146,
        0.0341, 0.0207, 0.0522, 0.0979, 0.0249, 0.1359], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,554][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0047, 0.4164, 0.0528, 0.1706, 0.1850, 0.0130, 0.0092, 0.0112, 0.0168,
        0.0220, 0.0166, 0.0276, 0.0133, 0.0125, 0.0283], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,554][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0641, 0.0803, 0.0711, 0.0717, 0.0704, 0.0631, 0.0614, 0.0637, 0.0617,
        0.0652, 0.0615, 0.0645, 0.0677, 0.0655, 0.0681], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,555][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0468, 0.0730, 0.0844, 0.0641, 0.0750, 0.0571, 0.0758, 0.0535, 0.0618,
        0.0639, 0.0806, 0.0670, 0.0915, 0.0534, 0.0521], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,555][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1564, 0.0135, 0.0152, 0.0719, 0.0342, 0.0693, 0.0557, 0.0570, 0.0250,
        0.0983, 0.0579, 0.1129, 0.0888, 0.0567, 0.0872], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,556][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0376, 0.2265, 0.2182, 0.0369, 0.0656, 0.0448, 0.0422, 0.0256, 0.0436,
        0.0283, 0.0717, 0.0140, 0.0522, 0.0387, 0.0542], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,559][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0194, 0.0532, 0.0697, 0.0627, 0.0896, 0.0500, 0.0475, 0.0678, 0.0526,
        0.0494, 0.0842, 0.0716, 0.0690, 0.0722, 0.1410], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,562][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0801, 0.2088, 0.0220, 0.0812, 0.0375, 0.0086, 0.0071, 0.0127, 0.0369,
        0.0429, 0.0219, 0.1156, 0.1412, 0.0578, 0.1258], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,566][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.1112, 0.1807, 0.0254, 0.0443, 0.0578, 0.0008, 0.0005, 0.0018, 0.0109,
        0.0223, 0.0179, 0.0161, 0.1685, 0.0650, 0.2770], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,569][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0034, 0.0395, 0.1159, 0.0270, 0.0726, 0.0369, 0.0473, 0.0350, 0.0637,
        0.0242, 0.1169, 0.0308, 0.0771, 0.2626, 0.0472], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,573][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1895, 0.0604, 0.0348, 0.0763, 0.0439, 0.0536, 0.0378, 0.0379, 0.0478,
        0.0558, 0.0755, 0.0874, 0.0768, 0.0462, 0.0761], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,577][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.1065, 0.0578, 0.0331, 0.0414, 0.0533, 0.0639, 0.0843, 0.0659, 0.0614,
        0.0718, 0.0549, 0.0647, 0.1125, 0.0649, 0.0636], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,577][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.1072, 0.2825, 0.0181, 0.0669, 0.0289, 0.0017, 0.0013, 0.0014, 0.0123,
        0.0161, 0.0095, 0.0470, 0.0655, 0.0305, 0.1016, 0.2095],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,578][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0028, 0.3672, 0.0544, 0.1639, 0.2027, 0.0126, 0.0096, 0.0112, 0.0156,
        0.0195, 0.0144, 0.0261, 0.0134, 0.0125, 0.0289, 0.0454],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,578][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0592, 0.0752, 0.0669, 0.0676, 0.0664, 0.0594, 0.0576, 0.0602, 0.0577,
        0.0616, 0.0572, 0.0597, 0.0631, 0.0612, 0.0638, 0.0631],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,578][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0466, 0.0686, 0.0784, 0.0610, 0.0751, 0.0543, 0.0619, 0.0503, 0.0551,
        0.0583, 0.0784, 0.0608, 0.0868, 0.0565, 0.0537, 0.0541],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,579][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.1445, 0.0165, 0.0296, 0.0820, 0.0300, 0.0738, 0.0377, 0.0478, 0.0292,
        0.0957, 0.0606, 0.1149, 0.0695, 0.0575, 0.0514, 0.0594],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,579][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0957, 0.2273, 0.1070, 0.0186, 0.0795, 0.0367, 0.0461, 0.0258, 0.0319,
        0.0246, 0.0620, 0.0104, 0.0708, 0.0385, 0.0621, 0.0629],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,580][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0168, 0.0633, 0.0490, 0.0669, 0.0735, 0.0453, 0.0358, 0.0470, 0.0754,
        0.0390, 0.0592, 0.0790, 0.0624, 0.0548, 0.0702, 0.1621],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,582][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0861, 0.1988, 0.0166, 0.0458, 0.0510, 0.0068, 0.0063, 0.0086, 0.0310,
        0.0367, 0.0220, 0.0553, 0.1106, 0.0353, 0.1268, 0.1625],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,583][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ it] are: tensor([4.3928e-02, 1.9098e-01, 1.7849e-02, 3.0324e-02, 4.8882e-02, 5.6664e-04,
        2.7546e-04, 1.1179e-03, 7.6917e-03, 1.1684e-02, 9.5277e-03, 9.5587e-03,
        1.1292e-01, 3.8545e-02, 3.0535e-01, 1.7080e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,586][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0039, 0.0518, 0.1867, 0.1079, 0.0417, 0.0290, 0.0321, 0.0365, 0.0371,
        0.0371, 0.0890, 0.1349, 0.0349, 0.1025, 0.0382, 0.0367],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,590][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.1784, 0.0586, 0.0278, 0.0705, 0.0405, 0.0497, 0.0342, 0.0312, 0.0430,
        0.0559, 0.0646, 0.0855, 0.0788, 0.0428, 0.0617, 0.0767],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,594][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.1230, 0.0479, 0.0256, 0.0381, 0.0480, 0.0506, 0.0770, 0.0634, 0.0494,
        0.0681, 0.0472, 0.0653, 0.1183, 0.0642, 0.0662, 0.0479],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,597][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1368, 0.2226, 0.0180, 0.0543, 0.0198, 0.0013, 0.0008, 0.0011, 0.0104,
        0.0232, 0.0104, 0.0338, 0.0673, 0.0128, 0.1276, 0.2296, 0.0301],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,601][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0019, 0.3699, 0.0476, 0.1496, 0.1877, 0.0123, 0.0091, 0.0094, 0.0146,
        0.0193, 0.0139, 0.0267, 0.0145, 0.0111, 0.0310, 0.0482, 0.0332],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,602][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0560, 0.0711, 0.0625, 0.0641, 0.0631, 0.0558, 0.0544, 0.0561, 0.0540,
        0.0575, 0.0535, 0.0561, 0.0599, 0.0575, 0.0603, 0.0584, 0.0599],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,602][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0480, 0.0684, 0.0697, 0.0590, 0.0731, 0.0492, 0.0639, 0.0504, 0.0532,
        0.0532, 0.0680, 0.0596, 0.0821, 0.0466, 0.0533, 0.0511, 0.0509],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,602][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2003, 0.0134, 0.0180, 0.0748, 0.0334, 0.0533, 0.0553, 0.0458, 0.0195,
        0.0810, 0.0466, 0.1026, 0.0671, 0.0410, 0.0623, 0.0459, 0.0398],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,603][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0819, 0.2701, 0.1220, 0.0214, 0.0756, 0.0404, 0.0336, 0.0205, 0.0306,
        0.0204, 0.0474, 0.0103, 0.0561, 0.0227, 0.0515, 0.0677, 0.0280],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,603][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0119, 0.0760, 0.0523, 0.0541, 0.0533, 0.0433, 0.0509, 0.0800, 0.0390,
        0.0416, 0.0506, 0.0547, 0.0398, 0.1287, 0.0466, 0.0419, 0.1353],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,603][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0706, 0.1249, 0.0159, 0.0390, 0.0373, 0.0057, 0.0061, 0.0088, 0.0287,
        0.0438, 0.0232, 0.0553, 0.1005, 0.0309, 0.1468, 0.2008, 0.0617],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,604][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.4682e-02, 1.4261e-01, 1.1773e-02, 2.1934e-02, 2.9617e-02, 4.8218e-04,
        2.3573e-04, 6.4294e-04, 6.9073e-03, 1.3985e-02, 7.1871e-03, 7.9354e-03,
        1.1157e-01, 2.6808e-02, 2.7382e-01, 2.4027e-01, 6.9540e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,606][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0112, 0.0504, 0.1053, 0.0820, 0.0716, 0.0220, 0.0371, 0.0208, 0.0341,
        0.0435, 0.0902, 0.1152, 0.0496, 0.0508, 0.0558, 0.0690, 0.0913],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,608][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1486, 0.0343, 0.0190, 0.0564, 0.0327, 0.0425, 0.0371, 0.0383, 0.0470,
        0.0585, 0.0624, 0.0816, 0.0798, 0.0481, 0.0674, 0.0913, 0.0551],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,612][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1066, 0.0534, 0.0285, 0.0373, 0.0510, 0.0515, 0.0796, 0.0531, 0.0479,
        0.0630, 0.0445, 0.0580, 0.1152, 0.0512, 0.0647, 0.0515, 0.0431],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,649][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:22:59,652][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,655][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,672][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,674][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,677][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,680][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,681][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,681][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,681][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,682][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,682][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,682][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:22:59,683][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.8822, 0.1178], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,683][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.3994, 0.6006], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,685][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.7911, 0.2089], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,687][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.9578, 0.0422], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,689][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([9.9972e-01, 2.8438e-04], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,693][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.6498, 0.3502], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,696][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.9344, 0.0656], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,700][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.8376, 0.1624], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,704][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9092, 0.0908], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,704][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0356, 0.9644], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,705][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.9338, 0.0662], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,705][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.3775, 0.6225], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:22:59,705][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3693, 0.5689, 0.0618], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,706][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0129, 0.8793, 0.1078], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,706][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5516, 0.2736, 0.1748], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,706][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5619, 0.3342, 0.1040], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,707][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9643e-01, 7.9687e-04, 2.7692e-03], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,707][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1837, 0.6174, 0.1989], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,709][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2749, 0.1239, 0.6012], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,711][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3837, 0.4765, 0.1398], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,715][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0938, 0.8518, 0.0544], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,718][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0492, 0.1602, 0.7906], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,722][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7049, 0.1406, 0.1545], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,726][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0437, 0.8795, 0.0769], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:22:59,728][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.3586, 0.5233, 0.0470, 0.0711], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,729][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0398, 0.7974, 0.0399, 0.1229], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,729][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.5130, 0.2245, 0.1504, 0.1121], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,729][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.7002, 0.1676, 0.0738, 0.0584], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,730][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([9.9808e-01, 3.8968e-04, 1.4049e-03, 1.2137e-04], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,730][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.1888, 0.5527, 0.0805, 0.1780], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,731][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.3614, 0.1248, 0.4323, 0.0815], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,731][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.4200, 0.4236, 0.0509, 0.1055], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,732][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.2596, 0.6161, 0.0471, 0.0772], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,735][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0258, 0.1287, 0.5696, 0.2759], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,739][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.7244, 0.0775, 0.0605, 0.1377], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,742][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0326, 0.8590, 0.0344, 0.0739], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:22:59,746][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.1521, 0.5899, 0.0555, 0.1516, 0.0509], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,749][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0068, 0.6930, 0.0512, 0.1585, 0.0905], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,752][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.4160, 0.2000, 0.1511, 0.1108, 0.1221], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,752][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.4574, 0.2348, 0.0604, 0.1107, 0.1367], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,753][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.9813, 0.0030, 0.0077, 0.0024, 0.0055], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,753][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.1142, 0.5591, 0.0639, 0.1835, 0.0793], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,754][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.1794, 0.2068, 0.3556, 0.0635, 0.1947], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,754][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.2178, 0.4715, 0.0731, 0.1362, 0.1014], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,754][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0898, 0.6102, 0.0488, 0.1372, 0.1140], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,755][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0143, 0.1413, 0.4731, 0.2538, 0.1175], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,755][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.4908, 0.1223, 0.0832, 0.1779, 0.1259], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,757][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0208, 0.7280, 0.0318, 0.1300, 0.0894], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:22:59,760][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0231, 0.6516, 0.0328, 0.1926, 0.0892, 0.0107], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,763][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0018, 0.6679, 0.0422, 0.1532, 0.1147, 0.0202], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,767][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3324, 0.2169, 0.1125, 0.1032, 0.1064, 0.1288], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,770][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1559, 0.3516, 0.0724, 0.1511, 0.2309, 0.0381], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,772][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.8901e-01, 1.3716e-03, 4.2029e-03, 6.3148e-04, 3.6296e-03, 1.1529e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,776][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0189, 0.5879, 0.0468, 0.1959, 0.1286, 0.0219], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,778][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4708, 0.1492, 0.2132, 0.0294, 0.0696, 0.0678], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,778][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0470, 0.5336, 0.0495, 0.1617, 0.1640, 0.0442], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,779][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0051, 0.7021, 0.0217, 0.1299, 0.1365, 0.0047], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,779][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0328, 0.1265, 0.3237, 0.2398, 0.1947, 0.0824], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,780][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4959, 0.1202, 0.0570, 0.1403, 0.0984, 0.0883], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,780][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0012, 0.6721, 0.0229, 0.0870, 0.2014, 0.0154], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:22:59,780][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0197, 0.6028, 0.0377, 0.1864, 0.1253, 0.0155, 0.0126],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,781][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([5.1783e-04, 5.7378e-01, 3.4809e-02, 2.0720e-01, 1.4292e-01, 2.7141e-02,
        1.3635e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,781][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.2040, 0.2111, 0.1297, 0.1157, 0.1115, 0.1323, 0.0957],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,783][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.1430, 0.3814, 0.0584, 0.1630, 0.1951, 0.0366, 0.0224],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,785][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.9724, 0.0039, 0.0084, 0.0021, 0.0092, 0.0025, 0.0014],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,789][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0092, 0.5078, 0.0494, 0.2363, 0.1523, 0.0310, 0.0140],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,792][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.2342, 0.1714, 0.2133, 0.0737, 0.1122, 0.0873, 0.1079],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,796][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0246, 0.5487, 0.0325, 0.1787, 0.1344, 0.0481, 0.0330],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,800][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0041, 0.6765, 0.0156, 0.1452, 0.1448, 0.0085, 0.0053],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,802][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0024, 0.1075, 0.3700, 0.3106, 0.1100, 0.0568, 0.0427],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,803][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.3396, 0.1001, 0.0831, 0.1464, 0.1211, 0.0926, 0.1171],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,803][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([5.8263e-04, 7.0753e-01, 1.9713e-02, 1.1471e-01, 1.2822e-01, 1.9903e-02,
        9.3359e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:22:59,803][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0306, 0.6593, 0.0282, 0.1734, 0.0720, 0.0171, 0.0106, 0.0090],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,804][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0015, 0.5165, 0.0367, 0.3014, 0.0890, 0.0188, 0.0196, 0.0165],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,804][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1941, 0.1866, 0.1230, 0.1251, 0.1227, 0.1025, 0.0864, 0.0596],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,804][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1475, 0.3262, 0.0765, 0.1379, 0.2153, 0.0377, 0.0239, 0.0349],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,805][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([9.8248e-01, 3.3559e-03, 4.3730e-03, 1.8669e-03, 4.0786e-03, 1.1448e-03,
        8.5101e-04, 1.8537e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,805][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0266, 0.5122, 0.0636, 0.1762, 0.1570, 0.0237, 0.0140, 0.0265],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,807][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1439, 0.1312, 0.3401, 0.0368, 0.0968, 0.0590, 0.0379, 0.1543],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,809][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0435, 0.4798, 0.0543, 0.1598, 0.1413, 0.0402, 0.0324, 0.0487],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,813][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0077, 0.6687, 0.0278, 0.1083, 0.1626, 0.0092, 0.0044, 0.0112],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,816][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0315, 0.1801, 0.3035, 0.1467, 0.1552, 0.0369, 0.0859, 0.0602],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,820][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.4510, 0.0568, 0.0752, 0.0867, 0.1166, 0.0551, 0.0828, 0.0758],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,824][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0017, 0.7040, 0.0130, 0.1342, 0.1083, 0.0164, 0.0135, 0.0088],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:22:59,826][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1132, 0.5676, 0.0332, 0.1621, 0.0627, 0.0063, 0.0052, 0.0064, 0.0433],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,827][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0073, 0.6608, 0.0291, 0.1732, 0.0703, 0.0099, 0.0072, 0.0110, 0.0313],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,827][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3018, 0.1417, 0.0797, 0.0808, 0.0849, 0.0678, 0.0619, 0.0545, 0.1269],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,828][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2709, 0.2842, 0.0524, 0.1032, 0.1672, 0.0224, 0.0150, 0.0257, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,828][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9303e-01, 8.3180e-04, 1.6954e-03, 4.0830e-04, 1.7719e-03, 4.6765e-04,
        3.8009e-04, 6.1887e-04, 7.9918e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,828][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0603, 0.5367, 0.0496, 0.1479, 0.1016, 0.0128, 0.0066, 0.0133, 0.0713],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,829][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2386, 0.1556, 0.2028, 0.0335, 0.0915, 0.0547, 0.0356, 0.0779, 0.1099],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,829][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1010, 0.4548, 0.0354, 0.1217, 0.1094, 0.0215, 0.0192, 0.0292, 0.1077],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,829][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0505, 0.6027, 0.0295, 0.1030, 0.1580, 0.0031, 0.0021, 0.0083, 0.0426],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,831][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0306, 0.1593, 0.2332, 0.1296, 0.1254, 0.0450, 0.1089, 0.1123, 0.0556],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,834][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.5047, 0.0631, 0.0455, 0.0756, 0.0724, 0.0515, 0.0754, 0.0420, 0.0697],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,838][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0082, 0.7013, 0.0176, 0.0830, 0.1141, 0.0057, 0.0046, 0.0060, 0.0597],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:22:59,842][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0514, 0.5805, 0.0379, 0.1585, 0.0535, 0.0070, 0.0037, 0.0061, 0.0544,
        0.0469], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,845][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0030, 0.5448, 0.0362, 0.1626, 0.0937, 0.0089, 0.0041, 0.0102, 0.0425,
        0.0940], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,849][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.1846, 0.1498, 0.1080, 0.0954, 0.0883, 0.0588, 0.0599, 0.0485, 0.1106,
        0.0961], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,851][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.2666, 0.3308, 0.0483, 0.0933, 0.0995, 0.0163, 0.0104, 0.0169, 0.0462,
        0.0717], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,851][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.9730, 0.0031, 0.0066, 0.0020, 0.0048, 0.0019, 0.0011, 0.0026, 0.0036,
        0.0013], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,852][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.0469, 0.4330, 0.0547, 0.1663, 0.1235, 0.0104, 0.0044, 0.0126, 0.0682,
        0.0800], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,852][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.1572, 0.0977, 0.1493, 0.0457, 0.0734, 0.0486, 0.0556, 0.1075, 0.1181,
        0.1469], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,852][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0591, 0.4723, 0.0295, 0.1502, 0.0827, 0.0153, 0.0109, 0.0153, 0.0776,
        0.0869], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,853][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0341, 0.5542, 0.0290, 0.1144, 0.1276, 0.0025, 0.0012, 0.0060, 0.0378,
        0.0933], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,853][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0055, 0.0690, 0.2940, 0.1935, 0.1191, 0.0574, 0.0571, 0.0631, 0.0974,
        0.0441], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,853][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.3111, 0.0392, 0.0478, 0.0757, 0.0759, 0.0631, 0.0808, 0.0721, 0.0968,
        0.1374], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,854][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.0069, 0.7106, 0.0196, 0.0953, 0.0793, 0.0049, 0.0019, 0.0035, 0.0522,
        0.0258], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:22:59,855][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0864, 0.5162, 0.0237, 0.1280, 0.0406, 0.0078, 0.0051, 0.0085, 0.0465,
        0.1068, 0.0303], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,858][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0083, 0.5523, 0.0306, 0.1186, 0.0721, 0.0154, 0.0096, 0.0157, 0.0459,
        0.0999, 0.0317], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,862][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1284, 0.1493, 0.0657, 0.0864, 0.0768, 0.0602, 0.0517, 0.0397, 0.1045,
        0.1089, 0.1284], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,866][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1550, 0.2213, 0.0474, 0.0913, 0.1612, 0.0306, 0.0197, 0.0377, 0.0788,
        0.0910, 0.0660], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,868][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.7831e-01, 1.5703e-03, 3.6754e-03, 7.6901e-04, 3.4124e-03, 9.6174e-04,
        6.6309e-04, 1.9951e-03, 1.8720e-03, 4.8792e-04, 6.2820e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,871][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0835, 0.3514, 0.0634, 0.1100, 0.1106, 0.0167, 0.0125, 0.0209, 0.0720,
        0.0875, 0.0716], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,875][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1296, 0.0678, 0.2077, 0.0241, 0.0612, 0.0440, 0.0255, 0.0916, 0.0936,
        0.0588, 0.1961], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,876][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0650, 0.3058, 0.0324, 0.1057, 0.0907, 0.0219, 0.0228, 0.0340, 0.1122,
        0.1387, 0.0709], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,876][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0401, 0.4802, 0.0286, 0.0831, 0.1253, 0.0047, 0.0038, 0.0112, 0.0572,
        0.1281, 0.0377], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,876][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0141, 0.1566, 0.1514, 0.2656, 0.0688, 0.0416, 0.0773, 0.0312, 0.0350,
        0.0723, 0.0861], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,877][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3484, 0.0394, 0.0592, 0.0390, 0.0836, 0.0466, 0.0825, 0.0663, 0.0859,
        0.0889, 0.0603], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,877][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0168, 0.5428, 0.0248, 0.1071, 0.0985, 0.0114, 0.0086, 0.0114, 0.0750,
        0.0526, 0.0512], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:22:59,877][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.1337, 0.4640, 0.0284, 0.0613, 0.0352, 0.0049, 0.0035, 0.0068, 0.0619,
        0.0879, 0.0372, 0.0750], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,878][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0139, 0.6233, 0.0260, 0.0715, 0.0345, 0.0103, 0.0055, 0.0078, 0.0313,
        0.0869, 0.0292, 0.0599], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,878][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.1394, 0.1692, 0.0545, 0.0696, 0.0587, 0.0484, 0.0454, 0.0248, 0.1042,
        0.0918, 0.1243, 0.0697], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,880][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.3078, 0.1577, 0.0536, 0.0465, 0.0829, 0.0216, 0.0068, 0.0210, 0.0582,
        0.0894, 0.0761, 0.0784], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,882][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([9.8949e-01, 7.7004e-04, 1.6936e-03, 2.7683e-04, 1.5355e-03, 4.2085e-04,
        3.1398e-04, 9.2327e-04, 9.2584e-04, 2.3410e-04, 2.7736e-03, 6.4476e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,885][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0495, 0.3950, 0.0295, 0.0991, 0.0793, 0.0083, 0.0043, 0.0086, 0.0638,
        0.0708, 0.0592, 0.1326], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,889][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.2813, 0.0596, 0.1467, 0.0288, 0.0523, 0.0465, 0.0359, 0.0736, 0.0665,
        0.0567, 0.1241, 0.0278], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,893][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0874, 0.2704, 0.0141, 0.0575, 0.0475, 0.0131, 0.0122, 0.0159, 0.0737,
        0.1145, 0.0409, 0.2528], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,896][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0830, 0.4626, 0.0194, 0.0428, 0.0926, 0.0017, 0.0010, 0.0071, 0.0382,
        0.1184, 0.0554, 0.0779], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,900][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0022, 0.0685, 0.0922, 0.1079, 0.2097, 0.0433, 0.0616, 0.0436, 0.0645,
        0.0585, 0.1232, 0.1247], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,900][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.3819, 0.0381, 0.0412, 0.0456, 0.0660, 0.0445, 0.0446, 0.0352, 0.0710,
        0.0818, 0.0457, 0.1045], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,900][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0122, 0.6649, 0.0109, 0.0388, 0.0539, 0.0041, 0.0018, 0.0045, 0.0634,
        0.0384, 0.0342, 0.0728], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:22:59,901][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0726, 0.4175, 0.0378, 0.0965, 0.0454, 0.0042, 0.0025, 0.0063, 0.0412,
        0.0647, 0.0359, 0.0913, 0.0840], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,901][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0109, 0.4210, 0.0447, 0.0794, 0.0674, 0.0070, 0.0040, 0.0067, 0.0274,
        0.0595, 0.0320, 0.0473, 0.1927], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,902][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.2009, 0.1066, 0.0666, 0.0581, 0.0580, 0.0453, 0.0323, 0.0315, 0.0844,
        0.0607, 0.1002, 0.0506, 0.1047], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,902][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1449, 0.1897, 0.0304, 0.0557, 0.1059, 0.0165, 0.0075, 0.0171, 0.0489,
        0.0691, 0.0596, 0.0832, 0.1714], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,902][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([9.6492e-01, 2.4219e-03, 3.6263e-03, 1.0474e-03, 4.6253e-03, 1.3013e-03,
        1.0785e-03, 2.1622e-03, 2.8016e-03, 8.3485e-04, 6.9718e-03, 1.6241e-03,
        6.5857e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,904][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0685, 0.4031, 0.0430, 0.0891, 0.0682, 0.0075, 0.0030, 0.0081, 0.0408,
        0.0276, 0.0444, 0.0632, 0.1335], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,906][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1734, 0.1031, 0.1472, 0.0310, 0.0677, 0.0460, 0.0239, 0.0671, 0.0866,
        0.0517, 0.1075, 0.0235, 0.0713], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,910][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0526, 0.3135, 0.0239, 0.0772, 0.0568, 0.0141, 0.0065, 0.0143, 0.0545,
        0.0788, 0.0372, 0.1230, 0.1477], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,913][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0621, 0.3947, 0.0344, 0.0697, 0.1118, 0.0016, 0.0008, 0.0026, 0.0219,
        0.0288, 0.0360, 0.0346, 0.2010], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,917][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0074, 0.1705, 0.1382, 0.0892, 0.0809, 0.0622, 0.0760, 0.0469, 0.0510,
        0.0541, 0.0888, 0.0786, 0.0561], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,921][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.2432, 0.0430, 0.0345, 0.0416, 0.0576, 0.0475, 0.0705, 0.0373, 0.0756,
        0.0960, 0.0479, 0.0603, 0.1450], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,924][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0166, 0.4668, 0.0206, 0.0646, 0.0765, 0.0051, 0.0021, 0.0036, 0.0493,
        0.0195, 0.0415, 0.0592, 0.1745], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:22:59,924][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1108, 0.3724, 0.0315, 0.1060, 0.0381, 0.0030, 0.0022, 0.0026, 0.0212,
        0.0564, 0.0196, 0.0856, 0.1279, 0.0228], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,925][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0057, 0.4354, 0.0357, 0.1376, 0.0428, 0.0069, 0.0049, 0.0042, 0.0235,
        0.0466, 0.0196, 0.0574, 0.1591, 0.0205], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,925][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1944, 0.0932, 0.0452, 0.0636, 0.0546, 0.0403, 0.0326, 0.0256, 0.0709,
        0.0504, 0.0783, 0.0525, 0.1021, 0.0963], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,926][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2417, 0.1368, 0.0392, 0.0494, 0.0799, 0.0126, 0.0079, 0.0182, 0.0353,
        0.0586, 0.0529, 0.0504, 0.1513, 0.0657], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,926][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8427e-01, 1.3630e-03, 2.0781e-03, 6.1694e-04, 1.9670e-03, 3.4426e-04,
        3.9986e-04, 6.2433e-04, 8.0749e-04, 1.9454e-04, 2.8965e-03, 6.2917e-04,
        1.5644e-03, 2.2444e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,926][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0848, 0.2857, 0.0544, 0.0812, 0.0795, 0.0072, 0.0045, 0.0071, 0.0358,
        0.0429, 0.0427, 0.0570, 0.1578, 0.0595], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,927][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3767, 0.0775, 0.1660, 0.0176, 0.0344, 0.0299, 0.0129, 0.0421, 0.0468,
        0.0237, 0.0835, 0.0142, 0.0351, 0.0396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,928][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0736, 0.2036, 0.0287, 0.0716, 0.0566, 0.0112, 0.0114, 0.0177, 0.0524,
        0.0860, 0.0451, 0.1101, 0.1771, 0.0549], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,931][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0361, 0.3132, 0.0252, 0.0559, 0.0758, 0.0016, 0.0009, 0.0022, 0.0195,
        0.0459, 0.0183, 0.0264, 0.3163, 0.0628], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,935][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0128, 0.0572, 0.1340, 0.1066, 0.1023, 0.0262, 0.0522, 0.0266, 0.0386,
        0.0561, 0.1064, 0.1475, 0.0538, 0.0796], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,938][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4470, 0.0497, 0.0335, 0.0520, 0.0480, 0.0231, 0.0339, 0.0205, 0.0424,
        0.0479, 0.0262, 0.0509, 0.0828, 0.0421], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,942][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0158, 0.5186, 0.0151, 0.0705, 0.0769, 0.0035, 0.0025, 0.0027, 0.0259,
        0.0265, 0.0199, 0.0441, 0.1359, 0.0422], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:22:59,946][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.1367, 0.3445, 0.0276, 0.0745, 0.0320, 0.0016, 0.0010, 0.0018, 0.0146,
        0.0341, 0.0207, 0.0522, 0.0979, 0.0249, 0.1359], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,949][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0056, 0.2583, 0.0342, 0.1023, 0.0439, 0.0046, 0.0019, 0.0045, 0.0262,
        0.0462, 0.0370, 0.0458, 0.1896, 0.0377, 0.1622], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,949][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1830, 0.0851, 0.0462, 0.0474, 0.0453, 0.0357, 0.0242, 0.0213, 0.0625,
        0.0436, 0.0772, 0.0534, 0.1121, 0.0863, 0.0767], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,949][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.3201, 0.1701, 0.0262, 0.0435, 0.0649, 0.0098, 0.0057, 0.0153, 0.0255,
        0.0409, 0.0348, 0.0465, 0.0799, 0.0561, 0.0606], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,950][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([9.5195e-01, 4.7079e-03, 5.4962e-03, 2.4532e-03, 6.3007e-03, 1.2255e-03,
        8.9243e-04, 1.5056e-03, 2.1675e-03, 9.3101e-04, 5.7828e-03, 2.3421e-03,
        4.3975e-03, 4.9468e-03, 4.9040e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,950][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0948, 0.2248, 0.0531, 0.0663, 0.0529, 0.0038, 0.0020, 0.0054, 0.0237,
        0.0229, 0.0404, 0.0380, 0.1130, 0.0609, 0.1978], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,951][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1515, 0.1006, 0.1319, 0.0287, 0.0749, 0.0341, 0.0221, 0.0558, 0.0610,
        0.0511, 0.0872, 0.0252, 0.0538, 0.0334, 0.0889], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,951][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1024, 0.2177, 0.0219, 0.0805, 0.0350, 0.0077, 0.0065, 0.0115, 0.0333,
        0.0406, 0.0210, 0.1145, 0.1341, 0.0569, 0.1166], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,951][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1112, 0.1807, 0.0254, 0.0443, 0.0578, 0.0008, 0.0005, 0.0018, 0.0109,
        0.0223, 0.0179, 0.0161, 0.1685, 0.0650, 0.2770], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,953][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0034, 0.0395, 0.1159, 0.0270, 0.0726, 0.0369, 0.0473, 0.0350, 0.0637,
        0.0242, 0.1169, 0.0308, 0.0771, 0.2626, 0.0472], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,956][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.2642, 0.0391, 0.0520, 0.0382, 0.0627, 0.0317, 0.0391, 0.0316, 0.0547,
        0.0522, 0.0382, 0.0385, 0.0921, 0.0448, 0.1208], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,960][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0373, 0.3759, 0.0308, 0.0589, 0.0865, 0.0026, 0.0017, 0.0031, 0.0302,
        0.0137, 0.0346, 0.0277, 0.1126, 0.0671, 0.1172], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:22:59,964][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.1072, 0.2825, 0.0181, 0.0669, 0.0289, 0.0017, 0.0013, 0.0014, 0.0123,
        0.0161, 0.0095, 0.0470, 0.0655, 0.0305, 0.1016, 0.2095],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,967][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0205, 0.4152, 0.0304, 0.0929, 0.0447, 0.0037, 0.0022, 0.0040, 0.0137,
        0.0277, 0.0130, 0.0338, 0.0896, 0.0291, 0.0908, 0.0886],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,971][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1895, 0.0699, 0.0360, 0.0402, 0.0400, 0.0279, 0.0260, 0.0223, 0.0524,
        0.0421, 0.0675, 0.0359, 0.0699, 0.0764, 0.0665, 0.1375],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,973][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.2039, 0.1460, 0.0254, 0.0442, 0.0604, 0.0099, 0.0050, 0.0129, 0.0262,
        0.0297, 0.0353, 0.0405, 0.0903, 0.0687, 0.0796, 0.1219],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,973][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([9.7437e-01, 1.4720e-03, 3.5968e-03, 6.7413e-04, 2.4629e-03, 6.2539e-04,
        5.0042e-04, 8.2178e-04, 1.0856e-03, 2.9804e-04, 3.1582e-03, 4.8576e-04,
        1.9822e-03, 2.2841e-03, 2.9894e-03, 3.1934e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,974][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.0768, 0.2378, 0.0369, 0.0647, 0.0453, 0.0037, 0.0020, 0.0039, 0.0175,
        0.0152, 0.0288, 0.0299, 0.0931, 0.0490, 0.1558, 0.1395],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,974][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.1860, 0.1069, 0.1025, 0.0232, 0.0638, 0.0367, 0.0201, 0.0397, 0.0520,
        0.0310, 0.0779, 0.0179, 0.0521, 0.0331, 0.0574, 0.0998],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,975][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.1033, 0.2075, 0.0164, 0.0457, 0.0482, 0.0061, 0.0058, 0.0079, 0.0284,
        0.0353, 0.0212, 0.0553, 0.1063, 0.0350, 0.1190, 0.1586],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,975][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([4.3928e-02, 1.9098e-01, 1.7849e-02, 3.0324e-02, 4.8882e-02, 5.6664e-04,
        2.7546e-04, 1.1179e-03, 7.6917e-03, 1.1684e-02, 9.5277e-03, 9.5587e-03,
        1.1292e-01, 3.8545e-02, 3.0535e-01, 1.7080e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,975][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0039, 0.0518, 0.1867, 0.1079, 0.0417, 0.0290, 0.0321, 0.0365, 0.0371,
        0.0371, 0.0890, 0.1349, 0.0349, 0.1025, 0.0382, 0.0367],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,976][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.1930, 0.0544, 0.0340, 0.0460, 0.0466, 0.0301, 0.0456, 0.0214, 0.0459,
        0.0721, 0.0312, 0.0524, 0.1094, 0.0329, 0.0886, 0.0963],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,977][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0129, 0.4970, 0.0189, 0.0486, 0.0908, 0.0019, 0.0013, 0.0016, 0.0148,
        0.0071, 0.0125, 0.0177, 0.0663, 0.0287, 0.0907, 0.0891],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:22:59,980][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1368, 0.2226, 0.0180, 0.0543, 0.0198, 0.0013, 0.0008, 0.0011, 0.0104,
        0.0232, 0.0104, 0.0338, 0.0673, 0.0128, 0.1276, 0.2296, 0.0301],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,984][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0090, 0.3650, 0.0278, 0.0976, 0.0302, 0.0040, 0.0023, 0.0024, 0.0123,
        0.0242, 0.0109, 0.0314, 0.1034, 0.0139, 0.0873, 0.1361, 0.0424],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,988][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1956, 0.0666, 0.0300, 0.0427, 0.0375, 0.0254, 0.0212, 0.0171, 0.0475,
        0.0321, 0.0546, 0.0365, 0.0726, 0.0650, 0.0639, 0.1131, 0.0787],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,991][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2718, 0.0846, 0.0232, 0.0285, 0.0473, 0.0062, 0.0035, 0.0094, 0.0171,
        0.0288, 0.0281, 0.0273, 0.0851, 0.0450, 0.0663, 0.1519, 0.0758],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,993][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8822e-01, 7.1991e-04, 1.3473e-03, 3.1912e-04, 9.6849e-04, 1.6030e-04,
        1.8919e-04, 2.7958e-04, 3.7387e-04, 8.9017e-05, 1.4308e-03, 2.9021e-04,
        6.7141e-04, 1.0314e-03, 1.1648e-03, 1.4551e-03, 1.2899e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,997][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0750, 0.1731, 0.0320, 0.0499, 0.0452, 0.0033, 0.0019, 0.0031, 0.0179,
        0.0199, 0.0228, 0.0276, 0.0944, 0.0336, 0.1731, 0.1631, 0.0641],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,998][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2709, 0.0810, 0.1504, 0.0185, 0.0415, 0.0265, 0.0153, 0.0373, 0.0362,
        0.0227, 0.0655, 0.0129, 0.0333, 0.0304, 0.0491, 0.0468, 0.0618],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,998][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0870, 0.1309, 0.0159, 0.0392, 0.0355, 0.0052, 0.0057, 0.0081, 0.0263,
        0.0423, 0.0226, 0.0558, 0.0973, 0.0309, 0.1388, 0.1974, 0.0610],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,999][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.4682e-02, 1.4261e-01, 1.1773e-02, 2.1934e-02, 2.9617e-02, 4.8218e-04,
        2.3573e-04, 6.4294e-04, 6.9073e-03, 1.3985e-02, 7.1871e-03, 7.9354e-03,
        1.1157e-01, 2.6808e-02, 2.7382e-01, 2.4027e-01, 6.9540e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,999][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0112, 0.0504, 0.1053, 0.0820, 0.0716, 0.0220, 0.0371, 0.0208, 0.0341,
        0.0435, 0.0902, 0.1152, 0.0496, 0.0508, 0.0558, 0.0690, 0.0913],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:22:59,999][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4432, 0.0328, 0.0250, 0.0305, 0.0306, 0.0148, 0.0209, 0.0139, 0.0274,
        0.0309, 0.0181, 0.0296, 0.0555, 0.0286, 0.0596, 0.0913, 0.0473],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,000][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0149, 0.3730, 0.0095, 0.0440, 0.0517, 0.0017, 0.0011, 0.0011, 0.0147,
        0.0124, 0.0125, 0.0225, 0.0840, 0.0221, 0.0991, 0.1752, 0.0604],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,001][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:00,002][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13775],
        [44638],
        [10182],
        [ 3197],
        [ 6247],
        [ 5556],
        [ 4423],
        [ 6559],
        [ 4159],
        [ 1462],
        [ 7268],
        [ 3293],
        [ 5157],
        [ 3394],
        [ 4136],
        [ 2162],
        [ 2789]], device='cuda:0')
[2024-07-24 10:23:00,003][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14107],
        [37275],
        [12431],
        [ 4343],
        [ 9559],
        [ 8870],
        [ 7542],
        [11019],
        [ 7920],
        [ 3576],
        [14197],
        [ 8493],
        [15791],
        [10772],
        [10235],
        [ 5427],
        [ 9990]], device='cuda:0')
[2024-07-24 10:23:00,005][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21395],
        [27007],
        [36744],
        [34218],
        [32921],
        [32674],
        [32374],
        [33067],
        [32143],
        [31937],
        [30965],
        [28903],
        [27157],
        [26609],
        [28016],
        [28274],
        [28127]], device='cuda:0')
[2024-07-24 10:23:00,007][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[25775],
        [ 8465],
        [ 8750],
        [ 9768],
        [10406],
        [10717],
        [10771],
        [10835],
        [10703],
        [10763],
        [10725],
        [10507],
        [10936],
        [11089],
        [11192],
        [11322],
        [11145]], device='cuda:0')
[2024-07-24 10:23:00,008][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8961],
        [10595],
        [ 9234],
        [ 8720],
        [ 9127],
        [ 9062],
        [ 9431],
        [ 9250],
        [ 9258],
        [ 9701],
        [ 9879],
        [ 9720],
        [ 9816],
        [ 9688],
        [ 9707],
        [ 9617],
        [ 9570]], device='cuda:0')
[2024-07-24 10:23:00,010][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12291],
        [21949],
        [21094],
        [19392],
        [18757],
        [18726],
        [21246],
        [20383],
        [19847],
        [20396],
        [20508],
        [20210],
        [20237],
        [19988],
        [20310],
        [20356],
        [20353]], device='cuda:0')
[2024-07-24 10:23:00,013][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1944],
        [1523],
        [1614],
        [ 801],
        [1054],
        [1484],
        [2328],
        [2716],
        [2988],
        [3298],
        [3512],
        [2785],
        [2840],
        [3133],
        [3830],
        [4042],
        [4129]], device='cuda:0')
[2024-07-24 10:23:00,016][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8429],
        [22425],
        [22303],
        [22540],
        [21632],
        [22852],
        [22112],
        [20592],
        [19116],
        [20373],
        [16962],
        [17609],
        [17688],
        [17560],
        [15633],
        [13222],
        [14398]], device='cuda:0')
[2024-07-24 10:23:00,018][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[21057],
        [44906],
        [12517],
        [29333],
        [14840],
        [14289],
        [11568],
        [11949],
        [11409],
        [11463],
        [ 9495],
        [14261],
        [ 9337],
        [ 9088],
        [ 7453],
        [ 8345],
        [ 8028]], device='cuda:0')
[2024-07-24 10:23:00,021][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 5462],
        [19124],
        [34755],
        [32866],
        [32988],
        [33796],
        [34133],
        [33686],
        [34330],
        [34438],
        [34341],
        [36091],
        [36635],
        [36117],
        [34848],
        [30877],
        [28620]], device='cuda:0')
[2024-07-24 10:23:00,023][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20331],
        [19540],
        [17379],
        [17540],
        [15463],
        [15510],
        [15415],
        [14577],
        [14114],
        [14928],
        [14268],
        [15204],
        [ 9474],
        [ 7466],
        [ 8820],
        [ 8997],
        [ 8437]], device='cuda:0')
[2024-07-24 10:23:00,026][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[35092],
        [50238],
        [33069],
        [35913],
        [36751],
        [36815],
        [36696],
        [41598],
        [41403],
        [35058],
        [44720],
        [39234],
        [45158],
        [38358],
        [30686],
        [36670],
        [36526]], device='cuda:0')
[2024-07-24 10:23:00,028][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25240],
        [24204],
        [21686],
        [18964],
        [17781],
        [15784],
        [14629],
        [12826],
        [12118],
        [12008],
        [12374],
        [13391],
        [13067],
        [12260],
        [12597],
        [12558],
        [11593]], device='cuda:0')
[2024-07-24 10:23:00,029][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[47782],
        [48208],
        [48065],
        [47997],
        [48153],
        [47787],
        [47079],
        [47413],
        [47429],
        [47161],
        [47600],
        [47432],
        [47712],
        [47622],
        [47536],
        [47659],
        [47538]], device='cuda:0')
[2024-07-24 10:23:00,030][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[36275],
        [19793],
        [17456],
        [15660],
        [15463],
        [17841],
        [18363],
        [17711],
        [12618],
        [11444],
        [10153],
        [ 5627],
        [ 2403],
        [ 2885],
        [ 9309],
        [20622],
        [ 6917]], device='cuda:0')
[2024-07-24 10:23:00,031][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[27901],
        [24356],
        [19967],
        [20972],
        [22371],
        [22841],
        [23335],
        [22655],
        [23296],
        [23615],
        [24679],
        [26544],
        [28022],
        [28698],
        [29350],
        [33131],
        [34891]], device='cuda:0')
[2024-07-24 10:23:00,032][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41132],
        [ 4924],
        [ 5042],
        [ 5243],
        [ 6064],
        [ 6104],
        [ 6795],
        [ 7599],
        [ 6040],
        [ 5788],
        [ 5399],
        [ 5193],
        [ 6843],
        [ 7067],
        [ 8314],
        [ 6589],
        [ 6854]], device='cuda:0')
[2024-07-24 10:23:00,033][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17230],
        [29463],
        [25007],
        [26733],
        [23050],
        [23855],
        [24184],
        [22313],
        [19356],
        [23651],
        [22873],
        [24493],
        [21170],
        [20222],
        [19179],
        [19070],
        [18624]], device='cuda:0')
[2024-07-24 10:23:00,036][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12218],
        [12321],
        [13319],
        [13655],
        [14852],
        [15347],
        [14967],
        [15606],
        [14532],
        [14621],
        [15854],
        [15194],
        [12487],
        [13119],
        [13840],
        [12219],
        [11587]], device='cuda:0')
[2024-07-24 10:23:00,037][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23408],
        [23355],
        [22863],
        [23131],
        [21238],
        [22177],
        [20494],
        [21141],
        [22542],
        [20317],
        [20891],
        [22168],
        [19331],
        [21318],
        [18083],
        [20517],
        [21911]], device='cuda:0')
[2024-07-24 10:23:00,039][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5144],
        [20930],
        [23918],
        [25822],
        [25545],
        [25166],
        [24713],
        [24226],
        [23786],
        [22960],
        [22803],
        [24663],
        [24798],
        [24142],
        [21016],
        [18866],
        [17896]], device='cuda:0')
[2024-07-24 10:23:00,042][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32003],
        [26943],
        [45619],
        [44007],
        [45333],
        [42612],
        [44354],
        [44531],
        [43128],
        [42763],
        [43036],
        [42022],
        [42336],
        [41869],
        [42969],
        [41325],
        [42113]], device='cuda:0')
[2024-07-24 10:23:00,044][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[42385],
        [37771],
        [23917],
        [24661],
        [22245],
        [20726],
        [20189],
        [21048],
        [18732],
        [19239],
        [16316],
        [19031],
        [18803],
        [17147],
        [16238],
        [16688],
        [15492]], device='cuda:0')
[2024-07-24 10:23:00,047][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12837],
        [16462],
        [45510],
        [45148],
        [44461],
        [44370],
        [44197],
        [44227],
        [44367],
        [43861],
        [43356],
        [43210],
        [42520],
        [40312],
        [32651],
        [35504],
        [35308]], device='cuda:0')
[2024-07-24 10:23:00,049][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39800],
        [33146],
        [30781],
        [34809],
        [34152],
        [33167],
        [34535],
        [32898],
        [32178],
        [31462],
        [33310],
        [31699],
        [32190],
        [32312],
        [28410],
        [31830],
        [29869]], device='cuda:0')
[2024-07-24 10:23:00,052][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21673],
        [18441],
        [10138],
        [12203],
        [13202],
        [13554],
        [19041],
        [23152],
        [22431],
        [27394],
        [26784],
        [28444],
        [31612],
        [29667],
        [30981],
        [34056],
        [34175]], device='cuda:0')
[2024-07-24 10:23:00,054][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5950],
        [ 4917],
        [ 9582],
        [ 8910],
        [ 9625],
        [11653],
        [10368],
        [ 9764],
        [ 9574],
        [ 8724],
        [ 7964],
        [ 6958],
        [ 3942],
        [ 4922],
        [ 8042],
        [ 7075],
        [ 4469]], device='cuda:0')
[2024-07-24 10:23:00,057][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25925],
        [33570],
        [28622],
        [26195],
        [26068],
        [24085],
        [21992],
        [22787],
        [24577],
        [23186],
        [24564],
        [23982],
        [24724],
        [25743],
        [27642],
        [25755],
        [27878]], device='cuda:0')
[2024-07-24 10:23:00,058][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[20701],
        [26670],
        [21237],
        [21963],
        [25629],
        [33942],
        [30246],
        [27209],
        [33216],
        [33360],
        [31883],
        [33460],
        [38082],
        [36862],
        [33766],
        [29090],
        [33874]], device='cuda:0')
[2024-07-24 10:23:00,059][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414],
        [20414]], device='cuda:0')
[2024-07-24 10:23:00,097][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:00,100][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,103][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,107][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,107][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,107][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,120][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,123][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,126][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,129][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,130][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,131][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,131][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,131][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.1268, 0.8732], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,132][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.4720, 0.5280], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,132][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.0428, 0.9572], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,132][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.1479, 0.8521], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,133][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.9864, 0.0136], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,133][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.9441, 0.0559], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,134][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.9874, 0.0126], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,137][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0792, 0.9208], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,139][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.3143, 0.6857], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,143][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.3529, 0.6471], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,146][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0100, 0.9900], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,150][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.9569, 0.0431], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,154][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0086, 0.9712, 0.0202], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,155][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2906, 0.3802, 0.3292], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,155][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0083, 0.4564, 0.5353], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,155][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1018, 0.5245, 0.3738], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,156][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9687, 0.0262, 0.0051], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,156][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8595, 0.1162, 0.0243], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,156][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9770, 0.0175, 0.0055], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,157][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0459, 0.6521, 0.3020], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,157][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0338, 0.8249, 0.1413], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,157][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0665, 0.7223, 0.2111], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,159][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0088, 0.3729, 0.6184], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,161][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0880, 0.1579, 0.7541], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,165][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0111, 0.9111, 0.0085, 0.0693], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,168][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.2375, 0.2755, 0.2384, 0.2485], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,172][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0027, 0.4549, 0.2673, 0.2751], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,176][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0784, 0.4358, 0.2970, 0.1888], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,179][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.7580, 0.1387, 0.0342, 0.0691], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,179][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.8913, 0.0571, 0.0164, 0.0352], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,179][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.9304, 0.0361, 0.0068, 0.0266], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,180][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0293, 0.4339, 0.2213, 0.3154], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,180][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0326, 0.6896, 0.0446, 0.2332], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,180][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.1142, 0.4082, 0.1534, 0.3242], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,181][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0094, 0.2483, 0.4000, 0.3423], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,181][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.4733, 0.2844, 0.1751, 0.0672], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,181][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0038, 0.8032, 0.0097, 0.1479, 0.0354], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,183][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.1591, 0.2341, 0.1985, 0.2078, 0.2005], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,185][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0013, 0.3180, 0.2854, 0.1903, 0.2050], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,189][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0819, 0.3144, 0.2807, 0.1844, 0.1385], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,192][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.8887, 0.0599, 0.0152, 0.0249, 0.0112], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,196][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.5676, 0.0879, 0.0209, 0.0853, 0.2383], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,200][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.9351, 0.0226, 0.0106, 0.0253, 0.0064], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,203][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0153, 0.3367, 0.1672, 0.2598, 0.2210], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,203][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0135, 0.4550, 0.0764, 0.3355, 0.1196], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,203][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.0331, 0.3585, 0.0901, 0.3499, 0.1684], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,204][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0012, 0.1478, 0.3020, 0.2515, 0.2974], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,204][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.3534, 0.0379, 0.5177, 0.0550, 0.0360], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,204][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.2051e-04, 7.5009e-01, 7.2768e-03, 1.4905e-01, 9.0210e-02, 3.1549e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,205][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1224, 0.1941, 0.1722, 0.1747, 0.1681, 0.1686], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,205][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0016, 0.2571, 0.1525, 0.1616, 0.1846, 0.2425], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,205][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0943, 0.2814, 0.2324, 0.1610, 0.1194, 0.1115], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,207][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5993, 0.1465, 0.0352, 0.0607, 0.0254, 0.1328], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,209][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0924, 0.0729, 0.0206, 0.0666, 0.3156, 0.4319], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,213][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9238, 0.0280, 0.0101, 0.0266, 0.0053, 0.0063], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,216][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0089, 0.3190, 0.1202, 0.2423, 0.1756, 0.1341], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,220][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0046, 0.3081, 0.0543, 0.1731, 0.3245, 0.1354], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,224][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0075, 0.2868, 0.0904, 0.3101, 0.2119, 0.0934], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,227][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0022, 0.1248, 0.1018, 0.1905, 0.2573, 0.3233], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,227][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0468, 0.0571, 0.8552, 0.0202, 0.0151, 0.0057], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,227][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([7.1537e-05, 6.6522e-01, 4.5773e-03, 2.2869e-01, 9.2239e-02, 6.1973e-03,
        3.0015e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,228][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.1090, 0.1681, 0.1472, 0.1499, 0.1458, 0.1406, 0.1393],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,228][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0010, 0.2622, 0.1169, 0.1541, 0.1106, 0.1558, 0.1994],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,228][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0546, 0.2333, 0.1973, 0.1265, 0.0967, 0.1030, 0.1886],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,229][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.7105, 0.0600, 0.0167, 0.0249, 0.0144, 0.1542, 0.0193],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,229][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.1899, 0.0475, 0.0174, 0.0483, 0.1662, 0.4446, 0.0861],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,230][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.7407, 0.0457, 0.0320, 0.0207, 0.0171, 0.0342, 0.1096],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,233][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0051, 0.2325, 0.1135, 0.2039, 0.1884, 0.1261, 0.1305],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,235][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0009, 0.1555, 0.0309, 0.1888, 0.1881, 0.4225, 0.0133],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,239][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0102, 0.2609, 0.0816, 0.2746, 0.1878, 0.0934, 0.0915],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,242][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0005, 0.1713, 0.0937, 0.3292, 0.1459, 0.1717, 0.0878],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,246][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.1932, 0.1563, 0.2362, 0.1001, 0.2042, 0.0518, 0.0581],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,250][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0012, 0.6373, 0.0130, 0.2314, 0.0991, 0.0082, 0.0047, 0.0052],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,251][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0934, 0.1495, 0.1331, 0.1348, 0.1293, 0.1252, 0.1212, 0.1136],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,251][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0009, 0.1703, 0.1096, 0.1066, 0.1237, 0.1436, 0.1577, 0.1875],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,252][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0586, 0.2214, 0.1740, 0.1228, 0.0811, 0.0968, 0.1478, 0.0976],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,252][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.7493, 0.0544, 0.0133, 0.0230, 0.0151, 0.0930, 0.0092, 0.0427],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,252][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.1062, 0.0640, 0.0114, 0.0539, 0.1742, 0.3491, 0.1204, 0.1208],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,253][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.7987, 0.0296, 0.0241, 0.0343, 0.0131, 0.0098, 0.0630, 0.0274],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,253][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0038, 0.2447, 0.0990, 0.1899, 0.1557, 0.1168, 0.1111, 0.0789],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,253][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0102, 0.2577, 0.0396, 0.1494, 0.2916, 0.1277, 0.0071, 0.1168],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,255][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0079, 0.2620, 0.0649, 0.2854, 0.1562, 0.0785, 0.0917, 0.0535],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,257][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0012, 0.2222, 0.0716, 0.1667, 0.1663, 0.1985, 0.1132, 0.0603],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,261][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2101, 0.0371, 0.5389, 0.0409, 0.0490, 0.0764, 0.0149, 0.0328],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,264][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0054, 0.7604, 0.0090, 0.1155, 0.0722, 0.0012, 0.0011, 0.0015, 0.0337],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,268][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0786, 0.1364, 0.1196, 0.1205, 0.1159, 0.1133, 0.1097, 0.1018, 0.1042],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,272][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0004, 0.1380, 0.1005, 0.0872, 0.0965, 0.1480, 0.1392, 0.1664, 0.1239],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,275][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0696, 0.1844, 0.1711, 0.1104, 0.0775, 0.0722, 0.1295, 0.1204, 0.0649],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,275][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4688, 0.0907, 0.0295, 0.0385, 0.0258, 0.1237, 0.0210, 0.0993, 0.1028],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,275][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0656, 0.0466, 0.0125, 0.0510, 0.2142, 0.3049, 0.1041, 0.1355, 0.0655],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,276][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.9131, 0.0114, 0.0071, 0.0207, 0.0060, 0.0075, 0.0184, 0.0132, 0.0025],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,276][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0049, 0.2168, 0.0899, 0.1781, 0.1429, 0.1053, 0.1008, 0.0711, 0.0902],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,277][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0306, 0.2562, 0.0396, 0.1120, 0.1826, 0.0286, 0.0035, 0.0559, 0.2909],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,277][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0120, 0.2237, 0.0769, 0.2426, 0.1588, 0.0749, 0.0736, 0.0528, 0.0847],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,277][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0013, 0.1370, 0.0772, 0.1289, 0.1368, 0.1980, 0.1186, 0.0723, 0.1299],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,279][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1459, 0.0252, 0.6663, 0.0166, 0.0210, 0.0110, 0.0050, 0.1021, 0.0068],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,281][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ house] are: tensor([1.9325e-03, 6.8365e-01, 1.0367e-02, 1.6131e-01, 6.1366e-02, 1.0512e-03,
        4.6458e-04, 9.1476e-04, 2.7976e-02, 5.0974e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,284][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0783, 0.1223, 0.1088, 0.1078, 0.1052, 0.1022, 0.1003, 0.0913, 0.0949,
        0.0889], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,287][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0002, 0.1627, 0.0986, 0.0999, 0.0729, 0.1244, 0.1002, 0.1242, 0.1064,
        0.1105], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,290][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0322, 0.1761, 0.1300, 0.1013, 0.0558, 0.0684, 0.1533, 0.0762, 0.0658,
        0.1409], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,294][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.6309, 0.0426, 0.0150, 0.0220, 0.0108, 0.1044, 0.0121, 0.0620, 0.0749,
        0.0252], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,298][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.3213, 0.0274, 0.0061, 0.0226, 0.0798, 0.2779, 0.0617, 0.1165, 0.0572,
        0.0295], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,299][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.4975, 0.0895, 0.0290, 0.0643, 0.0241, 0.0530, 0.1133, 0.0367, 0.0227,
        0.0699], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,299][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0035, 0.1920, 0.0828, 0.1637, 0.1387, 0.0895, 0.0902, 0.0612, 0.0830,
        0.0955], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,299][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0134, 0.1899, 0.0485, 0.1000, 0.1120, 0.0303, 0.0018, 0.0655, 0.2959,
        0.1426], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,300][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0219, 0.2067, 0.0644, 0.2249, 0.1118, 0.0519, 0.0533, 0.0360, 0.0693,
        0.1598], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,300][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0003, 0.0430, 0.0480, 0.1311, 0.1366, 0.1986, 0.0937, 0.0499, 0.1696,
        0.1292], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,301][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.2907, 0.0514, 0.3348, 0.0274, 0.0412, 0.0223, 0.0183, 0.1834, 0.0276,
        0.0029], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,301][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0092, 0.5808, 0.0101, 0.0957, 0.0547, 0.0025, 0.0019, 0.0031, 0.0596,
        0.1637, 0.0189], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,301][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0648, 0.1094, 0.1015, 0.1006, 0.0967, 0.0937, 0.0909, 0.0846, 0.0881,
        0.0828, 0.0867], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,303][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0001, 0.1170, 0.0935, 0.0787, 0.0725, 0.1181, 0.0851, 0.1374, 0.1008,
        0.1071, 0.0897], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,305][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0553, 0.1539, 0.1129, 0.0945, 0.0655, 0.0811, 0.1153, 0.0920, 0.0840,
        0.0969, 0.0484], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,308][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8581, 0.0186, 0.0047, 0.0075, 0.0066, 0.0306, 0.0041, 0.0196, 0.0327,
        0.0085, 0.0090], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,312][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1155, 0.0363, 0.0066, 0.0317, 0.1324, 0.2823, 0.0879, 0.1139, 0.0908,
        0.0707, 0.0320], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,316][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9196, 0.0075, 0.0037, 0.0142, 0.0068, 0.0072, 0.0129, 0.0098, 0.0028,
        0.0134, 0.0020], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,319][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0028, 0.1763, 0.0675, 0.1403, 0.1135, 0.0905, 0.0872, 0.0645, 0.0798,
        0.0902, 0.0875], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,323][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0132, 0.1233, 0.0208, 0.0721, 0.0773, 0.0201, 0.0039, 0.0654, 0.2229,
        0.2124, 0.1686], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,323][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0110, 0.1665, 0.0623, 0.1881, 0.1245, 0.0660, 0.0717, 0.0530, 0.0757,
        0.1439, 0.0372], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,323][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0005, 0.1075, 0.0866, 0.1699, 0.0959, 0.1946, 0.0946, 0.0445, 0.0959,
        0.0588, 0.0512], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,324][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1116, 0.0362, 0.2883, 0.0921, 0.1187, 0.0580, 0.0125, 0.1741, 0.0323,
        0.0682, 0.0081], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,324][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ William] are: tensor([5.5857e-03, 7.5872e-01, 4.2396e-03, 4.2335e-02, 2.9662e-02, 4.2041e-04,
        3.1888e-04, 5.2400e-04, 2.2842e-02, 5.9658e-02, 1.5666e-02, 6.0028e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,324][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0640, 0.1035, 0.0927, 0.0911, 0.0885, 0.0848, 0.0834, 0.0781, 0.0788,
        0.0749, 0.0788, 0.0815], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,325][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ William] are: tensor([1.0916e-04, 1.3342e-01, 6.3094e-02, 9.0869e-02, 6.4114e-02, 1.1606e-01,
        9.8836e-02, 1.2549e-01, 9.3029e-02, 9.1240e-02, 5.7670e-02, 6.6061e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,325][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0393, 0.1633, 0.1322, 0.0780, 0.0572, 0.0653, 0.1154, 0.0742, 0.0643,
        0.0974, 0.0540, 0.0594], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,326][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.4683, 0.0690, 0.0198, 0.0362, 0.0174, 0.1181, 0.0178, 0.0578, 0.0748,
        0.0276, 0.0303, 0.0630], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,327][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.3071, 0.0376, 0.0074, 0.0234, 0.0966, 0.1701, 0.0724, 0.1099, 0.0588,
        0.0369, 0.0200, 0.0598], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,330][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.6685, 0.0378, 0.0136, 0.0299, 0.0217, 0.0285, 0.0506, 0.0321, 0.0133,
        0.0464, 0.0153, 0.0424], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,334][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0020, 0.1549, 0.0677, 0.1188, 0.1049, 0.0725, 0.0683, 0.0516, 0.0686,
        0.0672, 0.0891, 0.1345], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,337][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0096, 0.1065, 0.0138, 0.0328, 0.0170, 0.0112, 0.0011, 0.0469, 0.2136,
        0.1141, 0.0932, 0.3403], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,340][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0155, 0.1706, 0.0572, 0.1305, 0.1026, 0.0572, 0.0485, 0.0475, 0.0765,
        0.1512, 0.0412, 0.1016], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,343][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ William] are: tensor([1.9051e-04, 4.1628e-02, 1.8312e-02, 4.5928e-02, 7.9679e-02, 1.0561e-01,
        9.0311e-02, 2.9484e-02, 2.0528e-01, 1.0266e-01, 7.8071e-02, 2.0286e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,347][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.2399, 0.1309, 0.1415, 0.0307, 0.0875, 0.0528, 0.0301, 0.1310, 0.0181,
        0.0804, 0.0287, 0.0284], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,347][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([8.7026e-03, 5.6810e-01, 1.0352e-02, 1.0963e-01, 3.3902e-02, 4.5337e-04,
        3.3633e-04, 5.0553e-04, 1.0124e-02, 1.3382e-02, 1.2553e-02, 5.0402e-02,
        1.8155e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,347][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0565, 0.0947, 0.0835, 0.0846, 0.0807, 0.0806, 0.0784, 0.0729, 0.0751,
        0.0722, 0.0729, 0.0763, 0.0716], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,348][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0002, 0.1052, 0.0653, 0.0639, 0.0653, 0.1061, 0.0977, 0.1205, 0.0896,
        0.0912, 0.0673, 0.0514, 0.0765], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,348][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0813, 0.1439, 0.1294, 0.0771, 0.0527, 0.0549, 0.0635, 0.0960, 0.0586,
        0.0817, 0.0607, 0.0513, 0.0488], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,348][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.8732, 0.0110, 0.0055, 0.0065, 0.0038, 0.0231, 0.0046, 0.0200, 0.0188,
        0.0059, 0.0085, 0.0108, 0.0082], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,349][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.1834, 0.0274, 0.0070, 0.0218, 0.0957, 0.2520, 0.0488, 0.0872, 0.0719,
        0.0340, 0.0248, 0.0801, 0.0660], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,349][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.7592, 0.0166, 0.0117, 0.0143, 0.0171, 0.0136, 0.0436, 0.0348, 0.0074,
        0.0314, 0.0072, 0.0253, 0.0179], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,351][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0012, 0.1326, 0.0539, 0.1060, 0.1113, 0.0717, 0.0654, 0.0449, 0.0681,
        0.0722, 0.0726, 0.1162, 0.0837], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,353][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0091, 0.0871, 0.0374, 0.0697, 0.0728, 0.0319, 0.0016, 0.0344, 0.1327,
        0.0368, 0.0847, 0.1276, 0.2742], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,356][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0228, 0.1911, 0.0446, 0.1689, 0.0969, 0.0415, 0.0433, 0.0269, 0.0501,
        0.1011, 0.0278, 0.0965, 0.0885], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,360][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0006, 0.1075, 0.0564, 0.0914, 0.1174, 0.1705, 0.0516, 0.0289, 0.1063,
        0.0502, 0.0509, 0.0852, 0.0831], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,362][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([8.7839e-01, 1.1585e-02, 1.2637e-02, 1.5836e-02, 1.5848e-02, 6.3778e-03,
        8.6171e-03, 2.3395e-02, 3.6715e-03, 5.8917e-03, 5.5212e-03, 1.1410e-02,
        8.1655e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,366][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0108, 0.4176, 0.0098, 0.0690, 0.0395, 0.0004, 0.0005, 0.0006, 0.0142,
        0.0433, 0.0116, 0.0436, 0.2918, 0.0475], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,369][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0511, 0.0883, 0.0795, 0.0807, 0.0792, 0.0742, 0.0733, 0.0675, 0.0691,
        0.0653, 0.0673, 0.0704, 0.0672, 0.0669], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,371][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0004, 0.0838, 0.0763, 0.0652, 0.0690, 0.0863, 0.0831, 0.0989, 0.0745,
        0.0805, 0.0740, 0.0477, 0.0706, 0.0897], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,371][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0397, 0.1353, 0.0975, 0.0769, 0.0548, 0.0622, 0.1112, 0.0780, 0.0758,
        0.0774, 0.0462, 0.0583, 0.0513, 0.0357], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,371][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6839, 0.0198, 0.0095, 0.0125, 0.0083, 0.0717, 0.0110, 0.0316, 0.0605,
        0.0131, 0.0196, 0.0256, 0.0165, 0.0163], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,372][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2990, 0.0378, 0.0043, 0.0271, 0.0655, 0.0985, 0.0705, 0.0537, 0.0460,
        0.0542, 0.0198, 0.1111, 0.0891, 0.0235], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,372][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7421, 0.0175, 0.0115, 0.0225, 0.0173, 0.0056, 0.0509, 0.0162, 0.0041,
        0.0315, 0.0058, 0.0338, 0.0315, 0.0097], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,373][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0019, 0.1379, 0.0497, 0.1128, 0.0901, 0.0697, 0.0647, 0.0462, 0.0624,
        0.0728, 0.0612, 0.1096, 0.0670, 0.0540], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,373][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0132, 0.0980, 0.0126, 0.0553, 0.0423, 0.0073, 0.0010, 0.0086, 0.0511,
        0.0369, 0.0411, 0.1171, 0.4170, 0.0986], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,373][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0126, 0.1435, 0.0477, 0.1845, 0.0928, 0.0347, 0.0443, 0.0242, 0.0437,
        0.0934, 0.0254, 0.1071, 0.0962, 0.0500], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,375][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0009, 0.0802, 0.0611, 0.1241, 0.1424, 0.1098, 0.0555, 0.0287, 0.0939,
        0.0449, 0.0725, 0.0995, 0.0469, 0.0396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,377][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2708, 0.0237, 0.3399, 0.0212, 0.0373, 0.0680, 0.0036, 0.0602, 0.0771,
        0.0275, 0.0305, 0.0110, 0.0103, 0.0188], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,379][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([1.9663e-02, 3.9417e-01, 1.8749e-02, 6.7548e-02, 3.7470e-02, 1.8228e-04,
        1.7549e-04, 3.2949e-04, 5.6660e-03, 1.0770e-02, 9.5830e-03, 1.2535e-02,
        1.2750e-01, 4.5294e-02, 2.5036e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,383][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0490, 0.0837, 0.0734, 0.0747, 0.0741, 0.0695, 0.0686, 0.0634, 0.0646,
        0.0619, 0.0627, 0.0662, 0.0632, 0.0624, 0.0627], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,386][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0003, 0.0926, 0.0766, 0.0524, 0.0650, 0.0878, 0.0779, 0.0830, 0.0710,
        0.0659, 0.0605, 0.0339, 0.0555, 0.0824, 0.0951], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,390][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0408, 0.1591, 0.1047, 0.0744, 0.0400, 0.0562, 0.0824, 0.0643, 0.0620,
        0.0877, 0.0472, 0.0533, 0.0422, 0.0491, 0.0365], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,394][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.6700, 0.0185, 0.0115, 0.0145, 0.0099, 0.0614, 0.0107, 0.0349, 0.0465,
        0.0130, 0.0178, 0.0258, 0.0234, 0.0203, 0.0218], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,395][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.2217, 0.0359, 0.0054, 0.0319, 0.0733, 0.1601, 0.0686, 0.0689, 0.0460,
        0.0534, 0.0213, 0.1118, 0.0575, 0.0271, 0.0172], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,395][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.6247, 0.0180, 0.0208, 0.0317, 0.0143, 0.0130, 0.0692, 0.0395, 0.0079,
        0.0430, 0.0074, 0.0379, 0.0211, 0.0142, 0.0375], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,396][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0023, 0.1136, 0.0486, 0.1084, 0.0890, 0.0618, 0.0619, 0.0415, 0.0545,
        0.0636, 0.0581, 0.1070, 0.0630, 0.0511, 0.0756], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,396][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0185, 0.0525, 0.0137, 0.0441, 0.0273, 0.0059, 0.0006, 0.0087, 0.0434,
        0.0295, 0.0330, 0.0923, 0.2284, 0.1423, 0.2598], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,396][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0234, 0.1343, 0.0546, 0.1725, 0.0862, 0.0318, 0.0371, 0.0221, 0.0367,
        0.0778, 0.0279, 0.0931, 0.0749, 0.0469, 0.0808], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,397][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0003, 0.0227, 0.0553, 0.0522, 0.1505, 0.1634, 0.0527, 0.0319, 0.1146,
        0.0259, 0.0790, 0.0467, 0.0794, 0.0557, 0.0697], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,397][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.3088, 0.0183, 0.1565, 0.0367, 0.0649, 0.0472, 0.0123, 0.1956, 0.0397,
        0.0083, 0.0272, 0.0179, 0.0059, 0.0207, 0.0401], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,397][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ it] are: tensor([1.0754e-02, 3.2942e-01, 5.9248e-03, 4.3028e-02, 2.1379e-02, 1.3880e-04,
        9.7813e-05, 1.3625e-04, 3.0087e-03, 4.5023e-03, 2.9768e-03, 7.4796e-03,
        8.4755e-02, 1.5179e-02, 2.4320e-01, 2.2802e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,399][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0418, 0.0769, 0.0716, 0.0699, 0.0695, 0.0665, 0.0645, 0.0602, 0.0619,
        0.0572, 0.0603, 0.0613, 0.0596, 0.0583, 0.0579, 0.0625],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,401][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0001, 0.0831, 0.0603, 0.0557, 0.0494, 0.0893, 0.0751, 0.0827, 0.0685,
        0.0702, 0.0551, 0.0458, 0.0655, 0.0684, 0.0734, 0.0575],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,405][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0483, 0.1300, 0.1243, 0.0739, 0.0566, 0.0490, 0.0941, 0.0703, 0.0475,
        0.0701, 0.0451, 0.0481, 0.0362, 0.0473, 0.0383, 0.0211],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,408][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.3692, 0.0464, 0.0208, 0.0219, 0.0177, 0.0904, 0.0232, 0.0732, 0.0750,
        0.0286, 0.0394, 0.0432, 0.0409, 0.0620, 0.0331, 0.0149],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,412][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0554, 0.0257, 0.0091, 0.0403, 0.1218, 0.1843, 0.0689, 0.0934, 0.0532,
        0.0382, 0.0275, 0.0964, 0.0841, 0.0327, 0.0364, 0.0328],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,416][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.7672, 0.0077, 0.0107, 0.0141, 0.0170, 0.0148, 0.0144, 0.0211, 0.0053,
        0.0151, 0.0059, 0.0229, 0.0366, 0.0096, 0.0323, 0.0054],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,419][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0021, 0.1119, 0.0466, 0.1007, 0.0853, 0.0545, 0.0526, 0.0364, 0.0500,
        0.0562, 0.0553, 0.1007, 0.0668, 0.0512, 0.0714, 0.0580],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,419][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0061, 0.0344, 0.0126, 0.0335, 0.0402, 0.0105, 0.0005, 0.0109, 0.0544,
        0.0170, 0.0347, 0.0611, 0.1576, 0.0989, 0.2722, 0.1554],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,419][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0199, 0.1370, 0.0529, 0.1591, 0.1000, 0.0336, 0.0325, 0.0248, 0.0354,
        0.0685, 0.0256, 0.0716, 0.0807, 0.0423, 0.0620, 0.0540],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,420][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0005, 0.1024, 0.0553, 0.0975, 0.0967, 0.1388, 0.0605, 0.0334, 0.0668,
        0.0425, 0.0327, 0.0778, 0.0571, 0.0400, 0.0505, 0.0476],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,420][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.5621, 0.0186, 0.1020, 0.0123, 0.0373, 0.0095, 0.0075, 0.1661, 0.0033,
        0.0119, 0.0231, 0.0074, 0.0030, 0.0171, 0.0142, 0.0046],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,421][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.6318e-03, 1.2874e-01, 3.4880e-03, 1.7759e-02, 1.0743e-02, 7.9120e-05,
        7.0876e-05, 8.7674e-05, 2.7419e-03, 6.7705e-03, 2.5507e-03, 5.4860e-03,
        7.5084e-02, 1.1430e-02, 2.5598e-01, 4.3160e-01, 4.0764e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,421][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0417, 0.0726, 0.0675, 0.0669, 0.0659, 0.0619, 0.0608, 0.0568, 0.0580,
        0.0539, 0.0566, 0.0579, 0.0559, 0.0551, 0.0546, 0.0589, 0.0550],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,421][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0002, 0.0713, 0.0625, 0.0514, 0.0527, 0.0737, 0.0621, 0.0815, 0.0617,
        0.0602, 0.0595, 0.0386, 0.0545, 0.0714, 0.0801, 0.0520, 0.0666],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,423][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0420, 0.1461, 0.0966, 0.0730, 0.0503, 0.0492, 0.0988, 0.0604, 0.0614,
        0.0685, 0.0387, 0.0501, 0.0429, 0.0300, 0.0367, 0.0245, 0.0309],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,425][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6233, 0.0198, 0.0099, 0.0132, 0.0086, 0.0719, 0.0123, 0.0322, 0.0630,
        0.0143, 0.0219, 0.0271, 0.0178, 0.0181, 0.0207, 0.0099, 0.0160],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,429][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2277, 0.0365, 0.0047, 0.0284, 0.0664, 0.0921, 0.0664, 0.0543, 0.0426,
        0.0459, 0.0189, 0.1025, 0.0766, 0.0242, 0.0363, 0.0464, 0.0301],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,433][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7989, 0.0113, 0.0077, 0.0170, 0.0109, 0.0033, 0.0291, 0.0130, 0.0022,
        0.0206, 0.0039, 0.0240, 0.0168, 0.0066, 0.0240, 0.0058, 0.0051],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,436][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0021, 0.0915, 0.0397, 0.0981, 0.0841, 0.0542, 0.0516, 0.0395, 0.0488,
        0.0600, 0.0486, 0.0964, 0.0614, 0.0500, 0.0692, 0.0559, 0.0487],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,438][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.7938e-03, 2.5291e-02, 5.3226e-03, 1.3653e-02, 1.7879e-02, 2.0586e-03,
        2.2171e-04, 2.4125e-03, 1.6677e-02, 1.1441e-02, 1.4227e-02, 2.0879e-02,
        1.9259e-01, 3.5226e-02, 3.3793e-01, 1.9229e-01, 1.0211e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,442][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0104, 0.1183, 0.0440, 0.1659, 0.0779, 0.0292, 0.0359, 0.0198, 0.0342,
        0.0677, 0.0214, 0.0818, 0.0754, 0.0393, 0.0628, 0.0778, 0.0384],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,442][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0008, 0.0797, 0.0428, 0.0908, 0.1201, 0.0911, 0.0476, 0.0212, 0.0797,
        0.0366, 0.0568, 0.0713, 0.0469, 0.0270, 0.0652, 0.0757, 0.0467],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,443][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2262, 0.0194, 0.2803, 0.0145, 0.0281, 0.0462, 0.0028, 0.0492, 0.0469,
        0.0184, 0.0276, 0.0077, 0.0086, 0.0133, 0.0380, 0.1628, 0.0101],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,482][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:00,485][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,488][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,491][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,493][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,494][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,494][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,494][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,495][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,495][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,495][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,504][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,506][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,510][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.1268, 0.8732], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,513][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.7432, 0.2568], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,517][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.0112, 0.9888], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,517][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.7996, 0.2004], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,517][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.4733, 0.5267], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,518][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.9714, 0.0286], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,518][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.9434, 0.0566], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,518][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.3721, 0.6279], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,519][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.2393, 0.7607], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,519][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.3799, 0.6201], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,520][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0100, 0.9900], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,523][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.8271, 0.1729], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,526][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0086, 0.9712, 0.0202], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,529][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6778, 0.1667, 0.1555], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,533][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0020, 0.1632, 0.8348], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,537][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3030, 0.5034, 0.1936], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,540][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0563, 0.6929, 0.2508], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,540][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9069, 0.0549, 0.0382], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,540][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8807, 0.0483, 0.0710], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,541][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3107, 0.5718, 0.1176], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,541][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0138, 0.9304, 0.0558], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,541][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0550, 0.8433, 0.1016], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,542][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0088, 0.3729, 0.6184], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,542][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3904, 0.2111, 0.3985], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,542][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0111, 0.9111, 0.0085, 0.0693], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,544][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.5082, 0.1903, 0.1610, 0.1406], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,546][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0034, 0.1818, 0.3833, 0.4315], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,550][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.4438, 0.2944, 0.1667, 0.0951], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,553][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0419, 0.5403, 0.1177, 0.3001], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,557][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.8744, 0.0583, 0.0449, 0.0224], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,560][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.7369, 0.0600, 0.1547, 0.0484], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,563][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.2380, 0.5001, 0.1097, 0.1522], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,563][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0165, 0.8260, 0.0154, 0.1421], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,564][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.1002, 0.6390, 0.1046, 0.1562], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,564][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0094, 0.2483, 0.4000, 0.3423], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,564][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.3791, 0.1003, 0.3724, 0.1482], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,565][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0038, 0.8032, 0.0097, 0.1479, 0.0354], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,565][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.1356, 0.2277, 0.1574, 0.2086, 0.2708], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,566][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0007, 0.0920, 0.5147, 0.2330, 0.1596], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,569][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.1505, 0.4293, 0.0844, 0.1593, 0.1765], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,571][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0301, 0.3246, 0.1285, 0.2465, 0.2703], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,575][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.5961, 0.0838, 0.0824, 0.0621, 0.1756], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,579][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.5859, 0.0908, 0.1175, 0.0878, 0.1181], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,582][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.1110, 0.5078, 0.1282, 0.1951, 0.0579], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,586][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0057, 0.6608, 0.0290, 0.2462, 0.0583], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,586][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.0185, 0.5217, 0.0442, 0.2523, 0.1632], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,587][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0012, 0.1478, 0.3020, 0.2515, 0.2974], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,587][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.1469, 0.1344, 0.2660, 0.1264, 0.3263], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,587][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.2051e-04, 7.5009e-01, 7.2768e-03, 1.4905e-01, 9.0210e-02, 3.1549e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,588][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2665, 0.1939, 0.1455, 0.0894, 0.1572, 0.1475], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,588][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0013, 0.1112, 0.2003, 0.1880, 0.2102, 0.2889], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,588][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0169, 0.4293, 0.0884, 0.1641, 0.2775, 0.0237], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,589][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0019, 0.2412, 0.0659, 0.3174, 0.3475, 0.0261], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,590][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4291, 0.0952, 0.0701, 0.0681, 0.2978, 0.0397], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,593][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4454, 0.0911, 0.1453, 0.0688, 0.1496, 0.0998], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,596][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1116, 0.5749, 0.0545, 0.1606, 0.0455, 0.0530], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,599][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0009, 0.5698, 0.0188, 0.2129, 0.1844, 0.0131], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,603][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0016, 0.4127, 0.0305, 0.2823, 0.2539, 0.0191], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,607][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0022, 0.1248, 0.1018, 0.1905, 0.2573, 0.3233], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,609][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1948, 0.1086, 0.2087, 0.1089, 0.3293, 0.0496], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:00,610][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([7.1537e-05, 6.6522e-01, 4.5773e-03, 2.2869e-01, 9.2239e-02, 6.1973e-03,
        3.0015e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,610][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0921, 0.1467, 0.1396, 0.1260, 0.2458, 0.1088, 0.1410],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,611][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0004, 0.0621, 0.1574, 0.1835, 0.1051, 0.1540, 0.3375],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,611][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0194, 0.3649, 0.0719, 0.1920, 0.3040, 0.0286, 0.0191],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,611][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0019, 0.2935, 0.0565, 0.3125, 0.2796, 0.0358, 0.0202],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,612][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.2487, 0.1487, 0.1006, 0.1227, 0.2388, 0.0689, 0.0716],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,614][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.3577, 0.1058, 0.1235, 0.0863, 0.1040, 0.1084, 0.1143],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,616][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0497, 0.3618, 0.0851, 0.2013, 0.0957, 0.0691, 0.1373],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,620][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0008, 0.5214, 0.0167, 0.2656, 0.1642, 0.0224, 0.0090],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,623][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0014, 0.3959, 0.0335, 0.2782, 0.2481, 0.0285, 0.0144],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,626][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0005, 0.1713, 0.0937, 0.3292, 0.1459, 0.1717, 0.0878],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,630][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.1776, 0.1047, 0.2502, 0.1000, 0.1832, 0.0749, 0.1095],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:00,632][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0012, 0.6373, 0.0130, 0.2314, 0.0991, 0.0082, 0.0047, 0.0052],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,633][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1664, 0.2125, 0.1572, 0.1190, 0.1420, 0.0775, 0.0715, 0.0540],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,633][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0005, 0.1004, 0.1855, 0.1412, 0.1288, 0.1215, 0.1780, 0.1442],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,633][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0355, 0.3762, 0.0881, 0.1364, 0.2904, 0.0250, 0.0118, 0.0368],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,634][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0036, 0.2546, 0.0813, 0.2578, 0.3190, 0.0327, 0.0143, 0.0366],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,634][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.4463, 0.1130, 0.0458, 0.0622, 0.1799, 0.0326, 0.0613, 0.0589],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,634][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.4915, 0.0630, 0.0866, 0.0517, 0.0942, 0.0539, 0.0647, 0.0944],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,635][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1329, 0.4232, 0.0595, 0.1576, 0.0587, 0.0482, 0.0959, 0.0240],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,635][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0017, 0.5198, 0.0182, 0.2128, 0.2079, 0.0192, 0.0087, 0.0117],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,637][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0030, 0.4649, 0.0194, 0.3127, 0.1565, 0.0149, 0.0132, 0.0155],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,639][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0012, 0.2222, 0.0716, 0.1667, 0.1663, 0.1985, 0.1132, 0.0603],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,642][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2629, 0.1068, 0.1522, 0.0738, 0.2203, 0.0406, 0.0428, 0.1005],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:00,645][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0054, 0.7604, 0.0090, 0.1155, 0.0722, 0.0012, 0.0011, 0.0015, 0.0337],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,649][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1612, 0.2159, 0.1342, 0.0919, 0.1356, 0.0897, 0.0832, 0.0509, 0.0373],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,653][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0003, 0.0727, 0.1694, 0.1151, 0.0920, 0.1407, 0.2030, 0.1329, 0.0738],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,656][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0757, 0.3973, 0.0726, 0.0994, 0.2040, 0.0108, 0.0047, 0.0150, 0.1206],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,656][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0113, 0.2493, 0.0818, 0.1850, 0.3137, 0.0150, 0.0054, 0.0229, 0.1155],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,656][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5990, 0.0592, 0.0359, 0.0428, 0.1524, 0.0170, 0.0334, 0.0372, 0.0232],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,657][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.5306, 0.0483, 0.0850, 0.0374, 0.0706, 0.0463, 0.0434, 0.0794, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,657][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1182, 0.4197, 0.0539, 0.1565, 0.0458, 0.0526, 0.0765, 0.0201, 0.0567],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,657][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0079, 0.5945, 0.0212, 0.1689, 0.1457, 0.0049, 0.0043, 0.0059, 0.0468],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,658][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0108, 0.4601, 0.0318, 0.2104, 0.1683, 0.0097, 0.0054, 0.0113, 0.0921],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,658][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0013, 0.1370, 0.0772, 0.1289, 0.1368, 0.1980, 0.1186, 0.0723, 0.1299],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,660][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2368, 0.0814, 0.1311, 0.1000, 0.2295, 0.0370, 0.0474, 0.0882, 0.0486],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:00,661][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([1.9325e-03, 6.8365e-01, 1.0367e-02, 1.6131e-01, 6.1366e-02, 1.0512e-03,
        4.6458e-04, 9.1476e-04, 2.7976e-02, 5.0974e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,664][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.1152, 0.0986, 0.1387, 0.0777, 0.1551, 0.1057, 0.1425, 0.0546, 0.0756,
        0.0364], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,666][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([7.8772e-05, 3.2336e-02, 1.8381e-01, 1.3227e-01, 6.9836e-02, 1.3854e-01,
        1.3828e-01, 8.8729e-02, 8.1788e-02, 1.3433e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,669][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0623, 0.3118, 0.0705, 0.1239, 0.1757, 0.0069, 0.0029, 0.0110, 0.0811,
        0.1540], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,672][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0095, 0.2718, 0.0724, 0.2022, 0.1737, 0.0086, 0.0032, 0.0126, 0.0919,
        0.1541], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,676][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.4450, 0.0936, 0.0459, 0.0608, 0.1419, 0.0299, 0.0340, 0.0560, 0.0375,
        0.0553], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,679][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.3529, 0.0478, 0.0964, 0.0414, 0.0804, 0.0614, 0.0631, 0.1219, 0.0864,
        0.0483], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,679][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0527, 0.3387, 0.0654, 0.1563, 0.0615, 0.0499, 0.0916, 0.0295, 0.0705,
        0.0839], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,680][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0075, 0.6025, 0.0264, 0.1543, 0.1029, 0.0028, 0.0014, 0.0039, 0.0362,
        0.0620], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,680][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.0092, 0.4180, 0.0345, 0.2105, 0.1176, 0.0054, 0.0030, 0.0053, 0.0716,
        0.1248], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,680][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0003, 0.0430, 0.0480, 0.1311, 0.1366, 0.1986, 0.0937, 0.0499, 0.1696,
        0.1292], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,681][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.1276, 0.0663, 0.1635, 0.0959, 0.1844, 0.0450, 0.0410, 0.1209, 0.0853,
        0.0701], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:00,681][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0092, 0.5808, 0.0101, 0.0957, 0.0547, 0.0025, 0.0019, 0.0031, 0.0596,
        0.1637, 0.0189], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,681][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1587, 0.0881, 0.1977, 0.0910, 0.1691, 0.0644, 0.0677, 0.0478, 0.0445,
        0.0171, 0.0539], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,682][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.1196e-04, 6.7043e-02, 2.0322e-01, 1.4219e-01, 6.5106e-02, 1.2685e-01,
        8.0590e-02, 7.5066e-02, 6.2851e-02, 6.9844e-02, 1.0713e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,683][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0721, 0.2244, 0.0688, 0.0868, 0.1485, 0.0123, 0.0068, 0.0189, 0.1114,
        0.1596, 0.0903], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,685][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0069, 0.1952, 0.0608, 0.1343, 0.1982, 0.0168, 0.0060, 0.0274, 0.1178,
        0.1632, 0.0733], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,689][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4575, 0.0678, 0.0278, 0.0380, 0.1295, 0.0206, 0.0404, 0.0455, 0.0417,
        0.0788, 0.0522], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,692][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3892, 0.0368, 0.0893, 0.0354, 0.0654, 0.0412, 0.0469, 0.0927, 0.0730,
        0.0405, 0.0896], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,696][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0715, 0.2608, 0.0757, 0.1196, 0.0586, 0.0468, 0.1123, 0.0302, 0.0560,
        0.0639, 0.1045], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,700][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0073, 0.4105, 0.0179, 0.1486, 0.0875, 0.0059, 0.0071, 0.0126, 0.0602,
        0.1839, 0.0586], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,702][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0163, 0.3472, 0.0333, 0.1612, 0.1373, 0.0114, 0.0090, 0.0172, 0.0952,
        0.1083, 0.0634], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,703][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0005, 0.1075, 0.0866, 0.1699, 0.0959, 0.1946, 0.0946, 0.0445, 0.0959,
        0.0588, 0.0512], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,703][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1468, 0.0584, 0.1416, 0.0946, 0.1930, 0.0366, 0.0557, 0.1168, 0.0560,
        0.0461, 0.0544], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:00,703][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([5.5857e-03, 7.5872e-01, 4.2396e-03, 4.2335e-02, 2.9662e-02, 4.2041e-04,
        3.1888e-04, 5.2400e-04, 2.2842e-02, 5.9658e-02, 1.5666e-02, 6.0028e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,704][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.1152, 0.1119, 0.1763, 0.0544, 0.1784, 0.0659, 0.0683, 0.0586, 0.0431,
        0.0252, 0.0632, 0.0396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,704][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([8.0691e-05, 3.8571e-02, 4.9197e-02, 1.3025e-01, 6.8957e-02, 9.9757e-02,
        2.1224e-01, 6.9701e-02, 6.1681e-02, 1.0659e-01, 5.5264e-02, 1.0771e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,704][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.1175, 0.2193, 0.0700, 0.0474, 0.1248, 0.0070, 0.0027, 0.0099, 0.1124,
        0.1536, 0.0876, 0.0477], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,706][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0059, 0.2348, 0.0343, 0.1106, 0.1103, 0.0072, 0.0028, 0.0122, 0.1057,
        0.1155, 0.0526, 0.2081], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,708][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.4927, 0.0700, 0.0365, 0.0328, 0.1127, 0.0186, 0.0251, 0.0584, 0.0363,
        0.0388, 0.0435, 0.0346], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,712][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.3100, 0.0449, 0.1196, 0.0367, 0.0802, 0.0603, 0.0578, 0.0879, 0.0776,
        0.0295, 0.0693, 0.0264], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,715][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0728, 0.2715, 0.0811, 0.0829, 0.0516, 0.0407, 0.0647, 0.0256, 0.0589,
        0.0502, 0.1020, 0.0979], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,719][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0071, 0.5269, 0.0126, 0.0744, 0.0317, 0.0016, 0.0013, 0.0040, 0.0328,
        0.0773, 0.0235, 0.2068], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,723][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0188, 0.3604, 0.0286, 0.0602, 0.0819, 0.0062, 0.0025, 0.0098, 0.0934,
        0.1339, 0.0664, 0.1378], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,725][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([1.9051e-04, 4.1628e-02, 1.8312e-02, 4.5928e-02, 7.9679e-02, 1.0561e-01,
        9.0311e-02, 2.9484e-02, 2.0528e-01, 1.0266e-01, 7.8071e-02, 2.0286e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,725][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0940, 0.0461, 0.1181, 0.0981, 0.2025, 0.0291, 0.0302, 0.0815, 0.0712,
        0.0523, 0.1038, 0.0731], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:00,726][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([8.7026e-03, 5.6810e-01, 1.0352e-02, 1.0963e-01, 3.3902e-02, 4.5337e-04,
        3.3633e-04, 5.0553e-04, 1.0124e-02, 1.3382e-02, 1.2553e-02, 5.0402e-02,
        1.8155e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,726][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.1166, 0.2090, 0.0940, 0.0650, 0.0735, 0.0871, 0.0583, 0.0393, 0.0422,
        0.0291, 0.0358, 0.0439, 0.1063], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,726][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0002, 0.0352, 0.1478, 0.0716, 0.1055, 0.1214, 0.1253, 0.0963, 0.0686,
        0.0678, 0.0866, 0.0284, 0.0452], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,727][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0413, 0.1867, 0.0512, 0.0702, 0.1015, 0.0047, 0.0022, 0.0095, 0.0541,
        0.0889, 0.0488, 0.0552, 0.2857], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,727][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0163, 0.1335, 0.0693, 0.0971, 0.1404, 0.0049, 0.0017, 0.0088, 0.0485,
        0.0499, 0.0470, 0.0702, 0.3124], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,728][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.3065, 0.0401, 0.0339, 0.0256, 0.1154, 0.0206, 0.0264, 0.0442, 0.0554,
        0.0592, 0.0665, 0.0489, 0.1574], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,728][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.3137, 0.0644, 0.0786, 0.0565, 0.0737, 0.0703, 0.0559, 0.0597, 0.0656,
        0.0352, 0.0485, 0.0314, 0.0464], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,729][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0451, 0.2154, 0.0640, 0.0774, 0.0610, 0.0608, 0.0982, 0.0252, 0.0722,
        0.0817, 0.0736, 0.0723, 0.0530], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,732][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0053, 0.3717, 0.0260, 0.1198, 0.0733, 0.0035, 0.0014, 0.0024, 0.0190,
        0.0238, 0.0228, 0.0644, 0.2666], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,735][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0132, 0.3604, 0.0206, 0.1074, 0.0914, 0.0040, 0.0022, 0.0037, 0.0392,
        0.0408, 0.0319, 0.1103, 0.1749], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,738][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0006, 0.1075, 0.0564, 0.0914, 0.1174, 0.1705, 0.0516, 0.0289, 0.1063,
        0.0502, 0.0509, 0.0852, 0.0831], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,742][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0494, 0.0758, 0.1000, 0.0892, 0.1519, 0.0470, 0.0539, 0.0588, 0.0848,
        0.0525, 0.0678, 0.0870, 0.0820], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:00,746][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0108, 0.4176, 0.0098, 0.0690, 0.0395, 0.0004, 0.0005, 0.0006, 0.0142,
        0.0433, 0.0116, 0.0436, 0.2918, 0.0475], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,749][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2340, 0.0921, 0.1193, 0.0817, 0.1656, 0.0385, 0.0520, 0.0356, 0.0208,
        0.0099, 0.0255, 0.0220, 0.0589, 0.0441], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,749][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0002, 0.0386, 0.1501, 0.0937, 0.0984, 0.0795, 0.1095, 0.0719, 0.0481,
        0.0631, 0.1170, 0.0320, 0.0285, 0.0695], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,749][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0755, 0.1494, 0.0458, 0.0449, 0.0919, 0.0036, 0.0017, 0.0068, 0.0408,
        0.0778, 0.0453, 0.0341, 0.2686, 0.1138], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,750][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0137, 0.1321, 0.0668, 0.0969, 0.1155, 0.0053, 0.0024, 0.0076, 0.0301,
        0.0628, 0.0274, 0.0571, 0.2709, 0.1113], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,750][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6514, 0.0328, 0.0170, 0.0202, 0.0505, 0.0051, 0.0159, 0.0125, 0.0146,
        0.0262, 0.0207, 0.0274, 0.0856, 0.0202], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,751][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5114, 0.0433, 0.0697, 0.0353, 0.0516, 0.0254, 0.0225, 0.0450, 0.0340,
        0.0161, 0.0415, 0.0282, 0.0355, 0.0404], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,751][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2616, 0.2180, 0.0507, 0.0637, 0.0349, 0.0294, 0.0752, 0.0115, 0.0471,
        0.0314, 0.0616, 0.0466, 0.0354, 0.0328], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,752][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0035, 0.2615, 0.0089, 0.0948, 0.0457, 0.0020, 0.0014, 0.0015, 0.0141,
        0.0323, 0.0141, 0.0914, 0.3953, 0.0334], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,755][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0153, 0.2318, 0.0199, 0.1525, 0.0749, 0.0029, 0.0026, 0.0030, 0.0264,
        0.0327, 0.0243, 0.1625, 0.1992, 0.0521], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,758][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0009, 0.0802, 0.0611, 0.1241, 0.1424, 0.1098, 0.0555, 0.0287, 0.0939,
        0.0449, 0.0725, 0.0995, 0.0469, 0.0396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,761][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2145, 0.0730, 0.0969, 0.0639, 0.1644, 0.0254, 0.0356, 0.0386, 0.0518,
        0.0353, 0.0631, 0.0414, 0.0439, 0.0523], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:00,764][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.9663e-02, 3.9417e-01, 1.8749e-02, 6.7548e-02, 3.7470e-02, 1.8228e-04,
        1.7549e-04, 3.2949e-04, 5.6660e-03, 1.0770e-02, 9.5830e-03, 1.2535e-02,
        1.2750e-01, 4.5294e-02, 2.5036e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,767][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1301, 0.0894, 0.0994, 0.0884, 0.2164, 0.0505, 0.0599, 0.0310, 0.0254,
        0.0173, 0.0225, 0.0250, 0.0752, 0.0404, 0.0292], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,771][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0004, 0.0393, 0.2031, 0.0563, 0.0772, 0.0840, 0.1309, 0.0434, 0.0406,
        0.0397, 0.0825, 0.0117, 0.0211, 0.0872, 0.0827], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,772][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1157, 0.1681, 0.0432, 0.0435, 0.0633, 0.0023, 0.0013, 0.0041, 0.0286,
        0.0413, 0.0332, 0.0236, 0.1275, 0.0664, 0.2380], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,772][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0215, 0.1003, 0.0681, 0.0620, 0.0927, 0.0033, 0.0009, 0.0045, 0.0240,
        0.0216, 0.0252, 0.0297, 0.1780, 0.0854, 0.2828], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,772][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.5109, 0.0407, 0.0269, 0.0312, 0.0877, 0.0086, 0.0149, 0.0203, 0.0159,
        0.0356, 0.0314, 0.0342, 0.0876, 0.0269, 0.0271], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,773][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.3034, 0.0450, 0.0919, 0.0457, 0.0642, 0.0358, 0.0360, 0.0645, 0.0499,
        0.0218, 0.0558, 0.0365, 0.0439, 0.0656, 0.0401], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,773][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.2414, 0.2222, 0.0613, 0.0753, 0.0299, 0.0313, 0.0618, 0.0102, 0.0322,
        0.0264, 0.0506, 0.0440, 0.0275, 0.0287, 0.0570], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,774][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0118, 0.2805, 0.0127, 0.0930, 0.0375, 0.0011, 0.0009, 0.0011, 0.0094,
        0.0220, 0.0119, 0.0612, 0.2564, 0.0359, 0.1647], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,774][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0327, 0.2551, 0.0281, 0.1278, 0.0655, 0.0018, 0.0013, 0.0018, 0.0176,
        0.0190, 0.0307, 0.0957, 0.1175, 0.0436, 0.1616], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,774][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0003, 0.0227, 0.0553, 0.0522, 0.1505, 0.1634, 0.0527, 0.0319, 0.1146,
        0.0259, 0.0790, 0.0467, 0.0794, 0.0557, 0.0697], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,776][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1307, 0.0696, 0.1066, 0.0771, 0.1676, 0.0389, 0.0324, 0.0283, 0.0576,
        0.0386, 0.0479, 0.0486, 0.0556, 0.0432, 0.0572], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:00,778][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([1.0754e-02, 3.2942e-01, 5.9248e-03, 4.3028e-02, 2.1379e-02, 1.3880e-04,
        9.7813e-05, 1.3625e-04, 3.0087e-03, 4.5023e-03, 2.9768e-03, 7.4796e-03,
        8.4755e-02, 1.5179e-02, 2.4320e-01, 2.2802e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,780][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.1265, 0.1029, 0.1500, 0.0518, 0.1314, 0.0647, 0.0504, 0.0401, 0.0284,
        0.0100, 0.0276, 0.0143, 0.0816, 0.0419, 0.0183, 0.0599],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,782][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([1.1759e-04, 3.3856e-02, 1.6141e-01, 7.6381e-02, 6.3966e-02, 9.6144e-02,
        8.8712e-02, 6.2277e-02, 4.2333e-02, 4.2134e-02, 8.9091e-02, 2.8404e-02,
        2.7769e-02, 6.2422e-02, 4.8813e-02, 7.6169e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,785][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0777, 0.1400, 0.0361, 0.0337, 0.0565, 0.0019, 0.0008, 0.0034, 0.0178,
        0.0214, 0.0210, 0.0136, 0.1020, 0.0452, 0.1689, 0.2601],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,789][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0092, 0.0885, 0.0329, 0.0685, 0.0653, 0.0018, 0.0009, 0.0034, 0.0133,
        0.0174, 0.0129, 0.0241, 0.1279, 0.0515, 0.2624, 0.2199],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,793][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.4083, 0.0410, 0.0390, 0.0434, 0.0955, 0.0089, 0.0214, 0.0231, 0.0175,
        0.0189, 0.0349, 0.0277, 0.0869, 0.0379, 0.0537, 0.0420],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,795][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.2819, 0.0575, 0.0842, 0.0485, 0.0674, 0.0472, 0.0299, 0.0539, 0.0487,
        0.0227, 0.0486, 0.0280, 0.0439, 0.0570, 0.0405, 0.0401],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,796][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0875, 0.3034, 0.0513, 0.0763, 0.0356, 0.0332, 0.0525, 0.0095, 0.0398,
        0.0307, 0.0539, 0.0512, 0.0287, 0.0287, 0.0633, 0.0543],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,796][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0070, 0.1981, 0.0133, 0.0759, 0.0569, 0.0019, 0.0007, 0.0013, 0.0116,
        0.0132, 0.0133, 0.0388, 0.1849, 0.0269, 0.1664, 0.1897],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,796][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.0216, 0.1978, 0.0242, 0.0859, 0.0850, 0.0024, 0.0012, 0.0026, 0.0168,
        0.0155, 0.0247, 0.0446, 0.1447, 0.0373, 0.1110, 0.1848],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,797][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0005, 0.1024, 0.0553, 0.0975, 0.0967, 0.1388, 0.0605, 0.0334, 0.0668,
        0.0425, 0.0327, 0.0778, 0.0571, 0.0400, 0.0505, 0.0476],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,797][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0836, 0.0705, 0.0897, 0.0680, 0.1254, 0.0393, 0.0378, 0.0491, 0.0486,
        0.0311, 0.0605, 0.0427, 0.0394, 0.0568, 0.0628, 0.0947],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:00,798][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.6318e-03, 1.2874e-01, 3.4880e-03, 1.7759e-02, 1.0743e-02, 7.9120e-05,
        7.0876e-05, 8.7674e-05, 2.7419e-03, 6.7705e-03, 2.5507e-03, 5.4860e-03,
        7.5084e-02, 1.1430e-02, 2.5598e-01, 4.3160e-01, 4.0764e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,799][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3804, 0.0670, 0.1108, 0.0515, 0.1202, 0.0250, 0.0366, 0.0208, 0.0127,
        0.0052, 0.0185, 0.0100, 0.0367, 0.0251, 0.0112, 0.0414, 0.0268],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,802][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0002, 0.0403, 0.1351, 0.0800, 0.0771, 0.0655, 0.0901, 0.0430, 0.0329,
        0.0461, 0.0866, 0.0226, 0.0211, 0.0429, 0.0549, 0.0535, 0.1080],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,805][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0618, 0.0702, 0.0223, 0.0182, 0.0418, 0.0012, 0.0006, 0.0022, 0.0149,
        0.0273, 0.0158, 0.0089, 0.1110, 0.0399, 0.2082, 0.2766, 0.0793],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,809][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0093, 0.0460, 0.0250, 0.0314, 0.0438, 0.0014, 0.0006, 0.0020, 0.0086,
        0.0191, 0.0093, 0.0149, 0.0934, 0.0378, 0.2872, 0.2806, 0.0896],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,812][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6969, 0.0188, 0.0112, 0.0127, 0.0353, 0.0030, 0.0093, 0.0080, 0.0093,
        0.0156, 0.0129, 0.0150, 0.0510, 0.0155, 0.0335, 0.0325, 0.0193],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,816][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5533, 0.0309, 0.0531, 0.0253, 0.0416, 0.0190, 0.0164, 0.0321, 0.0246,
        0.0104, 0.0310, 0.0178, 0.0288, 0.0303, 0.0190, 0.0315, 0.0350],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,818][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2536, 0.1987, 0.0495, 0.0618, 0.0314, 0.0247, 0.0607, 0.0080, 0.0319,
        0.0217, 0.0440, 0.0327, 0.0248, 0.0247, 0.0451, 0.0505, 0.0362],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,819][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0048, 0.1168, 0.0057, 0.0357, 0.0262, 0.0008, 0.0005, 0.0006, 0.0064,
        0.0134, 0.0073, 0.0237, 0.2125, 0.0164, 0.2183, 0.2613, 0.0495],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,819][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0167, 0.1404, 0.0126, 0.0817, 0.0450, 0.0013, 0.0011, 0.0012, 0.0120,
        0.0137, 0.0140, 0.0592, 0.1137, 0.0267, 0.0979, 0.2756, 0.0872],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,819][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0008, 0.0797, 0.0428, 0.0908, 0.1201, 0.0911, 0.0476, 0.0212, 0.0797,
        0.0366, 0.0568, 0.0713, 0.0469, 0.0270, 0.0652, 0.0757, 0.0467],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,820][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2255, 0.0549, 0.0734, 0.0459, 0.1281, 0.0203, 0.0246, 0.0316, 0.0384,
        0.0238, 0.0489, 0.0283, 0.0293, 0.0362, 0.0444, 0.0821, 0.0644],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:00,821][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:00,822][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10349],
        [45353],
        [ 5863],
        [ 2515],
        [ 3795],
        [ 1232],
        [ 1229],
        [ 2234],
        [  616],
        [  525],
        [ 1741],
        [ 1077],
        [ 2189],
        [ 1288],
        [ 1651],
        [  396],
        [  847]], device='cuda:0')
[2024-07-24 10:23:00,823][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13415],
        [39433],
        [ 8234],
        [ 3449],
        [ 5115],
        [ 3960],
        [ 3461],
        [ 4669],
        [ 2393],
        [ 1303],
        [ 5728],
        [ 3020],
        [ 3423],
        [ 3595],
        [ 4620],
        [ 1215],
        [ 2857]], device='cuda:0')
[2024-07-24 10:23:00,824][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16052],
        [ 7032],
        [ 6849],
        [ 6599],
        [ 5900],
        [ 5439],
        [ 5094],
        [ 4871],
        [ 5266],
        [ 4349],
        [ 2531],
        [ 4378],
        [ 3588],
        [ 2648],
        [ 3284],
        [ 3178],
        [ 3049]], device='cuda:0')
[2024-07-24 10:23:00,826][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20064],
        [32235],
        [33774],
        [32162],
        [31797],
        [31793],
        [30747],
        [30826],
        [31192],
        [31197],
        [30676],
        [30186],
        [30352],
        [30143],
        [29984],
        [30106],
        [30213]], device='cuda:0')
[2024-07-24 10:23:00,828][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3175],
        [43515],
        [25030],
        [20858],
        [15628],
        [11086],
        [17560],
        [14331],
        [13186],
        [13246],
        [13447],
        [13173],
        [12105],
        [11716],
        [10866],
        [10322],
        [ 9965]], device='cuda:0')
[2024-07-24 10:23:00,830][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 2420],
        [43050],
        [30761],
        [30210],
        [21495],
        [18922],
        [16678],
        [15353],
        [13668],
        [13716],
        [12660],
        [14109],
        [12615],
        [12698],
        [13405],
        [11883],
        [12297]], device='cuda:0')
[2024-07-24 10:23:00,832][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23652],
        [22751],
        [21490],
        [16750],
        [18883],
        [16741],
        [17617],
        [17581],
        [16676],
        [17575],
        [19173],
        [17334],
        [19497],
        [17886],
        [17411],
        [16721],
        [17315]], device='cuda:0')
[2024-07-24 10:23:00,835][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37936],
        [43485],
        [45205],
        [39599],
        [24688],
        [13783],
        [12858],
        [13302],
        [12793],
        [12787],
        [11995],
        [12956],
        [11342],
        [12710],
        [11791],
        [10629],
        [11889]], device='cuda:0')
[2024-07-24 10:23:00,837][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 8620],
        [ 9619],
        [ 9802],
        [12751],
        [11374],
        [12073],
        [15785],
        [14797],
        [10868],
        [23651],
        [10968],
        [20517],
        [18599],
        [19738],
        [18680],
        [16883],
        [14232]], device='cuda:0')
[2024-07-24 10:23:00,839][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[27639],
        [40384],
        [44058],
        [45132],
        [44709],
        [42085],
        [39369],
        [39142],
        [38151],
        [36739],
        [36694],
        [36653],
        [34093],
        [33569],
        [32639],
        [31999],
        [30876]], device='cuda:0')
[2024-07-24 10:23:00,842][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[26319],
        [41920],
        [41405],
        [39420],
        [36079],
        [32734],
        [25821],
        [33208],
        [29860],
        [29361],
        [29249],
        [33279],
        [31667],
        [32581],
        [32111],
        [32455],
        [32345]], device='cuda:0')
[2024-07-24 10:23:00,844][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[45573],
        [34736],
        [34213],
        [45564],
        [45917],
        [45671],
        [45563],
        [45660],
        [45273],
        [45574],
        [44691],
        [44837],
        [45531],
        [45955],
        [46011],
        [45933],
        [46468]], device='cuda:0')
[2024-07-24 10:23:00,847][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 2643],
        [50182],
        [35087],
        [31281],
        [25497],
        [24256],
        [32406],
        [36565],
        [27218],
        [18694],
        [25004],
        [25559],
        [27261],
        [26307],
        [18391],
        [27259],
        [25264]], device='cuda:0')
[2024-07-24 10:23:00,848][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10987],
        [ 2895],
        [  463],
        [   37],
        [  479],
        [  763],
        [   82],
        [  457],
        [  983],
        [  663],
        [  369],
        [  234],
        [ 1511],
        [  568],
        [  697],
        [ 1399],
        [  809]], device='cuda:0')
[2024-07-24 10:23:00,848][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14828],
        [15980],
        [15364],
        [14685],
        [18085],
        [13414],
        [15760],
        [18008],
        [13964],
        [17343],
        [12932],
        [15748],
        [17227],
        [16352],
        [14365],
        [15675],
        [14984]], device='cuda:0')
[2024-07-24 10:23:00,850][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43703],
        [34460],
        [32946],
        [33065],
        [33533],
        [33979],
        [34207],
        [34597],
        [33843],
        [33620],
        [32908],
        [32997],
        [33606],
        [33493],
        [33714],
        [29350],
        [25932]], device='cuda:0')
[2024-07-24 10:23:00,851][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[30871],
        [27384],
        [26297],
        [31925],
        [33035],
        [32892],
        [32736],
        [33170],
        [33376],
        [33508],
        [33681],
        [34001],
        [33903],
        [34204],
        [33974],
        [34273],
        [34287]], device='cuda:0')
[2024-07-24 10:23:00,852][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18604],
        [19823],
        [27313],
        [26188],
        [27672],
        [34450],
        [31289],
        [33106],
        [34502],
        [36062],
        [36950],
        [35373],
        [36584],
        [34895],
        [33369],
        [32979],
        [30815]], device='cuda:0')
[2024-07-24 10:23:00,854][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14550],
        [29121],
        [41784],
        [40630],
        [42534],
        [43045],
        [43007],
        [42909],
        [41754],
        [39993],
        [39799],
        [39259],
        [38881],
        [37590],
        [33541],
        [33600],
        [31102]], device='cuda:0')
[2024-07-24 10:23:00,855][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28752],
        [16903],
        [20752],
        [20398],
        [22209],
        [22282],
        [21799],
        [22358],
        [23094],
        [23296],
        [24884],
        [22907],
        [22876],
        [22728],
        [24356],
        [25901],
        [26572]], device='cuda:0')
[2024-07-24 10:23:00,857][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32881],
        [28902],
        [24031],
        [24430],
        [32063],
        [32398],
        [34838],
        [32193],
        [30390],
        [32171],
        [29770],
        [30615],
        [27067],
        [27706],
        [29290],
        [29798],
        [25801]], device='cuda:0')
[2024-07-24 10:23:00,860][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[41641],
        [41770],
        [43248],
        [40444],
        [33609],
        [29185],
        [31411],
        [34311],
        [33573],
        [30913],
        [30557],
        [29524],
        [29658],
        [34781],
        [31705],
        [30347],
        [36159]], device='cuda:0')
[2024-07-24 10:23:00,862][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[42023],
        [ 9776],
        [ 8439],
        [ 7388],
        [ 7243],
        [ 7107],
        [ 6216],
        [ 6397],
        [ 6046],
        [ 5806],
        [ 4999],
        [ 4539],
        [ 4927],
        [ 5138],
        [ 5528],
        [ 4938],
        [ 4672]], device='cuda:0')
[2024-07-24 10:23:00,865][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[43842],
        [25704],
        [26332],
        [21831],
        [15472],
        [12686],
        [11113],
        [11763],
        [15116],
        [16660],
        [17409],
        [18517],
        [14023],
        [13015],
        [11452],
        [ 9309],
        [12029]], device='cuda:0')
[2024-07-24 10:23:00,867][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[28895],
        [11891],
        [11009],
        [15695],
        [21147],
        [24990],
        [25156],
        [23201],
        [22076],
        [26302],
        [25294],
        [26937],
        [31742],
        [35165],
        [35074],
        [37890],
        [39322]], device='cuda:0')
[2024-07-24 10:23:00,870][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[40952],
        [47179],
        [49274],
        [48567],
        [49296],
        [49409],
        [48927],
        [49395],
        [49423],
        [49312],
        [49319],
        [48797],
        [49210],
        [49170],
        [49262],
        [48947],
        [48860]], device='cuda:0')
[2024-07-24 10:23:00,872][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33563],
        [ 9561],
        [ 9261],
        [10551],
        [13368],
        [13427],
        [10361],
        [12067],
        [11432],
        [10367],
        [10318],
        [ 8871],
        [ 7947],
        [ 8941],
        [ 9044],
        [ 8015],
        [ 8556]], device='cuda:0')
[2024-07-24 10:23:00,874][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 3223],
        [18308],
        [11586],
        [12821],
        [ 9172],
        [ 8065],
        [ 9874],
        [ 8525],
        [ 8771],
        [ 9042],
        [10129],
        [11176],
        [10905],
        [10631],
        [10899],
        [11724],
        [13487]], device='cuda:0')
[2024-07-24 10:23:00,875][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25590],
        [31656],
        [32326],
        [31991],
        [28187],
        [32863],
        [30954],
        [28293],
        [31765],
        [29330],
        [32892],
        [32031],
        [29214],
        [27913],
        [31002],
        [30696],
        [29503]], device='cuda:0')
[2024-07-24 10:23:00,876][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157],
        [15157]], device='cuda:0')
[2024-07-24 10:23:00,927][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:00,929][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,932][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,935][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,936][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,936][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,936][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,937][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,937][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,937][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,939][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,942][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,945][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:00,948][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.6529, 0.3471], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,948][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0144, 0.9856], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,948][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.6121, 0.3879], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,949][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.8259, 0.1741], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,949][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.4018, 0.5982], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,949][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.7588, 0.2412], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,950][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.9945, 0.0055], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,950][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.0116, 0.9884], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,950][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0785, 0.9215], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,952][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.3799, 0.6201], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,954][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.7125, 0.2875], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,956][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.7869, 0.2131], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:00,960][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5691, 0.2536, 0.1773], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,963][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0145, 0.7719, 0.2136], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,966][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3995, 0.2765, 0.3240], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,969][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3637, 0.2613, 0.3750], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,971][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0182, 0.9062, 0.0756], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,971][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3138, 0.3743, 0.3119], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,972][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9881, 0.0087, 0.0032], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,972][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0028, 0.9943, 0.0029], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,972][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0397, 0.5608, 0.3995], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,972][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2435, 0.6490, 0.1075], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,973][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2599, 0.3658, 0.3743], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,973][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3978, 0.1645, 0.4377], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:00,973][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.5111, 0.2031, 0.1261, 0.1598], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,974][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0074, 0.3571, 0.1041, 0.5314], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,975][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.2507, 0.2074, 0.2633, 0.2787], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,977][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.3025, 0.2333, 0.3151, 0.1491], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,981][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0481, 0.7204, 0.0409, 0.1905], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,984][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.1661, 0.3285, 0.3067, 0.1988], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,987][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.9316, 0.0327, 0.0213, 0.0144], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,990][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0021, 0.9876, 0.0024, 0.0079], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,994][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0230, 0.4257, 0.3212, 0.2301], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,994][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.1431, 0.5924, 0.1026, 0.1618], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,995][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.2949, 0.2694, 0.2230, 0.2127], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,995][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.1327, 0.0609, 0.3667, 0.4397], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:00,995][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.4078, 0.1510, 0.0991, 0.1290, 0.2131], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,995][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0031, 0.2958, 0.0922, 0.4946, 0.1144], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,996][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.1517, 0.1580, 0.2068, 0.2325, 0.2509], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,996][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.1330, 0.2874, 0.2642, 0.1681, 0.1473], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,996][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0151, 0.5142, 0.0425, 0.2049, 0.2233], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:00,998][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.1190, 0.3151, 0.2006, 0.1813, 0.1840], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,000][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.9545, 0.0165, 0.0160, 0.0076, 0.0053], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,004][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0014, 0.9863, 0.0023, 0.0082, 0.0019], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,006][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0187, 0.3730, 0.2793, 0.1868, 0.1422], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,009][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.1074, 0.5532, 0.0923, 0.1361, 0.1111], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,013][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.1075, 0.2649, 0.1736, 0.2597, 0.1943], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,017][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0715, 0.0693, 0.1782, 0.5354, 0.1456], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,017][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4051, 0.1421, 0.1020, 0.1300, 0.1947, 0.0260], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,018][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0050, 0.2300, 0.0386, 0.2653, 0.1008, 0.3603], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,018][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1297, 0.1224, 0.1459, 0.1682, 0.1779, 0.2559], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,018][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0499, 0.2430, 0.2428, 0.1519, 0.1857, 0.1267], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,018][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0012, 0.3905, 0.0268, 0.2805, 0.2794, 0.0216], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,019][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0086, 0.4390, 0.1627, 0.2029, 0.1833, 0.0035], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,019][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9214, 0.0339, 0.0231, 0.0102, 0.0073, 0.0041], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,019][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.0449e-04, 9.9236e-01, 9.8898e-04, 4.8367e-03, 1.2372e-03, 2.6798e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,020][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0158, 0.3205, 0.2505, 0.1573, 0.1278, 0.1281], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,021][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1330, 0.3894, 0.0815, 0.1118, 0.1034, 0.1809], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,024][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0518, 0.2332, 0.2135, 0.2032, 0.2564, 0.0419], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,026][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0361, 0.0204, 0.0966, 0.1877, 0.0574, 0.6018], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,030][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.4338, 0.1154, 0.0702, 0.1052, 0.1638, 0.0157, 0.0959],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,033][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0021, 0.1272, 0.0308, 0.2230, 0.0493, 0.3458, 0.2218],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,036][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0933, 0.0995, 0.1250, 0.1451, 0.1503, 0.2257, 0.1613],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,040][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0481, 0.2679, 0.1634, 0.1603, 0.1750, 0.1137, 0.0716],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,041][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([2.4588e-04, 3.1389e-01, 1.4337e-02, 2.6202e-01, 3.6862e-01, 3.7416e-02,
        3.4649e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,041][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0192, 0.4218, 0.1660, 0.2022, 0.1795, 0.0030, 0.0083],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,041][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.9405, 0.0166, 0.0124, 0.0104, 0.0070, 0.0072, 0.0059],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,041][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([1.2801e-04, 9.9422e-01, 8.8636e-04, 3.5333e-03, 8.7181e-04, 2.1653e-04,
        1.4803e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,042][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0128, 0.2756, 0.2021, 0.1399, 0.1013, 0.1107, 0.1576],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,042][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0899, 0.3727, 0.0659, 0.1071, 0.0883, 0.1503, 0.1259],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,042][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0331, 0.1862, 0.2048, 0.2306, 0.2555, 0.0539, 0.0359],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,043][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0079, 0.0093, 0.0378, 0.1507, 0.0204, 0.7531, 0.0207],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,044][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3286, 0.0975, 0.0677, 0.0956, 0.1457, 0.0186, 0.0852, 0.1610],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,047][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0021, 0.0930, 0.0261, 0.1465, 0.0644, 0.3274, 0.2198, 0.1208],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,050][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0827, 0.0894, 0.0998, 0.1205, 0.1223, 0.1729, 0.1270, 0.1854],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,053][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0444, 0.1566, 0.1994, 0.0994, 0.0913, 0.1206, 0.0912, 0.1972],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,057][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0017, 0.3420, 0.0175, 0.2808, 0.3227, 0.0184, 0.0040, 0.0129],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,060][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0119, 0.3923, 0.1724, 0.2066, 0.1894, 0.0059, 0.0152, 0.0063],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,063][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.7347, 0.0739, 0.0672, 0.0475, 0.0246, 0.0257, 0.0120, 0.0145],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,063][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.3163e-03, 9.8827e-01, 1.2657e-03, 6.0139e-03, 1.2966e-03, 3.2633e-04,
        2.4952e-04, 1.2607e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,064][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0101, 0.2285, 0.1884, 0.1139, 0.0977, 0.1018, 0.1481, 0.1115],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,064][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1552, 0.2981, 0.0526, 0.0691, 0.0687, 0.1047, 0.0843, 0.1673],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,064][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0595, 0.2659, 0.1611, 0.1970, 0.1989, 0.0377, 0.0238, 0.0560],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,065][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0540, 0.0256, 0.0753, 0.1286, 0.0430, 0.5437, 0.0306, 0.0992],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,065][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2670, 0.0998, 0.0791, 0.1074, 0.1459, 0.0215, 0.0967, 0.1690, 0.0137],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,065][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0019, 0.0957, 0.0200, 0.1276, 0.0469, 0.2000, 0.1610, 0.0860, 0.2609],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,066][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0693, 0.0724, 0.0846, 0.0988, 0.1055, 0.1551, 0.1093, 0.1557, 0.1493],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,067][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0497, 0.1843, 0.1752, 0.1086, 0.0998, 0.0964, 0.0431, 0.1141, 0.1289],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,070][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0188, 0.5185, 0.0226, 0.1295, 0.1613, 0.0055, 0.0007, 0.0081, 0.1352],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,072][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0101, 0.3663, 0.1798, 0.2211, 0.1934, 0.0046, 0.0115, 0.0053, 0.0078],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,076][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.6670, 0.1214, 0.0757, 0.0403, 0.0282, 0.0281, 0.0120, 0.0215, 0.0058],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,078][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.3815e-03, 9.8963e-01, 1.1062e-03, 4.5855e-03, 1.0332e-03, 2.2744e-04,
        1.6159e-04, 1.0470e-03, 8.2358e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,082][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0104, 0.2133, 0.1721, 0.1068, 0.0829, 0.0881, 0.1344, 0.1021, 0.0899],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,085][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1127, 0.2365, 0.0493, 0.0696, 0.0694, 0.1119, 0.0874, 0.1572, 0.1061],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,087][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1355, 0.2220, 0.1479, 0.1377, 0.1977, 0.0207, 0.0120, 0.0237, 0.1028],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,087][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0328, 0.0228, 0.0770, 0.1698, 0.0640, 0.4187, 0.0182, 0.0831, 0.1136],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,087][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.2897, 0.0822, 0.0611, 0.0824, 0.1219, 0.0135, 0.0669, 0.1387, 0.0079,
        0.1357], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,087][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0006, 0.0527, 0.0136, 0.1073, 0.0238, 0.2218, 0.0933, 0.0625, 0.2305,
        0.1939], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,088][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0523, 0.0609, 0.0751, 0.0843, 0.0902, 0.1390, 0.0911, 0.1364, 0.1310,
        0.1396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,088][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0324, 0.1725, 0.1727, 0.1159, 0.0801, 0.0650, 0.0599, 0.0680, 0.0976,
        0.1358], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,088][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ house] are: tensor([7.5411e-03, 2.6139e-01, 2.1559e-02, 1.3832e-01, 1.5573e-01, 2.8175e-03,
        1.9189e-04, 2.7154e-03, 1.0209e-01, 3.0765e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,089][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0145, 0.3635, 0.1816, 0.2112, 0.1977, 0.0031, 0.0082, 0.0038, 0.0057,
        0.0107], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,091][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.9194, 0.0168, 0.0178, 0.0129, 0.0074, 0.0092, 0.0042, 0.0074, 0.0021,
        0.0028], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,093][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ house] are: tensor([1.9377e-03, 9.8665e-01, 1.9867e-03, 5.7820e-03, 1.1231e-03, 2.3585e-04,
        1.3532e-04, 8.8928e-04, 8.3248e-04, 4.2996e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,093][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0089, 0.2009, 0.1526, 0.1009, 0.0699, 0.0771, 0.1212, 0.0902, 0.0798,
        0.0986], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,093][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0753, 0.2315, 0.0451, 0.0670, 0.0621, 0.1036, 0.0836, 0.1484, 0.0999,
        0.0836], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,094][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0804, 0.1781, 0.1449, 0.1830, 0.1873, 0.0146, 0.0112, 0.0184, 0.0723,
        0.1098], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,094][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0102, 0.0109, 0.0430, 0.1169, 0.0356, 0.4342, 0.0219, 0.0768, 0.1379,
        0.1126], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,097][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2334, 0.0783, 0.0557, 0.0804, 0.1043, 0.0154, 0.0709, 0.1202, 0.0106,
        0.1466, 0.0842], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,100][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0008, 0.0573, 0.0174, 0.1206, 0.0240, 0.1523, 0.1053, 0.0501, 0.1725,
        0.1427, 0.1569], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,103][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0558, 0.0546, 0.0699, 0.0770, 0.0817, 0.1223, 0.0887, 0.1207, 0.1146,
        0.1207, 0.0940], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,107][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0667, 0.1233, 0.1228, 0.0706, 0.0609, 0.0653, 0.0435, 0.1101, 0.1027,
        0.0928, 0.1414], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,110][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0069, 0.2749, 0.0170, 0.0873, 0.1049, 0.0053, 0.0010, 0.0082, 0.0941,
        0.3567, 0.0436], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,111][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0293, 0.3277, 0.1653, 0.2115, 0.1790, 0.0073, 0.0176, 0.0089, 0.0123,
        0.0248, 0.0163], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,111][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8676, 0.0398, 0.0203, 0.0202, 0.0143, 0.0148, 0.0066, 0.0079, 0.0036,
        0.0038, 0.0012], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,112][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([2.5509e-03, 9.8354e-01, 1.4753e-03, 6.2815e-03, 1.4043e-03, 3.2738e-04,
        2.5719e-04, 1.5908e-03, 1.2207e-03, 8.1526e-04, 5.3590e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,112][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0077, 0.1729, 0.1336, 0.0959, 0.0696, 0.0775, 0.1083, 0.0827, 0.0796,
        0.0935, 0.0788], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,112][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1342, 0.2381, 0.0362, 0.0547, 0.0534, 0.0824, 0.0726, 0.1248, 0.0829,
        0.0651, 0.0556], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,113][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0789, 0.1475, 0.1354, 0.1075, 0.1425, 0.0213, 0.0114, 0.0293, 0.0852,
        0.0743, 0.1669], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,113][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0315, 0.0179, 0.0305, 0.0669, 0.0408, 0.3821, 0.0269, 0.0848, 0.1669,
        0.1085, 0.0433], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,113][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.2490, 0.0794, 0.0461, 0.0704, 0.1062, 0.0104, 0.0599, 0.1066, 0.0056,
        0.1131, 0.0716, 0.0816], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,114][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ William] are: tensor([2.8788e-04, 1.5223e-02, 4.0631e-03, 3.9037e-02, 1.3087e-02, 6.4119e-02,
        4.2192e-02, 2.7992e-02, 1.2243e-01, 1.4153e-01, 6.0927e-02, 4.6911e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,116][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0482, 0.0520, 0.0628, 0.0710, 0.0722, 0.1064, 0.0770, 0.1041, 0.1051,
        0.1098, 0.0866, 0.1047], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,119][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0582, 0.1016, 0.0874, 0.0424, 0.0914, 0.0365, 0.0307, 0.0647, 0.0839,
        0.1628, 0.1219, 0.1184], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,121][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ William] are: tensor([9.0612e-03, 1.8585e-01, 1.1434e-02, 3.8170e-02, 5.2130e-02, 1.2166e-03,
        1.7839e-04, 3.0993e-03, 1.2629e-01, 3.5728e-01, 6.7155e-02, 1.4813e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,124][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0355, 0.3430, 0.1768, 0.1929, 0.1715, 0.0048, 0.0123, 0.0064, 0.0092,
        0.0160, 0.0129, 0.0188], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,128][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.7038, 0.0646, 0.0437, 0.0318, 0.0270, 0.0424, 0.0243, 0.0169, 0.0099,
        0.0105, 0.0053, 0.0199], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,130][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ William] are: tensor([5.7093e-03, 9.8534e-01, 1.3724e-03, 3.5231e-03, 5.5892e-04, 1.3758e-04,
        9.6839e-05, 5.7366e-04, 6.7159e-04, 3.8271e-04, 3.7110e-04, 1.2622e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,134][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0068, 0.1566, 0.1249, 0.0858, 0.0647, 0.0693, 0.1033, 0.0783, 0.0690,
        0.0873, 0.0782, 0.0759], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,134][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0764, 0.2153, 0.0352, 0.0587, 0.0539, 0.0891, 0.0663, 0.1207, 0.0838,
        0.0685, 0.0614, 0.0705], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,135][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.1437, 0.1294, 0.1203, 0.0951, 0.1216, 0.0102, 0.0067, 0.0139, 0.0534,
        0.0673, 0.1384, 0.1001], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,135][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0260, 0.0121, 0.0549, 0.0819, 0.0318, 0.1855, 0.0071, 0.0615, 0.1270,
        0.0543, 0.0608, 0.2972], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,135][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.2516, 0.0679, 0.0412, 0.0627, 0.0999, 0.0094, 0.0529, 0.1023, 0.0053,
        0.1097, 0.0703, 0.0735, 0.0534], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,136][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0003, 0.0294, 0.0075, 0.0371, 0.0159, 0.1180, 0.0855, 0.0366, 0.1578,
        0.1145, 0.0943, 0.2741, 0.0290], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,136][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0377, 0.0413, 0.0542, 0.0609, 0.0646, 0.1020, 0.0693, 0.1011, 0.0998,
        0.1061, 0.0815, 0.0952, 0.0861], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,136][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0284, 0.1641, 0.1006, 0.0445, 0.0810, 0.0541, 0.0326, 0.0388, 0.0750,
        0.0996, 0.0743, 0.0539, 0.1531], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,137][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([2.8421e-02, 1.3847e-01, 1.9138e-02, 3.6199e-02, 8.0216e-02, 1.7190e-03,
        1.6460e-04, 9.5682e-04, 1.4641e-02, 4.9559e-02, 9.8785e-03, 1.7259e-02,
        6.0337e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,140][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0481, 0.3088, 0.1557, 0.1979, 0.1902, 0.0045, 0.0110, 0.0057, 0.0082,
        0.0149, 0.0131, 0.0206, 0.0212], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,142][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.9436, 0.0105, 0.0108, 0.0074, 0.0050, 0.0052, 0.0032, 0.0035, 0.0015,
        0.0017, 0.0012, 0.0046, 0.0018], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,144][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([7.6342e-03, 9.7650e-01, 1.3697e-03, 5.3396e-03, 1.2331e-03, 2.5954e-04,
        1.9396e-04, 1.0675e-03, 9.6388e-04, 5.4914e-04, 4.9224e-04, 2.1964e-03,
        2.1974e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,147][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0079, 0.1639, 0.1214, 0.0820, 0.0624, 0.0610, 0.0916, 0.0713, 0.0632,
        0.0787, 0.0670, 0.0674, 0.0623], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,151][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0980, 0.1744, 0.0331, 0.0536, 0.0479, 0.0817, 0.0598, 0.1163, 0.0715,
        0.0583, 0.0525, 0.0561, 0.0968], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,154][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0734, 0.1226, 0.1159, 0.0940, 0.1111, 0.0089, 0.0068, 0.0116, 0.0418,
        0.0503, 0.0809, 0.0769, 0.2057], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,157][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0295, 0.0111, 0.0268, 0.0629, 0.0256, 0.2555, 0.0152, 0.0580, 0.1011,
        0.0916, 0.0248, 0.2420, 0.0559], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,157][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1794, 0.0621, 0.0430, 0.0659, 0.0885, 0.0124, 0.0547, 0.0978, 0.0082,
        0.1144, 0.0709, 0.0789, 0.0575, 0.0663], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,158][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0006, 0.0291, 0.0088, 0.0518, 0.0155, 0.0938, 0.0579, 0.0322, 0.1095,
        0.0924, 0.1205, 0.3169, 0.0352, 0.0358], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,158][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0384, 0.0405, 0.0499, 0.0551, 0.0568, 0.0857, 0.0620, 0.0894, 0.0866,
        0.0924, 0.0773, 0.0860, 0.0789, 0.1009], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,159][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0599, 0.1010, 0.1379, 0.0671, 0.0806, 0.0381, 0.0233, 0.0504, 0.0546,
        0.0533, 0.0774, 0.0500, 0.1153, 0.0910], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,159][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.7805e-02, 1.1591e-01, 4.5986e-03, 2.9110e-02, 2.9822e-02, 7.1683e-04,
        9.8503e-05, 6.5386e-04, 1.0948e-02, 4.3916e-02, 5.2928e-03, 2.6535e-02,
        6.6094e-01, 5.3662e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,159][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0276, 0.3015, 0.1566, 0.1929, 0.1749, 0.0062, 0.0147, 0.0075, 0.0105,
        0.0205, 0.0149, 0.0254, 0.0273, 0.0194], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,160][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.8842, 0.0339, 0.0171, 0.0117, 0.0136, 0.0079, 0.0069, 0.0057, 0.0026,
        0.0027, 0.0010, 0.0065, 0.0032, 0.0028], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,160][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.1068e-03, 9.6663e-01, 7.1921e-04, 5.1230e-03, 1.0632e-03, 1.5759e-04,
        1.2617e-04, 9.6076e-04, 7.3036e-04, 5.9396e-04, 3.3559e-04, 2.3123e-03,
        2.1222e-03, 1.1015e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,162][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0063, 0.1447, 0.1137, 0.0740, 0.0549, 0.0564, 0.0825, 0.0671, 0.0632,
        0.0720, 0.0639, 0.0631, 0.0605, 0.0776], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,164][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1733, 0.1747, 0.0321, 0.0492, 0.0433, 0.0595, 0.0447, 0.0847, 0.0563,
        0.0454, 0.0409, 0.0474, 0.0707, 0.0778], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,166][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1076, 0.1192, 0.1212, 0.0918, 0.1024, 0.0084, 0.0036, 0.0096, 0.0387,
        0.0314, 0.0770, 0.0700, 0.1407, 0.0784], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,170][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0443, 0.0111, 0.0245, 0.0611, 0.0366, 0.1327, 0.0248, 0.0384, 0.0629,
        0.0875, 0.0416, 0.3169, 0.0694, 0.0480], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,173][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2043, 0.0517, 0.0359, 0.0555, 0.0786, 0.0079, 0.0427, 0.0828, 0.0046,
        0.0934, 0.0564, 0.0647, 0.0447, 0.0499, 0.1269], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,177][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0005, 0.0339, 0.0074, 0.0545, 0.0157, 0.1082, 0.0633, 0.0271, 0.0921,
        0.0985, 0.0749, 0.3429, 0.0362, 0.0257, 0.0191], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,180][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0316, 0.0376, 0.0471, 0.0524, 0.0538, 0.0800, 0.0571, 0.0840, 0.0788,
        0.0843, 0.0679, 0.0767, 0.0708, 0.0925, 0.0855], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,183][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0514, 0.1230, 0.1741, 0.0738, 0.0880, 0.0225, 0.0233, 0.0344, 0.0304,
        0.0479, 0.0692, 0.0452, 0.1041, 0.0699, 0.0427], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,183][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([4.8163e-02, 4.5378e-02, 9.5438e-03, 1.5824e-02, 2.2019e-02, 2.9172e-04,
        3.6666e-05, 3.5266e-04, 7.1604e-03, 2.3622e-02, 5.7039e-03, 9.0092e-03,
        2.6543e-01, 5.1670e-02, 4.9580e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,184][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0397, 0.2974, 0.1571, 0.2024, 0.1715, 0.0037, 0.0090, 0.0049, 0.0069,
        0.0125, 0.0116, 0.0183, 0.0193, 0.0162, 0.0295], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,184][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.8115, 0.0397, 0.0472, 0.0216, 0.0133, 0.0138, 0.0073, 0.0101, 0.0036,
        0.0034, 0.0027, 0.0102, 0.0040, 0.0065, 0.0053], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,184][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([2.8197e-02, 8.9210e-01, 2.0906e-03, 7.8178e-03, 1.4506e-03, 2.9706e-04,
        2.0399e-04, 1.1847e-03, 1.1652e-03, 7.7151e-04, 7.8387e-04, 2.7905e-03,
        2.9373e-03, 1.7749e-02, 4.0460e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,185][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0064, 0.1304, 0.1074, 0.0715, 0.0508, 0.0550, 0.0799, 0.0614, 0.0593,
        0.0679, 0.0603, 0.0599, 0.0552, 0.0725, 0.0622], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,185][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0777, 0.1680, 0.0342, 0.0477, 0.0443, 0.0565, 0.0443, 0.0781, 0.0518,
        0.0429, 0.0395, 0.0428, 0.0738, 0.0725, 0.1259], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,185][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1033, 0.1161, 0.1054, 0.0910, 0.0874, 0.0054, 0.0036, 0.0064, 0.0277,
        0.0258, 0.0684, 0.0581, 0.1132, 0.0517, 0.1365], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,187][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0151, 0.0157, 0.0247, 0.0709, 0.0366, 0.1745, 0.0116, 0.0455, 0.0643,
        0.0434, 0.0249, 0.3069, 0.0528, 0.0639, 0.0493], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,189][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.1701, 0.0530, 0.0354, 0.0563, 0.0785, 0.0095, 0.0477, 0.0817, 0.0056,
        0.0974, 0.0618, 0.0694, 0.0476, 0.0498, 0.1192, 0.0172],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,193][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0008, 0.0442, 0.0078, 0.0572, 0.0162, 0.0823, 0.0602, 0.0277, 0.0967,
        0.0829, 0.0723, 0.3554, 0.0320, 0.0221, 0.0154, 0.0268],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,196][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0300, 0.0349, 0.0440, 0.0471, 0.0480, 0.0728, 0.0538, 0.0763, 0.0737,
        0.0799, 0.0611, 0.0685, 0.0667, 0.0834, 0.0805, 0.0793],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,200][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0412, 0.1748, 0.1066, 0.0669, 0.0673, 0.0269, 0.0189, 0.0349, 0.0390,
        0.0348, 0.0641, 0.0390, 0.1092, 0.0507, 0.0444, 0.0813],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,202][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ it] are: tensor([1.2878e-02, 5.2777e-02, 3.5041e-03, 7.4798e-03, 1.3951e-02, 1.2330e-04,
        1.7556e-05, 1.1844e-04, 2.0759e-03, 4.8963e-03, 2.4446e-03, 2.3409e-03,
        1.1227e-01, 1.3671e-02, 1.7765e-01, 5.9380e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,205][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0233, 0.2761, 0.1655, 0.1790, 0.1680, 0.0044, 0.0100, 0.0063, 0.0080,
        0.0143, 0.0136, 0.0205, 0.0224, 0.0186, 0.0362, 0.0339],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,206][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.8729, 0.0319, 0.0182, 0.0140, 0.0097, 0.0101, 0.0047, 0.0073, 0.0024,
        0.0036, 0.0019, 0.0076, 0.0026, 0.0047, 0.0047, 0.0037],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,207][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ it] are: tensor([1.4150e-02, 9.2631e-01, 1.4071e-03, 6.0710e-03, 1.2705e-03, 2.4613e-04,
        1.5478e-04, 9.0941e-04, 8.6843e-04, 3.8162e-04, 4.0636e-04, 1.5693e-03,
        1.5962e-03, 1.1364e-02, 2.1205e-02, 1.2090e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,207][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0052, 0.1252, 0.1021, 0.0646, 0.0488, 0.0518, 0.0748, 0.0581, 0.0535,
        0.0641, 0.0564, 0.0534, 0.0537, 0.0685, 0.0606, 0.0593],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,207][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0802, 0.1836, 0.0290, 0.0430, 0.0388, 0.0547, 0.0367, 0.0703, 0.0460,
        0.0359, 0.0347, 0.0372, 0.0644, 0.0673, 0.1156, 0.0627],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,208][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0606, 0.1072, 0.1035, 0.0669, 0.0914, 0.0053, 0.0025, 0.0056, 0.0198,
        0.0107, 0.0483, 0.0290, 0.1176, 0.0341, 0.0853, 0.2122],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,208][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0353, 0.0103, 0.0333, 0.0835, 0.0359, 0.1680, 0.0135, 0.0390, 0.0501,
        0.0472, 0.0312, 0.2754, 0.0514, 0.0604, 0.0511, 0.0145],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,208][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1364, 0.0516, 0.0359, 0.0549, 0.0723, 0.0105, 0.0453, 0.0770, 0.0069,
        0.0936, 0.0574, 0.0657, 0.0470, 0.0532, 0.1126, 0.0195, 0.0602],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,209][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0008, 0.0305, 0.0074, 0.0458, 0.0155, 0.0808, 0.0589, 0.0255, 0.0948,
        0.0878, 0.0958, 0.2916, 0.0351, 0.0288, 0.0204, 0.0351, 0.0455],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,210][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0321, 0.0331, 0.0383, 0.0425, 0.0449, 0.0652, 0.0497, 0.0684, 0.0662,
        0.0716, 0.0603, 0.0660, 0.0612, 0.0778, 0.0740, 0.0763, 0.0726],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,213][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0726, 0.0838, 0.1027, 0.0486, 0.0592, 0.0211, 0.0180, 0.0351, 0.0368,
        0.0312, 0.0611, 0.0303, 0.0991, 0.0662, 0.0336, 0.0787, 0.1220],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,215][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([4.4222e-03, 1.1919e-02, 5.6045e-04, 2.3359e-03, 3.7302e-03, 4.9504e-05,
        5.3560e-06, 3.8713e-05, 9.6134e-04, 4.4741e-03, 5.3935e-04, 1.4626e-03,
        8.1476e-02, 4.3667e-03, 1.7553e-01, 6.8135e-01, 2.6779e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,218][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0193, 0.2522, 0.1603, 0.1738, 0.1610, 0.0057, 0.0132, 0.0071, 0.0097,
        0.0189, 0.0140, 0.0232, 0.0258, 0.0188, 0.0399, 0.0366, 0.0206],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,221][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.8788, 0.0333, 0.0154, 0.0116, 0.0126, 0.0083, 0.0067, 0.0055, 0.0025,
        0.0029, 0.0010, 0.0064, 0.0030, 0.0027, 0.0023, 0.0047, 0.0024],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,223][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.7007e-03, 8.6950e-01, 1.0162e-03, 6.0857e-03, 1.2348e-03, 2.1555e-04,
        1.4736e-04, 1.1803e-03, 9.9111e-04, 6.4956e-04, 5.2285e-04, 2.7276e-03,
        2.3433e-03, 1.3992e-02, 3.8973e-02, 2.7526e-02, 2.5195e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,227][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0055, 0.1149, 0.0936, 0.0604, 0.0468, 0.0458, 0.0677, 0.0558, 0.0506,
        0.0595, 0.0535, 0.0516, 0.0493, 0.0644, 0.0574, 0.0579, 0.0653],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,229][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1176, 0.1551, 0.0283, 0.0423, 0.0368, 0.0437, 0.0336, 0.0599, 0.0404,
        0.0336, 0.0318, 0.0361, 0.0549, 0.0557, 0.1007, 0.0575, 0.0719],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,230][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1016, 0.0775, 0.0808, 0.0516, 0.0737, 0.0043, 0.0018, 0.0044, 0.0203,
        0.0138, 0.0516, 0.0307, 0.0827, 0.0393, 0.0847, 0.2251, 0.0562],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,230][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0567, 0.0125, 0.0288, 0.0564, 0.0439, 0.1230, 0.0228, 0.0344, 0.0598,
        0.0628, 0.0369, 0.2168, 0.0608, 0.0420, 0.0447, 0.0346, 0.0631],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,276][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:01,279][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,281][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,284][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,287][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,289][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,289][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,290][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,290][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,290][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,291][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,291][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,291][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,292][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9945, 0.0055], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,292][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0094, 0.9906], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,295][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.8773, 0.1227], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,299][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.8259, 0.1741], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,304][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.4018, 0.5982], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,309][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.8690, 0.1310], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,310][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.7630, 0.2370], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,310][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.1044, 0.8956], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,311][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9307, 0.0693], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,311][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.9411, 0.0589], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,311][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.7125, 0.2875], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,312][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.5896, 0.4104], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,312][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8664, 0.0097, 0.1239], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,312][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0096, 0.8842, 0.1062], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,312][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6526, 0.1896, 0.1578], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,313][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3637, 0.2613, 0.3750], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,315][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0182, 0.9062, 0.0756], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,318][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3419, 0.4917, 0.1664], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,324][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4326, 0.4310, 0.1364], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,328][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0117, 0.9118, 0.0765], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,331][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6199, 0.2977, 0.0824], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,332][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7763, 0.1225, 0.1012], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,332][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2599, 0.3658, 0.3743], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,332][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3884, 0.3161, 0.2956], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,332][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.9265, 0.0060, 0.0509, 0.0166], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,333][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0044, 0.5808, 0.0867, 0.3280], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,333][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.6371, 0.1468, 0.1500, 0.0662], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,333][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.3025, 0.2333, 0.3151, 0.1491], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,334][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0481, 0.7204, 0.0409, 0.1905], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,334][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.4151, 0.3780, 0.0909, 0.1160], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,337][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.3226, 0.3423, 0.2201, 0.1150], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,341][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0100, 0.6734, 0.0167, 0.2999], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,345][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.5546, 0.3060, 0.1040, 0.0354], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,350][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.7917, 0.1228, 0.0590, 0.0265], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,352][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.2949, 0.2694, 0.2230, 0.2127], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,353][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.2697, 0.2455, 0.2381, 0.2467], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,353][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.8846, 0.0053, 0.0822, 0.0165, 0.0114], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,353][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0016, 0.5146, 0.0908, 0.2916, 0.1014], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,354][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.4148, 0.1141, 0.1754, 0.1035, 0.1922], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,354][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.1330, 0.2874, 0.2642, 0.1681, 0.1473], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,354][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0151, 0.5142, 0.0425, 0.2049, 0.2233], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,354][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0636, 0.3028, 0.0844, 0.2344, 0.3148], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,355][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0825, 0.5986, 0.0849, 0.1663, 0.0678], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,355][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0033, 0.3797, 0.0273, 0.5099, 0.0798], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,358][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.3329, 0.3841, 0.0835, 0.0901, 0.1095], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,362][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([0.4652, 0.2448, 0.1235, 0.0831, 0.0835], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,366][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.1075, 0.2649, 0.1736, 0.2597, 0.1943], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,371][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.2649, 0.1889, 0.1745, 0.1888, 0.1829], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,373][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4541, 0.0021, 0.0349, 0.0060, 0.0030, 0.5000], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,374][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0043, 0.5373, 0.0308, 0.1803, 0.1120, 0.1353], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,374][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3205, 0.1548, 0.1452, 0.0799, 0.1830, 0.1165], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,374][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0499, 0.2430, 0.2428, 0.1519, 0.1857, 0.1267], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,375][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0012, 0.3905, 0.0268, 0.2805, 0.2794, 0.0216], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,375][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0053, 0.1912, 0.0468, 0.3067, 0.4344, 0.0155], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,375][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2550, 0.4683, 0.0720, 0.0907, 0.0721, 0.0420], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,376][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([4.9176e-05, 2.8430e-01, 1.0936e-02, 5.7222e-01, 1.3155e-01, 9.4322e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,376][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1279, 0.4106, 0.0987, 0.1141, 0.2096, 0.0390], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,377][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3850, 0.2476, 0.1486, 0.0714, 0.1089, 0.0385], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,381][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0518, 0.2332, 0.2135, 0.2032, 0.2564, 0.0419], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,387][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1735, 0.1568, 0.1556, 0.1635, 0.1623, 0.1883], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,391][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.3528, 0.0049, 0.0442, 0.0090, 0.0033, 0.5843, 0.0015],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,394][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0012, 0.2724, 0.0343, 0.2027, 0.0574, 0.2398, 0.1922],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,395][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.2975, 0.1250, 0.1237, 0.0778, 0.1257, 0.1102, 0.1401],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,395][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0481, 0.2679, 0.1634, 0.1603, 0.1750, 0.1137, 0.0716],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,395][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([2.4588e-04, 3.1389e-01, 1.4337e-02, 2.6202e-01, 3.6862e-01, 3.7416e-02,
        3.4649e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,396][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0033, 0.1528, 0.0262, 0.3555, 0.4237, 0.0312, 0.0071],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,396][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.1177, 0.2802, 0.1501, 0.1562, 0.1624, 0.0850, 0.0484],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,396][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([1.2928e-05, 2.3831e-01, 5.8356e-03, 6.0794e-01, 1.4435e-01, 3.1885e-03,
        3.6556e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,397][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0443, 0.4176, 0.1222, 0.1245, 0.2136, 0.0559, 0.0219],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,397][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.2335, 0.3353, 0.1407, 0.1099, 0.1209, 0.0437, 0.0159],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,400][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0331, 0.1862, 0.2048, 0.2306, 0.2555, 0.0539, 0.0359],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,404][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.1279, 0.1402, 0.1337, 0.1502, 0.1415, 0.1788, 0.1277],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,408][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.5166, 0.0028, 0.0354, 0.0081, 0.0032, 0.4061, 0.0013, 0.0264],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,414][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0012, 0.2085, 0.0362, 0.1283, 0.1209, 0.2681, 0.1825, 0.0542],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,416][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2299, 0.1706, 0.1225, 0.0961, 0.1373, 0.0764, 0.1144, 0.0528],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,416][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0444, 0.1566, 0.1994, 0.0994, 0.0913, 0.1206, 0.0912, 0.1972],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,416][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0017, 0.3420, 0.0175, 0.2808, 0.3227, 0.0184, 0.0040, 0.0129],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,417][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0102, 0.2184, 0.0394, 0.2484, 0.4138, 0.0200, 0.0077, 0.0420],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,417][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1395, 0.5046, 0.0611, 0.1032, 0.0930, 0.0314, 0.0357, 0.0315],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,417][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([3.1574e-04, 2.1040e-01, 1.6710e-02, 6.0583e-01, 1.5495e-01, 2.7807e-03,
        6.7854e-04, 8.3285e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,418][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1160, 0.4617, 0.0610, 0.1205, 0.1545, 0.0267, 0.0258, 0.0340],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,418][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.4796, 0.2067, 0.1239, 0.0534, 0.0809, 0.0180, 0.0071, 0.0305],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,418][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0595, 0.2659, 0.1611, 0.1970, 0.1989, 0.0377, 0.0238, 0.0560],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,420][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1584, 0.1191, 0.1155, 0.1194, 0.1193, 0.1408, 0.1006, 0.1268],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,424][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4830, 0.0013, 0.0190, 0.0030, 0.0014, 0.2215, 0.0005, 0.0118, 0.2585],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,429][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0013, 0.2568, 0.0260, 0.1239, 0.0768, 0.1406, 0.1415, 0.0395, 0.1937],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,434][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3885, 0.0977, 0.0860, 0.0528, 0.1090, 0.0812, 0.1042, 0.0361, 0.0443],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,437][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0497, 0.1843, 0.1752, 0.1086, 0.0998, 0.0964, 0.0431, 0.1141, 0.1289],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,438][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0188, 0.5185, 0.0226, 0.1295, 0.1613, 0.0055, 0.0007, 0.0081, 0.1352],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,438][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0858, 0.1796, 0.0384, 0.1231, 0.2931, 0.0052, 0.0016, 0.0116, 0.2617],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,438][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2033, 0.4785, 0.0464, 0.0936, 0.0590, 0.0277, 0.0276, 0.0192, 0.0448],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,439][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.7824e-03, 4.3151e-01, 1.8720e-02, 4.0447e-01, 8.9705e-02, 2.5643e-04,
        7.6173e-05, 8.7282e-04, 5.2612e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,439][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1948, 0.3881, 0.0728, 0.0812, 0.1274, 0.0180, 0.0130, 0.0188, 0.0861],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,439][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.6457, 0.1426, 0.0771, 0.0279, 0.0421, 0.0097, 0.0035, 0.0115, 0.0398],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,440][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1355, 0.2220, 0.1479, 0.1377, 0.1977, 0.0207, 0.0120, 0.0237, 0.1028],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,440][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1313, 0.1045, 0.1038, 0.1086, 0.1076, 0.1230, 0.0864, 0.1103, 0.1246],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,441][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([5.3375e-01, 9.1951e-04, 1.7974e-02, 2.2266e-03, 8.7156e-04, 2.0810e-01,
        5.2346e-04, 8.3237e-03, 2.2574e-01, 1.5670e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,445][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0002, 0.1255, 0.0190, 0.1094, 0.0355, 0.2094, 0.0742, 0.0278, 0.2105,
        0.1884], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,450][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.1770, 0.0895, 0.0975, 0.0549, 0.1096, 0.1446, 0.0867, 0.0588, 0.0716,
        0.1097], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,455][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0324, 0.1725, 0.1727, 0.1159, 0.0801, 0.0650, 0.0599, 0.0680, 0.0976,
        0.1358], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,457][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([7.5411e-03, 2.6139e-01, 2.1559e-02, 1.3832e-01, 1.5573e-01, 2.8175e-03,
        1.9189e-04, 2.7154e-03, 1.0209e-01, 3.0765e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,459][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.0570, 0.1146, 0.0529, 0.1220, 0.2276, 0.0028, 0.0006, 0.0061, 0.1885,
        0.2279], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,459][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0549, 0.5020, 0.0572, 0.1376, 0.0764, 0.0458, 0.0270, 0.0201, 0.0525,
        0.0265], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,460][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([1.4528e-03, 3.2182e-01, 2.0382e-02, 5.1863e-01, 7.8232e-02, 9.7935e-05,
        1.9704e-05, 2.2040e-04, 2.0047e-02, 3.9099e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,460][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.1681, 0.3033, 0.0836, 0.1102, 0.1435, 0.0168, 0.0115, 0.0134, 0.0962,
        0.0533], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,460][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([0.5129, 0.1575, 0.0782, 0.0512, 0.0641, 0.0129, 0.0041, 0.0149, 0.0581,
        0.0459], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,461][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0804, 0.1781, 0.1449, 0.1830, 0.1873, 0.0146, 0.0112, 0.0184, 0.0723,
        0.1098], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,461][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.1027, 0.0953, 0.0936, 0.0990, 0.0964, 0.1110, 0.0811, 0.0974, 0.1137,
        0.1099], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,461][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6088, 0.0022, 0.0250, 0.0036, 0.0024, 0.1358, 0.0010, 0.0118, 0.1621,
        0.0026, 0.0448], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,463][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0003, 0.1767, 0.0319, 0.1724, 0.0320, 0.1314, 0.0980, 0.0192, 0.1263,
        0.1083, 0.1035], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,465][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2772, 0.0849, 0.0904, 0.0452, 0.0887, 0.0849, 0.1234, 0.0379, 0.0393,
        0.0676, 0.0605], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,471][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0667, 0.1233, 0.1228, 0.0706, 0.0609, 0.0653, 0.0435, 0.1101, 0.1027,
        0.0928, 0.1414], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,475][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0069, 0.2749, 0.0170, 0.0873, 0.1049, 0.0053, 0.0010, 0.0082, 0.0941,
        0.3567, 0.0436], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,481][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0533, 0.1169, 0.0258, 0.0849, 0.1477, 0.0055, 0.0023, 0.0137, 0.1833,
        0.2630, 0.1035], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,481][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0731, 0.4049, 0.0474, 0.1066, 0.0767, 0.0227, 0.0586, 0.0281, 0.0608,
        0.0535, 0.0677], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,481][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([4.7770e-03, 2.9034e-01, 2.2438e-02, 2.4830e-01, 7.5018e-02, 6.1530e-04,
        1.8988e-04, 1.8286e-03, 8.0981e-02, 1.9783e-01, 7.7680e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,482][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1850, 0.2380, 0.0463, 0.0708, 0.0987, 0.0144, 0.0194, 0.0281, 0.0915,
        0.0989, 0.1090], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,482][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5194, 0.1424, 0.0862, 0.0386, 0.0482, 0.0118, 0.0069, 0.0153, 0.0530,
        0.0228, 0.0554], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,482][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0789, 0.1475, 0.1354, 0.1075, 0.1425, 0.0213, 0.0114, 0.0293, 0.0852,
        0.0743, 0.1669], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,483][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1142, 0.0860, 0.0820, 0.0839, 0.0834, 0.0997, 0.0704, 0.0896, 0.1034,
        0.0960, 0.0915], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,483][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([4.7068e-01, 1.0222e-03, 1.2709e-02, 3.1021e-03, 6.0299e-04, 2.0058e-01,
        4.0292e-04, 7.1159e-03, 2.5630e-01, 1.8008e-03, 4.1168e-02, 4.5043e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,483][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([8.6452e-05, 3.0776e-02, 4.5838e-03, 4.3771e-02, 2.4859e-02, 5.4278e-02,
        3.9478e-02, 1.4652e-02, 1.4063e-01, 2.1912e-01, 3.5977e-02, 3.9179e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,486][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.2334, 0.1056, 0.0847, 0.0572, 0.0882, 0.0649, 0.0906, 0.0282, 0.0460,
        0.0708, 0.0830, 0.0474], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,491][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.0582, 0.1016, 0.0874, 0.0424, 0.0914, 0.0365, 0.0307, 0.0647, 0.0839,
        0.1628, 0.1219, 0.1184], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,494][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([9.0612e-03, 1.8585e-01, 1.1434e-02, 3.8170e-02, 5.2130e-02, 1.2166e-03,
        1.7839e-04, 3.0993e-03, 1.2629e-01, 3.5728e-01, 6.7155e-02, 1.4813e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,498][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0827, 0.1089, 0.0268, 0.0390, 0.1127, 0.0015, 0.0003, 0.0047, 0.1655,
        0.1576, 0.1667, 0.1337], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,502][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0546, 0.3441, 0.0854, 0.1512, 0.0718, 0.0422, 0.0297, 0.0224, 0.0640,
        0.0258, 0.0303, 0.0785], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,502][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([2.4482e-03, 2.2193e-01, 8.3699e-03, 1.1164e-01, 3.0823e-02, 8.2091e-05,
        1.6161e-05, 4.4174e-04, 7.1788e-02, 1.4939e-01, 7.6405e-02, 3.2667e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,503][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.1470, 0.2911, 0.0759, 0.0514, 0.1007, 0.0133, 0.0073, 0.0134, 0.0951,
        0.0422, 0.1075, 0.0552], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,503][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.5283, 0.1514, 0.0457, 0.0293, 0.0359, 0.0103, 0.0030, 0.0107, 0.0485,
        0.0338, 0.0500, 0.0531], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,503][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.1437, 0.1294, 0.1203, 0.0951, 0.1216, 0.0102, 0.0067, 0.0139, 0.0534,
        0.0673, 0.1384, 0.1001], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,504][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0870, 0.0791, 0.0796, 0.0818, 0.0802, 0.0919, 0.0623, 0.0813, 0.0980,
        0.0871, 0.0893, 0.0825], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,504][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.5363, 0.0017, 0.0286, 0.0033, 0.0019, 0.1646, 0.0007, 0.0104, 0.1924,
        0.0016, 0.0421, 0.0027, 0.0139], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,505][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([1.4841e-04, 9.3355e-02, 1.2880e-02, 3.0395e-02, 3.2768e-02, 1.3067e-01,
        1.2382e-01, 1.9170e-02, 2.0110e-01, 1.3028e-01, 7.2178e-02, 1.1313e-01,
        4.0102e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,506][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1866, 0.0499, 0.0606, 0.0313, 0.0690, 0.0877, 0.0828, 0.0457, 0.0653,
        0.1037, 0.1043, 0.0388, 0.0743], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,510][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0284, 0.1641, 0.1006, 0.0445, 0.0810, 0.0541, 0.0326, 0.0388, 0.0750,
        0.0996, 0.0743, 0.0539, 0.1531], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,514][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([2.8421e-02, 1.3847e-01, 1.9138e-02, 3.6199e-02, 8.0216e-02, 1.7190e-03,
        1.6460e-04, 9.5682e-04, 1.4641e-02, 4.9559e-02, 9.8785e-03, 1.7259e-02,
        6.0337e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,516][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([7.3899e-02, 8.0151e-02, 3.9847e-02, 6.0907e-02, 1.1174e-01, 1.2855e-03,
        2.6918e-04, 2.5585e-03, 3.6406e-02, 3.3824e-02, 5.0849e-02, 4.0984e-02,
        4.6727e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,522][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0395, 0.3599, 0.0885, 0.1125, 0.0667, 0.0275, 0.0378, 0.0228, 0.0503,
        0.0288, 0.0412, 0.0808, 0.0435], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,524][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([1.4610e-02, 3.4586e-01, 3.8944e-02, 2.6599e-01, 6.1301e-02, 9.1677e-05,
        1.8576e-05, 1.7501e-04, 9.2300e-03, 9.7755e-03, 2.7242e-02, 3.6980e-02,
        1.8977e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,524][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1645, 0.2690, 0.0421, 0.0479, 0.0806, 0.0116, 0.0057, 0.0120, 0.0431,
        0.0500, 0.0476, 0.0458, 0.1801], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,524][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.4489, 0.1361, 0.0762, 0.0366, 0.0455, 0.0100, 0.0031, 0.0133, 0.0326,
        0.0220, 0.0440, 0.0348, 0.0969], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,525][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0734, 0.1226, 0.1159, 0.0940, 0.1111, 0.0089, 0.0068, 0.0116, 0.0418,
        0.0503, 0.0809, 0.0769, 0.2057], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,525][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.1029, 0.0745, 0.0718, 0.0738, 0.0695, 0.0800, 0.0578, 0.0728, 0.0831,
        0.0792, 0.0764, 0.0723, 0.0859], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,526][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4980, 0.0017, 0.0173, 0.0030, 0.0016, 0.1055, 0.0006, 0.0087, 0.1795,
        0.0014, 0.0535, 0.0023, 0.0179, 0.1089], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,526][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0006, 0.1044, 0.0202, 0.0679, 0.0351, 0.0990, 0.0646, 0.0151, 0.1116,
        0.0936, 0.1201, 0.1808, 0.0537, 0.0334], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,526][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3773, 0.0676, 0.0660, 0.0286, 0.0446, 0.0421, 0.0619, 0.0269, 0.0389,
        0.0514, 0.0928, 0.0232, 0.0545, 0.0242], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,529][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0599, 0.1010, 0.1379, 0.0671, 0.0806, 0.0381, 0.0233, 0.0504, 0.0546,
        0.0533, 0.0774, 0.0500, 0.1153, 0.0910], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,531][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.7805e-02, 1.1591e-01, 4.5986e-03, 2.9110e-02, 2.9822e-02, 7.1683e-04,
        9.8503e-05, 6.5386e-04, 1.0948e-02, 4.3916e-02, 5.2928e-03, 2.6535e-02,
        6.6094e-01, 5.3662e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,534][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.9433e-02, 8.2792e-02, 1.4022e-02, 4.9560e-02, 6.1780e-02, 6.8567e-04,
        3.6233e-04, 1.2384e-03, 2.7165e-02, 6.5378e-02, 2.4631e-02, 6.2246e-02,
        4.4361e-01, 1.2710e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,539][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2471, 0.3555, 0.0437, 0.0892, 0.0282, 0.0082, 0.0134, 0.0092, 0.0284,
        0.0157, 0.0341, 0.0820, 0.0212, 0.0242], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,542][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.3534e-03, 2.0809e-01, 1.6809e-02, 1.3715e-01, 3.0445e-02, 5.2841e-05,
        2.1084e-05, 1.4674e-04, 8.1130e-03, 2.4053e-02, 1.8129e-02, 5.5045e-02,
        4.1032e-01, 8.2272e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,545][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3443, 0.2382, 0.0318, 0.0405, 0.0698, 0.0041, 0.0056, 0.0065, 0.0225,
        0.0370, 0.0347, 0.0312, 0.0857, 0.0481], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,546][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5402, 0.1185, 0.0848, 0.0374, 0.0470, 0.0057, 0.0025, 0.0063, 0.0243,
        0.0114, 0.0237, 0.0249, 0.0374, 0.0359], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,546][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1076, 0.1192, 0.1212, 0.0918, 0.1024, 0.0084, 0.0036, 0.0096, 0.0387,
        0.0314, 0.0770, 0.0700, 0.1407, 0.0784], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,546][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0888, 0.0685, 0.0648, 0.0684, 0.0661, 0.0716, 0.0544, 0.0666, 0.0754,
        0.0740, 0.0727, 0.0701, 0.0807, 0.0779], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,547][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([5.3108e-01, 1.2309e-03, 1.9761e-02, 2.4485e-03, 1.6086e-03, 1.1409e-01,
        5.2895e-04, 8.2976e-03, 1.7554e-01, 1.0416e-03, 3.9558e-02, 1.7301e-03,
        1.1504e-02, 6.3735e-02, 2.7845e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,547][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0012, 0.1384, 0.0143, 0.0702, 0.0393, 0.1100, 0.0801, 0.0104, 0.0777,
        0.1038, 0.0528, 0.1883, 0.0634, 0.0197, 0.0302], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,547][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.2448, 0.0562, 0.0687, 0.0374, 0.0637, 0.0526, 0.0733, 0.0459, 0.0375,
        0.0608, 0.0931, 0.0270, 0.0684, 0.0305, 0.0400], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,548][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0514, 0.1230, 0.1741, 0.0738, 0.0880, 0.0225, 0.0233, 0.0344, 0.0304,
        0.0479, 0.0692, 0.0452, 0.1041, 0.0699, 0.0427], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,549][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([4.8163e-02, 4.5378e-02, 9.5438e-03, 1.5824e-02, 2.2019e-02, 2.9172e-04,
        3.6666e-05, 3.5266e-04, 7.1604e-03, 2.3622e-02, 5.7039e-03, 9.0092e-03,
        2.6543e-01, 5.1670e-02, 4.9580e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,551][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([9.4425e-02, 6.0898e-02, 1.6968e-02, 3.3142e-02, 4.7695e-02, 3.4343e-04,
        1.1677e-04, 5.8709e-04, 1.6625e-02, 2.1510e-02, 2.2979e-02, 1.9663e-02,
        2.4479e-01, 7.4407e-02, 3.4585e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,557][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1210, 0.4273, 0.0434, 0.1087, 0.0350, 0.0169, 0.0122, 0.0070, 0.0378,
        0.0145, 0.0183, 0.0737, 0.0246, 0.0149, 0.0446], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,559][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([4.5419e-02, 2.1618e-01, 3.9272e-02, 1.5110e-01, 2.6589e-02, 2.8640e-05,
        7.4540e-06, 8.9392e-05, 3.6672e-03, 6.4119e-03, 1.9526e-02, 1.4442e-02,
        1.2676e-01, 6.2855e-02, 2.8765e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,565][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.2937, 0.2176, 0.0210, 0.0330, 0.0528, 0.0043, 0.0039, 0.0046, 0.0160,
        0.0215, 0.0228, 0.0213, 0.0516, 0.0414, 0.1944], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,567][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.4555, 0.1439, 0.0781, 0.0513, 0.0445, 0.0044, 0.0022, 0.0053, 0.0189,
        0.0123, 0.0199, 0.0347, 0.0471, 0.0385, 0.0433], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,567][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1033, 0.1161, 0.1054, 0.0910, 0.0874, 0.0054, 0.0036, 0.0064, 0.0277,
        0.0258, 0.0684, 0.0581, 0.1132, 0.0517, 0.1365], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,567][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0688, 0.0663, 0.0613, 0.0657, 0.0623, 0.0681, 0.0498, 0.0628, 0.0722,
        0.0682, 0.0676, 0.0668, 0.0760, 0.0750, 0.0692], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,568][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.3407, 0.0010, 0.0152, 0.0017, 0.0009, 0.0691, 0.0004, 0.0085, 0.0867,
        0.0012, 0.0372, 0.0020, 0.0145, 0.0558, 0.0172, 0.3480],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,568][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0009, 0.1945, 0.0127, 0.0694, 0.0312, 0.0705, 0.0648, 0.0130, 0.0893,
        0.0770, 0.0501, 0.2229, 0.0442, 0.0156, 0.0175, 0.0264],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,568][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.3063, 0.0636, 0.0737, 0.0308, 0.0421, 0.0391, 0.0668, 0.0275, 0.0335,
        0.0646, 0.0656, 0.0198, 0.0587, 0.0179, 0.0361, 0.0540],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,569][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0412, 0.1748, 0.1066, 0.0669, 0.0673, 0.0269, 0.0189, 0.0349, 0.0390,
        0.0348, 0.0641, 0.0390, 0.1092, 0.0507, 0.0444, 0.0813],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,569][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([1.2878e-02, 5.2777e-02, 3.5041e-03, 7.4798e-03, 1.3951e-02, 1.2330e-04,
        1.7556e-05, 1.1844e-04, 2.0759e-03, 4.8963e-03, 2.4446e-03, 2.3409e-03,
        1.1227e-01, 1.3671e-02, 1.7765e-01, 5.9380e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,571][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([6.3749e-02, 5.8924e-02, 1.0215e-02, 2.1596e-02, 3.0178e-02, 2.1516e-04,
        8.8091e-05, 4.2347e-04, 7.8983e-03, 6.7522e-03, 8.0593e-03, 6.7261e-03,
        1.4205e-01, 4.0164e-02, 2.9126e-01, 3.1169e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,575][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([0.0770, 0.3713, 0.0409, 0.1042, 0.0464, 0.0224, 0.0155, 0.0125, 0.0341,
        0.0112, 0.0221, 0.0499, 0.0347, 0.0231, 0.0654, 0.0692],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,578][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([1.4975e-02, 1.3633e-01, 9.3622e-03, 7.2852e-02, 1.8747e-02, 1.0611e-05,
        3.0129e-06, 1.4712e-05, 1.0501e-03, 1.0010e-03, 2.9477e-03, 4.2014e-03,
        5.2785e-02, 1.0356e-02, 7.2170e-02, 6.0319e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,582][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.2403, 0.1366, 0.0267, 0.0258, 0.0845, 0.0053, 0.0036, 0.0049, 0.0171,
        0.0172, 0.0220, 0.0083, 0.0840, 0.0333, 0.2219, 0.0685],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,588][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([0.2871, 0.1731, 0.0681, 0.0456, 0.0492, 0.0085, 0.0017, 0.0069, 0.0284,
        0.0108, 0.0274, 0.0241, 0.0621, 0.0475, 0.0588, 0.1007],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,588][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0606, 0.1072, 0.1035, 0.0669, 0.0914, 0.0053, 0.0025, 0.0056, 0.0198,
        0.0107, 0.0483, 0.0290, 0.1176, 0.0341, 0.0853, 0.2122],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,589][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0662, 0.0565, 0.0569, 0.0593, 0.0562, 0.0638, 0.0457, 0.0582, 0.0675,
        0.0623, 0.0647, 0.0601, 0.0699, 0.0689, 0.0640, 0.0795],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,589][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.5162e-01, 8.2173e-04, 7.9931e-03, 1.1881e-03, 5.5740e-04, 4.4038e-02,
        1.9043e-04, 3.4377e-03, 6.8930e-02, 4.4300e-04, 2.1647e-02, 8.3172e-04,
        7.0650e-03, 3.9970e-02, 1.6609e-02, 2.1519e-01, 1.1946e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,589][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0012, 0.1146, 0.0146, 0.0542, 0.0350, 0.0740, 0.0654, 0.0104, 0.0891,
        0.0844, 0.0885, 0.1555, 0.0537, 0.0235, 0.0315, 0.0499, 0.0546],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,590][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4619, 0.0469, 0.0456, 0.0166, 0.0319, 0.0268, 0.0451, 0.0161, 0.0247,
        0.0362, 0.0676, 0.0114, 0.0354, 0.0150, 0.0271, 0.0692, 0.0226],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,590][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0726, 0.0838, 0.1027, 0.0486, 0.0592, 0.0211, 0.0180, 0.0351, 0.0368,
        0.0312, 0.0611, 0.0303, 0.0991, 0.0662, 0.0336, 0.0787, 0.1220],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,591][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.4222e-03, 1.1919e-02, 5.6045e-04, 2.3359e-03, 3.7302e-03, 4.9504e-05,
        5.3560e-06, 3.8713e-05, 9.6134e-04, 4.4741e-03, 5.3935e-04, 1.4626e-03,
        8.1476e-02, 4.3667e-03, 1.7553e-01, 6.8135e-01, 2.6779e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,592][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.8840e-02, 1.4902e-02, 3.1075e-03, 8.2390e-03, 1.4140e-02, 9.5603e-05,
        3.5757e-05, 1.5925e-04, 4.3583e-03, 8.7360e-03, 3.9977e-03, 5.8866e-03,
        8.7871e-02, 2.3090e-02, 2.6483e-01, 4.6790e-01, 7.3808e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,596][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3565, 0.2809, 0.0300, 0.0649, 0.0213, 0.0057, 0.0080, 0.0060, 0.0192,
        0.0090, 0.0208, 0.0512, 0.0145, 0.0166, 0.0274, 0.0395, 0.0285],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,599][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.7423e-03, 1.4178e-02, 1.3430e-03, 8.1457e-03, 2.0315e-03, 2.0002e-06,
        5.5305e-07, 4.6178e-06, 3.6209e-04, 1.0464e-03, 1.0374e-03, 1.6287e-03,
        2.3825e-02, 4.2031e-03, 4.8396e-02, 8.6609e-01, 2.5965e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,604][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3899, 0.1260, 0.0163, 0.0203, 0.0415, 0.0018, 0.0023, 0.0027, 0.0088,
        0.0129, 0.0137, 0.0104, 0.0427, 0.0208, 0.1616, 0.0900, 0.0381],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,609][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5803, 0.0966, 0.0628, 0.0264, 0.0342, 0.0032, 0.0013, 0.0033, 0.0134,
        0.0056, 0.0116, 0.0120, 0.0230, 0.0191, 0.0244, 0.0584, 0.0242],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,610][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1016, 0.0775, 0.0808, 0.0516, 0.0737, 0.0043, 0.0018, 0.0044, 0.0203,
        0.0138, 0.0516, 0.0307, 0.0827, 0.0393, 0.0847, 0.2251, 0.0562],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,610][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0740, 0.0547, 0.0527, 0.0535, 0.0531, 0.0578, 0.0429, 0.0529, 0.0613,
        0.0579, 0.0588, 0.0536, 0.0641, 0.0624, 0.0574, 0.0750, 0.0679],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,611][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:01,612][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7767],
        [27783],
        [ 1334],
        [ 1293],
        [  291],
        [   88],
        [  211],
        [  227],
        [   43],
        [   33],
        [  170],
        [  460],
        [  342],
        [  292],
        [   75],
        [   33],
        [   33]], device='cuda:0')
[2024-07-24 10:23:01,613][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8307],
        [36029],
        [ 4796],
        [ 4776],
        [ 2702],
        [ 1101],
        [ 1341],
        [ 2008],
        [  571],
        [  532],
        [ 1409],
        [ 2868],
        [ 1813],
        [ 2334],
        [  650],
        [  320],
        [  453]], device='cuda:0')
[2024-07-24 10:23:01,616][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10882],
        [14702],
        [12210],
        [10393],
        [ 8895],
        [ 8859],
        [ 9563],
        [ 8065],
        [ 8105],
        [ 8032],
        [ 7929],
        [ 7618],
        [ 7165],
        [ 6699],
        [ 6104],
        [ 6118],
        [ 5828]], device='cuda:0')
[2024-07-24 10:23:01,618][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8029],
        [47216],
        [44874],
        [40630],
        [38347],
        [35752],
        [36714],
        [34218],
        [33654],
        [30837],
        [33998],
        [42956],
        [39764],
        [41035],
        [40710],
        [41080],
        [39415]], device='cuda:0')
[2024-07-24 10:23:01,621][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2766],
        [8712],
        [9595],
        [8632],
        [9087],
        [9189],
        [9129],
        [9026],
        [9292],
        [9646],
        [9849],
        [9558],
        [9240],
        [8886],
        [8700],
        [8644],
        [8507]], device='cuda:0')
[2024-07-24 10:23:01,623][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16063],
        [48127],
        [49894],
        [50050],
        [49984],
        [49550],
        [49479],
        [47883],
        [48182],
        [48149],
        [42640],
        [41375],
        [43414],
        [40352],
        [43834],
        [42483],
        [31180]], device='cuda:0')
[2024-07-24 10:23:01,626][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38202],
        [20824],
        [17844],
        [20427],
        [21805],
        [23557],
        [24359],
        [24116],
        [21432],
        [19993],
        [19679],
        [20337],
        [15899],
        [15665],
        [21696],
        [ 8548],
        [ 7697]], device='cuda:0')
[2024-07-24 10:23:01,628][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[2391],
        [2324],
        [3358],
        [3945],
        [4068],
        [4479],
        [4433],
        [4484],
        [4498],
        [4464],
        [4401],
        [4344],
        [4292],
        [4373],
        [4373],
        [4560],
        [4641]], device='cuda:0')
[2024-07-24 10:23:01,631][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[8544],
        [8112],
        [7833],
        [5782],
        [6847],
        [5899],
        [6429],
        [5361],
        [5262],
        [6334],
        [5353],
        [5194],
        [6585],
        [5602],
        [5690],
        [5547],
        [5612]], device='cuda:0')
[2024-07-24 10:23:01,633][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13805],
        [23150],
        [23158],
        [23092],
        [23061],
        [23113],
        [23128],
        [23064],
        [23075],
        [23050],
        [22993],
        [23043],
        [22937],
        [22714],
        [21672],
        [22074],
        [20860]], device='cuda:0')
[2024-07-24 10:23:01,635][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[4887],
        [  24],
        [  76],
        [ 100],
        [ 146],
        [ 192],
        [ 174],
        [ 214],
        [ 239],
        [ 213],
        [ 240],
        [ 206],
        [ 204],
        [ 248],
        [ 282],
        [ 288],
        [ 339]], device='cuda:0')
[2024-07-24 10:23:01,636][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20792],
        [ 2094],
        [ 2021],
        [ 1949],
        [ 2110],
        [ 2488],
        [ 2411],
        [ 2768],
        [ 2905],
        [ 2874],
        [ 2911],
        [ 2882],
        [ 3188],
        [ 3128],
        [ 2954],
        [ 2875],
        [ 2905]], device='cuda:0')
[2024-07-24 10:23:01,637][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33080],
        [  887],
        [ 2154],
        [ 4165],
        [ 6988],
        [ 9655],
        [11857],
        [ 8162],
        [10721],
        [12766],
        [12768],
        [12176],
        [12679],
        [13300],
        [14367],
        [15350],
        [18361]], device='cuda:0')
[2024-07-24 10:23:01,638][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23767],
        [50195],
        [45880],
        [22843],
        [23650],
        [15328],
        [13205],
        [17723],
        [17386],
        [17773],
        [20411],
        [20265],
        [19341],
        [22111],
        [20135],
        [19412],
        [21330]], device='cuda:0')
[2024-07-24 10:23:01,639][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15193],
        [12037],
        [16427],
        [16410],
        [11103],
        [15093],
        [17036],
        [12961],
        [17234],
        [13669],
        [14139],
        [17477],
        [19267],
        [13008],
        [18916],
        [25474],
        [16709]], device='cuda:0')
[2024-07-24 10:23:01,642][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19545],
        [18816],
        [ 8179],
        [15423],
        [10656],
        [ 1123],
        [  988],
        [ 1369],
        [ 1993],
        [ 2081],
        [ 2388],
        [ 1994],
        [ 2170],
        [ 2162],
        [ 2208],
        [ 2942],
        [ 2395]], device='cuda:0')
[2024-07-24 10:23:01,644][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9838],
        [29860],
        [32320],
        [32656],
        [34408],
        [31079],
        [27801],
        [29003],
        [27771],
        [25433],
        [27117],
        [22675],
        [25052],
        [26711],
        [26945],
        [26072],
        [27621]], device='cuda:0')
[2024-07-24 10:23:01,647][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33718],
        [20147],
        [14825],
        [23386],
        [37037],
        [37065],
        [38506],
        [38175],
        [40117],
        [38350],
        [37528],
        [38697],
        [37511],
        [38806],
        [38554],
        [39119],
        [40255]], device='cuda:0')
[2024-07-24 10:23:01,649][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[35729],
        [39370],
        [33806],
        [33870],
        [35542],
        [35224],
        [37359],
        [34345],
        [35353],
        [35422],
        [34710],
        [35578],
        [34796],
        [32590],
        [33222],
        [34823],
        [31931]], device='cuda:0')
[2024-07-24 10:23:01,652][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[38810],
        [31334],
        [31556],
        [32477],
        [38753],
        [40917],
        [43264],
        [42086],
        [37924],
        [37474],
        [34833],
        [33492],
        [33575],
        [30855],
        [28367],
        [41498],
        [41877]], device='cuda:0')
[2024-07-24 10:23:01,654][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[43041],
        [43032],
        [43658],
        [43977],
        [41551],
        [39535],
        [38923],
        [39331],
        [35561],
        [30027],
        [24812],
        [26624],
        [24047],
        [19886],
        [23006],
        [23586],
        [20975]], device='cuda:0')
[2024-07-24 10:23:01,657][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32895],
        [ 3870],
        [ 3153],
        [ 4195],
        [ 4488],
        [ 3861],
        [ 5021],
        [ 4050],
        [ 3948],
        [ 4674],
        [ 4342],
        [ 4909],
        [ 4377],
        [ 3513],
        [ 3895],
        [ 3585],
        [ 2751]], device='cuda:0')
[2024-07-24 10:23:01,659][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7453],
        [12128],
        [13559],
        [17074],
        [22682],
        [24667],
        [25566],
        [25804],
        [22270],
        [24848],
        [31755],
        [27693],
        [21686],
        [27699],
        [26997],
        [21635],
        [22699]], device='cuda:0')
[2024-07-24 10:23:01,661][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24052],
        [23636],
        [21101],
        [20928],
        [20952],
        [21011],
        [20751],
        [21795],
        [21426],
        [21648],
        [22533],
        [23306],
        [24166],
        [24054],
        [17641],
        [18488],
        [20874]], device='cuda:0')
[2024-07-24 10:23:01,662][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34471],
        [25146],
        [15569],
        [13869],
        [ 8195],
        [ 8435],
        [ 6775],
        [ 9517],
        [11843],
        [10084],
        [11227],
        [ 9404],
        [11250],
        [11464],
        [10176],
        [10606],
        [13618]], device='cuda:0')
[2024-07-24 10:23:01,663][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 5823],
        [23969],
        [26936],
        [28340],
        [20595],
        [15323],
        [14316],
        [17897],
        [13972],
        [13701],
        [12716],
        [13928],
        [12623],
        [13198],
        [12341],
        [13285],
        [13198]], device='cuda:0')
[2024-07-24 10:23:01,664][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8147],
        [29758],
        [25769],
        [21392],
        [18096],
        [15187],
        [17338],
        [17752],
        [16875],
        [18921],
        [19373],
        [18932],
        [18816],
        [19100],
        [19602],
        [20712],
        [20838]], device='cuda:0')
[2024-07-24 10:23:01,665][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17571],
        [18139],
        [30039],
        [25751],
        [25651],
        [29886],
        [27855],
        [27576],
        [28928],
        [29989],
        [30486],
        [30952],
        [32797],
        [33851],
        [35197],
        [32453],
        [31409]], device='cuda:0')
[2024-07-24 10:23:01,668][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33487],
        [37141],
        [17113],
        [27175],
        [17822],
        [19856],
        [32770],
        [19288],
        [23447],
        [25456],
        [27162],
        [34899],
        [32720],
        [27373],
        [32910],
        [26673],
        [24724]], device='cuda:0')
[2024-07-24 10:23:01,670][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739],
        [32739]], device='cuda:0')
[2024-07-24 10:23:01,703][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:01,704][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,704][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,706][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,706][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,707][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,707][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,707][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,708][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,708][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,708][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,708][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,709][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:01,709][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,709][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0244, 0.9756], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,710][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.9826, 0.0174], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,710][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.9641, 0.0359], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,710][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.5609, 0.4391], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,711][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.2588, 0.7412], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,711][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.6860, 0.3140], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,711][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.1454, 0.8546], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,712][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.1150, 0.8850], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,712][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.7847, 0.2153], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,712][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.0766, 0.9234], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,713][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.6008, 0.3992], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:01,713][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9407, 0.0209, 0.0384], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,713][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0452, 0.8597, 0.0950], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,714][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7989, 0.0915, 0.1097], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,714][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6131, 0.3602, 0.0267], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,716][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1375, 0.2537, 0.6088], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,719][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1558, 0.5050, 0.3393], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,723][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3637, 0.5816, 0.0547], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,727][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0276, 0.4285, 0.5440], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,730][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0740, 0.4583, 0.4677], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,731][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7613, 0.1700, 0.0688], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,732][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0047, 0.5082, 0.4871], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,732][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3793, 0.1745, 0.4462], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:01,732][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.9165, 0.0479, 0.0203, 0.0153], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,732][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0079, 0.6663, 0.0543, 0.2715], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,733][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.8670, 0.0706, 0.0342, 0.0281], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,733][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.7883, 0.1669, 0.0127, 0.0322], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,733][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.2244, 0.1503, 0.3184, 0.3069], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,734][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0583, 0.3214, 0.2206, 0.3996], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,734][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.1408, 0.7467, 0.0315, 0.0810], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,735][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0074, 0.3174, 0.4299, 0.2453], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,738][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0328, 0.3024, 0.3329, 0.3319], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,740][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.2488, 0.4174, 0.1111, 0.2228], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,744][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0096, 0.0736, 0.3830, 0.5338], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,747][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.2698, 0.1793, 0.3198, 0.2310], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:01,750][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.6275, 0.0785, 0.1090, 0.0537, 0.1314], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,754][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0070, 0.5491, 0.0370, 0.3074, 0.0995], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,755][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.4252, 0.2389, 0.1348, 0.0751, 0.1261], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,755][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.3889, 0.2581, 0.0322, 0.1205, 0.2003], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,755][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0657, 0.0775, 0.1846, 0.1770, 0.4952], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,756][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0514, 0.2007, 0.1983, 0.2249, 0.3247], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,756][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.2642, 0.5466, 0.0372, 0.1192, 0.0329], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,756][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0029, 0.3103, 0.3510, 0.2523, 0.0836], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,756][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0235, 0.2305, 0.2345, 0.2428, 0.2687], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,757][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ got] are: tensor([0.4999, 0.1663, 0.0729, 0.1599, 0.1010], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,757][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0012, 0.0426, 0.2030, 0.6880, 0.0652], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,757][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0742, 0.1941, 0.2181, 0.2663, 0.2473], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:01,759][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5083, 0.0872, 0.1202, 0.0742, 0.1800, 0.0301], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,761][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0127, 0.4739, 0.0330, 0.2336, 0.1247, 0.1221], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,765][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4565, 0.1997, 0.1143, 0.0849, 0.1241, 0.0206], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,768][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0181, 0.1000, 0.0152, 0.2148, 0.6504, 0.0015], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,771][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0731, 0.0834, 0.1563, 0.0912, 0.3720, 0.2240], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,775][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0245, 0.3724, 0.1060, 0.1595, 0.2684, 0.0694], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,778][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2396, 0.5862, 0.0585, 0.0565, 0.0504, 0.0088], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,778][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0019, 0.2486, 0.3326, 0.2321, 0.0981, 0.0868], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,778][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0317, 0.1889, 0.1988, 0.2001, 0.2077, 0.1728], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,779][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2718, 0.2089, 0.0969, 0.1567, 0.1674, 0.0984], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,779][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([7.7764e-05, 2.1443e-02, 3.1240e-01, 5.5058e-01, 1.0161e-01, 1.3883e-02],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,779][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1096, 0.0942, 0.1750, 0.1232, 0.2198, 0.2782], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:01,780][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.5201, 0.0885, 0.0586, 0.0763, 0.1902, 0.0321, 0.0341],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,780][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0039, 0.3277, 0.0284, 0.1969, 0.1291, 0.0898, 0.2242],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,780][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.2728, 0.1685, 0.1979, 0.1014, 0.2031, 0.0393, 0.0169],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,781][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0017, 0.0641, 0.0085, 0.2642, 0.6550, 0.0057, 0.0008],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,784][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0966, 0.0751, 0.1009, 0.0885, 0.2609, 0.1725, 0.2055],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,786][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0647, 0.2189, 0.1200, 0.2310, 0.2381, 0.0467, 0.0807],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,790][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0621, 0.4303, 0.0322, 0.0541, 0.1187, 0.0448, 0.2578],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,792][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0006, 0.2525, 0.2244, 0.2673, 0.0888, 0.0967, 0.0698],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,795][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0186, 0.1462, 0.1685, 0.1623, 0.1605, 0.1422, 0.2017],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,799][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.1433, 0.2042, 0.0893, 0.1221, 0.1257, 0.0938, 0.2216],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,801][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([1.5421e-04, 3.7352e-02, 2.2887e-01, 5.7078e-01, 9.4562e-02, 5.9503e-02,
        8.7793e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,801][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0363, 0.0921, 0.1980, 0.0936, 0.1739, 0.2691, 0.1371],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:01,802][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3967, 0.1115, 0.1591, 0.0680, 0.1399, 0.0208, 0.0354, 0.0685],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,802][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0082, 0.3798, 0.0262, 0.1647, 0.0912, 0.0812, 0.0975, 0.1511],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,802][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.3654, 0.2500, 0.1421, 0.0926, 0.1100, 0.0153, 0.0087, 0.0159],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,803][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0328, 0.1244, 0.0185, 0.1912, 0.6007, 0.0036, 0.0009, 0.0278],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,803][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0203, 0.0561, 0.1464, 0.0855, 0.2280, 0.2322, 0.1004, 0.1310],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,803][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0121, 0.2542, 0.1421, 0.1234, 0.1666, 0.0513, 0.0652, 0.1850],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,804][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1315, 0.3418, 0.0768, 0.0838, 0.0534, 0.0600, 0.2345, 0.0183],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,805][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0024, 0.2878, 0.2127, 0.2042, 0.0866, 0.0740, 0.0804, 0.0520],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,808][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0176, 0.1323, 0.1476, 0.1414, 0.1552, 0.1252, 0.1549, 0.1257],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,811][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1458, 0.1700, 0.0809, 0.1207, 0.1074, 0.0830, 0.1919, 0.1002],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,814][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0007, 0.0685, 0.1214, 0.5255, 0.1093, 0.0395, 0.0113, 0.1238],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,818][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0364, 0.0934, 0.1629, 0.0904, 0.1519, 0.1951, 0.0899, 0.1799],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:01,821][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5264, 0.1124, 0.0917, 0.0475, 0.1268, 0.0167, 0.0181, 0.0338, 0.0266],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,825][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0078, 0.4194, 0.0177, 0.1381, 0.0546, 0.0506, 0.0885, 0.0714, 0.1520],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,825][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.4436, 0.2008, 0.0942, 0.0886, 0.1116, 0.0173, 0.0092, 0.0145, 0.0203],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,825][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([5.1848e-01, 1.2560e-01, 9.2701e-03, 5.2820e-02, 2.2806e-01, 1.6142e-04,
        4.0862e-05, 1.0484e-03, 6.4515e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,826][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0226, 0.0557, 0.1231, 0.0636, 0.1978, 0.1561, 0.0956, 0.1180, 0.1676],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,826][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0313, 0.2494, 0.0715, 0.1210, 0.1876, 0.0346, 0.0583, 0.1681, 0.0782],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,826][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2178, 0.2966, 0.0825, 0.0359, 0.0321, 0.0048, 0.3226, 0.0069, 0.0008],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,827][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0042, 0.2254, 0.2586, 0.1682, 0.0868, 0.0536, 0.0447, 0.0479, 0.1105],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,827][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0163, 0.1164, 0.1241, 0.1235, 0.1365, 0.1081, 0.1574, 0.1133, 0.1044],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,827][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1363, 0.1203, 0.0737, 0.1051, 0.1167, 0.0847, 0.1955, 0.0916, 0.0763],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,828][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0011, 0.0250, 0.1432, 0.3391, 0.0984, 0.0108, 0.0025, 0.3118, 0.0681],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,829][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0697, 0.0952, 0.1244, 0.1138, 0.0953, 0.1590, 0.0784, 0.1548, 0.1094],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:01,832][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.5211, 0.0950, 0.0732, 0.0719, 0.1280, 0.0140, 0.0248, 0.0274, 0.0202,
        0.0244], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,835][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0010, 0.1688, 0.0150, 0.1163, 0.0561, 0.0658, 0.1158, 0.0525, 0.1982,
        0.2104], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,838][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.4151, 0.1380, 0.0991, 0.0872, 0.1349, 0.0363, 0.0146, 0.0212, 0.0321,
        0.0215], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,841][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ house] are: tensor([4.1138e-01, 1.2399e-01, 1.2493e-02, 5.4257e-02, 1.8390e-01, 5.0881e-05,
        1.1558e-05, 3.1196e-04, 3.8045e-02, 1.7556e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,845][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0427, 0.0306, 0.0588, 0.0615, 0.1420, 0.1507, 0.0826, 0.0753, 0.2476,
        0.1082], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,848][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ house] are: tensor([0.0274, 0.1053, 0.0535, 0.0800, 0.0547, 0.0230, 0.0246, 0.0599, 0.0440,
        0.5275], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,849][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0348, 0.3536, 0.1126, 0.0433, 0.0179, 0.0848, 0.2208, 0.0472, 0.0371,
        0.0481], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,849][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0017, 0.1763, 0.2199, 0.1501, 0.0788, 0.0482, 0.0351, 0.0382, 0.1004,
        0.1512], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,850][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0095, 0.1023, 0.1125, 0.1083, 0.1185, 0.1087, 0.1318, 0.1135, 0.1071,
        0.0879], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,850][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ house] are: tensor([0.0516, 0.1393, 0.0563, 0.0797, 0.0975, 0.0650, 0.1383, 0.1001, 0.0767,
        0.1956], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,850][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0013, 0.0510, 0.0681, 0.4021, 0.0612, 0.0106, 0.0035, 0.2283, 0.1210,
        0.0529], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,851][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0347, 0.0708, 0.1441, 0.1027, 0.0880, 0.1442, 0.0674, 0.1291, 0.0942,
        0.1247], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:01,851][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4121, 0.1335, 0.1134, 0.0584, 0.1406, 0.0121, 0.0280, 0.0302, 0.0268,
        0.0144, 0.0305], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,851][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0091, 0.2045, 0.0173, 0.1003, 0.0498, 0.0486, 0.0872, 0.0889, 0.1334,
        0.1830, 0.0780], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,852][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3774, 0.1537, 0.0884, 0.0729, 0.1504, 0.0186, 0.0128, 0.0200, 0.0226,
        0.0096, 0.0736], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,853][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.9799e-01, 6.9674e-02, 4.7438e-03, 1.8317e-02, 8.6575e-02, 1.5697e-04,
        6.5639e-05, 1.1886e-03, 5.4744e-02, 4.0857e-01, 5.7976e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,855][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0139, 0.0331, 0.1004, 0.0566, 0.1272, 0.1291, 0.0792, 0.0840, 0.1890,
        0.1176, 0.0699], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,858][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0131, 0.0903, 0.0581, 0.0776, 0.1061, 0.0221, 0.0290, 0.0817, 0.0499,
        0.3904, 0.0816], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,862][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1063, 0.2312, 0.0295, 0.0548, 0.0181, 0.0086, 0.0435, 0.0059, 0.0017,
        0.4954, 0.0051], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,866][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0054, 0.1816, 0.1526, 0.1125, 0.0608, 0.0418, 0.0446, 0.0387, 0.1125,
        0.1508, 0.0987], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,869][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0115, 0.0939, 0.1043, 0.0990, 0.1089, 0.0927, 0.1221, 0.0956, 0.0914,
        0.0793, 0.1014], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,873][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1390, 0.0961, 0.0530, 0.0859, 0.0868, 0.0647, 0.1118, 0.0621, 0.0627,
        0.2037, 0.0343], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,875][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0005, 0.0553, 0.0564, 0.4776, 0.0376, 0.0146, 0.0041, 0.0683, 0.1193,
        0.1430, 0.0232], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,875][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0263, 0.0274, 0.1312, 0.0478, 0.0777, 0.1116, 0.0652, 0.1546, 0.0655,
        0.1043, 0.1883], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:01,876][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.3702, 0.3307, 0.0474, 0.0655, 0.1012, 0.0077, 0.0132, 0.0165, 0.0128,
        0.0080, 0.0130, 0.0136], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,876][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0008, 0.2014, 0.0072, 0.0764, 0.0274, 0.0210, 0.0425, 0.0361, 0.0867,
        0.0837, 0.0256, 0.3912], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,876][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.4956, 0.1569, 0.0426, 0.0590, 0.0823, 0.0187, 0.0087, 0.0130, 0.0215,
        0.0106, 0.0551, 0.0361], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,877][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ William] are: tensor([3.2954e-01, 3.2643e-02, 2.8558e-03, 6.9990e-03, 6.0886e-02, 1.6672e-05,
        6.3249e-06, 2.6416e-04, 4.8274e-02, 3.1312e-01, 1.1170e-01, 9.3697e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,877][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0292, 0.0255, 0.0642, 0.0605, 0.1168, 0.1071, 0.0852, 0.0650, 0.1669,
        0.1181, 0.0630, 0.0984], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,877][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0173, 0.0853, 0.0772, 0.1348, 0.1171, 0.0332, 0.0159, 0.0469, 0.0397,
        0.1874, 0.1175, 0.1278], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,878][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0045, 0.0787, 0.0059, 0.0087, 0.0072, 0.0039, 0.1081, 0.0040, 0.0026,
        0.7539, 0.0124, 0.0102], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,879][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0030, 0.1832, 0.1424, 0.1117, 0.0498, 0.0369, 0.0324, 0.0301, 0.0981,
        0.1302, 0.0937, 0.0885], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,882][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0063, 0.0821, 0.0919, 0.0906, 0.0983, 0.0876, 0.1044, 0.0883, 0.0919,
        0.0686, 0.0912, 0.0990], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,885][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0263, 0.1342, 0.0408, 0.0691, 0.0659, 0.0595, 0.1342, 0.0624, 0.0540,
        0.2241, 0.0329, 0.0966], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,889][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0039, 0.0262, 0.0822, 0.1685, 0.0731, 0.0112, 0.0029, 0.1532, 0.1037,
        0.0995, 0.1271, 0.1484], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,892][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0208, 0.0532, 0.0638, 0.0930, 0.0684, 0.0769, 0.0410, 0.0757, 0.0481,
        0.0911, 0.0768, 0.2912], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:01,896][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.4181, 0.0986, 0.0908, 0.0470, 0.0893, 0.0203, 0.0193, 0.0196, 0.0247,
        0.0167, 0.0246, 0.0139, 0.1172], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,899][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0007, 0.2490, 0.0102, 0.1137, 0.0161, 0.0319, 0.0373, 0.0225, 0.0825,
        0.0629, 0.0265, 0.3254, 0.0213], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,899][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.4094, 0.1216, 0.0712, 0.0550, 0.1277, 0.0176, 0.0071, 0.0115, 0.0165,
        0.0097, 0.0459, 0.0176, 0.0893], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,900][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([7.4727e-01, 2.4398e-02, 4.8271e-03, 5.6846e-03, 2.1064e-02, 4.9591e-06,
        1.3439e-06, 1.8572e-05, 9.5240e-04, 3.3923e-03, 5.8196e-03, 1.6171e-03,
        1.8495e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,900][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0208, 0.0158, 0.0574, 0.0309, 0.1012, 0.0666, 0.0379, 0.0574, 0.1321,
        0.0582, 0.0400, 0.0475, 0.3340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,900][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0050, 0.0215, 0.0515, 0.0386, 0.0692, 0.0142, 0.0081, 0.0466, 0.0251,
        0.1249, 0.0784, 0.0470, 0.4699], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,901][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0182, 0.1505, 0.0503, 0.0376, 0.0305, 0.0641, 0.1206, 0.0233, 0.0153,
        0.2566, 0.1285, 0.0242, 0.0804], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,901][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0041, 0.1999, 0.1678, 0.1216, 0.0485, 0.0288, 0.0213, 0.0262, 0.0645,
        0.0980, 0.0640, 0.0692, 0.0861], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,902][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0061, 0.0742, 0.0807, 0.0777, 0.0879, 0.0788, 0.0931, 0.0826, 0.0739,
        0.0640, 0.0801, 0.0857, 0.1150], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,905][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0549, 0.0785, 0.0451, 0.0630, 0.0580, 0.0635, 0.0922, 0.0711, 0.0657,
        0.1246, 0.0472, 0.0958, 0.1406], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,907][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0008, 0.0419, 0.1549, 0.2207, 0.0611, 0.0115, 0.0018, 0.1571, 0.0949,
        0.0616, 0.0551, 0.1023, 0.0362], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,911][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0128, 0.0651, 0.0602, 0.0469, 0.0455, 0.0840, 0.0538, 0.1091, 0.0581,
        0.1060, 0.0806, 0.1847, 0.0930], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:01,914][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3141, 0.0914, 0.1612, 0.0820, 0.1306, 0.0093, 0.0131, 0.0244, 0.0159,
        0.0101, 0.0253, 0.0187, 0.0716, 0.0324], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,918][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0099, 0.3048, 0.0165, 0.0784, 0.0437, 0.0270, 0.0304, 0.0415, 0.0823,
        0.0954, 0.0473, 0.1533, 0.0352, 0.0340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,922][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3410, 0.1176, 0.0744, 0.0901, 0.0877, 0.0139, 0.0069, 0.0109, 0.0108,
        0.0038, 0.0383, 0.0188, 0.0587, 0.1270], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,923][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2326e-01, 1.5332e-02, 1.0766e-03, 3.1949e-03, 1.6184e-02, 4.4754e-06,
        2.1345e-06, 2.0862e-05, 1.8471e-03, 1.2811e-02, 4.9975e-03, 4.1369e-03,
        7.1041e-01, 1.0672e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,923][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0037, 0.0135, 0.0648, 0.0277, 0.0885, 0.0824, 0.0367, 0.0476, 0.0997,
        0.0587, 0.0442, 0.0440, 0.2338, 0.1547], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,923][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0109, 0.0621, 0.0333, 0.0349, 0.0621, 0.0142, 0.0219, 0.0460, 0.0274,
        0.1947, 0.0485, 0.0386, 0.2396, 0.1657], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,924][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0405, 0.2249, 0.0362, 0.0274, 0.0149, 0.0113, 0.0825, 0.0085, 0.0072,
        0.3986, 0.0226, 0.0193, 0.0884, 0.0177], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,924][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0046, 0.2027, 0.1465, 0.0908, 0.0420, 0.0248, 0.0204, 0.0214, 0.0657,
        0.0945, 0.0608, 0.0613, 0.0992, 0.0652], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,924][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0064, 0.0709, 0.0814, 0.0728, 0.0813, 0.0705, 0.0877, 0.0726, 0.0663,
        0.0589, 0.0772, 0.0766, 0.1063, 0.0713], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,925][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0211, 0.0751, 0.0495, 0.0595, 0.0727, 0.0563, 0.0835, 0.0488, 0.0585,
        0.1459, 0.0361, 0.0818, 0.1448, 0.0667], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,925][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0015, 0.0338, 0.0301, 0.2248, 0.0268, 0.0035, 0.0023, 0.0362, 0.0395,
        0.0862, 0.0555, 0.1832, 0.1618, 0.1148], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,927][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0512, 0.0416, 0.1557, 0.0406, 0.0587, 0.0875, 0.0344, 0.0858, 0.0551,
        0.0429, 0.1021, 0.0696, 0.0550, 0.1197], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:01,929][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2021, 0.1162, 0.1222, 0.0816, 0.1366, 0.0126, 0.0173, 0.0268, 0.0199,
        0.0155, 0.0241, 0.0169, 0.0419, 0.0263, 0.1397], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,933][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0047, 0.2353, 0.0094, 0.0675, 0.0194, 0.0285, 0.0324, 0.0264, 0.0937,
        0.1025, 0.0442, 0.2338, 0.0205, 0.0257, 0.0560], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,936][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1699, 0.1524, 0.0486, 0.0556, 0.0763, 0.0086, 0.0044, 0.0056, 0.0090,
        0.0060, 0.0214, 0.0104, 0.0566, 0.0695, 0.3058], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,938][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([6.0035e-01, 1.1301e-02, 1.7648e-03, 1.5543e-03, 7.8975e-03, 1.1695e-06,
        4.3481e-07, 6.6619e-06, 3.8860e-04, 1.6585e-03, 2.7605e-03, 4.1053e-04,
        1.4678e-01, 5.1678e-02, 1.7344e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,942][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0088, 0.0162, 0.0325, 0.0238, 0.0939, 0.0650, 0.0353, 0.0435, 0.0941,
        0.0483, 0.0356, 0.0414, 0.2435, 0.1176, 0.1005], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,946][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0170, 0.0492, 0.0583, 0.0406, 0.0284, 0.0160, 0.0160, 0.0290, 0.0264,
        0.1137, 0.0774, 0.0423, 0.2700, 0.1390, 0.0767], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,947][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0609, 0.1590, 0.0374, 0.0304, 0.0202, 0.0224, 0.0885, 0.0103, 0.0104,
        0.3239, 0.0325, 0.0262, 0.0892, 0.0183, 0.0703], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,947][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0033, 0.1667, 0.1581, 0.0840, 0.0494, 0.0254, 0.0220, 0.0239, 0.0633,
        0.0718, 0.0556, 0.0516, 0.0823, 0.0626, 0.0799], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,948][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0055, 0.0627, 0.0716, 0.0702, 0.0773, 0.0673, 0.0819, 0.0699, 0.0661,
        0.0533, 0.0700, 0.0754, 0.0983, 0.0654, 0.0650], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,948][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0551, 0.0688, 0.0329, 0.0547, 0.0507, 0.0464, 0.0867, 0.0660, 0.0506,
        0.1293, 0.0319, 0.0894, 0.0985, 0.0611, 0.0780], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,948][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0045, 0.0271, 0.0489, 0.1989, 0.0190, 0.0055, 0.0028, 0.0425, 0.0186,
        0.0329, 0.0250, 0.0967, 0.0332, 0.1711, 0.2732], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,949][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0350, 0.0644, 0.0647, 0.0368, 0.0376, 0.0548, 0.0317, 0.0347, 0.0452,
        0.0438, 0.0462, 0.1267, 0.0441, 0.0533, 0.2810], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:01,949][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.2449, 0.1717, 0.0711, 0.0806, 0.1121, 0.0102, 0.0050, 0.0153, 0.0174,
        0.0053, 0.0127, 0.0082, 0.0784, 0.0192, 0.0743, 0.0736],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,951][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0025, 0.2031, 0.0093, 0.0940, 0.0227, 0.0247, 0.0454, 0.0230, 0.0588,
        0.0463, 0.0259, 0.2505, 0.0393, 0.0174, 0.0427, 0.0945],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,953][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.1870, 0.1085, 0.0244, 0.0329, 0.0979, 0.0077, 0.0047, 0.0046, 0.0091,
        0.0038, 0.0248, 0.0054, 0.0632, 0.0446, 0.2363, 0.1451],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,955][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ it] are: tensor([3.4210e-01, 1.0484e-02, 5.5830e-04, 1.0459e-03, 2.7132e-03, 5.0748e-07,
        1.4950e-07, 1.1011e-06, 6.6188e-05, 2.3936e-04, 3.8034e-04, 1.0590e-04,
        3.4896e-02, 4.8137e-03, 7.9863e-02, 5.2273e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,959][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.0061, 0.0116, 0.0512, 0.0192, 0.0725, 0.0622, 0.0312, 0.0533, 0.0720,
        0.0436, 0.0604, 0.0352, 0.1579, 0.1209, 0.0917, 0.1109],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,962][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ it] are: tensor([0.0085, 0.0740, 0.0417, 0.0551, 0.0393, 0.0106, 0.0111, 0.0433, 0.0192,
        0.0890, 0.0566, 0.0417, 0.2402, 0.1216, 0.0837, 0.0644],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,966][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0201, 0.0561, 0.0763, 0.0349, 0.0549, 0.0359, 0.0259, 0.0192, 0.0067,
        0.1935, 0.1271, 0.0238, 0.0680, 0.0364, 0.2121, 0.0090],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,970][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0066, 0.1583, 0.1677, 0.0911, 0.0467, 0.0242, 0.0140, 0.0204, 0.0504,
        0.0473, 0.0590, 0.0407, 0.0741, 0.0564, 0.0657, 0.0776],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,970][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0038, 0.0576, 0.0667, 0.0609, 0.0719, 0.0615, 0.0744, 0.0681, 0.0604,
        0.0511, 0.0691, 0.0678, 0.0955, 0.0642, 0.0624, 0.0648],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,971][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ it] are: tensor([0.0399, 0.0466, 0.0316, 0.0484, 0.0464, 0.0524, 0.0730, 0.0435, 0.0489,
        0.1319, 0.0362, 0.0737, 0.1044, 0.0654, 0.1035, 0.0542],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,971][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0013, 0.0229, 0.0289, 0.1664, 0.0275, 0.0022, 0.0007, 0.0446, 0.0168,
        0.0140, 0.0214, 0.0763, 0.0319, 0.1297, 0.3659, 0.0495],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,972][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0256, 0.0130, 0.0406, 0.0302, 0.0283, 0.0603, 0.0227, 0.0473, 0.0312,
        0.0286, 0.0545, 0.0798, 0.0374, 0.0825, 0.1826, 0.2355],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:01,972][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4124, 0.0523, 0.0934, 0.0469, 0.0857, 0.0042, 0.0077, 0.0143, 0.0104,
        0.0044, 0.0134, 0.0076, 0.0438, 0.0163, 0.1090, 0.0586, 0.0196],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,972][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0133, 0.2427, 0.0101, 0.0443, 0.0247, 0.0136, 0.0204, 0.0206, 0.0603,
        0.0568, 0.0309, 0.1137, 0.0271, 0.0185, 0.0405, 0.2248, 0.0376],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,973][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4115, 0.0908, 0.0517, 0.0431, 0.0622, 0.0052, 0.0029, 0.0038, 0.0052,
        0.0013, 0.0180, 0.0044, 0.0242, 0.0472, 0.0871, 0.0768, 0.0646],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,973][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.7927e-02, 4.2822e-04, 4.1698e-05, 8.2869e-05, 4.4969e-04, 6.0827e-08,
        2.2640e-08, 2.5518e-07, 2.6585e-05, 2.4085e-04, 1.1254e-04, 4.2186e-05,
        2.2880e-02, 2.5093e-03, 4.8446e-02, 8.8839e-01, 1.8420e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,975][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0019, 0.0106, 0.0452, 0.0211, 0.0589, 0.0639, 0.0248, 0.0356, 0.0839,
        0.0476, 0.0356, 0.0324, 0.1601, 0.1098, 0.0810, 0.1024, 0.0851],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,977][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0091, 0.0441, 0.0284, 0.0327, 0.0388, 0.0105, 0.0139, 0.0364, 0.0221,
        0.1219, 0.0397, 0.0320, 0.1869, 0.1243, 0.0539, 0.0602, 0.1450],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,981][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0374, 0.2427, 0.0322, 0.0241, 0.0144, 0.0114, 0.0502, 0.0076, 0.0057,
        0.3109, 0.0258, 0.0148, 0.0926, 0.0130, 0.1034, 0.0044, 0.0094],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,984][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0058, 0.1721, 0.1198, 0.0777, 0.0383, 0.0181, 0.0152, 0.0159, 0.0493,
        0.0633, 0.0453, 0.0463, 0.0806, 0.0485, 0.0644, 0.0845, 0.0549],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,988][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0045, 0.0582, 0.0672, 0.0592, 0.0663, 0.0586, 0.0733, 0.0619, 0.0551,
        0.0496, 0.0643, 0.0629, 0.0876, 0.0598, 0.0563, 0.0579, 0.0573],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,992][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0162, 0.0651, 0.0371, 0.0455, 0.0586, 0.0465, 0.0692, 0.0435, 0.0475,
        0.1171, 0.0324, 0.0639, 0.1160, 0.0552, 0.0829, 0.0517, 0.0514],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,994][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0006, 0.0082, 0.0076, 0.0525, 0.0072, 0.0008, 0.0005, 0.0081, 0.0089,
        0.0174, 0.0136, 0.0372, 0.0362, 0.0260, 0.3134, 0.4057, 0.0559],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:01,995][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0492, 0.0275, 0.0774, 0.0268, 0.0306, 0.0480, 0.0188, 0.0466, 0.0315,
        0.0210, 0.0556, 0.0396, 0.0276, 0.0563, 0.1515, 0.1473, 0.1447],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,039][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:02,039][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,039][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,040][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,040][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,040][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,041][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,041][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,041][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,042][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,042][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,042][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,042][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,045][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,047][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0244, 0.9756], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,050][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.9826, 0.0174], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,054][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.9641, 0.0359], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,058][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.2447, 0.7553], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,061][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.8698, 0.1302], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,063][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.0054, 0.9946], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,063][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.6301, 0.3699], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,063][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.9680, 0.0320], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,064][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0015, 0.9985], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,064][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0332, 0.9668], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,064][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.6008, 0.3992], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,064][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9407, 0.0209, 0.0384], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,065][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0452, 0.8597, 0.0950], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,065][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7989, 0.0915, 0.1097], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,067][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6131, 0.3602, 0.0267], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,069][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0307, 0.8818, 0.0874], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,072][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6722, 0.2057, 0.1221], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,076][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0046, 0.5733, 0.4222], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,079][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3314, 0.2880, 0.3806], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,083][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8613, 0.0625, 0.0762], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,086][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0013, 0.5065, 0.4923], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,086][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0040, 0.9576, 0.0384], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,086][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3793, 0.1745, 0.4462], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,087][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.9165, 0.0479, 0.0203, 0.0153], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,087][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0079, 0.6663, 0.0543, 0.2715], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,087][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.8670, 0.0706, 0.0342, 0.0281], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,087][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.7883, 0.1669, 0.0127, 0.0322], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,088][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.1064, 0.5327, 0.0527, 0.3081], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,088][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.7269, 0.1547, 0.0654, 0.0530], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,088][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0024, 0.4664, 0.1150, 0.4161], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,090][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.1116, 0.2450, 0.3724, 0.2710], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,092][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.8515, 0.0682, 0.0629, 0.0173], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,094][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([1.8510e-04, 2.8312e-01, 7.0752e-02, 6.4595e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,097][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0046, 0.4668, 0.0119, 0.5167], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,101][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.2698, 0.1793, 0.3198, 0.2310], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,105][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.6275, 0.0785, 0.1090, 0.0537, 0.1314], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,108][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0070, 0.5491, 0.0370, 0.3074, 0.0995], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,109][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.4252, 0.2389, 0.1348, 0.0751, 0.1261], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,110][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.3889, 0.2581, 0.0322, 0.1205, 0.2003], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,110][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0120, 0.5474, 0.0410, 0.3337, 0.0659], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,110][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.5407, 0.1760, 0.0877, 0.0658, 0.1297], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,111][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0009, 0.3206, 0.1545, 0.3951, 0.1289], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,111][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0467, 0.2536, 0.2887, 0.3051, 0.1060], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,111][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.2495, 0.3463, 0.1334, 0.2108, 0.0600], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,111][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([1.9064e-04, 1.3421e-01, 1.3415e-01, 5.6185e-01, 1.6960e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,112][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0017, 0.2711, 0.0215, 0.5848, 0.1210], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,115][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0742, 0.1941, 0.2181, 0.2663, 0.2473], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,117][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5083, 0.0872, 0.1202, 0.0742, 0.1800, 0.0301], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,121][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0127, 0.4739, 0.0330, 0.2336, 0.1247, 0.1221], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,124][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4565, 0.1997, 0.1143, 0.0849, 0.1241, 0.0206], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,128][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0181, 0.1000, 0.0152, 0.2148, 0.6504, 0.0015], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,132][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0154, 0.5986, 0.0518, 0.2058, 0.0734, 0.0550], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,132][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5052, 0.1905, 0.0927, 0.0671, 0.1334, 0.0110], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,133][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.0551e-04, 2.6020e-01, 5.5817e-02, 1.7897e-01, 9.0234e-02, 4.1437e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,133][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0175, 0.1689, 0.2823, 0.3219, 0.1467, 0.0627], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,133][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4307, 0.2356, 0.1645, 0.0976, 0.0504, 0.0211], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,134][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.1173e-04, 8.8214e-02, 5.3406e-02, 2.3022e-01, 1.3242e-01, 4.9563e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,134][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.7467e-05, 9.5113e-02, 6.6791e-03, 7.2832e-01, 1.6711e-01, 2.7117e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,134][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1096, 0.0942, 0.1750, 0.1232, 0.2198, 0.2782], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,135][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.5201, 0.0885, 0.0586, 0.0763, 0.1902, 0.0321, 0.0341],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,135][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0039, 0.3277, 0.0284, 0.1969, 0.1291, 0.0898, 0.2242],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,135][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.2728, 0.1685, 0.1979, 0.1014, 0.2031, 0.0393, 0.0169],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,137][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0017, 0.0641, 0.0085, 0.2642, 0.6550, 0.0057, 0.0008],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,139][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0259, 0.5164, 0.0320, 0.2222, 0.0775, 0.0583, 0.0677],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,143][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.4823, 0.1703, 0.0511, 0.0789, 0.1632, 0.0110, 0.0433],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,145][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([2.7096e-04, 1.2523e-01, 3.8599e-02, 2.0922e-01, 6.8425e-02, 4.6131e-01,
        9.6941e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,148][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0033, 0.1373, 0.1060, 0.4335, 0.1399, 0.1247, 0.0553],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,152][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.3870, 0.3140, 0.1355, 0.0916, 0.0315, 0.0306, 0.0099],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,154][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([1.1590e-05, 5.9181e-02, 5.3491e-02, 2.4228e-01, 3.6577e-02, 4.8233e-01,
        1.2613e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,156][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([1.9324e-05, 7.0276e-02, 3.9894e-03, 6.8346e-01, 2.3374e-01, 7.3143e-03,
        1.2032e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,156][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0363, 0.0921, 0.1980, 0.0936, 0.1739, 0.2691, 0.1371],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,157][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.3967, 0.1115, 0.1591, 0.0680, 0.1399, 0.0208, 0.0354, 0.0685],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,157][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0082, 0.3798, 0.0262, 0.1647, 0.0912, 0.0812, 0.0975, 0.1511],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,157][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3654, 0.2500, 0.1421, 0.0926, 0.1100, 0.0153, 0.0087, 0.0159],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,158][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0328, 0.1244, 0.0185, 0.1912, 0.6007, 0.0036, 0.0009, 0.0278],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,158][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0172, 0.5570, 0.0470, 0.2056, 0.0330, 0.0408, 0.0512, 0.0483],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,158][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.2994, 0.2253, 0.1280, 0.0799, 0.1489, 0.0140, 0.0194, 0.0851],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,160][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0008, 0.2196, 0.0815, 0.2047, 0.1040, 0.2633, 0.0437, 0.0824],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,162][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0190, 0.2497, 0.1567, 0.2984, 0.1474, 0.0477, 0.0508, 0.0303],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,166][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2288, 0.4437, 0.1203, 0.1216, 0.0265, 0.0220, 0.0129, 0.0243],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,168][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([4.7371e-05, 1.1945e-01, 7.0250e-02, 2.1908e-01, 3.7670e-02, 2.6998e-01,
        7.7189e-02, 2.0633e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,170][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([2.0561e-04, 1.0631e-01, 1.1048e-02, 6.3529e-01, 2.2727e-01, 6.9677e-03,
        1.6478e-03, 1.1273e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,173][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0364, 0.0934, 0.1629, 0.0904, 0.1519, 0.1951, 0.0899, 0.1799],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,177][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.5264, 0.1124, 0.0917, 0.0475, 0.1268, 0.0167, 0.0181, 0.0338, 0.0266],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,179][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0078, 0.4194, 0.0177, 0.1381, 0.0546, 0.0506, 0.0885, 0.0714, 0.1520],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,179][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4436, 0.2008, 0.0942, 0.0886, 0.1116, 0.0173, 0.0092, 0.0145, 0.0203],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,180][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([5.1848e-01, 1.2560e-01, 9.2701e-03, 5.2820e-02, 2.2806e-01, 1.6142e-04,
        4.0862e-05, 1.0484e-03, 6.4515e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,180][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0143, 0.5297, 0.0656, 0.1768, 0.0607, 0.0352, 0.0377, 0.0463, 0.0337],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,180][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5138, 0.1849, 0.0618, 0.0560, 0.0970, 0.0070, 0.0155, 0.0423, 0.0218],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,181][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0004, 0.2651, 0.0528, 0.1902, 0.0795, 0.2103, 0.0373, 0.0757, 0.0886],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,181][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0560, 0.1885, 0.2636, 0.1977, 0.1350, 0.0208, 0.0149, 0.0212, 0.1023],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,181][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3638, 0.2957, 0.0970, 0.1250, 0.0358, 0.0153, 0.0087, 0.0317, 0.0268],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,182][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.6416e-05, 1.0096e-01, 2.8782e-02, 1.6470e-01, 4.5550e-02, 2.2962e-01,
        9.4198e-02, 1.4163e-01, 1.9452e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,183][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.0762e-03, 1.8657e-01, 1.3963e-02, 3.5117e-01, 2.2524e-01, 7.6307e-04,
        1.5096e-04, 1.3688e-03, 2.1670e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,185][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0697, 0.0952, 0.1244, 0.1138, 0.0953, 0.1590, 0.0784, 0.1548, 0.1094],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,188][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.5211, 0.0950, 0.0732, 0.0719, 0.1280, 0.0140, 0.0248, 0.0274, 0.0202,
        0.0244], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,191][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0010, 0.1688, 0.0150, 0.1163, 0.0561, 0.0658, 0.1158, 0.0525, 0.1982,
        0.2104], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,195][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.4151, 0.1380, 0.0991, 0.0872, 0.1349, 0.0363, 0.0146, 0.0212, 0.0321,
        0.0215], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,197][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([4.1138e-01, 1.2399e-01, 1.2493e-02, 5.4257e-02, 1.8390e-01, 5.0881e-05,
        1.1558e-05, 3.1196e-04, 3.8045e-02, 1.7556e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,200][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0116, 0.2967, 0.0588, 0.2192, 0.0700, 0.0496, 0.0609, 0.0708, 0.0649,
        0.0975], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,203][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([0.4819, 0.1557, 0.0598, 0.0538, 0.0816, 0.0070, 0.0177, 0.0424, 0.0252,
        0.0749], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,203][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([8.5310e-05, 1.3761e-01, 2.5250e-02, 1.2002e-01, 5.4544e-02, 2.7559e-01,
        5.3889e-02, 8.6854e-02, 1.2345e-01, 1.2270e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,203][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0126, 0.1119, 0.1871, 0.1959, 0.1307, 0.0222, 0.0106, 0.0201, 0.1304,
        0.1784], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,204][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.2461, 0.3575, 0.0734, 0.1685, 0.0337, 0.0156, 0.0114, 0.0267, 0.0417,
        0.0253], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,204][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([2.5055e-06, 2.0110e-02, 1.2125e-02, 1.0468e-01, 2.5749e-02, 2.0137e-01,
        9.2921e-02, 8.1401e-02, 1.7224e-01, 2.8940e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,204][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([2.4537e-03, 1.5073e-01, 8.4099e-03, 3.9194e-01, 1.0735e-01, 1.5703e-04,
        2.3412e-05, 3.1533e-04, 8.0917e-02, 2.5770e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,205][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.0347, 0.0708, 0.1441, 0.1027, 0.0880, 0.1442, 0.0674, 0.1291, 0.0942,
        0.1247], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,205][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4121, 0.1335, 0.1134, 0.0584, 0.1406, 0.0121, 0.0280, 0.0302, 0.0268,
        0.0144, 0.0305], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,207][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0091, 0.2045, 0.0173, 0.1003, 0.0498, 0.0486, 0.0872, 0.0889, 0.1334,
        0.1830, 0.0780], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,209][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3774, 0.1537, 0.0884, 0.0729, 0.1504, 0.0186, 0.0128, 0.0200, 0.0226,
        0.0096, 0.0736], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,211][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.9799e-01, 6.9674e-02, 4.7438e-03, 1.8317e-02, 8.6575e-02, 1.5697e-04,
        6.5639e-05, 1.1886e-03, 5.4744e-02, 4.0857e-01, 5.7976e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,215][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0131, 0.4636, 0.0483, 0.1939, 0.0465, 0.0320, 0.0364, 0.0513, 0.0402,
        0.0412, 0.0333], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,218][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3643, 0.1589, 0.0619, 0.0597, 0.1096, 0.0080, 0.0204, 0.0555, 0.0262,
        0.0524, 0.0832], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,222][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0004, 0.1898, 0.0678, 0.1891, 0.1002, 0.1962, 0.0286, 0.0698, 0.0890,
        0.0426, 0.0266], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,226][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0592, 0.1450, 0.1290, 0.1086, 0.0844, 0.0142, 0.0162, 0.0149, 0.1048,
        0.1144, 0.2093], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,226][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3790, 0.3390, 0.0727, 0.0837, 0.0220, 0.0111, 0.0097, 0.0234, 0.0140,
        0.0183, 0.0269], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,227][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.8863e-05, 5.0263e-02, 4.0115e-02, 1.2358e-01, 4.8246e-02, 2.2563e-01,
        5.9371e-02, 9.1648e-02, 1.3304e-01, 1.5315e-01, 7.4913e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,227][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.3299e-03, 1.0156e-01, 5.6409e-03, 1.4348e-01, 5.9870e-02, 6.8083e-04,
        1.7204e-04, 1.2620e-03, 1.7024e-01, 4.3862e-01, 7.7146e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,227][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0263, 0.0274, 0.1312, 0.0478, 0.0777, 0.1116, 0.0652, 0.1546, 0.0655,
        0.1043, 0.1883], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,228][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.3702, 0.3307, 0.0474, 0.0655, 0.1012, 0.0077, 0.0132, 0.0165, 0.0128,
        0.0080, 0.0130, 0.0136], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,228][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0008, 0.2014, 0.0072, 0.0764, 0.0274, 0.0210, 0.0425, 0.0361, 0.0867,
        0.0837, 0.0256, 0.3912], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,228][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.4956, 0.1569, 0.0426, 0.0590, 0.0823, 0.0187, 0.0087, 0.0130, 0.0215,
        0.0106, 0.0551, 0.0361], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,229][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([3.2954e-01, 3.2643e-02, 2.8558e-03, 6.9990e-03, 6.0886e-02, 1.6672e-05,
        6.3249e-06, 2.6416e-04, 4.8274e-02, 3.1312e-01, 1.1170e-01, 9.3697e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,229][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0257, 0.2177, 0.0353, 0.2035, 0.0594, 0.0371, 0.0414, 0.0482, 0.0443,
        0.0750, 0.0412, 0.1712], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,231][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.6404, 0.1103, 0.0360, 0.0559, 0.0645, 0.0025, 0.0054, 0.0104, 0.0066,
        0.0117, 0.0311, 0.0253], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,233][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([1.2219e-04, 1.0626e-01, 1.9845e-02, 9.4406e-02, 5.5323e-02, 1.7397e-01,
        5.0252e-02, 6.3784e-02, 1.1298e-01, 1.0432e-01, 3.6297e-02, 1.8244e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,235][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0193, 0.1099, 0.0858, 0.1133, 0.0533, 0.0094, 0.0065, 0.0092, 0.1011,
        0.1244, 0.2422, 0.1256], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,239][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.2403, 0.4349, 0.0681, 0.0754, 0.0196, 0.0099, 0.0079, 0.0151, 0.0175,
        0.0177, 0.0364, 0.0570], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,242][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([2.4351e-06, 1.7180e-02, 3.4634e-03, 4.1179e-02, 1.0824e-02, 5.6302e-02,
        4.3969e-02, 3.8356e-02, 6.0914e-02, 9.3174e-02, 2.2430e-02, 6.1221e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,244][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([8.1497e-04, 4.0632e-02, 1.6128e-03, 5.2945e-02, 1.7126e-02, 5.5012e-05,
        7.0292e-06, 2.0197e-04, 8.3749e-02, 2.7486e-01, 4.3227e-02, 4.8477e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,247][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0208, 0.0532, 0.0638, 0.0930, 0.0684, 0.0769, 0.0410, 0.0757, 0.0481,
        0.0911, 0.0768, 0.2912], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,251][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.4181, 0.0986, 0.0908, 0.0470, 0.0893, 0.0203, 0.0193, 0.0196, 0.0247,
        0.0167, 0.0246, 0.0139, 0.1172], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,251][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0007, 0.2490, 0.0102, 0.1137, 0.0161, 0.0319, 0.0373, 0.0225, 0.0825,
        0.0629, 0.0265, 0.3254, 0.0213], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,252][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.4094, 0.1216, 0.0712, 0.0550, 0.1277, 0.0176, 0.0071, 0.0115, 0.0165,
        0.0097, 0.0459, 0.0176, 0.0893], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,252][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([7.4727e-01, 2.4398e-02, 4.8271e-03, 5.6846e-03, 2.1064e-02, 4.9591e-06,
        1.3439e-06, 1.8572e-05, 9.5240e-04, 3.3923e-03, 5.8196e-03, 1.6171e-03,
        1.8495e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,252][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0057, 0.2908, 0.0219, 0.1147, 0.0616, 0.0527, 0.0614, 0.0518, 0.0545,
        0.0969, 0.0448, 0.0953, 0.0479], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,253][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.3831, 0.0872, 0.0536, 0.0412, 0.0839, 0.0064, 0.0110, 0.0281, 0.0173,
        0.0263, 0.0464, 0.0244, 0.1913], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,253][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([9.7877e-05, 1.4284e-01, 2.0996e-02, 1.1102e-01, 3.5332e-02, 1.8664e-01,
        2.8739e-02, 4.1611e-02, 9.3894e-02, 8.1648e-02, 1.6229e-02, 1.6886e-01,
        7.2089e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,253][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0418, 0.1591, 0.1480, 0.1521, 0.0638, 0.0067, 0.0039, 0.0074, 0.0418,
        0.0557, 0.1244, 0.0709, 0.1244], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,255][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.4831, 0.2597, 0.0564, 0.0361, 0.0304, 0.0132, 0.0065, 0.0168, 0.0183,
        0.0113, 0.0198, 0.0194, 0.0290], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,257][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([4.7719e-06, 1.7158e-02, 6.6208e-03, 4.7075e-02, 7.2615e-03, 6.1030e-02,
        4.2633e-02, 3.7746e-02, 6.4608e-02, 1.1393e-01, 1.9306e-02, 5.4438e-01,
        3.8245e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,259][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([3.4518e-03, 7.4767e-02, 9.2227e-03, 1.0252e-01, 3.4359e-02, 6.2524e-05,
        8.5331e-06, 1.0290e-04, 8.1390e-03, 1.3444e-02, 1.2797e-02, 2.8813e-02,
        7.1231e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,262][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0128, 0.0651, 0.0602, 0.0469, 0.0455, 0.0840, 0.0538, 0.1091, 0.0581,
        0.1060, 0.0806, 0.1847, 0.0930], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,266][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3141, 0.0914, 0.1612, 0.0820, 0.1306, 0.0093, 0.0131, 0.0244, 0.0159,
        0.0101, 0.0253, 0.0187, 0.0716, 0.0324], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,270][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0099, 0.3048, 0.0165, 0.0784, 0.0437, 0.0270, 0.0304, 0.0415, 0.0823,
        0.0954, 0.0473, 0.1533, 0.0352, 0.0340], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,273][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3410, 0.1176, 0.0744, 0.0901, 0.0877, 0.0139, 0.0069, 0.0109, 0.0108,
        0.0038, 0.0383, 0.0188, 0.0587, 0.1270], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,275][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2326e-01, 1.5332e-02, 1.0766e-03, 3.1949e-03, 1.6184e-02, 4.4754e-06,
        2.1345e-06, 2.0862e-05, 1.8471e-03, 1.2811e-02, 4.9975e-03, 4.1369e-03,
        7.1041e-01, 1.0672e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,275][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0208, 0.4688, 0.0857, 0.1116, 0.0472, 0.0172, 0.0308, 0.0313, 0.0328,
        0.0236, 0.0335, 0.0477, 0.0275, 0.0216], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,276][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4246, 0.1010, 0.0480, 0.0257, 0.0827, 0.0043, 0.0072, 0.0152, 0.0130,
        0.0202, 0.0317, 0.0125, 0.1155, 0.0984], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,276][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0004, 0.1866, 0.0392, 0.1170, 0.0549, 0.1052, 0.0128, 0.0347, 0.0699,
        0.0464, 0.0193, 0.0829, 0.0823, 0.1484], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,276][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0700, 0.1640, 0.1104, 0.0910, 0.0487, 0.0048, 0.0035, 0.0043, 0.0405,
        0.0488, 0.1103, 0.0576, 0.1667, 0.0795], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,277][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3849, 0.2485, 0.0968, 0.0691, 0.0266, 0.0097, 0.0072, 0.0156, 0.0151,
        0.0119, 0.0262, 0.0279, 0.0307, 0.0297], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,277][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.8373e-05, 2.3509e-02, 1.6264e-02, 5.1474e-02, 1.3913e-02, 4.4536e-02,
        1.7354e-02, 4.1644e-02, 8.4439e-02, 8.4027e-02, 5.6402e-02, 3.4245e-01,
        3.7537e-02, 1.8643e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,278][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.4954e-03, 1.8829e-02, 1.2329e-03, 1.6427e-02, 6.6614e-03, 2.0316e-05,
        5.9439e-06, 3.1238e-05, 4.3604e-03, 1.9742e-02, 4.7925e-03, 1.8961e-02,
        8.2534e-01, 8.2102e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,278][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0512, 0.0416, 0.1557, 0.0406, 0.0587, 0.0875, 0.0344, 0.0858, 0.0551,
        0.0429, 0.1021, 0.0696, 0.0550, 0.1197], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,280][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2021, 0.1162, 0.1222, 0.0816, 0.1366, 0.0126, 0.0173, 0.0268, 0.0199,
        0.0155, 0.0241, 0.0169, 0.0419, 0.0263, 0.1397], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,284][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0047, 0.2353, 0.0094, 0.0675, 0.0194, 0.0285, 0.0324, 0.0264, 0.0937,
        0.1025, 0.0442, 0.2338, 0.0205, 0.0257, 0.0560], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,287][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1699, 0.1524, 0.0486, 0.0556, 0.0763, 0.0086, 0.0044, 0.0056, 0.0090,
        0.0060, 0.0214, 0.0104, 0.0566, 0.0695, 0.3058], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,289][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([6.0035e-01, 1.1301e-02, 1.7648e-03, 1.5543e-03, 7.8975e-03, 1.1695e-06,
        4.3481e-07, 6.6619e-06, 3.8860e-04, 1.6585e-03, 2.7605e-03, 4.1053e-04,
        1.4678e-01, 5.1678e-02, 1.7344e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,293][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0091, 0.3087, 0.0726, 0.1401, 0.0475, 0.0244, 0.0306, 0.0557, 0.0283,
        0.0499, 0.0468, 0.0790, 0.0353, 0.0299, 0.0422], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,297][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.4571, 0.0973, 0.0441, 0.0189, 0.0453, 0.0031, 0.0092, 0.0140, 0.0084,
        0.0222, 0.0323, 0.0124, 0.1429, 0.0565, 0.0362], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,299][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([1.3612e-04, 1.1372e-01, 2.0747e-02, 8.6314e-02, 2.7717e-02, 9.2739e-02,
        1.4081e-02, 2.6013e-02, 6.3721e-02, 5.3327e-02, 1.3408e-02, 9.7014e-02,
        4.8842e-02, 8.1790e-02, 2.6043e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,300][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0723, 0.1414, 0.1501, 0.0845, 0.0636, 0.0041, 0.0034, 0.0048, 0.0358,
        0.0238, 0.0825, 0.0331, 0.1034, 0.0650, 0.1320], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,300][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1149, 0.2230, 0.0580, 0.0904, 0.0306, 0.0157, 0.0091, 0.0276, 0.0480,
        0.0268, 0.0496, 0.0628, 0.0218, 0.0187, 0.2031], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,301][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.0070e-05, 5.2226e-03, 3.1476e-03, 1.8154e-02, 7.0329e-03, 5.2438e-02,
        1.7907e-02, 2.7046e-02, 6.1621e-02, 7.5137e-02, 3.8631e-02, 4.8232e-01,
        3.8644e-02, 1.0885e-01, 6.3841e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,301][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([9.7829e-03, 2.2846e-02, 1.9113e-03, 1.4606e-02, 8.8403e-03, 6.4968e-06,
        1.9002e-06, 1.1830e-05, 1.1174e-03, 3.9475e-03, 2.6537e-03, 4.2888e-03,
        3.5844e-01, 4.2898e-02, 5.2865e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,301][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0350, 0.0644, 0.0647, 0.0368, 0.0376, 0.0548, 0.0317, 0.0347, 0.0452,
        0.0438, 0.0462, 0.1267, 0.0441, 0.0533, 0.2810], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,302][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.2449, 0.1717, 0.0711, 0.0806, 0.1121, 0.0102, 0.0050, 0.0153, 0.0174,
        0.0053, 0.0127, 0.0082, 0.0784, 0.0192, 0.0743, 0.0736],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,302][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0025, 0.2031, 0.0093, 0.0940, 0.0227, 0.0247, 0.0454, 0.0230, 0.0588,
        0.0463, 0.0259, 0.2505, 0.0393, 0.0174, 0.0427, 0.0945],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,304][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.1870, 0.1085, 0.0244, 0.0329, 0.0979, 0.0077, 0.0047, 0.0046, 0.0091,
        0.0038, 0.0248, 0.0054, 0.0632, 0.0446, 0.2363, 0.1451],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,306][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([3.4210e-01, 1.0484e-02, 5.5830e-04, 1.0459e-03, 2.7132e-03, 5.0748e-07,
        1.4950e-07, 1.1011e-06, 6.6188e-05, 2.3936e-04, 3.8034e-04, 1.0590e-04,
        3.4896e-02, 4.8137e-03, 7.9863e-02, 5.2273e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,309][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.0038, 0.4217, 0.0313, 0.2136, 0.0361, 0.0231, 0.0125, 0.0353, 0.0271,
        0.0223, 0.0175, 0.0743, 0.0144, 0.0104, 0.0153, 0.0412],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,313][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([0.2881, 0.1476, 0.0536, 0.0408, 0.0418, 0.0034, 0.0074, 0.0256, 0.0098,
        0.0202, 0.0352, 0.0128, 0.1221, 0.0654, 0.0339, 0.0923],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,315][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([1.2225e-04, 1.2383e-01, 1.8269e-02, 1.0921e-01, 3.7826e-02, 9.0497e-02,
        1.8191e-02, 2.4542e-02, 4.9567e-02, 3.0649e-02, 9.9458e-03, 6.5355e-02,
        5.0843e-02, 6.7185e-02, 2.1143e-01, 9.2541e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,319][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0909, 0.1052, 0.1360, 0.0705, 0.0461, 0.0034, 0.0013, 0.0027, 0.0160,
        0.0066, 0.0695, 0.0147, 0.0635, 0.0420, 0.0624, 0.2692],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,322][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.1043, 0.1776, 0.0629, 0.1782, 0.0279, 0.0096, 0.0038, 0.0233, 0.0176,
        0.0157, 0.0292, 0.0532, 0.0151, 0.0201, 0.1775, 0.0840],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,324][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([6.4459e-06, 2.5418e-02, 8.9488e-03, 4.4723e-02, 1.1956e-02, 6.3888e-02,
        2.3760e-02, 3.4755e-02, 6.2517e-02, 6.0549e-02, 3.0365e-02, 3.5011e-01,
        4.5920e-02, 1.2804e-01, 4.2311e-02, 6.6735e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,324][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([1.9077e-03, 2.3108e-02, 1.0172e-03, 1.3938e-02, 3.9470e-03, 4.4981e-06,
        7.8225e-07, 3.2759e-06, 5.4662e-04, 5.6722e-04, 9.0412e-04, 1.5614e-03,
        6.6083e-02, 8.6677e-03, 6.3362e-02, 8.1438e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,325][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0256, 0.0130, 0.0406, 0.0302, 0.0283, 0.0603, 0.0227, 0.0473, 0.0312,
        0.0286, 0.0545, 0.0798, 0.0374, 0.0825, 0.1826, 0.2355],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,325][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4124, 0.0523, 0.0934, 0.0469, 0.0857, 0.0042, 0.0077, 0.0143, 0.0104,
        0.0044, 0.0134, 0.0076, 0.0438, 0.0163, 0.1090, 0.0586, 0.0196],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,325][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0133, 0.2427, 0.0101, 0.0443, 0.0247, 0.0136, 0.0204, 0.0206, 0.0603,
        0.0568, 0.0309, 0.1137, 0.0271, 0.0185, 0.0405, 0.2248, 0.0376],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,326][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4115, 0.0908, 0.0517, 0.0431, 0.0622, 0.0052, 0.0029, 0.0038, 0.0052,
        0.0013, 0.0180, 0.0044, 0.0242, 0.0472, 0.0871, 0.0768, 0.0646],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,326][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.7927e-02, 4.2822e-04, 4.1698e-05, 8.2869e-05, 4.4969e-04, 6.0827e-08,
        2.2640e-08, 2.5518e-07, 2.6585e-05, 2.4085e-04, 1.1254e-04, 4.2186e-05,
        2.2880e-02, 2.5093e-03, 4.8446e-02, 8.8839e-01, 1.8420e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,327][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0171, 0.4002, 0.0743, 0.1096, 0.0491, 0.0148, 0.0280, 0.0281, 0.0296,
        0.0186, 0.0371, 0.0459, 0.0257, 0.0178, 0.0151, 0.0497, 0.0394],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,328][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4864, 0.0785, 0.0370, 0.0187, 0.0539, 0.0025, 0.0037, 0.0105, 0.0070,
        0.0089, 0.0181, 0.0055, 0.0823, 0.0588, 0.0252, 0.0432, 0.0600],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,331][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0003, 0.1526, 0.0171, 0.0795, 0.0288, 0.0631, 0.0086, 0.0150, 0.0452,
        0.0215, 0.0099, 0.0426, 0.0452, 0.0574, 0.1861, 0.0931, 0.1340],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,335][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0885, 0.1066, 0.0693, 0.0466, 0.0290, 0.0014, 0.0011, 0.0012, 0.0138,
        0.0120, 0.0413, 0.0181, 0.0707, 0.0272, 0.0594, 0.3427, 0.0710],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,339][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3317, 0.2413, 0.0703, 0.0526, 0.0215, 0.0064, 0.0042, 0.0096, 0.0113,
        0.0079, 0.0226, 0.0188, 0.0168, 0.0152, 0.0698, 0.0670, 0.0329],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,341][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.0372e-05, 2.1782e-02, 8.0813e-03, 3.9999e-02, 8.0080e-03, 3.2429e-02,
        1.1626e-02, 2.0758e-02, 7.6618e-02, 6.0476e-02, 4.4650e-02, 3.1751e-01,
        2.2455e-02, 9.2738e-02, 2.8794e-02, 5.7281e-02, 1.5678e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,343][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.7659e-04, 8.6123e-04, 7.5943e-05, 6.3144e-04, 3.4880e-04, 4.5126e-07,
        1.1055e-07, 5.4934e-07, 1.0482e-04, 4.6790e-04, 1.5487e-04, 3.1517e-04,
        3.5367e-02, 3.2158e-03, 4.5038e-02, 8.8776e-01, 2.5384e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,346][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0492, 0.0275, 0.0774, 0.0268, 0.0306, 0.0480, 0.0188, 0.0466, 0.0315,
        0.0210, 0.0556, 0.0396, 0.0276, 0.0563, 0.1515, 0.1473, 0.1447],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,347][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:02,350][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4428],
        [ 812],
        [  68],
        [  46],
        [ 102],
        [  21],
        [  33],
        [  51],
        [  42],
        [  46],
        [  52],
        [  69],
        [  21],
        [ 112],
        [  38],
        [  40],
        [  47]], device='cuda:0')
[2024-07-24 10:23:02,351][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3952],
        [1884],
        [ 381],
        [ 454],
        [ 247],
        [  40],
        [  64],
        [ 100],
        [  37],
        [  80],
        [  81],
        [ 105],
        [  25],
        [ 110],
        [  46],
        [  22],
        [  50]], device='cuda:0')
[2024-07-24 10:23:02,352][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5258],
        [ 5807],
        [14089],
        [24404],
        [45542],
        [46397],
        [47215],
        [46951],
        [46988],
        [46860],
        [47339],
        [48925],
        [47070],
        [46758],
        [46279],
        [47471],
        [44912]], device='cuda:0')
[2024-07-24 10:23:02,353][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31188],
        [36031],
        [36541],
        [29584],
        [29067],
        [30868],
        [35442],
        [33145],
        [33491],
        [33120],
        [32733],
        [23958],
        [24849],
        [29685],
        [27692],
        [27108],
        [30711]], device='cuda:0')
[2024-07-24 10:23:02,354][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20226],
        [25647],
        [36473],
        [34306],
        [37850],
        [35265],
        [29217],
        [36290],
        [33988],
        [28061],
        [29782],
        [32815],
        [29516],
        [26524],
        [34907],
        [31640],
        [27460]], device='cuda:0')
[2024-07-24 10:23:02,355][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[22940],
        [23977],
        [33900],
        [29972],
        [37139],
        [37737],
        [37994],
        [37976],
        [34208],
        [39564],
        [43741],
        [43497],
        [35567],
        [46388],
        [39974],
        [44050],
        [45593]], device='cuda:0')
[2024-07-24 10:23:02,358][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[25253],
        [49324],
        [49344],
        [49533],
        [48561],
        [48057],
        [47829],
        [47901],
        [47314],
        [46630],
        [47226],
        [47686],
        [45589],
        [45962],
        [45274],
        [45745],
        [45782]], device='cuda:0')
[2024-07-24 10:23:02,359][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[49533],
        [ 4465],
        [ 5888],
        [ 6608],
        [ 9115],
        [ 8234],
        [10105],
        [10028],
        [11077],
        [ 9797],
        [10528],
        [10148],
        [15859],
        [15814],
        [17383],
        [16972],
        [19595]], device='cuda:0')
[2024-07-24 10:23:02,361][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[40013],
        [   19],
        [   10],
        [    7],
        [   25],
        [   24],
        [  564],
        [ 1227],
        [ 1804],
        [ 2177],
        [ 9616],
        [25730],
        [19861],
        [11795],
        [19261],
        [35620],
        [11949]], device='cuda:0')
[2024-07-24 10:23:02,364][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9804],
        [ 4894],
        [10598],
        [13670],
        [12625],
        [12631],
        [10809],
        [ 9952],
        [10794],
        [10095],
        [ 9031],
        [ 9659],
        [11041],
        [10722],
        [10865],
        [10670],
        [10204]], device='cuda:0')
[2024-07-24 10:23:02,366][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4137],
        [  371],
        [ 3943],
        [ 2159],
        [ 5108],
        [ 5720],
        [11185],
        [10028],
        [12575],
        [11282],
        [11576],
        [ 8145],
        [11116],
        [11093],
        [10007],
        [10532],
        [10571]], device='cuda:0')
[2024-07-24 10:23:02,369][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 9926],
        [    3],
        [   31],
        [   11],
        [  184],
        [  587],
        [ 1566],
        [ 2210],
        [ 5331],
        [ 7969],
        [12197],
        [ 6879],
        [10116],
        [13995],
        [15257],
        [21892],
        [19786]], device='cuda:0')
[2024-07-24 10:23:02,371][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[9146],
        [5645],
        [3201],
        [6940],
        [9834],
        [8016],
        [8518],
        [7860],
        [4988],
        [5812],
        [7228],
        [5356],
        [5093],
        [6544],
        [6675],
        [6770],
        [5671]], device='cuda:0')
[2024-07-24 10:23:02,374][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13425],
        [46284],
        [32805],
        [42532],
        [42074],
        [30547],
        [27615],
        [29876],
        [32379],
        [28686],
        [27555],
        [39462],
        [32049],
        [29347],
        [31729],
        [32525],
        [32074]], device='cuda:0')
[2024-07-24 10:23:02,377][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[43181],
        [28404],
        [18450],
        [13484],
        [22159],
        [29571],
        [23975],
        [22018],
        [33697],
        [14726],
        [16199],
        [14888],
        [11622],
        [22831],
        [12090],
        [29386],
        [22356]], device='cuda:0')
[2024-07-24 10:23:02,379][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14850],
        [14589],
        [10629],
        [ 9743],
        [12645],
        [13003],
        [13611],
        [16300],
        [15837],
        [15923],
        [16542],
        [18512],
        [18180],
        [15833],
        [16143],
        [16851],
        [16496]], device='cuda:0')
[2024-07-24 10:23:02,380][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[31853],
        [26834],
        [26298],
        [22981],
        [19359],
        [15858],
        [12282],
        [13671],
        [13428],
        [10126],
        [10463],
        [ 8631],
        [ 9435],
        [10127],
        [ 8667],
        [ 8610],
        [ 9776]], device='cuda:0')
[2024-07-24 10:23:02,381][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32657],
        [34283],
        [32954],
        [39422],
        [35640],
        [36098],
        [33964],
        [36833],
        [37019],
        [36239],
        [36634],
        [40525],
        [36501],
        [37034],
        [37191],
        [35325],
        [37009]], device='cuda:0')
[2024-07-24 10:23:02,382][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12115],
        [10723],
        [ 9795],
        [ 8112],
        [ 7670],
        [ 8194],
        [ 8035],
        [ 8158],
        [ 5714],
        [ 3076],
        [ 1396],
        [ 1329],
        [ 4794],
        [ 3174],
        [ 2579],
        [ 2738],
        [ 3172]], device='cuda:0')
[2024-07-24 10:23:02,383][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15728],
        [20258],
        [18666],
        [13063],
        [12001],
        [12048],
        [11175],
        [12121],
        [11795],
        [ 8947],
        [10945],
        [ 8182],
        [ 8668],
        [10674],
        [ 8990],
        [10424],
        [10340]], device='cuda:0')
[2024-07-24 10:23:02,385][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9936],
        [20748],
        [30448],
        [32061],
        [32845],
        [32851],
        [32235],
        [31071],
        [30914],
        [31301],
        [31403],
        [33632],
        [28666],
        [29454],
        [28829],
        [31093],
        [30582]], device='cuda:0')
[2024-07-24 10:23:02,387][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10368],
        [ 8428],
        [ 8632],
        [13902],
        [13074],
        [11995],
        [14479],
        [11459],
        [11257],
        [ 9487],
        [11054],
        [11856],
        [13930],
        [14376],
        [ 8341],
        [ 8950],
        [ 9547]], device='cuda:0')
[2024-07-24 10:23:02,388][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24281],
        [  230],
        [  446],
        [ 1315],
        [ 1624],
        [ 2860],
        [ 5909],
        [ 2935],
        [ 3298],
        [ 8116],
        [11772],
        [14092],
        [ 7163],
        [ 8577],
        [ 9705],
        [13758],
        [16809]], device='cuda:0')
[2024-07-24 10:23:02,390][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[17088],
        [22235],
        [32237],
        [34774],
        [42558],
        [41710],
        [41871],
        [42209],
        [42036],
        [42020],
        [41601],
        [41111],
        [40516],
        [41227],
        [37218],
        [37523],
        [38916]], device='cuda:0')
[2024-07-24 10:23:02,393][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16936],
        [22407],
        [26033],
        [34444],
        [35901],
        [30477],
        [29263],
        [29324],
        [31191],
        [35012],
        [33065],
        [29254],
        [30316],
        [33293],
        [31026],
        [33042],
        [33301]], device='cuda:0')
[2024-07-24 10:23:02,395][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6490],
        [38581],
        [37434],
        [19625],
        [15520],
        [13077],
        [13335],
        [13603],
        [13579],
        [15162],
        [15886],
        [ 9804],
        [14197],
        [16073],
        [ 8908],
        [21351],
        [21660]], device='cuda:0')
[2024-07-24 10:23:02,398][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22230],
        [21889],
        [21003],
        [18131],
        [19933],
        [24895],
        [25471],
        [25828],
        [26473],
        [27244],
        [26632],
        [25460],
        [27304],
        [26275],
        [26453],
        [26008],
        [26022]], device='cuda:0')
[2024-07-24 10:23:02,401][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[38096],
        [33582],
        [30002],
        [32506],
        [29826],
        [29397],
        [29345],
        [28072],
        [27782],
        [29510],
        [28536],
        [30177],
        [30929],
        [29326],
        [35020],
        [29754],
        [26941]], device='cuda:0')
[2024-07-24 10:23:02,403][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 6415],
        [19393],
        [17827],
        [22421],
        [22996],
        [23288],
        [22025],
        [11937],
        [26108],
        [31587],
        [22455],
        [21489],
        [30796],
        [27001],
        [29883],
        [21691],
        [28010]], device='cuda:0')
[2024-07-24 10:23:02,406][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881],
        [18881]], device='cuda:0')
[2024-07-24 10:23:02,442][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:02,442][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,443][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,443][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,443][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,444][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,444][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,444][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,445][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,445][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,445][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,446][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,446][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,446][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.9510, 0.0490], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,447][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,447][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.1208, 0.8792], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,447][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.8221, 0.1779], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,448][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.9961, 0.0039], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,448][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([0.6152, 0.3848], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,448][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.1732, 0.8268], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,449][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.9522, 0.0478], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,449][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.2407, 0.7593], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,449][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.1351, 0.8649], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,450][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.5684, 0.4316], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,450][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0140, 0.9860], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,450][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5039, 0.0837, 0.4124], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,451][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0027, 0.6631, 0.3341], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,451][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0712, 0.3704, 0.5584], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,451][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5093, 0.1243, 0.3665], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,452][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6815, 0.0573, 0.2613], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,452][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0413, 0.4160, 0.5427], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,452][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0476, 0.3277, 0.6247], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,453][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5687, 0.1214, 0.3098], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,453][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1189, 0.6191, 0.2620], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,453][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0017, 0.4209, 0.5774], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,454][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4281, 0.2304, 0.3416], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,454][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0010, 0.6853, 0.3137], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,454][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0490, 0.1247, 0.2279, 0.5984], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,455][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ William] are: tensor([5.2120e-05, 4.3585e-01, 8.5664e-02, 4.7844e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,455][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0302, 0.2778, 0.3582, 0.3338], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,455][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.2723, 0.2237, 0.3274, 0.1767], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,456][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.7582, 0.0126, 0.1945, 0.0347], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,456][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ William] are: tensor([0.0354, 0.1205, 0.0860, 0.7581], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,456][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0324, 0.2933, 0.3220, 0.3524], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,457][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.5516, 0.1386, 0.2832, 0.0266], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,457][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0921, 0.6679, 0.1352, 0.1048], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,457][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ William] are: tensor([0.0007, 0.2208, 0.1278, 0.6507], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,458][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.2280, 0.1889, 0.3347, 0.2484], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,458][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ William] are: tensor([1.5294e-04, 5.6438e-01, 1.1968e-01, 3.1578e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,458][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0146, 0.0496, 0.2846, 0.3912, 0.2601], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,459][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ got] are: tensor([6.5392e-05, 1.5830e-01, 4.2461e-02, 7.1578e-01, 8.3391e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,462][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.0196, 0.1764, 0.2383, 0.2324, 0.3333], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,463][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.0737, 0.2363, 0.2159, 0.3889, 0.0851], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,463][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.2467, 0.0354, 0.3223, 0.3171, 0.0786], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,464][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ got] are: tensor([0.0109, 0.0723, 0.0842, 0.4754, 0.3571], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,464][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.0181, 0.1761, 0.2467, 0.2441, 0.3150], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,464][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.3585, 0.1713, 0.2721, 0.0131, 0.1851], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,465][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ got] are: tensor([0.0336, 0.3487, 0.1670, 0.2233, 0.2275], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,465][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ got] are: tensor([5.8553e-04, 4.3609e-02, 9.9842e-02, 7.1727e-01, 1.3870e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,465][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.3207, 0.1135, 0.1944, 0.1708, 0.2005], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,466][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ got] are: tensor([5.8476e-05, 2.1361e-01, 6.3462e-02, 2.4529e-01, 4.7758e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,467][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0159, 0.0782, 0.2305, 0.3834, 0.2216, 0.0705], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,469][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.9616e-05, 2.3598e-01, 2.7769e-02, 4.4556e-01, 9.8888e-02, 1.9175e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,470][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0107, 0.1374, 0.1752, 0.1788, 0.2445, 0.2534], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,470][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1255, 0.2664, 0.2385, 0.2088, 0.0947, 0.0661], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,471][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6869, 0.0078, 0.1442, 0.1036, 0.0356, 0.0218], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,471][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.7923e-05, 3.6904e-03, 1.0409e-02, 6.6604e-01, 3.1909e-01, 7.3644e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,473][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0145, 0.1594, 0.1537, 0.1665, 0.2254, 0.2805], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,477][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1354, 0.4182, 0.2845, 0.0393, 0.0973, 0.0254], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,481][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0488, 0.5259, 0.0701, 0.0979, 0.0871, 0.1703], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,483][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.4017e-07, 3.2001e-03, 1.4709e-02, 8.9194e-01, 8.9001e-02, 1.1464e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,487][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1423, 0.1233, 0.2051, 0.1483, 0.1625, 0.2184], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,488][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.3365e-04, 1.4648e-01, 3.4930e-02, 1.3005e-01, 4.1216e-01, 2.7624e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,489][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0128, 0.0813, 0.0967, 0.3497, 0.2615, 0.0722, 0.1259],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,489][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([5.0503e-06, 1.4196e-01, 1.5867e-02, 2.7254e-01, 5.8370e-02, 1.3686e-01,
        3.7440e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,489][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0143, 0.1050, 0.1538, 0.1491, 0.1922, 0.2403, 0.1453],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,489][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.1394, 0.1583, 0.2256, 0.2783, 0.0761, 0.0836, 0.0387],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,490][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.1344, 0.0207, 0.3342, 0.3631, 0.0684, 0.0616, 0.0177],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,490][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([1.1675e-05, 3.6346e-03, 7.1043e-03, 7.5317e-01, 2.3302e-01, 3.0043e-03,
        5.2939e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,490][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0059, 0.0967, 0.1107, 0.1264, 0.1730, 0.2547, 0.2327],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,492][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.1903, 0.2359, 0.3445, 0.0671, 0.0861, 0.0271, 0.0490],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,494][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0097, 0.2592, 0.1112, 0.0775, 0.0927, 0.2069, 0.2428],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,495][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([4.4482e-08, 4.8812e-04, 4.1757e-03, 8.7516e-01, 1.1606e-01, 4.0644e-03,
        5.2556e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,499][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.1549, 0.0848, 0.1538, 0.1071, 0.1580, 0.2000, 0.1414],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,501][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([2.1846e-06, 4.7478e-02, 2.8723e-02, 1.4143e-01, 2.6686e-01, 2.4653e-01,
        2.6896e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,505][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0034, 0.0489, 0.1770, 0.4697, 0.1209, 0.0421, 0.0479, 0.0901],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,507][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.8203e-05, 2.5635e-01, 3.6914e-02, 3.5927e-01, 6.3153e-02, 7.3186e-02,
        1.4952e-01, 6.1584e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,510][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0093, 0.0926, 0.1264, 0.1252, 0.1647, 0.1634, 0.1125, 0.2058],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,512][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0636, 0.1746, 0.2475, 0.2097, 0.1349, 0.0622, 0.0398, 0.0677],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,512][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2939, 0.0525, 0.1992, 0.2329, 0.0613, 0.0373, 0.0138, 0.1091],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,512][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.2279e-04, 4.2973e-03, 1.2122e-02, 5.3766e-01, 4.3399e-01, 2.5521e-03,
        9.6571e-05, 9.1550e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,513][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0071, 0.1062, 0.1246, 0.1199, 0.1762, 0.1974, 0.1388, 0.1298],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,513][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0828, 0.2067, 0.2723, 0.0428, 0.0803, 0.0179, 0.0367, 0.2605],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,513][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0144, 0.3334, 0.0966, 0.1034, 0.0780, 0.1400, 0.1244, 0.1099],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,514][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([5.5968e-07, 1.8757e-03, 2.3591e-02, 8.2817e-01, 1.3339e-01, 4.2245e-03,
        4.8337e-05, 8.7006e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,514][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1116, 0.0710, 0.1400, 0.1140, 0.1256, 0.1784, 0.1178, 0.1417],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,514][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.6536e-05, 3.9567e-02, 1.4819e-02, 4.4877e-02, 5.9844e-02, 5.9395e-02,
        5.2742e-02, 7.2873e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,515][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0060, 0.0761, 0.1237, 0.3055, 0.1521, 0.0427, 0.0948, 0.0712, 0.1279],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,515][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.5094e-05, 2.6443e-01, 2.1340e-02, 2.1075e-01, 7.5860e-02, 8.4538e-02,
        1.5502e-01, 6.2104e-02, 1.2593e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,518][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0067, 0.0911, 0.1036, 0.1127, 0.1443, 0.1419, 0.1044, 0.1715, 0.1237],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,521][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0591, 0.2525, 0.1868, 0.2271, 0.0946, 0.0511, 0.0453, 0.0559, 0.0276],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,524][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6883, 0.0130, 0.1120, 0.0703, 0.0241, 0.0165, 0.0027, 0.0401, 0.0329],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,527][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([2.3747e-02, 5.6920e-03, 1.3268e-02, 6.8618e-02, 3.2475e-01, 7.8109e-05,
        4.0620e-06, 2.0493e-04, 5.6364e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,530][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0061, 0.0996, 0.0976, 0.1104, 0.1365, 0.1735, 0.1310, 0.1061, 0.1392],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,534][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1112, 0.2951, 0.1922, 0.0296, 0.0783, 0.0154, 0.0431, 0.1251, 0.1098],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,536][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0165, 0.2862, 0.0583, 0.0610, 0.0515, 0.1653, 0.0703, 0.1020, 0.1890],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,536][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.0981e-04, 3.3227e-03, 1.0996e-02, 4.9613e-02, 3.6222e-02, 4.8946e-05,
        7.9681e-07, 7.1850e-05, 8.9962e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,536][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0831, 0.0703, 0.1156, 0.0961, 0.1158, 0.1535, 0.1259, 0.1232, 0.1166],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,537][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.4973e-05, 4.9838e-02, 8.4727e-03, 4.6375e-02, 5.5760e-02, 6.4745e-02,
        1.1433e-01, 5.7360e-01, 8.6861e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,537][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0005, 0.0354, 0.0624, 0.3305, 0.1309, 0.0337, 0.0465, 0.0699, 0.1317,
        0.1584], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,537][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ house] are: tensor([1.0482e-06, 4.4124e-02, 7.9106e-03, 1.0973e-01, 4.0909e-02, 4.8402e-02,
        1.7516e-01, 5.1345e-02, 1.0754e-01, 4.1488e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,538][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0057, 0.0685, 0.0979, 0.0924, 0.1251, 0.1396, 0.0872, 0.1568, 0.1098,
        0.1170], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,538][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.0450, 0.1221, 0.2154, 0.1657, 0.1120, 0.0747, 0.0601, 0.0761, 0.0535,
        0.0755], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,540][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.4955, 0.0062, 0.1793, 0.0955, 0.0158, 0.0150, 0.0029, 0.0993, 0.0524,
        0.0381], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,541][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ house] are: tensor([9.2255e-03, 9.3312e-03, 2.3349e-02, 1.2745e-01, 1.7770e-01, 4.8368e-05,
        7.1041e-07, 4.7657e-05, 4.2461e-01, 2.2824e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,544][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.0036, 0.0861, 0.0799, 0.0920, 0.1395, 0.1500, 0.1318, 0.0928, 0.1234,
        0.1009], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,548][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0488, 0.1447, 0.2094, 0.0380, 0.0785, 0.0142, 0.0358, 0.2102, 0.1380,
        0.0823], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,551][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ house] are: tensor([0.0036, 0.0966, 0.0562, 0.0443, 0.0475, 0.2168, 0.1127, 0.1195, 0.2352,
        0.0677], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,553][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ house] are: tensor([6.0401e-05, 6.9956e-04, 1.0280e-02, 4.5838e-02, 2.5596e-02, 8.0293e-06,
        1.2990e-07, 1.1664e-05, 2.7950e-01, 6.3800e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,557][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0911, 0.0567, 0.1158, 0.0828, 0.1026, 0.1560, 0.0941, 0.1231, 0.1267,
        0.0511], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,559][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ house] are: tensor([2.6114e-07, 4.6977e-03, 1.8980e-03, 2.1337e-02, 4.6469e-02, 4.0499e-02,
        5.0696e-02, 5.4086e-01, 6.1721e-02, 2.3183e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,560][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0074, 0.0407, 0.1369, 0.1539, 0.1470, 0.0294, 0.0904, 0.0614, 0.0891,
        0.1009, 0.1429], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,560][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.6299e-05, 8.1345e-02, 2.0582e-02, 1.1129e-01, 8.9635e-02, 6.1052e-02,
        1.4365e-01, 7.2136e-02, 6.2797e-02, 3.3018e-01, 2.7321e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,560][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0049, 0.0634, 0.0879, 0.0873, 0.1144, 0.1129, 0.0776, 0.1394, 0.0943,
        0.1074, 0.1103], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,561][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0586, 0.1561, 0.1821, 0.1969, 0.1276, 0.0447, 0.0454, 0.0560, 0.0259,
        0.0794, 0.0276], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,561][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3944, 0.0318, 0.1510, 0.1201, 0.0392, 0.0216, 0.0065, 0.0719, 0.0386,
        0.0365, 0.0883], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,561][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([2.0700e-03, 2.5099e-03, 4.0158e-03, 1.7506e-02, 8.4445e-02, 7.0203e-05,
        3.5758e-06, 2.7594e-04, 3.2801e-01, 3.3034e-01, 2.3076e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,562][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0032, 0.0536, 0.0925, 0.0724, 0.1299, 0.1408, 0.1121, 0.1063, 0.1144,
        0.0778, 0.0971], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,562][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0329, 0.0760, 0.0848, 0.0062, 0.0364, 0.0071, 0.0196, 0.0614, 0.0514,
        0.0178, 0.6064], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,564][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0103, 0.1610, 0.0601, 0.0693, 0.0634, 0.1212, 0.0988, 0.0943, 0.1242,
        0.0426, 0.1547], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,565][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([3.8520e-05, 5.8790e-04, 1.7354e-03, 5.7447e-03, 4.9648e-03, 1.1122e-05,
        3.8894e-07, 4.3355e-05, 1.8640e-01, 3.1488e-01, 4.8559e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,568][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0538, 0.0582, 0.0965, 0.0900, 0.0998, 0.1354, 0.1057, 0.1126, 0.0971,
        0.0703, 0.0807], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,570][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([3.0989e-06, 6.0807e-02, 4.0272e-03, 3.3130e-02, 6.5960e-02, 2.4864e-02,
        8.2846e-02, 4.4539e-01, 6.0649e-02, 2.0969e-01, 1.2635e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,573][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ William] are: tensor([2.6832e-04, 3.9691e-02, 3.6551e-02, 1.7999e-01, 1.0154e-01, 1.7156e-02,
        4.2735e-02, 3.7424e-02, 6.3993e-02, 9.2199e-02, 8.5214e-02, 3.0323e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,575][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ William] are: tensor([6.3331e-07, 6.3162e-02, 5.6861e-03, 4.7256e-02, 2.9949e-02, 4.1905e-02,
        9.8570e-02, 4.9590e-02, 1.2349e-01, 3.5158e-01, 2.1031e-02, 1.6778e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,579][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0029, 0.0587, 0.0791, 0.0740, 0.1043, 0.1041, 0.0672, 0.1266, 0.0839,
        0.0960, 0.0917, 0.1114], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,582][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.0264, 0.1373, 0.1263, 0.1246, 0.1307, 0.0573, 0.0378, 0.0938, 0.0529,
        0.0783, 0.0411, 0.0935], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,583][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.5128, 0.0045, 0.2196, 0.0369, 0.0128, 0.0073, 0.0015, 0.0580, 0.0417,
        0.0194, 0.0759, 0.0096], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,584][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ William] are: tensor([4.0168e-04, 8.1685e-04, 8.5245e-04, 7.6702e-03, 2.6916e-02, 5.2752e-06,
        2.6350e-07, 2.8961e-05, 3.6819e-01, 1.7629e-01, 2.8023e-01, 1.3860e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,584][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.0027, 0.0708, 0.0689, 0.0706, 0.1110, 0.1366, 0.0891, 0.0964, 0.1091,
        0.0716, 0.0787, 0.0944], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,585][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0511, 0.1143, 0.0986, 0.0185, 0.0368, 0.0058, 0.0144, 0.0683, 0.0714,
        0.0464, 0.4593, 0.0150], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,585][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ William] are: tensor([0.0070, 0.2194, 0.0264, 0.0273, 0.0465, 0.0920, 0.0771, 0.0922, 0.1515,
        0.0316, 0.1105, 0.1185], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,585][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ William] are: tensor([1.6199e-06, 2.8360e-05, 1.6197e-04, 6.2440e-04, 7.5749e-04, 3.8709e-07,
        6.3621e-09, 1.9955e-06, 1.7732e-01, 2.3457e-01, 5.5560e-01, 3.0938e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,586][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0372, 0.0511, 0.1061, 0.0685, 0.0916, 0.1254, 0.0872, 0.1160, 0.1061,
        0.0531, 0.0881, 0.0697], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,586][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ William] are: tensor([1.7734e-06, 5.6112e-02, 4.9952e-03, 4.5275e-02, 8.0831e-02, 3.9374e-02,
        7.2411e-02, 2.2572e-01, 5.9231e-02, 3.4653e-01, 1.4371e-02, 5.5142e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,589][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0008, 0.0291, 0.0400, 0.1075, 0.0778, 0.0201, 0.0274, 0.0690, 0.0761,
        0.1122, 0.0800, 0.2473, 0.1126], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,590][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([4.6383e-06, 5.0602e-02, 9.2333e-03, 8.6205e-02, 2.1336e-02, 4.5051e-02,
        9.0288e-02, 4.4873e-02, 5.5406e-02, 3.1700e-01, 1.7538e-02, 2.1539e-01,
        4.7071e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,593][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0022, 0.0519, 0.0623, 0.0680, 0.0875, 0.0922, 0.0606, 0.1072, 0.0769,
        0.0848, 0.0806, 0.1061, 0.1195], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,597][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0247, 0.1058, 0.0779, 0.2140, 0.0829, 0.0596, 0.0469, 0.0570, 0.0339,
        0.0858, 0.0258, 0.1188, 0.0668], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,600][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.3891, 0.0050, 0.1808, 0.0488, 0.0128, 0.0158, 0.0038, 0.0814, 0.0501,
        0.0182, 0.0870, 0.0166, 0.0907], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,603][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.2138e-02, 2.5343e-03, 6.7586e-03, 6.9572e-03, 2.3786e-02, 3.5582e-06,
        1.7234e-07, 3.9870e-06, 9.3813e-03, 4.9166e-03, 1.6333e-02, 1.0409e-03,
        9.1615e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,607][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0029, 0.0693, 0.0598, 0.0721, 0.0829, 0.1305, 0.0850, 0.0740, 0.0971,
        0.0770, 0.0774, 0.1028, 0.0693], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,607][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0274, 0.0829, 0.1074, 0.0015, 0.0621, 0.0075, 0.0225, 0.0477, 0.0691,
        0.0232, 0.4797, 0.0015, 0.0675], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,607][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0026, 0.1400, 0.0291, 0.0297, 0.0457, 0.1307, 0.1079, 0.0727, 0.1352,
        0.0433, 0.0818, 0.0713, 0.1100], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,608][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([2.3071e-04, 4.1773e-04, 5.1544e-03, 5.5553e-03, 2.1621e-03, 7.0898e-07,
        6.1484e-09, 6.4365e-07, 4.4462e-03, 3.3906e-03, 3.5910e-02, 5.3022e-04,
        9.4220e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,608][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0422, 0.0424, 0.1048, 0.0631, 0.0920, 0.1211, 0.0722, 0.1040, 0.1024,
        0.0392, 0.0871, 0.0614, 0.0680], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,609][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([1.1166e-06, 6.2127e-02, 6.0021e-03, 7.1646e-02, 4.3919e-02, 5.1413e-02,
        9.3871e-02, 3.5797e-01, 4.9135e-02, 1.4021e-01, 1.3173e-02, 6.3201e-02,
        4.7334e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:02,609][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0027, 0.0602, 0.0831, 0.1701, 0.0586, 0.0132, 0.0331, 0.0237, 0.0678,
        0.0748, 0.0765, 0.0949, 0.1100, 0.1313], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,609][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.8773e-05, 1.0572e-01, 1.7578e-02, 1.2417e-01, 4.6885e-02, 2.7759e-02,
        4.7302e-02, 2.3244e-02, 4.2672e-02, 2.4121e-01, 2.7818e-02, 2.1642e-01,
        3.4303e-02, 4.4910e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,610][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0041, 0.0465, 0.0571, 0.0611, 0.0782, 0.0757, 0.0509, 0.0940, 0.0667,
        0.0775, 0.0776, 0.0909, 0.1054, 0.1142], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,611][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0622, 0.1440, 0.1451, 0.1883, 0.0839, 0.0322, 0.0211, 0.0393, 0.0284,
        0.0666, 0.0307, 0.0748, 0.0473, 0.0361], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,614][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3769, 0.0153, 0.1113, 0.0565, 0.0195, 0.0104, 0.0014, 0.0310, 0.0248,
        0.0157, 0.1264, 0.0113, 0.0451, 0.1543], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,616][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.1753e-04, 1.7269e-04, 3.8793e-04, 8.6458e-04, 3.5220e-03, 1.2327e-06,
        5.8053e-08, 1.9111e-06, 4.2492e-03, 5.3979e-03, 5.6416e-03, 8.3022e-04,
        9.5405e-01, 2.4264e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,620][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0023, 0.0576, 0.0655, 0.0634, 0.0822, 0.1063, 0.0593, 0.0795, 0.0890,
        0.0654, 0.0909, 0.0780, 0.0687, 0.0919], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,623][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0342, 0.1273, 0.0888, 0.0047, 0.0183, 0.0049, 0.0080, 0.0259, 0.0522,
        0.0139, 0.5294, 0.0053, 0.0140, 0.0732], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,627][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0046, 0.1388, 0.0363, 0.0277, 0.0370, 0.0628, 0.0432, 0.0538, 0.1249,
        0.0353, 0.1530, 0.0550, 0.0932, 0.1344], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,629][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.6464e-05, 5.2654e-05, 3.9831e-04, 5.6755e-04, 4.6789e-04, 3.0613e-07,
        5.3578e-09, 4.8812e-07, 3.5581e-03, 9.4613e-03, 2.1571e-02, 6.8311e-04,
        8.3455e-01, 1.2868e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,634][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0238, 0.0485, 0.0918, 0.0710, 0.0730, 0.1062, 0.0785, 0.0902, 0.0800,
        0.0470, 0.0704, 0.0649, 0.0661, 0.0885], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,634][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.3114e-05, 2.9973e-02, 6.9404e-03, 3.4101e-02, 6.7840e-02, 2.7441e-02,
        7.4042e-02, 3.9279e-01, 5.4971e-02, 1.6203e-01, 1.2285e-02, 1.5227e-02,
        3.1120e-02, 9.1222e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:02,634][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.5269e-05, 1.8510e-02, 3.5508e-02, 1.0802e-01, 4.9300e-02, 9.3442e-03,
        2.4729e-02, 2.5540e-02, 4.9134e-02, 6.8405e-02, 7.4755e-02, 1.3561e-01,
        1.0076e-01, 6.5004e-02, 2.3528e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,635][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([1.0550e-06, 3.2528e-02, 3.5343e-03, 6.7416e-02, 1.3447e-02, 2.1535e-02,
        5.4716e-02, 2.1984e-02, 4.4941e-02, 1.7073e-01, 2.5363e-02, 3.8767e-01,
        3.2127e-02, 2.0694e-02, 1.0331e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,635][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0026, 0.0433, 0.0505, 0.0545, 0.0699, 0.0675, 0.0453, 0.0783, 0.0581,
        0.0663, 0.0651, 0.0815, 0.0906, 0.0966, 0.1299], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,635][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0148, 0.1969, 0.1412, 0.1978, 0.0798, 0.0405, 0.0198, 0.0291, 0.0219,
        0.0407, 0.0237, 0.0636, 0.0280, 0.0274, 0.0747], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,636][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.2710, 0.0105, 0.1667, 0.0511, 0.0132, 0.0110, 0.0015, 0.0474, 0.0332,
        0.0164, 0.0813, 0.0109, 0.0485, 0.1769, 0.0604], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,636][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([2.3866e-03, 1.6404e-04, 4.6818e-04, 7.8151e-04, 2.2943e-03, 4.7809e-07,
        2.8895e-08, 4.5829e-07, 2.1196e-03, 1.7721e-03, 3.9132e-03, 3.8780e-04,
        3.4790e-01, 7.6487e-03, 6.3016e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,637][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0013, 0.0635, 0.0505, 0.0605, 0.0747, 0.1055, 0.0671, 0.0645, 0.0837,
        0.0652, 0.0806, 0.0863, 0.0561, 0.0703, 0.0701], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,638][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0172, 0.0800, 0.0720, 0.0047, 0.0210, 0.0068, 0.0217, 0.0821, 0.0744,
        0.0280, 0.4546, 0.0035, 0.0137, 0.0627, 0.0576], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,641][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0025, 0.0830, 0.0186, 0.0264, 0.0167, 0.0749, 0.0318, 0.0404, 0.0554,
        0.0207, 0.0761, 0.0744, 0.0712, 0.0598, 0.3482], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,643][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.7490e-05, 2.0642e-05, 3.8662e-04, 3.8005e-04, 3.5607e-04, 7.2961e-08,
        1.5516e-09, 1.5077e-07, 1.0229e-03, 2.0400e-03, 7.3704e-03, 1.3045e-04,
        2.5590e-01, 4.5456e-02, 6.8692e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,647][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0381, 0.0387, 0.0946, 0.0557, 0.0699, 0.1041, 0.0597, 0.0968, 0.0895,
        0.0333, 0.0768, 0.0550, 0.0629, 0.0819, 0.0431], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,650][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.7921e-07, 3.6563e-03, 2.6128e-03, 1.2738e-02, 2.5835e-02, 1.3326e-02,
        3.0550e-02, 2.0694e-01, 1.9165e-02, 1.2440e-01, 9.0027e-03, 1.3641e-02,
        2.4708e-02, 4.2254e-02, 4.7118e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:02,652][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ it] are: tensor([1.7732e-04, 3.7226e-02, 3.8598e-02, 1.2384e-01, 3.5847e-02, 1.0870e-02,
        1.7286e-02, 2.6161e-02, 5.0963e-02, 3.7031e-02, 4.5881e-02, 4.8069e-02,
        8.9940e-02, 6.6424e-02, 1.5579e-01, 2.1589e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,654][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ it] are: tensor([1.1264e-06, 4.5831e-02, 5.3549e-03, 4.9716e-02, 1.1027e-02, 2.2163e-02,
        3.3138e-02, 3.0555e-02, 4.8671e-02, 1.8005e-01, 2.0880e-02, 1.3342e-01,
        2.4628e-02, 3.4911e-02, 1.1574e-01, 2.4392e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,659][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0022, 0.0393, 0.0506, 0.0504, 0.0635, 0.0670, 0.0430, 0.0772, 0.0538,
        0.0595, 0.0586, 0.0698, 0.0855, 0.0945, 0.1199, 0.0653],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,659][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.0136, 0.1816, 0.1299, 0.1899, 0.0870, 0.0373, 0.0163, 0.0386, 0.0219,
        0.0361, 0.0208, 0.0425, 0.0420, 0.0225, 0.0800, 0.0401],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,659][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ it] are: tensor([0.2133, 0.0166, 0.1898, 0.0600, 0.0113, 0.0049, 0.0010, 0.0184, 0.0250,
        0.0069, 0.0487, 0.0045, 0.0236, 0.0732, 0.0288, 0.2739],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,660][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ it] are: tensor([4.5158e-03, 3.8158e-04, 5.7569e-04, 4.9122e-04, 1.7495e-03, 1.4420e-07,
        7.3577e-09, 1.3422e-07, 4.6388e-04, 1.2438e-04, 6.9681e-04, 3.0940e-05,
        4.7306e-02, 1.7974e-03, 2.5301e-01, 6.8886e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,660][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.0012, 0.0551, 0.0488, 0.0625, 0.0658, 0.0987, 0.0649, 0.0683, 0.0774,
        0.0541, 0.0661, 0.0726, 0.0580, 0.0690, 0.0600, 0.0775],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,660][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0261, 0.1710, 0.0879, 0.0070, 0.0137, 0.0061, 0.0138, 0.0489, 0.0497,
        0.0089, 0.2897, 0.0027, 0.0067, 0.0481, 0.0185, 0.2011],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,661][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0013, 0.1262, 0.0107, 0.0168, 0.0118, 0.0376, 0.0186, 0.0274, 0.0469,
        0.0093, 0.0436, 0.0379, 0.0514, 0.0463, 0.2040, 0.3100],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,661][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ it] are: tensor([2.4254e-04, 1.6713e-04, 8.5195e-04, 3.7663e-04, 5.2385e-04, 5.3548e-08,
        1.4743e-09, 2.5285e-08, 2.9627e-04, 2.3691e-04, 2.2349e-03, 1.4219e-05,
        7.2668e-02, 4.1189e-03, 2.9741e-01, 6.2086e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,662][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0252, 0.0349, 0.0858, 0.0519, 0.0705, 0.1094, 0.0619, 0.0880, 0.0858,
        0.0358, 0.0729, 0.0502, 0.0529, 0.0797, 0.0424, 0.0526],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,663][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ it] are: tensor([3.9515e-06, 3.1763e-02, 3.4862e-03, 3.1076e-02, 2.8497e-02, 2.6998e-02,
        3.2409e-02, 2.5199e-01, 5.3016e-02, 1.8236e-01, 7.3604e-03, 1.6188e-02,
        2.8398e-02, 3.2573e-02, 2.0632e-01, 6.7551e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:02,665][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0010, 0.0469, 0.0611, 0.1491, 0.0443, 0.0097, 0.0172, 0.0175, 0.0404,
        0.0363, 0.0505, 0.0450, 0.0434, 0.0641, 0.1113, 0.1834, 0.0788],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,667][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3009e-05, 9.0374e-02, 1.0190e-02, 6.2039e-02, 3.0654e-02, 2.4178e-02,
        2.6018e-02, 1.2462e-02, 3.9719e-02, 1.0724e-01, 2.5280e-02, 1.0923e-01,
        2.2517e-02, 2.7504e-02, 5.8203e-02, 2.7733e-01, 7.7045e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,671][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0028, 0.0351, 0.0432, 0.0449, 0.0561, 0.0569, 0.0385, 0.0694, 0.0508,
        0.0584, 0.0593, 0.0671, 0.0771, 0.0858, 0.1096, 0.0622, 0.0828],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,675][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0398, 0.1805, 0.1166, 0.1486, 0.0725, 0.0232, 0.0181, 0.0254, 0.0237,
        0.0500, 0.0237, 0.0553, 0.0375, 0.0253, 0.0751, 0.0605, 0.0242],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,679][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2051, 0.0097, 0.0927, 0.0298, 0.0099, 0.0055, 0.0005, 0.0132, 0.0164,
        0.0053, 0.0464, 0.0031, 0.0164, 0.0634, 0.0493, 0.3083, 0.1249],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,681][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.0201e-04, 6.4321e-06, 1.9628e-05, 2.3909e-05, 1.7783e-04, 2.0099e-08,
        1.0657e-09, 2.5953e-08, 1.0681e-04, 8.6454e-05, 1.2576e-04, 1.2438e-05,
        3.7447e-02, 6.0441e-04, 5.3645e-02, 8.9762e-01, 9.9185e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,684][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0016, 0.0538, 0.0457, 0.0549, 0.0592, 0.0825, 0.0464, 0.0579, 0.0691,
        0.0497, 0.0709, 0.0714, 0.0498, 0.0664, 0.0583, 0.0780, 0.0844],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,684][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0236, 0.1259, 0.0588, 0.0033, 0.0104, 0.0036, 0.0045, 0.0222, 0.0502,
        0.0076, 0.4484, 0.0031, 0.0062, 0.0461, 0.0215, 0.0805, 0.0842],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,684][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0033, 0.0983, 0.0153, 0.0191, 0.0180, 0.0342, 0.0303, 0.0187, 0.0578,
        0.0117, 0.0597, 0.0318, 0.0327, 0.0342, 0.1783, 0.2513, 0.1051],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,685][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.8231e-06, 1.7826e-06, 2.2530e-05, 1.5607e-05, 2.4797e-05, 5.7490e-09,
        8.6992e-11, 6.3983e-09, 9.7726e-05, 2.6660e-04, 5.9755e-04, 8.4457e-06,
        3.8805e-02, 3.2007e-03, 1.7190e-01, 7.6662e-01, 1.8437e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,685][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0165, 0.0434, 0.0777, 0.0566, 0.0599, 0.0911, 0.0661, 0.0767, 0.0695,
        0.0395, 0.0633, 0.0529, 0.0543, 0.0780, 0.0433, 0.0482, 0.0629],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,686][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.3331e-06, 1.9428e-02, 3.9920e-03, 3.4782e-02, 3.1820e-02, 2.1802e-02,
        4.4072e-02, 1.8876e-01, 4.7011e-02, 1.1427e-01, 1.0725e-02, 1.5943e-02,
        2.3243e-02, 4.6536e-02, 2.4374e-01, 6.2674e-02, 9.1207e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:02,721][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:02,722][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,723][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,724][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,725][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,725][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,726][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,727][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,727][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,728][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,729][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,729][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,730][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:02,731][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.9510, 0.0490], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,731][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,732][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.3402, 0.6598], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,733][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.9632, 0.0368], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,735][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.9961, 0.0039], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,736][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([0.6152, 0.3848], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,736][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.1867, 0.8133], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,737][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.9522, 0.0478], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,738][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([0.2407, 0.7593], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,739][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.1351, 0.8649], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,742][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.0035, 0.9965], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,746][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.1102, 0.8898], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:02,750][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5039, 0.0837, 0.4124], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,754][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0027, 0.6631, 0.3341], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,758][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1877, 0.2497, 0.5626], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,760][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6089, 0.0952, 0.2959], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,761][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6815, 0.0573, 0.2613], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,761][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0413, 0.4160, 0.5427], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,762][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0203, 0.2927, 0.6870], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,763][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5687, 0.1214, 0.3098], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,765][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1189, 0.6191, 0.2620], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,768][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0017, 0.4209, 0.5774], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,772][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0059, 0.9929, 0.0012], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,776][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0051, 0.7098, 0.2851], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:02,780][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0490, 0.1247, 0.2279, 0.5984], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,782][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([5.2120e-05, 4.3585e-01, 8.5664e-02, 4.7844e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,785][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0374, 0.3711, 0.2035, 0.3879], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,785][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.3524, 0.1905, 0.3248, 0.1323], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,786][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.7582, 0.0126, 0.1945, 0.0347], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,787][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([0.0354, 0.1205, 0.0860, 0.7581], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,788][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0035, 0.3871, 0.3183, 0.2911], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,790][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.5516, 0.1386, 0.2832, 0.0266], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,793][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0921, 0.6679, 0.1352, 0.1048], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,797][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([0.0007, 0.2208, 0.1278, 0.6507], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,799][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([4.2643e-04, 9.9386e-01, 1.7701e-04, 5.5342e-03], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,803][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0008, 0.6556, 0.0996, 0.2440], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:02,807][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0146, 0.0496, 0.2846, 0.3912, 0.2601], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,810][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([6.5392e-05, 1.5830e-01, 4.2461e-02, 7.1578e-01, 8.3391e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,810][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([0.0214, 0.2055, 0.1546, 0.3508, 0.2676], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,811][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.0775, 0.1866, 0.1681, 0.4750, 0.0930], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,812][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.2467, 0.0354, 0.3223, 0.3171, 0.0786], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,813][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([0.0109, 0.0723, 0.0842, 0.4754, 0.3571], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,815][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0020, 0.1929, 0.3295, 0.2371, 0.2384], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,818][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.3585, 0.1713, 0.2721, 0.0131, 0.1851], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,821][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([0.0336, 0.3487, 0.1670, 0.2233, 0.2275], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,824][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([5.8553e-04, 4.3609e-02, 9.9842e-02, 7.1727e-01, 1.3870e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,826][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([4.9097e-04, 9.6440e-01, 6.6941e-04, 2.7954e-02, 6.4879e-03],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,830][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0005, 0.2094, 0.0664, 0.1984, 0.5253], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:02,834][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0159, 0.0782, 0.2305, 0.3834, 0.2216, 0.0705], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,835][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([5.9616e-05, 2.3598e-01, 2.7769e-02, 4.4556e-01, 9.8888e-02, 1.9175e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,836][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0118, 0.1657, 0.0942, 0.3145, 0.2299, 0.1839], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,837][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1002, 0.2200, 0.2093, 0.2458, 0.1613, 0.0635], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,838][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6869, 0.0078, 0.1442, 0.1036, 0.0356, 0.0218], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,839][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.7923e-05, 3.6904e-03, 1.0409e-02, 6.6604e-01, 3.1909e-01, 7.3644e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,842][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0012, 0.2820, 0.1655, 0.1932, 0.1436, 0.2144], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,846][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1354, 0.4182, 0.2845, 0.0393, 0.0973, 0.0254], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,850][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0488, 0.5259, 0.0701, 0.0979, 0.0871, 0.1703], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,852][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.4017e-07, 3.2001e-03, 1.4709e-02, 8.9194e-01, 8.9001e-02, 1.1464e-03],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,855][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.3232e-04, 9.8899e-01, 1.4459e-04, 6.9044e-03, 2.9052e-03, 8.2187e-04],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,858][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0008, 0.1202, 0.0297, 0.0881, 0.5439, 0.2173], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:02,860][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0128, 0.0813, 0.0967, 0.3497, 0.2615, 0.0722, 0.1259],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,861][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([5.0503e-06, 1.4196e-01, 1.5867e-02, 2.7254e-01, 5.8370e-02, 1.3686e-01,
        3.7440e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,861][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0074, 0.0755, 0.0873, 0.2897, 0.0908, 0.1914, 0.2579],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,862][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0567, 0.1416, 0.2151, 0.3656, 0.0858, 0.0641, 0.0710],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,864][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1344, 0.0207, 0.3342, 0.3631, 0.0684, 0.0616, 0.0177],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,866][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([1.1675e-05, 3.6346e-03, 7.1043e-03, 7.5317e-01, 2.3302e-01, 3.0043e-03,
        5.2939e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,868][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([2.8594e-04, 9.1572e-02, 9.6847e-02, 1.4592e-01, 6.4730e-02, 1.7958e-01,
        4.2107e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,872][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.1903, 0.2359, 0.3445, 0.0671, 0.0861, 0.0271, 0.0490],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,876][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0097, 0.2592, 0.1112, 0.0775, 0.0927, 0.2069, 0.2428],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,878][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([4.4482e-08, 4.8812e-04, 4.1757e-03, 8.7516e-01, 1.1606e-01, 4.0644e-03,
        5.2556e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,881][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([1.9186e-04, 9.7216e-01, 3.1250e-04, 1.5285e-02, 5.2411e-03, 2.3974e-03,
        4.4087e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,883][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([6.1106e-05, 6.1085e-02, 3.3449e-02, 1.2387e-01, 3.0279e-01, 1.6954e-01,
        3.0920e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:02,885][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0034, 0.0489, 0.1770, 0.4697, 0.1209, 0.0421, 0.0479, 0.0901],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,886][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.8203e-05, 2.5635e-01, 3.6914e-02, 3.5927e-01, 6.3153e-02, 7.3186e-02,
        1.4952e-01, 6.1584e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,886][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0088, 0.0507, 0.0836, 0.2392, 0.1213, 0.0639, 0.1497, 0.2828],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,887][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0457, 0.1319, 0.2122, 0.2156, 0.2036, 0.0484, 0.0825, 0.0601],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,889][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2939, 0.0525, 0.1992, 0.2329, 0.0613, 0.0373, 0.0138, 0.1091],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,891][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.2279e-04, 4.2973e-03, 1.2122e-02, 5.3766e-01, 4.3399e-01, 2.5521e-03,
        9.6571e-05, 9.1550e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,895][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0008, 0.1930, 0.2281, 0.1452, 0.1276, 0.1272, 0.1192, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,899][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0828, 0.2067, 0.2723, 0.0428, 0.0803, 0.0179, 0.0367, 0.2605],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,903][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0144, 0.3334, 0.0966, 0.1034, 0.0780, 0.1400, 0.1244, 0.1099],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,905][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([5.5968e-07, 1.8757e-03, 2.3591e-02, 8.2817e-01, 1.3339e-01, 4.2245e-03,
        4.8337e-05, 8.7006e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,908][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([3.3454e-04, 9.7764e-01, 3.5291e-04, 1.4853e-02, 4.1734e-03, 1.1777e-03,
        1.4014e-03, 6.8735e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,909][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.2421e-04, 4.8075e-02, 1.2849e-02, 3.9847e-02, 7.0990e-02, 5.0141e-02,
        8.3791e-02, 6.9418e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:02,910][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0060, 0.0761, 0.1237, 0.3055, 0.1521, 0.0427, 0.0948, 0.0712, 0.1279],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,911][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.5094e-05, 2.6443e-01, 2.1340e-02, 2.1075e-01, 7.5860e-02, 8.4538e-02,
        1.5502e-01, 6.2104e-02, 1.2593e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,912][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0178, 0.1955, 0.0556, 0.2485, 0.0952, 0.0525, 0.1424, 0.1420, 0.0504],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,914][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0928, 0.2449, 0.1623, 0.1930, 0.1186, 0.0351, 0.0917, 0.0415, 0.0200],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,917][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.6883, 0.0130, 0.1120, 0.0703, 0.0241, 0.0165, 0.0027, 0.0401, 0.0329],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,919][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.3747e-02, 5.6920e-03, 1.3268e-02, 6.8618e-02, 3.2475e-01, 7.8109e-05,
        4.0620e-06, 2.0493e-04, 5.6364e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,923][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0008, 0.2187, 0.1069, 0.1222, 0.1007, 0.1208, 0.1642, 0.0533, 0.1124],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,927][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1112, 0.2951, 0.1922, 0.0296, 0.0783, 0.0154, 0.0431, 0.1251, 0.1098],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,930][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0165, 0.2862, 0.0583, 0.0610, 0.0515, 0.1653, 0.0703, 0.1020, 0.1890],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,933][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.0981e-04, 3.3227e-03, 1.0996e-02, 4.9613e-02, 3.6222e-02, 4.8946e-05,
        7.9681e-07, 7.1850e-05, 8.9962e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,934][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.6140e-04, 9.9304e-01, 8.2499e-05, 4.0697e-03, 1.5702e-03, 3.9147e-04,
        5.7334e-04, 1.7844e-05, 9.0036e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,935][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([7.2588e-05, 5.4138e-02, 8.2187e-03, 3.0162e-02, 7.1544e-02, 5.4656e-02,
        1.4651e-01, 5.3996e-01, 9.4741e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:02,936][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0005, 0.0354, 0.0624, 0.3305, 0.1309, 0.0337, 0.0465, 0.0699, 0.1317,
        0.1584], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,937][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([1.0482e-06, 4.4124e-02, 7.9106e-03, 1.0973e-01, 4.0909e-02, 4.8402e-02,
        1.7516e-01, 5.1345e-02, 1.0754e-01, 4.1488e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,939][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([0.0017, 0.0637, 0.0552, 0.1955, 0.0812, 0.0812, 0.1349, 0.1942, 0.0526,
        0.1397], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,942][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0112, 0.1046, 0.2011, 0.1353, 0.1152, 0.0357, 0.1013, 0.0404, 0.0313,
        0.2240], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,946][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.4955, 0.0062, 0.1793, 0.0955, 0.0158, 0.0150, 0.0029, 0.0993, 0.0524,
        0.0381], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,948][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([9.2255e-03, 9.3312e-03, 2.3349e-02, 1.2745e-01, 1.7770e-01, 4.8368e-05,
        7.1041e-07, 4.7657e-05, 4.2461e-01, 2.2824e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,951][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([1.3140e-04, 1.1352e-01, 9.1845e-02, 1.1277e-01, 1.1952e-01, 7.1124e-02,
        2.1984e-01, 4.7289e-02, 9.6054e-02, 1.2790e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,955][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0488, 0.1447, 0.2094, 0.0380, 0.0785, 0.0142, 0.0358, 0.2102, 0.1380,
        0.0823], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,959][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([0.0036, 0.0966, 0.0562, 0.0443, 0.0475, 0.2168, 0.1127, 0.1195, 0.2352,
        0.0677], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,960][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([6.0401e-05, 6.9956e-04, 1.0280e-02, 4.5838e-02, 2.5596e-02, 8.0293e-06,
        1.2990e-07, 1.1664e-05, 2.7950e-01, 6.3800e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,961][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([5.9587e-05, 9.8931e-01, 7.4904e-05, 5.8557e-03, 2.6902e-03, 3.7563e-04,
        1.4600e-03, 1.6177e-05, 1.0219e-04, 5.3355e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,961][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([9.6638e-06, 1.1516e-02, 2.6050e-03, 2.6895e-02, 7.9511e-02, 3.4112e-02,
        1.0815e-01, 4.2903e-01, 6.1646e-02, 2.4652e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:02,963][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0074, 0.0407, 0.1369, 0.1539, 0.1470, 0.0294, 0.0904, 0.0614, 0.0891,
        0.1009, 0.1429], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,966][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.6299e-05, 8.1345e-02, 2.0582e-02, 1.1129e-01, 8.9635e-02, 6.1052e-02,
        1.4365e-01, 7.2136e-02, 6.2797e-02, 3.3018e-01, 2.7321e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,970][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0115, 0.0546, 0.0695, 0.1994, 0.1065, 0.0515, 0.1187, 0.1833, 0.0314,
        0.0999, 0.0737], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,973][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1277, 0.1058, 0.1439, 0.1109, 0.1567, 0.0247, 0.0734, 0.0336, 0.0143,
        0.1958, 0.0131], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,977][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3944, 0.0318, 0.1510, 0.1201, 0.0392, 0.0216, 0.0065, 0.0719, 0.0386,
        0.0365, 0.0883], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,980][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.0700e-03, 2.5099e-03, 4.0158e-03, 1.7506e-02, 8.4445e-02, 7.0203e-05,
        3.5758e-06, 2.7594e-04, 3.2801e-01, 3.3034e-01, 2.3076e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,984][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0005, 0.1173, 0.1566, 0.0826, 0.1161, 0.0940, 0.1916, 0.0608, 0.0653,
        0.0527, 0.0626], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,985][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0329, 0.0760, 0.0848, 0.0062, 0.0364, 0.0071, 0.0196, 0.0614, 0.0514,
        0.0178, 0.6064], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,986][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0103, 0.1610, 0.0601, 0.0693, 0.0634, 0.1212, 0.0988, 0.0943, 0.1242,
        0.0426, 0.1547], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,986][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([3.8520e-05, 5.8790e-04, 1.7354e-03, 5.7447e-03, 4.9648e-03, 1.1122e-05,
        3.8894e-07, 4.3355e-05, 1.8640e-01, 3.1488e-01, 4.8559e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,988][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.9054e-04, 9.8221e-01, 2.1703e-04, 1.0524e-02, 3.7710e-03, 8.8234e-04,
        1.5776e-03, 4.4748e-05, 1.2856e-04, 1.0899e-04, 4.5565e-05],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,989][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.3528e-05, 7.8008e-02, 4.6973e-03, 2.1028e-02, 8.7422e-02, 2.1396e-02,
        1.6588e-01, 3.2727e-01, 5.8858e-02, 2.2139e-01, 1.4024e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:02,991][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([2.6832e-04, 3.9691e-02, 3.6551e-02, 1.7999e-01, 1.0154e-01, 1.7156e-02,
        4.2735e-02, 3.7424e-02, 6.3993e-02, 9.2199e-02, 8.5214e-02, 3.0323e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,993][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([6.3331e-07, 6.3162e-02, 5.6861e-03, 4.7256e-02, 2.9949e-02, 4.1905e-02,
        9.8570e-02, 4.9590e-02, 1.2349e-01, 3.5158e-01, 2.1031e-02, 1.6778e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:02,998][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([0.0014, 0.0761, 0.0391, 0.1348, 0.0881, 0.0369, 0.0594, 0.1572, 0.0227,
        0.0923, 0.0281, 0.2639], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,002][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.0187, 0.1295, 0.1013, 0.0858, 0.1557, 0.0217, 0.0640, 0.0597, 0.0323,
        0.2333, 0.0186, 0.0794], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,006][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.5128, 0.0045, 0.2196, 0.0369, 0.0128, 0.0073, 0.0015, 0.0580, 0.0417,
        0.0194, 0.0759, 0.0096], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,009][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([4.0168e-04, 8.1685e-04, 8.5245e-04, 7.6702e-03, 2.6916e-02, 5.2752e-06,
        2.6350e-07, 2.8961e-05, 3.6819e-01, 1.7629e-01, 2.8023e-01, 1.3860e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,009][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([3.7589e-05, 8.9118e-02, 5.7430e-02, 7.8488e-02, 7.9855e-02, 8.0249e-02,
        1.0726e-01, 7.9897e-02, 1.0161e-01, 8.1554e-02, 8.0532e-02, 1.6396e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,010][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0511, 0.1143, 0.0986, 0.0185, 0.0368, 0.0058, 0.0144, 0.0683, 0.0714,
        0.0464, 0.4593, 0.0150], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,011][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([0.0070, 0.2194, 0.0264, 0.0273, 0.0465, 0.0920, 0.0771, 0.0922, 0.1515,
        0.0316, 0.1105, 0.1185], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,013][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([1.6199e-06, 2.8360e-05, 1.6197e-04, 6.2440e-04, 7.5749e-04, 3.8709e-07,
        6.3621e-09, 1.9955e-06, 1.7732e-01, 2.3457e-01, 5.5560e-01, 3.0938e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,015][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([4.9715e-05, 9.9314e-01, 2.1167e-05, 3.8076e-03, 1.6322e-03, 1.6559e-04,
        7.7407e-04, 7.3075e-06, 3.7787e-05, 2.7427e-05, 5.9655e-06, 3.2957e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,017][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([9.4072e-06, 7.0534e-02, 4.0739e-03, 2.8676e-02, 8.2403e-02, 2.7850e-02,
        1.0257e-01, 2.0075e-01, 5.7657e-02, 3.6106e-01, 1.4072e-02, 5.0333e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,020][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0008, 0.0291, 0.0400, 0.1075, 0.0778, 0.0201, 0.0274, 0.0690, 0.0761,
        0.1122, 0.0800, 0.2473, 0.1126], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,023][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([4.6383e-06, 5.0602e-02, 9.2333e-03, 8.6205e-02, 2.1336e-02, 4.5051e-02,
        9.0288e-02, 4.4873e-02, 5.5406e-02, 3.1700e-01, 1.7538e-02, 2.1539e-01,
        4.7071e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,027][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0008, 0.0493, 0.0157, 0.1352, 0.0401, 0.0334, 0.0424, 0.1039, 0.0272,
        0.0561, 0.0231, 0.3152, 0.1575], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,031][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0207, 0.0591, 0.0544, 0.1344, 0.0785, 0.0269, 0.1007, 0.0257, 0.0154,
        0.3106, 0.0086, 0.0718, 0.0932], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,033][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.3891, 0.0050, 0.1808, 0.0488, 0.0128, 0.0158, 0.0038, 0.0814, 0.0501,
        0.0182, 0.0870, 0.0166, 0.0907], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,034][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.2138e-02, 2.5343e-03, 6.7586e-03, 6.9572e-03, 2.3786e-02, 3.5582e-06,
        1.7234e-07, 3.9870e-06, 9.3813e-03, 4.9166e-03, 1.6333e-02, 1.0409e-03,
        9.1615e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,035][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([1.0692e-04, 1.4422e-01, 5.3560e-02, 8.6769e-02, 6.3358e-02, 9.8976e-02,
        1.2066e-01, 4.7107e-02, 6.4400e-02, 8.2415e-02, 3.8489e-02, 1.6932e-01,
        3.0626e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,036][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0274, 0.0829, 0.1074, 0.0015, 0.0621, 0.0075, 0.0225, 0.0477, 0.0691,
        0.0232, 0.4797, 0.0015, 0.0675], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,038][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0026, 0.1400, 0.0291, 0.0297, 0.0457, 0.1307, 0.1079, 0.0727, 0.1352,
        0.0433, 0.0818, 0.0713, 0.1100], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,040][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([2.3071e-04, 4.1773e-04, 5.1544e-03, 5.5553e-03, 2.1621e-03, 7.0898e-07,
        6.1484e-09, 6.4365e-07, 4.4462e-03, 3.3906e-03, 3.5910e-02, 5.3022e-04,
        9.4220e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,042][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([1.0361e-04, 9.8736e-01, 9.0926e-05, 4.8967e-03, 3.0093e-03, 8.2231e-04,
        1.4916e-03, 3.5906e-05, 1.5167e-04, 2.1715e-04, 2.9815e-05, 9.9063e-04,
        8.0033e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,044][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([1.8083e-05, 7.5412e-02, 7.4490e-03, 4.5439e-02, 5.0075e-02, 4.4259e-02,
        1.3694e-01, 2.8047e-01, 5.0213e-02, 1.7041e-01, 1.7919e-02, 6.5256e-02,
        5.6151e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,049][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0027, 0.0602, 0.0831, 0.1701, 0.0586, 0.0132, 0.0331, 0.0237, 0.0678,
        0.0748, 0.0765, 0.0949, 0.1100, 0.1313], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,051][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.8773e-05, 1.0572e-01, 1.7578e-02, 1.2417e-01, 4.6885e-02, 2.7759e-02,
        4.7302e-02, 2.3244e-02, 4.2672e-02, 2.4121e-01, 2.7818e-02, 2.1642e-01,
        3.4303e-02, 4.4910e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,055][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0112, 0.0388, 0.0334, 0.1084, 0.0668, 0.0236, 0.0428, 0.0935, 0.0263,
        0.0818, 0.0717, 0.1499, 0.1174, 0.1345], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,057][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0741, 0.0892, 0.1128, 0.1421, 0.1156, 0.0174, 0.0329, 0.0255, 0.0188,
        0.1995, 0.0195, 0.0543, 0.0754, 0.0228], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,058][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3769, 0.0153, 0.1113, 0.0565, 0.0195, 0.0104, 0.0014, 0.0310, 0.0248,
        0.0157, 0.1264, 0.0113, 0.0451, 0.1543], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,059][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.1753e-04, 1.7269e-04, 3.8793e-04, 8.6458e-04, 3.5220e-03, 1.2327e-06,
        5.8053e-08, 1.9111e-06, 4.2492e-03, 5.3979e-03, 5.6416e-03, 8.3022e-04,
        9.5405e-01, 2.4264e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,060][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0003, 0.1082, 0.1083, 0.0985, 0.0578, 0.0787, 0.0487, 0.0463, 0.0716,
        0.0518, 0.0709, 0.0963, 0.0232, 0.1394], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,062][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0342, 0.1273, 0.0888, 0.0047, 0.0183, 0.0049, 0.0080, 0.0259, 0.0522,
        0.0139, 0.5294, 0.0053, 0.0140, 0.0732], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,065][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0046, 0.1388, 0.0363, 0.0277, 0.0370, 0.0628, 0.0432, 0.0538, 0.1249,
        0.0353, 0.1530, 0.0550, 0.0932, 0.1344], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,067][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6464e-05, 5.2654e-05, 3.9831e-04, 5.6755e-04, 4.6789e-04, 3.0613e-07,
        5.3578e-09, 4.8812e-07, 3.5581e-03, 9.4613e-03, 2.1571e-02, 6.8311e-04,
        8.3455e-01, 1.2868e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,069][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.8496e-04, 9.8591e-01, 2.0552e-04, 8.0865e-03, 2.7839e-03, 4.1547e-04,
        5.2525e-04, 3.1595e-05, 1.1030e-04, 1.2018e-04, 3.7648e-05, 5.0892e-04,
        6.5530e-04, 4.2573e-04], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,071][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0560e-04, 4.2414e-02, 6.7032e-03, 2.3872e-02, 8.0445e-02, 2.1244e-02,
        1.1457e-01, 3.1037e-01, 6.4549e-02, 2.0071e-01, 1.4330e-02, 1.4115e-02,
        3.4199e-02, 7.2378e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,074][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([9.5269e-05, 1.8510e-02, 3.5508e-02, 1.0802e-01, 4.9300e-02, 9.3442e-03,
        2.4729e-02, 2.5540e-02, 4.9134e-02, 6.8405e-02, 7.4755e-02, 1.3561e-01,
        1.0076e-01, 6.5004e-02, 2.3528e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,076][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.0550e-06, 3.2528e-02, 3.5343e-03, 6.7416e-02, 1.3447e-02, 2.1535e-02,
        5.4716e-02, 2.1984e-02, 4.4941e-02, 1.7073e-01, 2.5363e-02, 3.8767e-01,
        3.2127e-02, 2.0694e-02, 1.0331e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,080][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0007, 0.0536, 0.0112, 0.0818, 0.0230, 0.0115, 0.0149, 0.0287, 0.0106,
        0.0299, 0.0161, 0.1437, 0.0552, 0.0422, 0.4769], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,082][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0098, 0.1357, 0.1201, 0.1777, 0.0842, 0.0237, 0.0309, 0.0156, 0.0138,
        0.1198, 0.0148, 0.0632, 0.0359, 0.0131, 0.1419], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,083][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.2710, 0.0105, 0.1667, 0.0511, 0.0132, 0.0110, 0.0015, 0.0474, 0.0332,
        0.0164, 0.0813, 0.0109, 0.0485, 0.1769, 0.0604], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,084][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([2.3866e-03, 1.6404e-04, 4.6818e-04, 7.8151e-04, 2.2943e-03, 4.7809e-07,
        2.8895e-08, 4.5829e-07, 2.1196e-03, 1.7721e-03, 3.9132e-03, 3.8780e-04,
        3.4790e-01, 7.6487e-03, 6.3016e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,085][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([3.6756e-05, 7.7934e-02, 4.6451e-02, 5.4589e-02, 6.1906e-02, 8.1243e-02,
        9.3419e-02, 3.2864e-02, 6.1801e-02, 8.9262e-02, 6.4053e-02, 1.1815e-01,
        2.2247e-02, 5.7673e-02, 1.3837e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,087][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0172, 0.0800, 0.0720, 0.0047, 0.0210, 0.0068, 0.0217, 0.0821, 0.0744,
        0.0280, 0.4546, 0.0035, 0.0137, 0.0627, 0.0576], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,089][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0025, 0.0830, 0.0186, 0.0264, 0.0167, 0.0749, 0.0318, 0.0404, 0.0554,
        0.0207, 0.0761, 0.0744, 0.0712, 0.0598, 0.3482], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,092][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.7490e-05, 2.0642e-05, 3.8662e-04, 3.8005e-04, 3.5607e-04, 7.2961e-08,
        1.5516e-09, 1.5077e-07, 1.0229e-03, 2.0400e-03, 7.3704e-03, 1.3045e-04,
        2.5590e-01, 4.5456e-02, 6.8692e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,094][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([6.0198e-05, 9.7480e-01, 1.7100e-04, 1.2018e-02, 5.0490e-03, 7.5565e-04,
        1.4840e-03, 4.1863e-05, 1.6791e-04, 1.4592e-04, 6.2182e-05, 1.2886e-03,
        1.3623e-03, 5.9242e-04, 1.9983e-03], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,096][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([6.0521e-06, 6.7499e-03, 3.3616e-03, 1.0305e-02, 2.7128e-02, 9.8308e-03,
        4.3831e-02, 1.5639e-01, 2.0354e-02, 1.7041e-01, 1.3091e-02, 1.5417e-02,
        3.0716e-02, 3.9238e-02, 4.5316e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,099][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([1.7732e-04, 3.7226e-02, 3.8598e-02, 1.2384e-01, 3.5847e-02, 1.0870e-02,
        1.7286e-02, 2.6161e-02, 5.0963e-02, 3.7031e-02, 4.5881e-02, 4.8069e-02,
        8.9940e-02, 6.6424e-02, 1.5579e-01, 2.1589e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,101][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([1.1264e-06, 4.5831e-02, 5.3549e-03, 4.9716e-02, 1.1027e-02, 2.2163e-02,
        3.3138e-02, 3.0555e-02, 4.8671e-02, 1.8005e-01, 2.0880e-02, 1.3342e-01,
        2.4628e-02, 3.4911e-02, 1.1574e-01, 2.4392e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,105][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([0.0012, 0.0752, 0.0330, 0.1262, 0.0301, 0.0246, 0.0347, 0.0478, 0.0135,
        0.0301, 0.0164, 0.0733, 0.0658, 0.0639, 0.3147, 0.0493],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,107][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([0.0144, 0.1482, 0.0908, 0.1836, 0.0987, 0.0203, 0.0264, 0.0226, 0.0128,
        0.0911, 0.0096, 0.0268, 0.0720, 0.0095, 0.1454, 0.0279],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,108][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([0.2133, 0.0166, 0.1898, 0.0600, 0.0113, 0.0049, 0.0010, 0.0184, 0.0250,
        0.0069, 0.0487, 0.0045, 0.0236, 0.0732, 0.0288, 0.2739],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,109][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([4.5158e-03, 3.8158e-04, 5.7569e-04, 4.9122e-04, 1.7495e-03, 1.4420e-07,
        7.3577e-09, 1.3422e-07, 4.6388e-04, 1.2438e-04, 6.9681e-04, 3.0940e-05,
        4.7306e-02, 1.7974e-03, 2.5301e-01, 6.8886e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,110][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([4.2687e-05, 1.1106e-01, 4.2278e-02, 7.7449e-02, 2.8854e-02, 4.6429e-02,
        4.7586e-02, 3.3394e-02, 4.8809e-02, 3.0702e-02, 3.9968e-02, 6.1399e-02,
        2.3870e-02, 7.8161e-02, 6.6687e-02, 2.6332e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,112][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0261, 0.1710, 0.0879, 0.0070, 0.0137, 0.0061, 0.0138, 0.0489, 0.0497,
        0.0089, 0.2897, 0.0027, 0.0067, 0.0481, 0.0185, 0.2011],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,115][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([0.0013, 0.1262, 0.0107, 0.0168, 0.0118, 0.0376, 0.0186, 0.0274, 0.0469,
        0.0093, 0.0436, 0.0379, 0.0514, 0.0463, 0.2040, 0.3100],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,118][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([2.4254e-04, 1.6713e-04, 8.5195e-04, 3.7663e-04, 5.2385e-04, 5.3548e-08,
        1.4743e-09, 2.5285e-08, 2.9627e-04, 2.3691e-04, 2.2349e-03, 1.4219e-05,
        7.2668e-02, 4.1189e-03, 2.9741e-01, 6.2086e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,120][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([6.2658e-05, 9.8681e-01, 1.4268e-04, 7.2418e-03, 2.1337e-03, 3.9009e-04,
        6.3595e-04, 2.0794e-05, 1.0901e-04, 8.3640e-05, 2.2870e-05, 3.9414e-04,
        5.2576e-04, 4.5042e-04, 8.9588e-04, 7.8612e-05], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,122][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([6.0545e-05, 3.4169e-02, 4.5650e-03, 1.8799e-02, 3.5962e-02, 2.0603e-02,
        3.2504e-02, 1.6832e-01, 4.8460e-02, 1.9451e-01, 1.0534e-02, 1.4803e-02,
        3.8228e-02, 3.1153e-02, 1.9550e-01, 1.5183e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,126][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0010, 0.0469, 0.0611, 0.1491, 0.0443, 0.0097, 0.0172, 0.0175, 0.0404,
        0.0363, 0.0505, 0.0450, 0.0434, 0.0641, 0.1113, 0.1834, 0.0788],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,128][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3009e-05, 9.0374e-02, 1.0190e-02, 6.2039e-02, 3.0654e-02, 2.4178e-02,
        2.6018e-02, 1.2462e-02, 3.9719e-02, 1.0724e-01, 2.5280e-02, 1.0923e-01,
        2.2517e-02, 2.7504e-02, 5.8203e-02, 2.7733e-01, 7.7045e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,132][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0039, 0.0233, 0.0158, 0.0453, 0.0212, 0.0110, 0.0181, 0.0412, 0.0139,
        0.0334, 0.0397, 0.0628, 0.0422, 0.0619, 0.3109, 0.0710, 0.1843],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,133][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0622, 0.1251, 0.0934, 0.1099, 0.1001, 0.0102, 0.0228, 0.0126, 0.0135,
        0.1082, 0.0131, 0.0338, 0.0523, 0.0121, 0.1569, 0.0590, 0.0148],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,134][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2051, 0.0097, 0.0927, 0.0298, 0.0099, 0.0055, 0.0005, 0.0132, 0.0164,
        0.0053, 0.0464, 0.0031, 0.0164, 0.0634, 0.0493, 0.3083, 0.1249],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,135][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.0201e-04, 6.4321e-06, 1.9628e-05, 2.3909e-05, 1.7783e-04, 2.0099e-08,
        1.0657e-09, 2.5953e-08, 1.0681e-04, 8.6454e-05, 1.2576e-04, 1.2438e-05,
        3.7447e-02, 6.0441e-04, 5.3645e-02, 8.9762e-01, 9.9185e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,136][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.5299e-04, 8.9913e-02, 5.0136e-02, 6.1029e-02, 2.7759e-02, 4.1783e-02,
        2.7111e-02, 1.8231e-02, 4.1088e-02, 2.0822e-02, 4.4541e-02, 6.4302e-02,
        1.0390e-02, 6.7685e-02, 4.9659e-02, 1.9588e-01, 1.8952e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,139][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0236, 0.1259, 0.0588, 0.0033, 0.0104, 0.0036, 0.0045, 0.0222, 0.0502,
        0.0076, 0.4484, 0.0031, 0.0062, 0.0461, 0.0215, 0.0805, 0.0842],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,143][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0033, 0.0983, 0.0153, 0.0191, 0.0180, 0.0342, 0.0303, 0.0187, 0.0578,
        0.0117, 0.0597, 0.0318, 0.0327, 0.0342, 0.1783, 0.2513, 0.1051],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,146][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.8231e-06, 1.7826e-06, 2.2530e-05, 1.5607e-05, 2.4797e-05, 5.7490e-09,
        8.6992e-11, 6.3983e-09, 9.7726e-05, 2.6660e-04, 5.9755e-04, 8.4457e-06,
        3.8805e-02, 3.2007e-03, 1.7190e-01, 7.6662e-01, 1.8437e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,148][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.4687e-04, 9.9094e-01, 8.2572e-05, 4.7131e-03, 1.5830e-03, 2.1336e-04,
        3.5724e-04, 1.4196e-05, 6.4770e-05, 5.5401e-05, 2.5728e-05, 3.2648e-04,
        3.2543e-04, 2.5249e-04, 6.8718e-04, 4.0886e-05, 1.7583e-04],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,150][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.2853e-05, 2.1006e-02, 3.9878e-03, 2.1612e-02, 3.2978e-02, 1.4327e-02,
        5.0183e-02, 1.2970e-01, 4.6066e-02, 1.2464e-01, 1.1449e-02, 1.3672e-02,
        2.3862e-02, 3.5609e-02, 2.2703e-01, 1.5753e-01, 8.6307e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,154][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:03,156][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2758],
        [ 240],
        [  61],
        [  86],
        [  34],
        [   6],
        [   2],
        [   9],
        [   3],
        [  10],
        [   7],
        [  18],
        [   9],
        [  19],
        [   9],
        [   5],
        [   6]], device='cuda:0')
[2024-07-24 10:23:03,159][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1733],
        [ 136],
        [  40],
        [  53],
        [  20],
        [   5],
        [   2],
        [   7],
        [   2],
        [   6],
        [   7],
        [  20],
        [   6],
        [  21],
        [   9],
        [   5],
        [   5]], device='cuda:0')
[2024-07-24 10:23:03,160][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 2317],
        [43480],
        [48852],
        [48910],
        [47930],
        [48650],
        [49283],
        [48661],
        [49523],
        [49712],
        [49815],
        [49746],
        [49808],
        [49825],
        [49650],
        [49673],
        [49752]], device='cuda:0')
[2024-07-24 10:23:03,162][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17317],
        [39855],
        [34510],
        [30233],
        [22252],
        [23980],
        [23493],
        [26188],
        [26976],
        [25123],
        [24248],
        [26513],
        [24899],
        [25230],
        [22303],
        [23203],
        [24710]], device='cuda:0')
[2024-07-24 10:23:03,163][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6713],
        [49980],
        [43652],
        [42716],
        [38139],
        [32123],
        [29823],
        [31143],
        [29316],
        [24821],
        [26867],
        [26870],
        [23572],
        [21950],
        [20367],
        [18850],
        [17010]], device='cuda:0')
[2024-07-24 10:23:03,166][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6959],
        [11225],
        [14388],
        [14736],
        [15129],
        [14991],
        [14663],
        [14829],
        [14681],
        [13990],
        [14342],
        [14124],
        [14242],
        [14384],
        [14489],
        [14044],
        [13617]], device='cuda:0')
[2024-07-24 10:23:03,169][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32625],
        [33096],
        [41802],
        [39883],
        [34816],
        [37006],
        [33710],
        [35402],
        [38047],
        [38058],
        [37266],
        [38835],
        [35312],
        [32494],
        [31872],
        [29803],
        [26651]], device='cuda:0')
[2024-07-24 10:23:03,171][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23229],
        [10305],
        [15288],
        [18699],
        [21729],
        [22179],
        [21582],
        [23118],
        [21889],
        [19943],
        [20334],
        [19023],
        [19257],
        [19258],
        [25079],
        [25524],
        [24886]], device='cuda:0')
[2024-07-24 10:23:03,174][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[21854],
        [48029],
        [36832],
        [36614],
        [34342],
        [32752],
        [31514],
        [29904],
        [27607],
        [26190],
        [23335],
        [23089],
        [22509],
        [21211],
        [20397],
        [19505],
        [19209]], device='cuda:0')
[2024-07-24 10:23:03,177][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45267],
        [29696],
        [20276],
        [18216],
        [11384],
        [ 4348],
        [11060],
        [ 8507],
        [ 6690],
        [14631],
        [10499],
        [10902],
        [12521],
        [10684],
        [13732],
        [14487],
        [14124]], device='cuda:0')
[2024-07-24 10:23:03,179][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17985],
        [25032],
        [26564],
        [24885],
        [26862],
        [27364],
        [31189],
        [28886],
        [29266],
        [30598],
        [29081],
        [26452],
        [27789],
        [26038],
        [23153],
        [29328],
        [27940]], device='cuda:0')
[2024-07-24 10:23:03,182][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34120],
        [34133],
        [35311],
        [23017],
        [22103],
        [19272],
        [19605],
        [20240],
        [30513],
        [34146],
        [27593],
        [26331],
        [44345],
        [44564],
        [45398],
        [44873],
        [44523]], device='cuda:0')
[2024-07-24 10:23:03,185][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2569],
        [ 115],
        [ 478],
        [ 605],
        [ 572],
        [ 579],
        [ 549],
        [ 493],
        [ 520],
        [ 547],
        [ 478],
        [ 499],
        [ 476],
        [ 441],
        [ 453],
        [ 457],
        [ 415]], device='cuda:0')
[2024-07-24 10:23:03,187][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27374],
        [41226],
        [38281],
        [36298],
        [29079],
        [28119],
        [29863],
        [16330],
        [19222],
        [17578],
        [20549],
        [23934],
        [22952],
        [18934],
        [23956],
        [22606],
        [21408]], device='cuda:0')
[2024-07-24 10:23:03,189][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[36906],
        [33106],
        [28894],
        [27607],
        [26247],
        [24360],
        [22026],
        [21755],
        [25576],
        [27740],
        [18929],
        [24827],
        [23667],
        [15123],
        [20731],
        [21292],
        [17199]], device='cuda:0')
[2024-07-24 10:23:03,190][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[38428],
        [35987],
        [39046],
        [35194],
        [35737],
        [36072],
        [36598],
        [36513],
        [38892],
        [35894],
        [39492],
        [37376],
        [37525],
        [39596],
        [40841],
        [42924],
        [43277]], device='cuda:0')
[2024-07-24 10:23:03,192][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[40381],
        [31655],
        [30143],
        [23759],
        [20705],
        [26210],
        [31190],
        [28977],
        [30490],
        [31279],
        [33390],
        [32284],
        [32660],
        [33142],
        [32718],
        [31674],
        [31261]], device='cuda:0')
[2024-07-24 10:23:03,195][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42960],
        [39337],
        [43307],
        [44548],
        [43907],
        [44244],
        [44829],
        [44944],
        [44698],
        [44650],
        [44562],
        [44606],
        [44765],
        [44383],
        [43156],
        [44254],
        [43922]], device='cuda:0')
[2024-07-24 10:23:03,197][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[29291],
        [29959],
        [27195],
        [27782],
        [29314],
        [27686],
        [28519],
        [27306],
        [27149],
        [28767],
        [28580],
        [28031],
        [27704],
        [27158],
        [28590],
        [27854],
        [27541]], device='cuda:0')
[2024-07-24 10:23:03,200][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12111],
        [12296],
        [32256],
        [31507],
        [34348],
        [35500],
        [34259],
        [33147],
        [32883],
        [33024],
        [35485],
        [35992],
        [36483],
        [40391],
        [39410],
        [39573],
        [41281]], device='cuda:0')
[2024-07-24 10:23:03,203][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22659],
        [19519],
        [25800],
        [33270],
        [26053],
        [27364],
        [29165],
        [24667],
        [20026],
        [24095],
        [23854],
        [23526],
        [29081],
        [28962],
        [24164],
        [27876],
        [29507]], device='cuda:0')
[2024-07-24 10:23:03,205][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32126],
        [31666],
        [26521],
        [26950],
        [24995],
        [27873],
        [23057],
        [26618],
        [27472],
        [27011],
        [26066],
        [28271],
        [28371],
        [28144],
        [26669],
        [33145],
        [33420]], device='cuda:0')
[2024-07-24 10:23:03,208][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26953],
        [30197],
        [33558],
        [34418],
        [36215],
        [32536],
        [34051],
        [29596],
        [28940],
        [28164],
        [33464],
        [33303],
        [32963],
        [32132],
        [30240],
        [25913],
        [28426]], device='cuda:0')
[2024-07-24 10:23:03,211][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13606],
        [16755],
        [16807],
        [17040],
        [18844],
        [16831],
        [12973],
        [17124],
        [19272],
        [20340],
        [20127],
        [19319],
        [17876],
        [19912],
        [24175],
        [24444],
        [23564]], device='cuda:0')
[2024-07-24 10:23:03,213][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26673],
        [35191],
        [31437],
        [34863],
        [34277],
        [35141],
        [35052],
        [34838],
        [38914],
        [40760],
        [45303],
        [45964],
        [24432],
        [26765],
        [32004],
        [30578],
        [30019]], device='cuda:0')
[2024-07-24 10:23:03,216][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44449],
        [40948],
        [40969],
        [41001],
        [41241],
        [41046],
        [41153],
        [41126],
        [41006],
        [41042],
        [41087],
        [41007],
        [41054],
        [41071],
        [41162],
        [41069],
        [41039]], device='cuda:0')
[2024-07-24 10:23:03,218][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[15143],
        [38880],
        [34441],
        [36280],
        [23703],
        [23346],
        [28093],
        [30289],
        [30300],
        [28172],
        [29181],
        [26419],
        [30267],
        [26968],
        [19314],
        [21592],
        [18549]], device='cuda:0')
[2024-07-24 10:23:03,219][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[5246],
        [3755],
        [3793],
        [2838],
        [4487],
        [4227],
        [4170],
        [4365],
        [4096],
        [4118],
        [2969],
        [3059],
        [3409],
        [3137],
        [3611],
        [3038],
        [2992]], device='cuda:0')
[2024-07-24 10:23:03,220][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7098],
        [ 7249],
        [10388],
        [ 8654],
        [18486],
        [19787],
        [18225],
        [18017],
        [16479],
        [15761],
        [21155],
        [12596],
        [18291],
        [28657],
        [22503],
        [22725],
        [25455]], device='cuda:0')
[2024-07-24 10:23:03,223][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115],
        [34115]], device='cuda:0')
[2024-07-24 10:23:03,340][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:03,341][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,342][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,342][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,343][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,344][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,344][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,345][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,346][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,346][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,347][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,348][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,348][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,349][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Katherine] are: tensor([0.4194, 0.5806], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,350][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Katherine] are: tensor([0.6559, 0.3441], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,350][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Katherine] are: tensor([0.9502, 0.0498], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,351][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Katherine] are: tensor([0.9413, 0.0587], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,352][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Katherine] are: tensor([0.0269, 0.9731], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,353][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Katherine] are: tensor([7.6381e-04, 9.9924e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,353][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Katherine] are: tensor([0.9484, 0.0516], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,354][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Katherine] are: tensor([0.1718, 0.8282], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,355][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Katherine] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,358][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Katherine] are: tensor([0.0645, 0.9355], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,362][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Katherine] are: tensor([0.5815, 0.4185], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,366][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Katherine] are: tensor([0.0840, 0.9160], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,368][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0221, 0.2446, 0.7333], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,369][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4644, 0.1478, 0.3878], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,369][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7488, 0.0902, 0.1610], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,370][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8321, 0.1543, 0.0136], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,371][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0035, 0.0998, 0.8966], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,372][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([2.3503e-04, 6.8390e-01, 3.1587e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,374][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9309, 0.0495, 0.0196], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,377][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0544, 0.3087, 0.6370], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,379][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.5413e-05, 1.7769e-01, 8.2221e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,383][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0007, 0.4679, 0.5314], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,386][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0280, 0.4763, 0.4957], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,390][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0137, 0.5411, 0.4452], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,393][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0153, 0.1186, 0.6277, 0.2384], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,393][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0857, 0.5701, 0.2424, 0.1018], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,394][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.5184, 0.2314, 0.2007, 0.0495], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,395][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.8506, 0.1239, 0.0113, 0.0142], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,396][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0153, 0.4405, 0.2083, 0.3358], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,397][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ William] are: tensor([5.0991e-05, 8.5496e-01, 1.2170e-01, 2.3286e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,399][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.9458, 0.0389, 0.0073, 0.0081], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,403][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0046, 0.7836, 0.2055, 0.0063], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,405][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ William] are: tensor([2.1530e-04, 1.2849e-01, 5.6421e-01, 3.0709e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,408][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ William] are: tensor([3.2266e-04, 7.0486e-01, 2.7888e-01, 1.5942e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,411][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0097, 0.5551, 0.2076, 0.2276], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,415][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0145, 0.2609, 0.2527, 0.4719], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,419][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ got] are: tensor([0.0380, 0.1470, 0.3258, 0.2991, 0.1901], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,420][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ got] are: tensor([0.0291, 0.1399, 0.1624, 0.0671, 0.6015], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,421][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ got] are: tensor([0.3485, 0.1584, 0.2495, 0.1214, 0.1221], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,421][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ got] are: tensor([0.8097, 0.1353, 0.0051, 0.0093, 0.0406], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,422][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ got] are: tensor([0.0015, 0.0647, 0.4344, 0.2836, 0.2158], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,423][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ got] are: tensor([2.3284e-05, 6.2710e-01, 1.8451e-01, 2.4491e-02, 1.6388e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,426][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ got] are: tensor([0.9200, 0.0363, 0.0125, 0.0133, 0.0178], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,431][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ got] are: tensor([0.0023, 0.1338, 0.3952, 0.0087, 0.4600], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,433][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ got] are: tensor([1.4277e-04, 4.3049e-02, 3.8166e-01, 7.4234e-02, 5.0092e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,435][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ got] are: tensor([2.9865e-05, 2.1682e-01, 4.4602e-01, 4.7857e-03, 3.3234e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,439][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ got] are: tensor([0.0099, 0.1755, 0.3994, 0.0608, 0.3545], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,442][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ got] are: tensor([0.0023, 0.0998, 0.1069, 0.3023, 0.4887], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,444][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0039, 0.0647, 0.1979, 0.1829, 0.0750, 0.4757], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,445][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0301, 0.1140, 0.0845, 0.0603, 0.4532, 0.2579], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,446][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1210, 0.3689, 0.1864, 0.1916, 0.0687, 0.0633], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,447][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6785, 0.2062, 0.0068, 0.0155, 0.0815, 0.0116], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,448][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0013, 0.0578, 0.3527, 0.0835, 0.1392, 0.3655], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,450][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.6988e-05, 6.9464e-01, 1.4760e-01, 2.7850e-02, 4.0494e-02, 8.9329e-02],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,455][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9132, 0.0484, 0.0090, 0.0103, 0.0140, 0.0051], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,458][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0022, 0.5074, 0.2246, 0.0068, 0.1571, 0.1018], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,462][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0007, 0.0136, 0.3822, 0.0776, 0.4343, 0.0917], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,465][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.3216e-04, 3.0601e-01, 1.8161e-01, 7.0954e-03, 3.3417e-01, 1.7078e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,469][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0020, 0.1681, 0.3226, 0.1094, 0.3540, 0.0438], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,469][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0004, 0.0474, 0.1440, 0.3679, 0.3824, 0.0580], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:03,470][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0104, 0.0474, 0.1218, 0.1130, 0.0711, 0.5049, 0.1314],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,471][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0169, 0.0593, 0.1029, 0.0484, 0.2148, 0.3977, 0.1599],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,472][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0676, 0.2827, 0.1989, 0.1923, 0.1012, 0.1146, 0.0427],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,474][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.6921, 0.1699, 0.0079, 0.0130, 0.0712, 0.0125, 0.0334],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,477][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0003, 0.0509, 0.3289, 0.1794, 0.1161, 0.2704, 0.0539],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,480][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([2.0086e-05, 2.9607e-01, 3.2242e-01, 3.8623e-02, 7.2791e-02, 1.3879e-01,
        1.3129e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,483][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.8194, 0.0813, 0.0179, 0.0191, 0.0311, 0.0135, 0.0176],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,487][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0032, 0.3506, 0.3136, 0.0143, 0.1249, 0.1343, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,489][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([8.4818e-05, 1.6586e-02, 3.0106e-01, 1.1085e-01, 4.3961e-01, 1.1260e-01,
        1.9218e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,492][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([2.9465e-05, 2.9550e-01, 2.5215e-01, 6.5803e-03, 2.3142e-01, 1.1218e-01,
        1.0214e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,494][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0032, 0.0967, 0.2978, 0.2757, 0.2324, 0.0250, 0.0692],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,494][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([3.2095e-04, 5.0638e-02, 1.0400e-01, 2.4570e-01, 4.7052e-01, 1.1360e-01,
        1.5226e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:03,495][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0085, 0.0390, 0.0799, 0.0917, 0.0648, 0.2380, 0.0586, 0.4195],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,496][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0098, 0.0751, 0.1496, 0.0751, 0.3418, 0.1809, 0.0755, 0.0921],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,498][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1519, 0.1824, 0.2876, 0.1764, 0.0853, 0.0474, 0.0348, 0.0343],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,500][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.5672, 0.2090, 0.0110, 0.0200, 0.1067, 0.0179, 0.0521, 0.0160],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,504][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0014, 0.0296, 0.3526, 0.1001, 0.0965, 0.2177, 0.0480, 0.1541],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,507][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.3543e-05, 5.8333e-01, 1.9433e-01, 1.6357e-02, 4.0636e-02, 6.5441e-02,
        4.1816e-02, 5.8076e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,511][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.8785, 0.0509, 0.0147, 0.0144, 0.0188, 0.0073, 0.0090, 0.0064],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,514][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0009, 0.2901, 0.3019, 0.0114, 0.2700, 0.0794, 0.0198, 0.0266],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,518][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0003, 0.0183, 0.1969, 0.1174, 0.2948, 0.1019, 0.0221, 0.2482],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,519][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([2.3480e-04, 3.8506e-01, 1.2590e-01, 1.9128e-02, 2.9693e-01, 9.9641e-02,
        3.2879e-02, 4.0225e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,520][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0085, 0.1033, 0.4204, 0.0677, 0.1518, 0.0282, 0.0677, 0.1524],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,520][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0006, 0.0403, 0.1942, 0.2702, 0.3835, 0.0378, 0.0176, 0.0558],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:03,521][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0041, 0.0369, 0.0487, 0.0455, 0.0453, 0.0993, 0.0124, 0.1681, 0.5396],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,523][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0163, 0.1079, 0.0513, 0.0420, 0.3351, 0.1272, 0.0757, 0.0364, 0.2082],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,527][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1332, 0.3323, 0.2424, 0.1267, 0.0397, 0.0317, 0.0251, 0.0189, 0.0500],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,530][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.6771, 0.1713, 0.0067, 0.0131, 0.0695, 0.0108, 0.0353, 0.0095, 0.0068],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,534][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0007, 0.0308, 0.2351, 0.0421, 0.0699, 0.1477, 0.0198, 0.0831, 0.3707],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,536][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.5373e-05, 5.8018e-01, 6.7007e-02, 9.9364e-03, 3.2740e-02, 2.7218e-02,
        4.0136e-02, 2.0732e-02, 2.2203e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,541][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.8988, 0.0485, 0.0110, 0.0097, 0.0120, 0.0045, 0.0060, 0.0037, 0.0058],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,543][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0028, 0.4066, 0.1188, 0.0034, 0.1453, 0.0586, 0.0223, 0.0102, 0.2321],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,544][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0024, 0.0120, 0.1682, 0.0373, 0.2207, 0.0461, 0.0077, 0.1244, 0.3813],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,544][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.7456e-05, 4.0140e-01, 3.8170e-02, 2.2451e-03, 1.4479e-01, 5.9355e-02,
        1.2717e-02, 1.6463e-02, 3.2476e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,545][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0077, 0.1545, 0.2764, 0.0342, 0.2475, 0.0128, 0.0266, 0.0611, 0.1791],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,547][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([2.8804e-04, 4.1943e-02, 6.1444e-02, 1.2581e-01, 3.0610e-01, 1.4565e-02,
        4.0649e-03, 1.3151e-02, 4.3263e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:03,549][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ house] are: tensor([0.0028, 0.0130, 0.0517, 0.0255, 0.0160, 0.1045, 0.0075, 0.1084, 0.5445,
        0.1259], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,554][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ house] are: tensor([0.0145, 0.0440, 0.0975, 0.0356, 0.2790, 0.1354, 0.1030, 0.0495, 0.1665,
        0.0749], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,558][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ house] are: tensor([0.0367, 0.2594, 0.3064, 0.1580, 0.0742, 0.0499, 0.0321, 0.0176, 0.0482,
        0.0174], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,561][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ house] are: tensor([0.4962, 0.2272, 0.0092, 0.0166, 0.0962, 0.0173, 0.0470, 0.0137, 0.0109,
        0.0655], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,565][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ house] are: tensor([0.0025, 0.0264, 0.1366, 0.0757, 0.0271, 0.2192, 0.0322, 0.0563, 0.2080,
        0.2159], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,567][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ house] are: tensor([1.2501e-05, 2.3400e-01, 1.8743e-01, 2.0856e-02, 3.9009e-02, 7.9970e-02,
        5.3468e-02, 3.7273e-02, 2.9293e-01, 5.5052e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,568][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ house] are: tensor([0.8475, 0.0637, 0.0146, 0.0119, 0.0195, 0.0078, 0.0095, 0.0061, 0.0092,
        0.0101], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,569][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ house] are: tensor([0.0019, 0.4427, 0.1646, 0.0141, 0.0912, 0.0668, 0.0429, 0.0134, 0.1191,
        0.0433], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,570][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ house] are: tensor([2.5126e-04, 1.0165e-02, 2.6333e-01, 5.1007e-02, 1.2352e-01, 1.0424e-01,
        8.7161e-03, 5.0410e-02, 2.1070e-01, 1.7766e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,570][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ house] are: tensor([5.1937e-05, 2.6776e-01, 1.4609e-01, 5.4319e-03, 1.9178e-01, 6.8387e-02,
        3.3157e-02, 1.6258e-02, 2.0861e-01, 6.2475e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,573][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ house] are: tensor([0.0138, 0.0469, 0.4720, 0.0447, 0.1442, 0.0137, 0.0208, 0.0643, 0.1475,
        0.0320], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,576][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ house] are: tensor([0.0004, 0.0157, 0.0525, 0.1443, 0.2200, 0.0242, 0.0042, 0.0228, 0.3823,
        0.1335], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:03,581][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0063, 0.0324, 0.0298, 0.0219, 0.0154, 0.0361, 0.0099, 0.0871, 0.2349,
        0.0412, 0.4850], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,585][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0100, 0.0834, 0.0483, 0.0384, 0.2171, 0.0766, 0.0605, 0.0271, 0.1768,
        0.0492, 0.2125], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,589][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1793, 0.1637, 0.1944, 0.0962, 0.0769, 0.0454, 0.0500, 0.0287, 0.0547,
        0.0304, 0.0803], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,592][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0877, 0.1965, 0.0131, 0.0298, 0.2452, 0.0431, 0.1228, 0.0344, 0.0299,
        0.1933, 0.0043], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,592][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0007, 0.0133, 0.1591, 0.0306, 0.0593, 0.0587, 0.0103, 0.0390, 0.1179,
        0.0657, 0.4454], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,593][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.3147e-06, 3.8656e-01, 7.7754e-02, 5.2077e-03, 4.3536e-02, 1.9420e-02,
        2.3091e-02, 2.5731e-02, 2.2726e-01, 3.1446e-02, 1.5998e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,594][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7941, 0.0591, 0.0200, 0.0174, 0.0303, 0.0123, 0.0168, 0.0100, 0.0133,
        0.0173, 0.0093], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,596][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0015, 0.3818, 0.1317, 0.0059, 0.1690, 0.0210, 0.0174, 0.0069, 0.1223,
        0.0318, 0.1108], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,598][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([2.3095e-04, 8.7939e-03, 7.5019e-02, 1.7149e-02, 1.4729e-01, 2.9540e-02,
        8.9194e-03, 8.7981e-02, 9.5283e-02, 1.2216e-01, 4.0763e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,601][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([7.5208e-05, 4.9970e-01, 8.2829e-02, 3.2938e-03, 1.4107e-01, 2.8307e-02,
        7.2497e-03, 9.9766e-03, 1.2261e-01, 1.2930e-02, 9.1959e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,605][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0084, 0.0875, 0.2518, 0.0094, 0.1278, 0.0051, 0.0150, 0.0242, 0.0697,
        0.0074, 0.3938], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,609][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0004, 0.0599, 0.0435, 0.1226, 0.3322, 0.0094, 0.0040, 0.0112, 0.2364,
        0.0430, 0.1374], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:03,612][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ William] are: tensor([0.0018, 0.0116, 0.0326, 0.0270, 0.0157, 0.0378, 0.0055, 0.0652, 0.2268,
        0.1003, 0.4033, 0.0724], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,616][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ William] are: tensor([0.0031, 0.0409, 0.0676, 0.0092, 0.2270, 0.0772, 0.0608, 0.0254, 0.1656,
        0.0429, 0.2697, 0.0107], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,617][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ William] are: tensor([0.0466, 0.2584, 0.2328, 0.0657, 0.0743, 0.0492, 0.0380, 0.0327, 0.1118,
        0.0193, 0.0628, 0.0083], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,618][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ William] are: tensor([0.2278, 0.2294, 0.0150, 0.0260, 0.1897, 0.0342, 0.0924, 0.0270, 0.0229,
        0.1221, 0.0038, 0.0098], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,619][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ William] are: tensor([0.0021, 0.0361, 0.0574, 0.0626, 0.0471, 0.0851, 0.0173, 0.0314, 0.1546,
        0.0795, 0.2527, 0.1741], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,620][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ William] are: tensor([5.7679e-06, 2.2982e-01, 1.8283e-01, 1.3095e-02, 7.7976e-02, 5.9788e-02,
        2.5517e-02, 2.9928e-02, 2.3015e-01, 2.4304e-02, 1.1929e-01, 7.3017e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,623][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ William] are: tensor([0.8509, 0.0669, 0.0096, 0.0101, 0.0164, 0.0061, 0.0093, 0.0050, 0.0082,
        0.0080, 0.0049, 0.0046], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,627][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ William] are: tensor([0.0011, 0.4363, 0.1504, 0.0080, 0.1095, 0.0357, 0.0276, 0.0096, 0.1174,
        0.0258, 0.0747, 0.0041], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,629][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ William] are: tensor([5.4178e-05, 3.7812e-03, 9.4312e-02, 2.9843e-02, 8.5451e-02, 5.2155e-02,
        7.2980e-03, 3.5207e-02, 1.3469e-01, 1.3536e-01, 3.7961e-01, 4.2233e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,631][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ William] are: tensor([1.8023e-05, 1.5684e-01, 7.1573e-02, 3.4912e-03, 3.3338e-01, 4.4507e-02,
        2.1184e-02, 1.9434e-02, 1.8111e-01, 3.6580e-02, 1.2693e-01, 4.9479e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,634][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ William] are: tensor([0.0016, 0.0364, 0.2769, 0.0442, 0.1292, 0.0065, 0.0100, 0.0162, 0.0860,
        0.0174, 0.3447, 0.0310], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,638][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ William] are: tensor([0.0012, 0.0192, 0.0480, 0.0646, 0.1597, 0.0110, 0.0027, 0.0135, 0.2950,
        0.0703, 0.2767, 0.0383], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:03,641][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0024, 0.0106, 0.0262, 0.0351, 0.0178, 0.0448, 0.0143, 0.0712, 0.1280,
        0.0740, 0.3466, 0.0846, 0.1442], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,641][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0045, 0.0348, 0.0580, 0.0236, 0.2671, 0.0837, 0.0640, 0.0371, 0.0995,
        0.0594, 0.1570, 0.0237, 0.0877], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,642][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0180, 0.1401, 0.2127, 0.1166, 0.0778, 0.0538, 0.0371, 0.0290, 0.0806,
        0.0491, 0.0390, 0.0196, 0.1267], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,644][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.2923, 0.2334, 0.0135, 0.0241, 0.1361, 0.0281, 0.0660, 0.0255, 0.0192,
        0.0906, 0.0037, 0.0087, 0.0589], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,646][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0011, 0.0239, 0.0867, 0.0214, 0.0405, 0.0940, 0.0182, 0.0294, 0.1089,
        0.0990, 0.2022, 0.1060, 0.1689], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,649][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([8.7234e-06, 2.7162e-01, 1.4204e-01, 1.2397e-02, 2.9629e-02, 5.2769e-02,
        7.2950e-02, 3.5108e-02, 1.8454e-01, 4.9894e-02, 1.1330e-01, 1.3126e-02,
        2.2624e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,653][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.5922, 0.1425, 0.0265, 0.0335, 0.0345, 0.0180, 0.0222, 0.0146, 0.0218,
        0.0251, 0.0129, 0.0169, 0.0392], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,656][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0012, 0.2748, 0.1221, 0.0061, 0.1355, 0.0377, 0.0293, 0.0208, 0.1186,
        0.0693, 0.0957, 0.0067, 0.0822], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,658][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([1.6406e-04, 7.4591e-03, 1.1104e-01, 3.0838e-02, 6.3604e-02, 3.8935e-02,
        5.3260e-03, 3.3347e-02, 8.8196e-02, 9.7620e-02, 3.4313e-01, 3.2486e-02,
        1.4785e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,661][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([4.3991e-05, 2.3995e-01, 1.9441e-01, 7.8428e-03, 1.1034e-01, 4.2768e-02,
        3.5685e-02, 2.1315e-02, 1.2893e-01, 8.0543e-02, 1.0122e-01, 1.1324e-02,
        2.5609e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,665][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0026, 0.0727, 0.3304, 0.0223, 0.0574, 0.0145, 0.0430, 0.0367, 0.0901,
        0.0155, 0.2551, 0.0200, 0.0396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,665][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0006, 0.0306, 0.0493, 0.1046, 0.1459, 0.0315, 0.0064, 0.0169, 0.2976,
        0.0862, 0.1286, 0.0508, 0.0511], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:03,666][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0017, 0.0038, 0.0113, 0.0047, 0.0064, 0.0117, 0.0033, 0.0244, 0.0781,
        0.0189, 0.1824, 0.0170, 0.1165, 0.5197], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,667][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0204, 0.0592, 0.0293, 0.0240, 0.1504, 0.0513, 0.0318, 0.0125, 0.1170,
        0.0529, 0.1708, 0.0174, 0.2167, 0.0463], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,669][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0754, 0.1810, 0.1719, 0.1400, 0.0627, 0.0343, 0.0337, 0.0185, 0.0449,
        0.0281, 0.0460, 0.0188, 0.1260, 0.0187], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,672][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2115, 0.1967, 0.0136, 0.0268, 0.1674, 0.0309, 0.0824, 0.0268, 0.0233,
        0.1232, 0.0049, 0.0116, 0.0730, 0.0081], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,676][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0011, 0.0122, 0.1267, 0.0145, 0.0428, 0.0382, 0.0076, 0.0237, 0.0780,
        0.0929, 0.2335, 0.0631, 0.1142, 0.1514], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,678][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.2740e-05, 3.2380e-01, 9.6455e-02, 6.6165e-03, 4.1574e-02, 2.2466e-02,
        2.1579e-02, 3.0346e-02, 1.7438e-01, 2.8562e-02, 1.7523e-01, 6.9113e-03,
        1.8644e-02, 5.3428e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,682][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.6996, 0.0867, 0.0229, 0.0209, 0.0311, 0.0119, 0.0159, 0.0117, 0.0141,
        0.0199, 0.0103, 0.0087, 0.0323, 0.0143], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,685][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0022, 0.3510, 0.1129, 0.0049, 0.1096, 0.0198, 0.0105, 0.0077, 0.1335,
        0.0314, 0.1069, 0.0045, 0.0490, 0.0561], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,689][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0007, 0.0133, 0.0877, 0.0143, 0.0592, 0.0121, 0.0031, 0.0362, 0.0730,
        0.0982, 0.3211, 0.0161, 0.1728, 0.0920], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,690][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0005, 0.3166, 0.0543, 0.0055, 0.1519, 0.0289, 0.0127, 0.0132, 0.1467,
        0.0426, 0.1110, 0.0065, 0.0695, 0.0401], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,691][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0080, 0.0731, 0.2321, 0.0159, 0.0641, 0.0023, 0.0068, 0.0215, 0.0525,
        0.0070, 0.3653, 0.0159, 0.0497, 0.0857], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,692][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0007, 0.0306, 0.0359, 0.1095, 0.2350, 0.0080, 0.0053, 0.0109, 0.2334,
        0.0707, 0.1359, 0.0401, 0.0499, 0.0342], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:03,694][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0011, 0.0037, 0.0088, 0.0053, 0.0058, 0.0109, 0.0030, 0.0268, 0.0708,
        0.0180, 0.1338, 0.0202, 0.0597, 0.4646, 0.1674], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,697][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0061, 0.0465, 0.0861, 0.0174, 0.3088, 0.0643, 0.0592, 0.0111, 0.0706,
        0.0439, 0.0999, 0.0069, 0.1058, 0.0110, 0.0625], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,701][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0138, 0.2173, 0.1962, 0.1338, 0.0485, 0.0327, 0.0350, 0.0167, 0.0524,
        0.0177, 0.0581, 0.0162, 0.1043, 0.0165, 0.0408], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,705][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.3058, 0.2342, 0.0127, 0.0226, 0.1155, 0.0228, 0.0554, 0.0195, 0.0156,
        0.0854, 0.0034, 0.0080, 0.0593, 0.0069, 0.0327], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,709][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0004, 0.0056, 0.0958, 0.0205, 0.0168, 0.0422, 0.0067, 0.0105, 0.0480,
        0.0634, 0.1553, 0.0685, 0.0795, 0.0647, 0.3221], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,711][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([4.5434e-06, 3.4713e-01, 8.2764e-02, 5.8989e-03, 4.4524e-02, 3.4815e-02,
        5.8879e-02, 1.7809e-02, 1.5846e-01, 2.3099e-02, 1.0879e-01, 5.0615e-03,
        1.8491e-02, 2.8901e-02, 6.5365e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,713][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.5673, 0.1179, 0.0289, 0.0278, 0.0392, 0.0180, 0.0224, 0.0150, 0.0211,
        0.0239, 0.0148, 0.0138, 0.0398, 0.0202, 0.0298], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,714][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0004, 0.1579, 0.1703, 0.0055, 0.1772, 0.0222, 0.0171, 0.0094, 0.1280,
        0.0426, 0.1110, 0.0031, 0.0412, 0.0360, 0.0781], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,715][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([6.5675e-05, 7.7138e-03, 7.7430e-02, 1.2271e-02, 3.9384e-02, 1.0174e-02,
        1.5682e-03, 1.6789e-02, 6.9956e-02, 7.9921e-02, 2.2122e-01, 1.0633e-02,
        1.1672e-01, 8.3124e-02, 2.5304e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,716][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([2.3902e-05, 1.5285e-01, 1.5279e-01, 4.4142e-03, 2.4843e-01, 4.0800e-02,
        4.1743e-02, 8.0414e-03, 1.2487e-01, 2.7464e-02, 1.2117e-01, 4.2056e-03,
        2.0084e-02, 1.6203e-02, 3.6921e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,718][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0066, 0.0555, 0.4354, 0.0122, 0.0564, 0.0034, 0.0152, 0.0104, 0.0520,
        0.0065, 0.2422, 0.0105, 0.0236, 0.0364, 0.0337], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,720][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0012, 0.0178, 0.0374, 0.0461, 0.1099, 0.0092, 0.0044, 0.0086, 0.1943,
        0.0481, 0.1406, 0.0296, 0.0518, 0.0392, 0.2616], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:03,724][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ it] are: tensor([0.0010, 0.0035, 0.0077, 0.0062, 0.0044, 0.0095, 0.0023, 0.0174, 0.0723,
        0.0151, 0.1197, 0.0149, 0.0656, 0.4173, 0.1456, 0.0974],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,728][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ it] are: tensor([0.0058, 0.0332, 0.0314, 0.0175, 0.1404, 0.0273, 0.0173, 0.0086, 0.0668,
        0.0179, 0.1114, 0.0062, 0.1514, 0.0209, 0.0579, 0.2859],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,732][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ it] are: tensor([0.0132, 0.2111, 0.1044, 0.0869, 0.0403, 0.0249, 0.0235, 0.0193, 0.0554,
        0.0211, 0.0439, 0.0103, 0.1492, 0.0142, 0.0327, 0.1498],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,736][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ it] are: tensor([0.3018, 0.2085, 0.0119, 0.0251, 0.1116, 0.0182, 0.0545, 0.0173, 0.0142,
        0.0796, 0.0027, 0.0072, 0.0542, 0.0056, 0.0294, 0.0581],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,738][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ it] are: tensor([9.6992e-05, 7.3868e-03, 7.7479e-02, 7.7446e-03, 1.7507e-02, 1.8660e-02,
        2.1408e-03, 9.5287e-03, 5.0066e-02, 3.0332e-02, 1.7909e-01, 3.1753e-02,
        5.2282e-02, 7.2551e-02, 2.9199e-01, 1.5139e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,739][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ it] are: tensor([4.5577e-06, 2.1656e-01, 1.2281e-01, 6.3620e-03, 2.3266e-02, 2.5930e-02,
        1.7298e-02, 2.1194e-02, 2.1509e-01, 2.2081e-02, 1.3998e-01, 3.4460e-03,
        1.8119e-02, 5.0172e-02, 5.0239e-02, 6.7451e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,740][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ it] are: tensor([0.6477, 0.1118, 0.0193, 0.0199, 0.0236, 0.0112, 0.0148, 0.0092, 0.0126,
        0.0149, 0.0075, 0.0076, 0.0291, 0.0129, 0.0194, 0.0384],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,741][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ it] are: tensor([0.0014, 0.2017, 0.0806, 0.0026, 0.0548, 0.0149, 0.0057, 0.0056, 0.1068,
        0.0219, 0.0566, 0.0010, 0.0314, 0.0205, 0.0458, 0.3487],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,744][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ it] are: tensor([0.0003, 0.0046, 0.0759, 0.0049, 0.0387, 0.0060, 0.0008, 0.0133, 0.0501,
        0.0273, 0.2377, 0.0033, 0.0601, 0.0562, 0.1461, 0.2747],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,747][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ it] are: tensor([2.3378e-05, 3.2224e-01, 7.6347e-02, 3.1035e-03, 1.4215e-01, 3.4032e-02,
        1.3789e-02, 4.5312e-03, 1.5463e-01, 1.2100e-02, 1.2698e-01, 1.7587e-03,
        3.0351e-02, 1.5374e-02, 1.6602e-02, 4.5984e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,751][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ it] are: tensor([0.0139, 0.0995, 0.4397, 0.0099, 0.0991, 0.0031, 0.0127, 0.0070, 0.0419,
        0.0017, 0.1310, 0.0025, 0.0309, 0.0131, 0.0077, 0.0863],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,755][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ it] are: tensor([0.0004, 0.0147, 0.0256, 0.0312, 0.0811, 0.0053, 0.0017, 0.0036, 0.1559,
        0.0214, 0.1471, 0.0166, 0.0480, 0.0352, 0.2834, 0.1287],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:03,758][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0007, 0.0036, 0.0068, 0.0047, 0.0045, 0.0078, 0.0019, 0.0163, 0.0578,
        0.0106, 0.0981, 0.0141, 0.0697, 0.2722, 0.1126, 0.0681, 0.2506],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,762][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0084, 0.0357, 0.0297, 0.0142, 0.1486, 0.0326, 0.0202, 0.0079, 0.0793,
        0.0247, 0.1168, 0.0081, 0.1312, 0.0196, 0.0828, 0.2175, 0.0229],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,763][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0335, 0.2814, 0.1337, 0.1327, 0.0371, 0.0194, 0.0213, 0.0122, 0.0339,
        0.0142, 0.0361, 0.0117, 0.0626, 0.0096, 0.0262, 0.1194, 0.0147],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,764][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2658, 0.1687, 0.0118, 0.0243, 0.1229, 0.0229, 0.0566, 0.0206, 0.0183,
        0.0914, 0.0041, 0.0101, 0.0587, 0.0073, 0.0365, 0.0695, 0.0106],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,765][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0006, 0.0116, 0.0748, 0.0109, 0.0198, 0.0190, 0.0037, 0.0099, 0.0473,
        0.0385, 0.1280, 0.0429, 0.0596, 0.0715, 0.2505, 0.0888, 0.1227],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,766][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.6748e-05, 3.3282e-01, 6.0494e-02, 6.3221e-03, 2.5872e-02, 1.8825e-02,
        1.5895e-02, 1.8164e-02, 1.4705e-01, 2.3835e-02, 1.0811e-01, 5.9215e-03,
        1.9168e-02, 3.3046e-02, 7.1589e-02, 7.2005e-02, 4.0877e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,769][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.6223, 0.1240, 0.0221, 0.0222, 0.0265, 0.0103, 0.0131, 0.0084, 0.0119,
        0.0151, 0.0087, 0.0080, 0.0248, 0.0124, 0.0187, 0.0313, 0.0202],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,773][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0015, 0.2404, 0.0505, 0.0037, 0.0674, 0.0120, 0.0048, 0.0039, 0.0881,
        0.0199, 0.0560, 0.0022, 0.0342, 0.0189, 0.0559, 0.3019, 0.0388],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,777][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0004, 0.0069, 0.0525, 0.0057, 0.0333, 0.0040, 0.0014, 0.0161, 0.0363,
        0.0679, 0.1413, 0.0056, 0.0939, 0.0443, 0.2721, 0.1910, 0.0272],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,780][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0004, 0.3011, 0.0712, 0.0076, 0.1239, 0.0278, 0.0105, 0.0078, 0.1428,
        0.0234, 0.1012, 0.0055, 0.0450, 0.0228, 0.0410, 0.0481, 0.0199],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,784][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0435, 0.0652, 0.2590, 0.0189, 0.0569, 0.0021, 0.0085, 0.0134, 0.0368,
        0.0068, 0.1943, 0.0116, 0.0378, 0.0308, 0.0349, 0.1453, 0.0341],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,786][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0007, 0.0186, 0.0304, 0.0546, 0.1002, 0.0048, 0.0034, 0.0052, 0.1235,
        0.0407, 0.0961, 0.0254, 0.0295, 0.0252, 0.2270, 0.1485, 0.0662],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:03,908][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:03,912][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,912][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,913][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,914][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,914][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,915][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,915][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,916][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,917][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,917][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,918][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,919][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [When] are: tensor([1.], device='cuda:0') for source tokens [When]
[2024-07-24 10:23:03,919][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Katherine] are: tensor([0.4194, 0.5806], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,920][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Katherine] are: tensor([0.6559, 0.3441], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,921][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Katherine] are: tensor([0.2523, 0.7477], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,921][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Katherine] are: tensor([0.9819, 0.0181], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,922][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Katherine] are: tensor([0.0269, 0.9731], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,923][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Katherine] are: tensor([7.6381e-04, 9.9924e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,927][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Katherine] are: tensor([0.1472, 0.8528], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,929][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Katherine] are: tensor([0.1718, 0.8282], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,930][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Katherine] are: tensor([4.3545e-04, 9.9956e-01], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,930][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Katherine] are: tensor([0.0645, 0.9355], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,931][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Katherine] are: tensor([0.5815, 0.4185], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,933][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Katherine] are: tensor([0.2752, 0.7248], device='cuda:0') for source tokens [When Katherine]
[2024-07-24 10:23:03,935][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0221, 0.2446, 0.7333], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,939][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4644, 0.1478, 0.3878], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,942][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0098, 0.3132, 0.6769], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,946][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5818, 0.2213, 0.1969], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,950][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0035, 0.0998, 0.8966], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,952][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([2.3503e-04, 6.8390e-01, 3.1587e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,953][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0413, 0.2973, 0.6614], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,954][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0544, 0.3087, 0.6370], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,955][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([2.4932e-05, 1.8078e-01, 8.1920e-01], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,955][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0007, 0.4679, 0.5314], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,957][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0280, 0.4763, 0.4957], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,960][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0813, 0.5330, 0.3857], device='cuda:0') for source tokens [When Katherine and]
[2024-07-24 10:23:03,963][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0153, 0.1186, 0.6277, 0.2384], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,967][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0857, 0.5701, 0.2424, 0.1018], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,969][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([4.6709e-04, 3.5174e-01, 6.0996e-01, 3.7832e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,973][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.1728, 0.1722, 0.1572, 0.4978], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,977][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0153, 0.4405, 0.2083, 0.3358], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,977][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([5.0991e-05, 8.5496e-01, 1.2170e-01, 2.3286e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,978][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([0.0027, 0.8726, 0.1016, 0.0231], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,979][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0046, 0.7836, 0.2055, 0.0063], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,979][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([5.9253e-05, 1.1601e-01, 5.7888e-01, 3.0505e-01], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,981][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([3.2266e-04, 7.0486e-01, 2.7888e-01, 1.5942e-02], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,983][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0097, 0.5551, 0.2076, 0.2276], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,986][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0463, 0.3128, 0.3176, 0.3233], device='cuda:0') for source tokens [When Katherine and William]
[2024-07-24 10:23:03,990][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ got] are: tensor([0.0380, 0.1470, 0.3258, 0.2991, 0.1901], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,994][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ got] are: tensor([0.0291, 0.1399, 0.1624, 0.0671, 0.6015], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,996][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ got] are: tensor([4.1187e-04, 3.1310e-01, 4.9010e-01, 1.0964e-01, 8.6749e-02],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:03,999][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ got] are: tensor([0.1210, 0.1328, 0.0776, 0.6060, 0.0625], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,001][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ got] are: tensor([0.0015, 0.0647, 0.4344, 0.2836, 0.2158], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,002][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ got] are: tensor([2.3284e-05, 6.2710e-01, 1.8451e-01, 2.4491e-02, 1.6388e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,002][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ got] are: tensor([0.0013, 0.3567, 0.3467, 0.0215, 0.2737], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,003][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ got] are: tensor([0.0023, 0.1338, 0.3952, 0.0087, 0.4600], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,004][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ got] are: tensor([3.9391e-05, 3.8584e-02, 4.0848e-01, 6.2240e-02, 4.9066e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,006][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ got] are: tensor([2.9865e-05, 2.1682e-01, 4.4602e-01, 4.7857e-03, 3.3234e-01],
       device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,008][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ got] are: tensor([0.0099, 0.1755, 0.3994, 0.0608, 0.3545], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,012][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ got] are: tensor([0.0108, 0.0967, 0.0809, 0.1569, 0.6547], device='cuda:0') for source tokens [When Katherine and William got]
[2024-07-24 10:23:04,016][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0039, 0.0647, 0.1979, 0.1829, 0.0750, 0.4757], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,019][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0301, 0.1140, 0.0845, 0.0603, 0.4532, 0.2579], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,021][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.0345e-05, 2.7186e-01, 3.4453e-01, 1.8864e-01, 4.6890e-02, 1.4803e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,025][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0062, 0.0165, 0.1043, 0.7631, 0.0766, 0.0333], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,026][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0013, 0.0578, 0.3527, 0.0835, 0.1392, 0.3655], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,027][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([7.6988e-05, 6.9464e-01, 1.4760e-01, 2.7850e-02, 4.0494e-02, 8.9329e-02],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,027][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0007, 0.2496, 0.2366, 0.0332, 0.3161, 0.1638], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,028][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0022, 0.5074, 0.2246, 0.0068, 0.1571, 0.1018], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,030][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.4927e-04, 1.1215e-02, 4.1623e-01, 6.1884e-02, 4.1902e-01, 9.1497e-02],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,032][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.3216e-04, 3.0601e-01, 1.8161e-01, 7.0954e-03, 3.3417e-01, 1.7078e-01],
       device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,036][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0020, 0.1681, 0.3226, 0.1094, 0.3540, 0.0438], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,039][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0009, 0.0353, 0.1136, 0.2675, 0.5590, 0.0237], device='cuda:0') for source tokens [When Katherine and William got a]
[2024-07-24 10:23:04,043][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0104, 0.0474, 0.1218, 0.1130, 0.0711, 0.5049, 0.1314],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,048][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0169, 0.0593, 0.1029, 0.0484, 0.2148, 0.3977, 0.1599],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,050][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([5.1994e-05, 1.6496e-01, 6.4069e-01, 8.6587e-02, 1.4317e-02, 6.5467e-02,
        2.7926e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,051][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0091, 0.0158, 0.0415, 0.8402, 0.0265, 0.0569, 0.0101],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,051][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0003, 0.0509, 0.3289, 0.1794, 0.1161, 0.2704, 0.0539],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,052][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([2.0086e-05, 2.9607e-01, 3.2242e-01, 3.8623e-02, 7.2791e-02, 1.3879e-01,
        1.3129e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,053][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([3.3601e-04, 3.4701e-01, 2.0768e-01, 3.0414e-02, 2.1283e-01, 1.1137e-01,
        9.0360e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,055][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0032, 0.3506, 0.3136, 0.0143, 0.1249, 0.1343, 0.0591],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,057][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([2.3299e-05, 1.5382e-02, 3.4676e-01, 9.3695e-02, 4.3066e-01, 9.9249e-02,
        1.4227e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,059][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([2.9465e-05, 2.9550e-01, 2.5215e-01, 6.5803e-03, 2.3142e-01, 1.1218e-01,
        1.0214e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,063][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0032, 0.0967, 0.2978, 0.2757, 0.2324, 0.0250, 0.0692],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,067][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0009, 0.0423, 0.0758, 0.1676, 0.6513, 0.0589, 0.0033],
       device='cuda:0') for source tokens [When Katherine and William got a basketball]
[2024-07-24 10:23:04,071][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0085, 0.0390, 0.0799, 0.0917, 0.0648, 0.2380, 0.0586, 0.4195],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,075][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0098, 0.0751, 0.1496, 0.0751, 0.3418, 0.1809, 0.0755, 0.0921],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,075][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.3818e-04, 1.5419e-01, 4.1097e-01, 1.9863e-01, 4.8159e-02, 8.7661e-02,
        6.2789e-02, 3.7365e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,076][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0070, 0.0181, 0.1353, 0.5586, 0.1723, 0.0580, 0.0141, 0.0366],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,077][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0014, 0.0296, 0.3526, 0.1001, 0.0965, 0.2177, 0.0480, 0.1541],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,078][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.3543e-05, 5.8333e-01, 1.9433e-01, 1.6357e-02, 4.0636e-02, 6.5441e-02,
        4.1816e-02, 5.8076e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,080][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0009, 0.2137, 0.3801, 0.0312, 0.1898, 0.0871, 0.0565, 0.0406],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,083][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0009, 0.2901, 0.3019, 0.0114, 0.2700, 0.0794, 0.0198, 0.0266],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,085][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([8.7653e-05, 1.6005e-02, 2.2038e-01, 1.0784e-01, 2.9583e-01, 1.0661e-01,
        1.8011e-02, 2.3524e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,088][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([2.3480e-04, 3.8506e-01, 1.2590e-01, 1.9128e-02, 2.9693e-01, 9.9641e-02,
        3.2879e-02, 4.0225e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,091][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0085, 0.1033, 0.4204, 0.0677, 0.1518, 0.0282, 0.0677, 0.1524],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,095][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0011, 0.0222, 0.2060, 0.1996, 0.5196, 0.0148, 0.0053, 0.0315],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at]
[2024-07-24 10:23:04,099][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0041, 0.0369, 0.0487, 0.0455, 0.0453, 0.0993, 0.0124, 0.1681, 0.5396],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,100][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0163, 0.1079, 0.0513, 0.0420, 0.3351, 0.1272, 0.0757, 0.0364, 0.2082],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,101][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.3538e-04, 3.0964e-01, 1.9379e-01, 7.9747e-02, 2.5265e-02, 6.4766e-02,
        4.0370e-02, 1.8412e-02, 2.6788e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,102][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0551, 0.0473, 0.0313, 0.4016, 0.0700, 0.0102, 0.0036, 0.0103, 0.3706],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,104][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0007, 0.0308, 0.2351, 0.0421, 0.0699, 0.1477, 0.0198, 0.0831, 0.3707],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,106][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.5373e-05, 5.8018e-01, 6.7007e-02, 9.9364e-03, 3.2740e-02, 2.7218e-02,
        4.0136e-02, 2.0732e-02, 2.2203e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,110][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0004, 0.2903, 0.1772, 0.0118, 0.1935, 0.0627, 0.0324, 0.0136, 0.2183],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,113][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0028, 0.4066, 0.1188, 0.0034, 0.1453, 0.0586, 0.0223, 0.0102, 0.2321],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,117][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0009, 0.0093, 0.1547, 0.0285, 0.1956, 0.0402, 0.0050, 0.1019, 0.4638],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,120][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.7456e-05, 4.0140e-01, 3.8170e-02, 2.2451e-03, 1.4479e-01, 5.9355e-02,
        1.2717e-02, 1.6463e-02, 3.2476e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,124][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0077, 0.1545, 0.2764, 0.0342, 0.2475, 0.0128, 0.0266, 0.0611, 0.1791],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,125][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0007, 0.0328, 0.0505, 0.0717, 0.4610, 0.0042, 0.0008, 0.0051, 0.3733],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the]
[2024-07-24 10:23:04,125][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ house] are: tensor([0.0028, 0.0130, 0.0517, 0.0255, 0.0160, 0.1045, 0.0075, 0.1084, 0.5445,
        0.1259], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,126][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ house] are: tensor([0.0145, 0.0440, 0.0975, 0.0356, 0.2790, 0.1354, 0.1030, 0.0495, 0.1665,
        0.0749], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,127][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ house] are: tensor([1.1728e-04, 1.3555e-01, 3.7832e-01, 1.1687e-01, 2.5315e-02, 6.6767e-02,
        3.1599e-02, 1.4957e-02, 1.3639e-01, 9.4104e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,130][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ house] are: tensor([0.0373, 0.0116, 0.0435, 0.2724, 0.0332, 0.0121, 0.0015, 0.0108, 0.2388,
        0.3388], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,131][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ house] are: tensor([0.0025, 0.0264, 0.1366, 0.0757, 0.0271, 0.2192, 0.0322, 0.0563, 0.2080,
        0.2159], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,132][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ house] are: tensor([1.2501e-05, 2.3400e-01, 1.8743e-01, 2.0856e-02, 3.9009e-02, 7.9970e-02,
        5.3468e-02, 3.7273e-02, 2.9293e-01, 5.5052e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,135][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ house] are: tensor([0.0003, 0.1954, 0.1956, 0.0127, 0.2243, 0.0777, 0.0480, 0.0325, 0.1933,
        0.0201], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,139][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ house] are: tensor([0.0019, 0.4427, 0.1646, 0.0141, 0.0912, 0.0668, 0.0429, 0.0134, 0.1191,
        0.0433], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,141][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ house] are: tensor([5.8137e-05, 8.6718e-03, 2.8329e-01, 4.6995e-02, 1.1080e-01, 9.9822e-02,
        6.6591e-03, 4.2971e-02, 2.5613e-01, 1.4461e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,144][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ house] are: tensor([5.1937e-05, 2.6776e-01, 1.4609e-01, 5.4319e-03, 1.9178e-01, 6.8387e-02,
        3.3157e-02, 1.6258e-02, 2.0861e-01, 6.2475e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,148][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ house] are: tensor([0.0138, 0.0469, 0.4720, 0.0447, 0.1442, 0.0137, 0.0208, 0.0643, 0.1475,
        0.0320], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,151][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ house] are: tensor([0.0010, 0.0095, 0.0559, 0.1128, 0.3525, 0.0094, 0.0008, 0.0103, 0.3322,
        0.1156], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house]
[2024-07-24 10:23:04,153][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0063, 0.0324, 0.0298, 0.0219, 0.0154, 0.0361, 0.0099, 0.0871, 0.2349,
        0.0412, 0.4850], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,154][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0100, 0.0834, 0.0483, 0.0384, 0.2171, 0.0766, 0.0605, 0.0271, 0.1768,
        0.0492, 0.2125], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,155][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0004, 0.1982, 0.1079, 0.0525, 0.0353, 0.0486, 0.0560, 0.0166, 0.2494,
        0.0909, 0.1442], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,155][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0551, 0.0498, 0.0320, 0.1676, 0.0722, 0.0052, 0.0019, 0.0090, 0.2028,
        0.2436, 0.1607], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,157][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0007, 0.0133, 0.1591, 0.0306, 0.0593, 0.0587, 0.0103, 0.0390, 0.1179,
        0.0657, 0.4454], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,159][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.3147e-06, 3.8656e-01, 7.7754e-02, 5.2077e-03, 4.3536e-02, 1.9420e-02,
        2.3091e-02, 2.5731e-02, 2.2726e-01, 3.1446e-02, 1.5998e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,164][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0014, 0.1715, 0.2587, 0.0086, 0.1665, 0.0384, 0.0256, 0.0146, 0.1241,
        0.0132, 0.1775], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,167][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0015, 0.3818, 0.1317, 0.0059, 0.1690, 0.0210, 0.0174, 0.0069, 0.1223,
        0.0318, 0.1108], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,169][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([8.1256e-05, 7.1190e-03, 5.8421e-02, 1.2897e-02, 1.1974e-01, 2.2765e-02,
        5.6929e-03, 7.2310e-02, 9.9467e-02, 9.6602e-02, 5.0491e-01],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,171][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([7.5208e-05, 4.9970e-01, 8.2829e-02, 3.2938e-03, 1.4107e-01, 2.8307e-02,
        7.2497e-03, 9.9766e-03, 1.2261e-01, 1.2930e-02, 9.1959e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,176][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0084, 0.0875, 0.2518, 0.0094, 0.1278, 0.0051, 0.0150, 0.0242, 0.0697,
        0.0074, 0.3938], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,178][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0012, 0.0540, 0.0397, 0.0650, 0.5674, 0.0021, 0.0008, 0.0041, 0.1620,
        0.0224, 0.0815], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house,]
[2024-07-24 10:23:04,179][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ William] are: tensor([0.0018, 0.0116, 0.0326, 0.0270, 0.0157, 0.0378, 0.0055, 0.0652, 0.2268,
        0.1003, 0.4033, 0.0724], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,179][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ William] are: tensor([0.0031, 0.0409, 0.0676, 0.0092, 0.2270, 0.0772, 0.0608, 0.0254, 0.1656,
        0.0429, 0.2697, 0.0107], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,180][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ William] are: tensor([7.0536e-05, 1.0236e-01, 2.9917e-01, 2.8311e-02, 2.6005e-02, 4.3398e-02,
        2.5846e-02, 2.0028e-02, 2.4027e-01, 6.9344e-02, 1.2322e-01, 2.1978e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,182][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ William] are: tensor([0.0064, 0.0131, 0.0578, 0.1043, 0.0432, 0.0063, 0.0007, 0.0054, 0.2287,
        0.1385, 0.3136, 0.0821], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,185][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ William] are: tensor([0.0021, 0.0361, 0.0574, 0.0626, 0.0471, 0.0851, 0.0173, 0.0314, 0.1546,
        0.0795, 0.2527, 0.1741], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,187][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ William] are: tensor([5.7679e-06, 2.2982e-01, 1.8283e-01, 1.3095e-02, 7.7976e-02, 5.9788e-02,
        2.5517e-02, 2.9928e-02, 2.3015e-01, 2.4304e-02, 1.1929e-01, 7.3017e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,190][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ William] are: tensor([2.1798e-04, 3.1406e-01, 9.2254e-02, 1.0820e-02, 1.6938e-01, 3.1456e-02,
        3.1613e-02, 1.8041e-02, 1.5895e-01, 1.2403e-02, 1.5785e-01, 2.9473e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,194][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ William] are: tensor([0.0011, 0.4363, 0.1504, 0.0080, 0.1095, 0.0357, 0.0276, 0.0096, 0.1174,
        0.0258, 0.0747, 0.0041], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,196][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ William] are: tensor([1.0860e-05, 2.6687e-03, 8.2739e-02, 2.4315e-02, 6.8081e-02, 3.7690e-02,
        4.7699e-03, 2.6675e-02, 1.4466e-01, 9.8667e-02, 4.7620e-01, 3.3518e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,199][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ William] are: tensor([1.8023e-05, 1.5684e-01, 7.1573e-02, 3.4912e-03, 3.3338e-01, 4.4507e-02,
        2.1184e-02, 1.9434e-02, 1.8111e-01, 3.6580e-02, 1.2693e-01, 4.9479e-03],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,202][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ William] are: tensor([0.0016, 0.0364, 0.2769, 0.0442, 0.1292, 0.0065, 0.0100, 0.0162, 0.0860,
        0.0174, 0.3447, 0.0310], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,203][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ William] are: tensor([0.0022, 0.0122, 0.0596, 0.0372, 0.2591, 0.0034, 0.0005, 0.0054, 0.2808,
        0.0506, 0.2783, 0.0108], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William]
[2024-07-24 10:23:04,204][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0024, 0.0106, 0.0262, 0.0351, 0.0178, 0.0448, 0.0143, 0.0712, 0.1280,
        0.0740, 0.3466, 0.0846, 0.1442], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,205][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0045, 0.0348, 0.0580, 0.0236, 0.2671, 0.0837, 0.0640, 0.0371, 0.0995,
        0.0594, 0.1570, 0.0237, 0.0877], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,206][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([7.4288e-05, 6.2537e-02, 2.1352e-01, 6.0150e-02, 3.4566e-02, 4.6362e-02,
        4.1941e-02, 3.0942e-02, 1.9135e-01, 1.8039e-01, 7.4146e-02, 4.5708e-02,
        1.8324e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,209][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0606, 0.0126, 0.0833, 0.2212, 0.0377, 0.0075, 0.0015, 0.0086, 0.1107,
        0.1652, 0.0885, 0.1736, 0.0291], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,213][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0011, 0.0239, 0.0867, 0.0214, 0.0405, 0.0940, 0.0182, 0.0294, 0.1089,
        0.0990, 0.2022, 0.1060, 0.1689], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,216][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([8.7234e-06, 2.7162e-01, 1.4204e-01, 1.2397e-02, 2.9629e-02, 5.2769e-02,
        7.2950e-02, 3.5108e-02, 1.8454e-01, 4.9894e-02, 1.1330e-01, 1.3126e-02,
        2.2624e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,219][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0004, 0.2240, 0.2577, 0.0226, 0.0820, 0.0444, 0.0452, 0.0295, 0.1235,
        0.0342, 0.1021, 0.0095, 0.0249], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,223][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0012, 0.2748, 0.1221, 0.0061, 0.1355, 0.0377, 0.0293, 0.0208, 0.1186,
        0.0693, 0.0957, 0.0067, 0.0822], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,225][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([5.0462e-05, 5.8237e-03, 1.1228e-01, 2.2723e-02, 5.3061e-02, 3.3428e-02,
        3.5193e-03, 2.6661e-02, 9.6588e-02, 6.9116e-02, 4.1940e-01, 2.3638e-02,
        1.3372e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,227][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([4.3991e-05, 2.3995e-01, 1.9441e-01, 7.8428e-03, 1.1034e-01, 4.2768e-02,
        3.5685e-02, 2.1315e-02, 1.2893e-01, 8.0543e-02, 1.0122e-01, 1.1324e-02,
        2.5609e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,228][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0026, 0.0727, 0.3304, 0.0223, 0.0574, 0.0145, 0.0430, 0.0367, 0.0901,
        0.0155, 0.2551, 0.0200, 0.0396], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,229][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0012, 0.0272, 0.0580, 0.0896, 0.2292, 0.0173, 0.0019, 0.0090, 0.3154,
        0.0820, 0.1044, 0.0222, 0.0425], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided]
[2024-07-24 10:23:04,230][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0017, 0.0038, 0.0113, 0.0047, 0.0064, 0.0117, 0.0033, 0.0244, 0.0781,
        0.0189, 0.1824, 0.0170, 0.1165, 0.5197], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,232][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0204, 0.0592, 0.0293, 0.0240, 0.1504, 0.0513, 0.0318, 0.0125, 0.1170,
        0.0529, 0.1708, 0.0174, 0.2167, 0.0463], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,234][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0004, 0.0824, 0.0690, 0.1011, 0.0273, 0.0392, 0.0264, 0.0142, 0.1529,
        0.1664, 0.0904, 0.0721, 0.0330, 0.1251], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,238][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0564, 0.0422, 0.0509, 0.1838, 0.0313, 0.0036, 0.0026, 0.0064, 0.1245,
        0.1869, 0.0905, 0.1354, 0.0556, 0.0299], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,243][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0011, 0.0122, 0.1267, 0.0145, 0.0428, 0.0382, 0.0076, 0.0237, 0.0780,
        0.0929, 0.2335, 0.0631, 0.1142, 0.1514], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,245][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.2740e-05, 3.2380e-01, 9.6455e-02, 6.6165e-03, 4.1574e-02, 2.2466e-02,
        2.1579e-02, 3.0346e-02, 1.7438e-01, 2.8562e-02, 1.7523e-01, 6.9113e-03,
        1.8644e-02, 5.3428e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,248][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0012, 0.0597, 0.2865, 0.0096, 0.0907, 0.0344, 0.0157, 0.0162, 0.1337,
        0.0403, 0.2356, 0.0043, 0.0180, 0.0538], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,252][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0022, 0.3510, 0.1129, 0.0049, 0.1096, 0.0198, 0.0105, 0.0077, 0.1335,
        0.0314, 0.1069, 0.0045, 0.0490, 0.0561], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,253][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.6540e-04, 9.7375e-03, 7.9282e-02, 8.8480e-03, 4.6468e-02, 9.9958e-03,
        1.8848e-03, 2.8567e-02, 7.7838e-02, 6.9286e-02, 4.0713e-01, 1.0722e-02,
        1.5673e-01, 9.3248e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,254][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0005, 0.3166, 0.0543, 0.0055, 0.1519, 0.0289, 0.0127, 0.0132, 0.1467,
        0.0426, 0.1110, 0.0065, 0.0695, 0.0401], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,255][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0080, 0.0731, 0.2321, 0.0159, 0.0641, 0.0023, 0.0068, 0.0215, 0.0525,
        0.0070, 0.3653, 0.0159, 0.0497, 0.0857], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,257][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0014, 0.0229, 0.0383, 0.0684, 0.4465, 0.0022, 0.0014, 0.0045, 0.2053,
        0.0525, 0.1041, 0.0112, 0.0335, 0.0076], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to]
[2024-07-24 10:23:04,259][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0011, 0.0037, 0.0088, 0.0053, 0.0058, 0.0109, 0.0030, 0.0268, 0.0708,
        0.0180, 0.1338, 0.0202, 0.0597, 0.4646, 0.1674], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,263][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0061, 0.0465, 0.0861, 0.0174, 0.3088, 0.0643, 0.0592, 0.0111, 0.0706,
        0.0439, 0.0999, 0.0069, 0.1058, 0.0110, 0.0625], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,266][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([6.3653e-05, 6.3792e-02, 3.1709e-01, 8.8327e-02, 2.0701e-02, 3.3159e-02,
        3.4309e-02, 1.0310e-02, 1.1596e-01, 4.6821e-02, 1.0792e-01, 3.1290e-02,
        1.3204e-02, 6.8369e-02, 4.8684e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,270][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0206, 0.0070, 0.0509, 0.0635, 0.0216, 0.0022, 0.0006, 0.0050, 0.1147,
        0.1023, 0.1176, 0.0788, 0.0468, 0.0606, 0.3077], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,274][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0004, 0.0056, 0.0958, 0.0205, 0.0168, 0.0422, 0.0067, 0.0105, 0.0480,
        0.0634, 0.1553, 0.0685, 0.0795, 0.0647, 0.3221], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,277][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([4.5434e-06, 3.4713e-01, 8.2764e-02, 5.8989e-03, 4.4524e-02, 3.4815e-02,
        5.8879e-02, 1.7809e-02, 1.5846e-01, 2.3099e-02, 1.0879e-01, 5.0615e-03,
        1.8491e-02, 2.8901e-02, 6.5365e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,277][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([1.7165e-04, 1.2728e-01, 2.9055e-01, 1.1944e-02, 1.4329e-01, 3.0604e-02,
        2.9563e-02, 9.1494e-03, 9.5906e-02, 1.6241e-02, 1.4286e-01, 3.5058e-03,
        1.0118e-02, 2.0302e-02, 6.8516e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,278][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0004, 0.1579, 0.1703, 0.0055, 0.1772, 0.0222, 0.0171, 0.0094, 0.1280,
        0.0426, 0.1110, 0.0031, 0.0412, 0.0360, 0.0781], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,279][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([1.6806e-05, 5.6793e-03, 7.3573e-02, 8.7294e-03, 3.1876e-02, 8.7897e-03,
        1.0813e-03, 1.2837e-02, 7.8893e-02, 6.0135e-02, 2.7948e-01, 7.8559e-03,
        1.1126e-01, 8.2804e-02, 2.3699e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,281][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([2.3902e-05, 1.5285e-01, 1.5279e-01, 4.4142e-03, 2.4843e-01, 4.0800e-02,
        4.1743e-02, 8.0414e-03, 1.2487e-01, 2.7464e-02, 1.2117e-01, 4.2056e-03,
        2.0084e-02, 1.6203e-02, 3.6921e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,283][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0066, 0.0555, 0.4354, 0.0122, 0.0564, 0.0034, 0.0152, 0.0104, 0.0520,
        0.0065, 0.2422, 0.0105, 0.0236, 0.0364, 0.0337], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,288][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0040, 0.0131, 0.0477, 0.0265, 0.2055, 0.0032, 0.0014, 0.0037, 0.2081,
        0.0409, 0.1435, 0.0096, 0.0468, 0.0107, 0.2354], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give]
[2024-07-24 10:23:04,292][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ it] are: tensor([0.0010, 0.0035, 0.0077, 0.0062, 0.0044, 0.0095, 0.0023, 0.0174, 0.0723,
        0.0151, 0.1197, 0.0149, 0.0656, 0.4173, 0.1456, 0.0974],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,295][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ it] are: tensor([0.0058, 0.0332, 0.0314, 0.0175, 0.1404, 0.0273, 0.0173, 0.0086, 0.0668,
        0.0179, 0.1114, 0.0062, 0.1514, 0.0209, 0.0579, 0.2859],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,297][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ it] are: tensor([1.6397e-05, 8.8565e-02, 1.2402e-01, 4.9535e-02, 1.5148e-02, 2.1712e-02,
        1.4348e-02, 7.5461e-03, 1.8990e-01, 3.2334e-02, 9.0086e-02, 1.1926e-02,
        1.7499e-02, 4.8135e-02, 2.6183e-02, 2.6305e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,300][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ it] are: tensor([2.6197e-02, 1.0980e-02, 4.4193e-02, 6.8264e-02, 1.3127e-02, 1.1775e-03,
        2.6905e-04, 2.3431e-03, 6.9951e-02, 6.0218e-02, 6.5249e-02, 3.7095e-02,
        3.3806e-02, 2.0886e-02, 1.6538e-01, 3.8087e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,301][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ it] are: tensor([9.6992e-05, 7.3868e-03, 7.7479e-02, 7.7446e-03, 1.7507e-02, 1.8660e-02,
        2.1408e-03, 9.5287e-03, 5.0066e-02, 3.0332e-02, 1.7909e-01, 3.1753e-02,
        5.2282e-02, 7.2551e-02, 2.9199e-01, 1.5139e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,302][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ it] are: tensor([4.5577e-06, 2.1656e-01, 1.2281e-01, 6.3620e-03, 2.3266e-02, 2.5930e-02,
        1.7298e-02, 2.1194e-02, 2.1509e-01, 2.2081e-02, 1.3998e-01, 3.4460e-03,
        1.8119e-02, 5.0172e-02, 5.0239e-02, 6.7451e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,303][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ it] are: tensor([1.4568e-04, 1.5350e-01, 2.1777e-01, 9.8753e-03, 8.5767e-02, 3.6137e-02,
        1.2525e-02, 5.7373e-03, 1.1874e-01, 9.0329e-03, 1.1905e-01, 1.2692e-03,
        1.0884e-02, 1.6293e-02, 3.9297e-02, 1.6397e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,304][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ it] are: tensor([0.0014, 0.2017, 0.0806, 0.0026, 0.0548, 0.0149, 0.0057, 0.0056, 0.1068,
        0.0219, 0.0566, 0.0010, 0.0314, 0.0205, 0.0458, 0.3487],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,305][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ it] are: tensor([7.5447e-05, 3.1936e-03, 7.3977e-02, 3.1100e-03, 3.2491e-02, 4.9808e-03,
        4.6799e-04, 9.2182e-03, 5.4961e-02, 1.7152e-02, 3.0057e-01, 2.1199e-03,
        5.1379e-02, 5.6028e-02, 1.3600e-01, 2.5427e-01], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,307][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ it] are: tensor([2.3378e-05, 3.2224e-01, 7.6347e-02, 3.1035e-03, 1.4215e-01, 3.4032e-02,
        1.3789e-02, 4.5312e-03, 1.5463e-01, 1.2100e-02, 1.2698e-01, 1.7587e-03,
        3.0351e-02, 1.5374e-02, 1.6602e-02, 4.5984e-02], device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,311][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ it] are: tensor([0.0139, 0.0995, 0.4397, 0.0099, 0.0991, 0.0031, 0.0127, 0.0070, 0.0419,
        0.0017, 0.1310, 0.0025, 0.0309, 0.0131, 0.0077, 0.0863],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,315][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ it] are: tensor([0.0006, 0.0108, 0.0342, 0.0182, 0.1566, 0.0016, 0.0004, 0.0012, 0.1647,
        0.0136, 0.1545, 0.0038, 0.0384, 0.0076, 0.2493, 0.1446],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it]
[2024-07-24 10:23:04,319][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0007, 0.0036, 0.0068, 0.0047, 0.0045, 0.0078, 0.0019, 0.0163, 0.0578,
        0.0106, 0.0981, 0.0141, 0.0697, 0.2722, 0.1126, 0.0681, 0.2506],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,322][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0084, 0.0357, 0.0297, 0.0142, 0.1486, 0.0326, 0.0202, 0.0079, 0.0793,
        0.0247, 0.1168, 0.0081, 0.1312, 0.0196, 0.0828, 0.2175, 0.0229],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,324][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.1736e-04, 6.1779e-02, 5.4493e-02, 7.5895e-02, 2.0166e-02, 2.2494e-02,
        1.2852e-02, 8.2707e-03, 9.6738e-02, 6.6389e-02, 5.8285e-02, 4.0980e-02,
        2.1096e-02, 5.8954e-02, 7.7100e-02, 2.2673e-01, 9.7556e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,326][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0339, 0.0076, 0.0303, 0.0473, 0.0181, 0.0009, 0.0008, 0.0017, 0.0368,
        0.0619, 0.0487, 0.0407, 0.0178, 0.0135, 0.1421, 0.4528, 0.0451],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,327][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0006, 0.0116, 0.0748, 0.0109, 0.0198, 0.0190, 0.0037, 0.0099, 0.0473,
        0.0385, 0.1280, 0.0429, 0.0596, 0.0715, 0.2505, 0.0888, 0.1227],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,328][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.6748e-05, 3.3282e-01, 6.0494e-02, 6.3221e-03, 2.5872e-02, 1.8825e-02,
        1.5895e-02, 1.8164e-02, 1.4705e-01, 2.3835e-02, 1.0811e-01, 5.9215e-03,
        1.9168e-02, 3.3046e-02, 7.1589e-02, 7.2005e-02, 4.0877e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,329][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0006, 0.0686, 0.2154, 0.0088, 0.0870, 0.0279, 0.0129, 0.0078, 0.0777,
        0.0238, 0.1678, 0.0032, 0.0114, 0.0279, 0.0655, 0.1571, 0.0365],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,331][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0015, 0.2404, 0.0505, 0.0037, 0.0674, 0.0120, 0.0048, 0.0039, 0.0881,
        0.0199, 0.0560, 0.0022, 0.0342, 0.0189, 0.0559, 0.3019, 0.0388],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,333][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.3443e-04, 5.0846e-03, 4.8953e-02, 3.4220e-03, 2.7751e-02, 3.3317e-03,
        8.5384e-04, 1.2712e-02, 4.0125e-02, 4.9666e-02, 1.8562e-01, 3.6720e-03,
        8.7087e-02, 4.6625e-02, 2.7694e-01, 1.8138e-01, 2.6638e-02],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,337][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0004, 0.3011, 0.0712, 0.0076, 0.1239, 0.0278, 0.0105, 0.0078, 0.1428,
        0.0234, 0.1012, 0.0055, 0.0450, 0.0228, 0.0410, 0.0481, 0.0199],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,340][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0435, 0.0652, 0.2590, 0.0189, 0.0569, 0.0021, 0.0085, 0.0134, 0.0368,
        0.0068, 0.1943, 0.0116, 0.0378, 0.0308, 0.0349, 0.1453, 0.0341],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,344][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0017, 0.0147, 0.0389, 0.0409, 0.2039, 0.0015, 0.0011, 0.0021, 0.1260,
        0.0356, 0.0881, 0.0081, 0.0209, 0.0055, 0.2119, 0.1839, 0.0151],
       device='cuda:0') for source tokens [When Katherine and William got a basketball at the house, William decided to give it to]
[2024-07-24 10:23:04,347][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:23:04,351][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5653],
        [ 225],
        [  57],
        [ 373],
        [  12],
        [  12],
        [   8],
        [   1],
        [   5],
        [  47],
        [   6],
        [  42],
        [   5],
        [   7],
        [   8],
        [   4],
        [   1]], device='cuda:0')
[2024-07-24 10:23:04,353][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5904],
        [ 151],
        [  48],
        [ 238],
        [  10],
        [  13],
        [   4],
        [   8],
        [  10],
        [  22],
        [   5],
        [  22],
        [   1],
        [   9],
        [  12],
        [   9],
        [   4]], device='cuda:0')
[2024-07-24 10:23:04,354][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16328],
        [  695],
        [ 8851],
        [10365],
        [ 7986],
        [11961],
        [12525],
        [15332],
        [17185],
        [18480],
        [17168],
        [17764],
        [16708],
        [18382],
        [17479],
        [17396],
        [18387]], device='cuda:0')
[2024-07-24 10:23:04,356][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  590],
        [15467],
        [13406],
        [25183],
        [23823],
        [15404],
        [11651],
        [15248],
        [13983],
        [10644],
        [12244],
        [12203],
        [10608],
        [ 8033],
        [11175],
        [ 5710],
        [ 5994]], device='cuda:0')
[2024-07-24 10:23:04,357][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4378],
        [32076],
        [47952],
        [49967],
        [49041],
        [49987],
        [49831],
        [49054],
        [49999],
        [49681],
        [49734],
        [49976],
        [49444],
        [49647],
        [49801],
        [49948],
        [50020]], device='cuda:0')
[2024-07-24 10:23:04,360][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11601],
        [13037],
        [16369],
        [16057],
        [17499],
        [22624],
        [22563],
        [27660],
        [23246],
        [30412],
        [39397],
        [37438],
        [35471],
        [36945],
        [34472],
        [35240],
        [36072]], device='cuda:0')
[2024-07-24 10:23:04,363][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23156],
        [ 1508],
        [ 1975],
        [ 2123],
        [ 3029],
        [ 3919],
        [ 3647],
        [ 3775],
        [ 5161],
        [ 5901],
        [ 4815],
        [ 5945],
        [ 4394],
        [ 4351],
        [ 5117],
        [ 5116],
        [ 4934]], device='cuda:0')
[2024-07-24 10:23:04,366][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38767],
        [36551],
        [37775],
        [37252],
        [38665],
        [37650],
        [37665],
        [37090],
        [35617],
        [34082],
        [33868],
        [34575],
        [34151],
        [33927],
        [34371],
        [33414],
        [34387]], device='cuda:0')
[2024-07-24 10:23:04,368][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[22837],
        [29889],
        [30420],
        [29075],
        [28763],
        [29939],
        [33866],
        [30765],
        [30121],
        [30967],
        [29559],
        [31109],
        [33378],
        [29265],
        [29509],
        [29973],
        [30439]], device='cuda:0')
[2024-07-24 10:23:04,371][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42769],
        [27042],
        [18380],
        [23750],
        [19939],
        [21540],
        [19600],
        [19802],
        [17783],
        [19400],
        [17520],
        [18255],
        [16612],
        [16408],
        [15373],
        [21029],
        [20698]], device='cuda:0')
[2024-07-24 10:23:04,374][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17671],
        [ 8136],
        [13519],
        [14569],
        [13931],
        [14397],
        [14505],
        [14724],
        [14373],
        [14544],
        [14318],
        [14448],
        [14387],
        [14168],
        [13944],
        [14687],
        [14378]], device='cuda:0')
[2024-07-24 10:23:04,376][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[45211],
        [49648],
        [48828],
        [49426],
        [46349],
        [47123],
        [47753],
        [47983],
        [48209],
        [47648],
        [48849],
        [45385],
        [47943],
        [48118],
        [46226],
        [48048],
        [48101]], device='cuda:0')
[2024-07-24 10:23:04,379][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[45717],
        [ 1675],
        [ 3830],
        [ 3289],
        [ 5957],
        [ 6414],
        [ 7620],
        [ 6841],
        [ 6578],
        [ 9447],
        [ 7604],
        [ 8998],
        [ 8335],
        [ 8197],
        [ 9230],
        [ 8587],
        [10294]], device='cuda:0')
[2024-07-24 10:23:04,382][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15893],
        [35783],
        [36295],
        [39257],
        [45503],
        [45200],
        [46226],
        [44923],
        [45684],
        [45818],
        [45763],
        [44752],
        [45361],
        [45926],
        [46119],
        [46901],
        [47195]], device='cuda:0')
[2024-07-24 10:23:04,383][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19263],
        [14017],
        [ 8325],
        [11096],
        [ 9374],
        [11297],
        [10979],
        [11549],
        [10933],
        [11960],
        [ 7903],
        [11545],
        [10610],
        [ 8919],
        [11259],
        [ 9364],
        [ 9870]], device='cuda:0')
[2024-07-24 10:23:04,384][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18836],
        [17949],
        [15325],
        [15093],
        [13413],
        [14335],
        [15174],
        [13445],
        [14913],
        [15936],
        [17787],
        [18012],
        [18069],
        [19094],
        [18581],
        [18181],
        [18786]], device='cuda:0')
[2024-07-24 10:23:04,386][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[27920],
        [29175],
        [32759],
        [33534],
        [27742],
        [29278],
        [33246],
        [31536],
        [30690],
        [31784],
        [29919],
        [29072],
        [30158],
        [32024],
        [29736],
        [32517],
        [32311]], device='cuda:0')
[2024-07-24 10:23:04,389][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38656],
        [19896],
        [27572],
        [27550],
        [29399],
        [30635],
        [31202],
        [32437],
        [26619],
        [30662],
        [27763],
        [29121],
        [30200],
        [31380],
        [32095],
        [31543],
        [33124]], device='cuda:0')
[2024-07-24 10:23:04,392][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17335],
        [14322],
        [11353],
        [ 8396],
        [ 8082],
        [ 8289],
        [ 8044],
        [ 8858],
        [ 8812],
        [ 9618],
        [10307],
        [10940],
        [ 9360],
        [ 9434],
        [10632],
        [10663],
        [10624]], device='cuda:0')
[2024-07-24 10:23:04,394][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31832],
        [17215],
        [22374],
        [16893],
        [20903],
        [18080],
        [18230],
        [17761],
        [14118],
        [14817],
        [14929],
        [13950],
        [13977],
        [14052],
        [12292],
        [11724],
        [12467]], device='cuda:0')
[2024-07-24 10:23:04,397][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5055],
        [ 9032],
        [ 6924],
        [ 8157],
        [ 9228],
        [ 8404],
        [ 8298],
        [ 8493],
        [10683],
        [10622],
        [11456],
        [10376],
        [10567],
        [10551],
        [10650],
        [10159],
        [10279]], device='cuda:0')
[2024-07-24 10:23:04,400][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38117],
        [33125],
        [37150],
        [33525],
        [32854],
        [31453],
        [31464],
        [32209],
        [31799],
        [31031],
        [32093],
        [31585],
        [31995],
        [31282],
        [31008],
        [30479],
        [29142]], device='cuda:0')
[2024-07-24 10:23:04,402][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34972],
        [31203],
        [36092],
        [33577],
        [39351],
        [37141],
        [37916],
        [38438],
        [37730],
        [37008],
        [37265],
        [36826],
        [37029],
        [36481],
        [37192],
        [37009],
        [36982]], device='cuda:0')
[2024-07-24 10:23:04,405][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21897],
        [15179],
        [16025],
        [16596],
        [17009],
        [17079],
        [17142],
        [17153],
        [16965],
        [16912],
        [17001],
        [16986],
        [16962],
        [17001],
        [16969],
        [16950],
        [16969]], device='cuda:0')
[2024-07-24 10:23:04,408][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24892],
        [16159],
        [15921],
        [17379],
        [12389],
        [12596],
        [12778],
        [13688],
        [15330],
        [12782],
        [15002],
        [11831],
        [12433],
        [13820],
        [11677],
        [13299],
        [13252]], device='cuda:0')
[2024-07-24 10:23:04,410][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19942],
        [34837],
        [39883],
        [35286],
        [38473],
        [37570],
        [35675],
        [38653],
        [37523],
        [37972],
        [36889],
        [36282],
        [37514],
        [36487],
        [38044],
        [38047],
        [35699]], device='cuda:0')
[2024-07-24 10:23:04,412][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7720],
        [25255],
        [21706],
        [17319],
        [11840],
        [11802],
        [11663],
        [12078],
        [ 9485],
        [ 9420],
        [11070],
        [11066],
        [10012],
        [10650],
        [10311],
        [ 9863],
        [ 9519]], device='cuda:0')
[2024-07-24 10:23:04,413][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17116],
        [19249],
        [17462],
        [20847],
        [22572],
        [22681],
        [21676],
        [20356],
        [23016],
        [22177],
        [20996],
        [22159],
        [22428],
        [20948],
        [21300],
        [20852],
        [20692]], device='cuda:0')
[2024-07-24 10:23:04,415][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26678],
        [31517],
        [37088],
        [35248],
        [35526],
        [33505],
        [33753],
        [33025],
        [33882],
        [33507],
        [37214],
        [34246],
        [34779],
        [36264],
        [32841],
        [35643],
        [35918]], device='cuda:0')
[2024-07-24 10:23:04,417][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848],
        [19848]], device='cuda:0')
