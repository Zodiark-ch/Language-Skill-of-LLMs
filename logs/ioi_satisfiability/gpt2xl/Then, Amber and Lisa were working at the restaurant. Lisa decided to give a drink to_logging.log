[2024-07-24 10:25:58,840][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to
[2024-07-24 10:25:58,840][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Amber
[2024-07-24 10:25:58,840][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:25:58,840][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:25:58,840][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:25:58,840][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,840][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,841][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:25:58,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:25:58,843][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit9', 'circuit13']
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:25:58,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:25:58,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:25:58,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,850][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:25:58,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,855][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit27']
[2024-07-24 10:25:58,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:25:58,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:25:58,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:25:58,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit25']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit10', 'circuit13']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,865][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,869][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit13']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit26']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,872][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:25:58,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23']
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,876][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit9', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit23']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:25:58,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit24']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:25:58,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit21']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,882][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21', 'circuit27']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,885][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,886][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,887][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,889][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,891][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21', 'circuit23', 'circuit27']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:25:58,892][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,893][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit21', 'circuit26']
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,897][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,898][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,899][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,900][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit2', 'circuit4', 'circuit7', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:25:58,901][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit19', 'circuit20']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,902][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit12']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2', 'circuit7', 'circuit13']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,903][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit23']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,904][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit24']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit15']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit25']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,905][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit20']
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,906][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,907][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:25:58,908][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,909][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,910][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:25:58,911][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,912][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,913][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17']
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,914][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,915][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit8', 'circuit9']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit23']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:58,916][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit23']
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit22']
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,917][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,918][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,919][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,920][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,921][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,922][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,923][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,924][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,925][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,926][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit18', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit9', 'circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit18', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13']
[2024-07-24 10:25:58,927][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit21']
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit10', 'circuit15', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit14']
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit23', 'circuit27']
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,928][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,929][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,930][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,931][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,932][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,933][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23']
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit18', 'circuit21']
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:25:58,934][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,935][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,936][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,937][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,938][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,939][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:58,940][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,941][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:58,942][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:26:00,552][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:00,553][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,554][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,555][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,556][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,556][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,557][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,558][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,559][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,560][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,561][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,563][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,564][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,566][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,567][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,569][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,570][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,571][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,571][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,572][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,573][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,574][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,576][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,578][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,579][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,581][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.4449, 0.3965, 0.1586], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,582][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([1.1269e-05, 1.6706e-05, 9.9997e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,583][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.5495, 0.2948, 0.1557], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,584][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([1.8765e-03, 2.0354e-05, 9.9810e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,586][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.0152, 0.0018, 0.9830], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,587][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([1.3508e-04, 1.2414e-08, 9.9986e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,589][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.4201, 0.3001, 0.2798], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,590][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.6321, 0.3196, 0.0482], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,592][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.6753, 0.1948, 0.1298], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,593][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.6018, 0.3523, 0.0459], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,595][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.4312, 0.2586, 0.3101], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,597][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.3094, 0.5296, 0.1609], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,598][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6803, 0.0771, 0.1825, 0.0601], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,599][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3030e-03, 3.9255e-02, 2.8662e-04, 9.5816e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,601][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2326, 0.1742, 0.0573, 0.5359], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,602][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1135, 0.3881, 0.0237, 0.4747], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,604][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3402, 0.1541, 0.2265, 0.2791], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,606][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1226, 0.1962, 0.0111, 0.6702], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,607][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6344, 0.0303, 0.3123, 0.0230], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,609][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2185, 0.1662, 0.3652, 0.2502], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,610][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0670, 0.4690, 0.0244, 0.4397], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,612][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4289, 0.2395, 0.1092, 0.2225], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,612][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4208, 0.3134, 0.0590, 0.2068], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,613][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4775, 0.2085, 0.0414, 0.2725], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,614][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.2817, 0.2422, 0.1404, 0.1552, 0.1805], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,615][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([2.7668e-04, 2.2834e-04, 6.6521e-04, 8.2364e-05, 9.9875e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,616][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.5079, 0.2344, 0.0695, 0.1238, 0.0644], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,617][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([1.8461e-02, 3.9841e-05, 1.2212e-02, 1.0086e-04, 9.6919e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,619][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.1004, 0.0057, 0.1827, 0.0048, 0.7065], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,620][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([1.6026e-02, 2.8854e-06, 7.4145e-05, 7.1867e-07, 9.8390e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,621][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.2488, 0.2070, 0.2086, 0.1112, 0.2243], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,623][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.2732, 0.1195, 0.1690, 0.2673, 0.1711], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,625][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.3484, 0.2503, 0.0640, 0.1777, 0.1595], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,626][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.4121, 0.2391, 0.1378, 0.1883, 0.0228], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,628][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.3346, 0.2050, 0.0871, 0.1196, 0.2537], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,630][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.2758, 0.2094, 0.0860, 0.2908, 0.1379], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,631][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.3998, 0.0389, 0.0605, 0.0359, 0.1129, 0.3521], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,633][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0012, 0.0083, 0.0026, 0.0080, 0.0039, 0.9759], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,635][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.4199, 0.1411, 0.0661, 0.1472, 0.0637, 0.1621], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,636][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0324, 0.0157, 0.0028, 0.0295, 0.0080, 0.9116], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,638][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3172, 0.0637, 0.0887, 0.1014, 0.0993, 0.3297], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,639][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ were] are: tensor([4.4479e-02, 3.7331e-03, 1.3379e-03, 1.0998e-03, 2.6539e-04, 9.4908e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,641][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.2509, 0.0365, 0.3159, 0.0354, 0.3316, 0.0298], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,643][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1239, 0.1006, 0.0577, 0.1902, 0.3212, 0.2063], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,644][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0883, 0.2944, 0.0187, 0.3662, 0.0308, 0.2015], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,646][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.3119, 0.1774, 0.1139, 0.1828, 0.0807, 0.1333], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,648][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2573, 0.1957, 0.0675, 0.1522, 0.0423, 0.2851], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,649][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.3655, 0.1802, 0.0346, 0.2045, 0.0860, 0.1291], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,651][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.2779, 0.0586, 0.1596, 0.0670, 0.2955, 0.1010, 0.0404],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,652][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ working] are: tensor([1.2292e-04, 1.0622e-03, 1.1815e-04, 2.3728e-03, 6.7404e-04, 4.5833e-04,
        9.9519e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,654][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.3380, 0.1318, 0.0366, 0.1393, 0.0887, 0.1183, 0.1473],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,654][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ working] are: tensor([5.7705e-03, 2.6504e-04, 3.3265e-04, 6.5582e-04, 2.3075e-04, 2.8413e-03,
        9.8990e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,655][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0797, 0.0211, 0.1088, 0.0225, 0.0435, 0.0349, 0.6896],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,656][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ working] are: tensor([4.9260e-03, 4.2449e-05, 4.4481e-05, 2.7747e-05, 2.8644e-04, 9.2147e-06,
        9.9466e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,657][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.3770, 0.0463, 0.1919, 0.0359, 0.1661, 0.0456, 0.1371],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,658][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.1158, 0.0758, 0.1895, 0.1620, 0.0664, 0.2960, 0.0946],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,659][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.1910, 0.1682, 0.0401, 0.2757, 0.0340, 0.2306, 0.0605],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,661][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.2836, 0.1616, 0.1204, 0.1574, 0.0919, 0.1386, 0.0464],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,663][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.2139, 0.1689, 0.0439, 0.1365, 0.0494, 0.0787, 0.3086],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,664][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.3572, 0.1440, 0.0322, 0.1490, 0.0902, 0.0661, 0.1612],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,666][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3472, 0.0553, 0.1193, 0.0507, 0.1654, 0.0518, 0.1770, 0.0332],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,667][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.2498e-04, 1.9074e-03, 3.0898e-04, 4.3565e-03, 4.9669e-04, 9.0182e-05,
        4.5196e-04, 9.9166e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,668][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2798, 0.1578, 0.0437, 0.1648, 0.0541, 0.1096, 0.0423, 0.1479],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,670][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([2.9034e-03, 2.1331e-03, 3.1721e-04, 5.8236e-03, 9.4085e-03, 1.2890e-02,
        6.1578e-02, 9.0495e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,671][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0990, 0.0131, 0.0492, 0.0212, 0.0633, 0.1319, 0.3840, 0.2382],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,673][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0641, 0.0255, 0.0050, 0.0100, 0.0058, 0.0142, 0.0053, 0.8701],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,674][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2194, 0.0189, 0.2175, 0.0175, 0.2973, 0.0514, 0.1540, 0.0241],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,676][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0649, 0.0341, 0.0389, 0.0855, 0.0619, 0.1320, 0.2861, 0.2967],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,678][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0419, 0.2068, 0.0128, 0.3495, 0.0113, 0.1839, 0.0379, 0.1558],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,679][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2172, 0.1518, 0.0698, 0.1597, 0.0526, 0.1146, 0.0974, 0.1370],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,681][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2103, 0.1660, 0.0477, 0.1499, 0.0421, 0.0709, 0.0617, 0.2513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,683][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3135, 0.1098, 0.0278, 0.1211, 0.0771, 0.0692, 0.1295, 0.1518],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,685][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4344, 0.0425, 0.1382, 0.0275, 0.1744, 0.0473, 0.0865, 0.0229, 0.0262],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,686][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.4368e-03, 2.5068e-02, 8.2903e-04, 5.3014e-02, 5.1605e-04, 1.0950e-03,
        5.3010e-04, 5.8399e-02, 8.5711e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,688][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2295, 0.1209, 0.0367, 0.1248, 0.0316, 0.1512, 0.0769, 0.1929, 0.0354],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,689][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0213, 0.0065, 0.0041, 0.0101, 0.0064, 0.0721, 0.0699, 0.1813, 0.6283],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,691][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1391, 0.0196, 0.0314, 0.0281, 0.0438, 0.1389, 0.2901, 0.1702, 0.1388],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,693][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1019, 0.1368, 0.0126, 0.1050, 0.0047, 0.0809, 0.0834, 0.0855, 0.3892],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,695][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2128, 0.0041, 0.3028, 0.0037, 0.3042, 0.0221, 0.1405, 0.0072, 0.0025],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,696][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0640, 0.0229, 0.0270, 0.0507, 0.0647, 0.0797, 0.1263, 0.2780, 0.2867],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,697][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0141, 0.1213, 0.0078, 0.1867, 0.0073, 0.1256, 0.0233, 0.0714, 0.4425],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,698][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2194, 0.1260, 0.0673, 0.1276, 0.0632, 0.0967, 0.0728, 0.1154, 0.1116],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,699][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2326, 0.1471, 0.0535, 0.1320, 0.0424, 0.0646, 0.0712, 0.0872, 0.1695],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,700][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2351, 0.0983, 0.0341, 0.1073, 0.1005, 0.0811, 0.1257, 0.1008, 0.1170],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:00,701][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.1748, 0.1474, 0.1119, 0.1127, 0.0922, 0.0654, 0.0465, 0.0978, 0.0616,
        0.0896], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,702][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([2.6545e-04, 2.8275e-04, 1.9207e-04, 2.5534e-04, 1.3429e-03, 4.0622e-05,
        3.8844e-04, 6.6268e-04, 6.6518e-05, 9.9650e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,704][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.2174, 0.0599, 0.0463, 0.0432, 0.0610, 0.0485, 0.1573, 0.0720, 0.0791,
        0.2153], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,705][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([1.1346e-03, 2.6740e-05, 4.9169e-04, 2.6078e-05, 1.5832e-03, 2.2219e-04,
        2.4698e-03, 6.6421e-04, 5.5461e-04, 9.9283e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,707][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0364, 0.0062, 0.0077, 0.0113, 0.0056, 0.0099, 0.0313, 0.0480, 0.0385,
        0.8050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,708][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([7.2120e-03, 1.0851e-05, 1.2290e-04, 2.0877e-06, 1.4039e-04, 2.3404e-07,
        5.8819e-06, 5.4532e-07, 6.7906e-07, 9.9250e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,709][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.1422, 0.0688, 0.1231, 0.0447, 0.1302, 0.0108, 0.0830, 0.0231, 0.0351,
        0.3389], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,711][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0760, 0.0323, 0.0199, 0.0575, 0.0091, 0.0719, 0.0370, 0.2417, 0.2867,
        0.1679], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,713][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.1991, 0.1173, 0.0477, 0.1169, 0.0386, 0.0588, 0.0898, 0.0889, 0.1270,
        0.1160], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,715][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.2503, 0.1315, 0.1136, 0.1135, 0.0551, 0.0709, 0.0502, 0.0941, 0.0987,
        0.0222], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,716][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.1537, 0.1268, 0.0453, 0.1242, 0.0387, 0.0494, 0.0409, 0.0803, 0.0711,
        0.2697], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,718][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.2012, 0.1043, 0.0447, 0.1282, 0.0737, 0.0641, 0.0825, 0.1129, 0.0493,
        0.1389], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:00,720][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.5232, 0.0185, 0.0735, 0.0152, 0.1097, 0.0560, 0.0641, 0.0192, 0.0421,
        0.0666, 0.0120], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,721][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.4224e-03, 4.1823e-02, 5.9177e-05, 7.7749e-03, 1.5673e-03, 3.0465e-04,
        1.6599e-03, 1.8134e-03, 3.6500e-04, 2.2089e-04, 9.4099e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,723][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.4152, 0.0574, 0.0369, 0.0470, 0.0294, 0.2053, 0.0514, 0.0596, 0.0254,
        0.0189, 0.0534], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,724][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0231, 0.0047, 0.0017, 0.0062, 0.0053, 0.0367, 0.0374, 0.0673, 0.1786,
        0.1421, 0.4968], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,726][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0527, 0.0200, 0.0085, 0.0414, 0.0187, 0.0466, 0.0650, 0.1387, 0.1185,
        0.1473, 0.3426], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,728][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1290, 0.1979, 0.0088, 0.1200, 0.0084, 0.0831, 0.0228, 0.0711, 0.0777,
        0.0161, 0.2650], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,730][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2345, 0.0066, 0.1520, 0.0047, 0.2622, 0.0180, 0.0678, 0.0075, 0.0041,
        0.2397, 0.0029], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,731][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0312, 0.0106, 0.0175, 0.0222, 0.0278, 0.0342, 0.0453, 0.0979, 0.1470,
        0.1623, 0.4039], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,733][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0187, 0.1706, 0.0047, 0.1319, 0.0038, 0.0320, 0.0141, 0.0466, 0.1550,
        0.0074, 0.4153], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,735][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1835, 0.1053, 0.0654, 0.1071, 0.0521, 0.0849, 0.0646, 0.0871, 0.0882,
        0.0587, 0.1031], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,737][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1427, 0.1254, 0.0437, 0.1252, 0.0543, 0.0898, 0.0674, 0.0885, 0.0709,
        0.0558, 0.1363], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,738][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2486, 0.0879, 0.0307, 0.0868, 0.0644, 0.0622, 0.1042, 0.0937, 0.0427,
        0.0565, 0.1224], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:00,739][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.1583, 0.1082, 0.0767, 0.0723, 0.0932, 0.0138, 0.0659, 0.0568, 0.0491,
        0.0840, 0.1160, 0.1059], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,740][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([1.8715e-04, 8.2915e-05, 2.3007e-04, 3.3392e-05, 5.3767e-01, 4.7451e-05,
        4.1878e-05, 5.6372e-05, 2.6123e-05, 3.7583e-04, 5.9519e-06, 4.6124e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,741][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.3070, 0.1257, 0.0541, 0.0841, 0.0457, 0.0770, 0.0280, 0.0759, 0.0855,
        0.0166, 0.0596, 0.0408], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,742][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([3.9823e-03, 1.0999e-06, 3.1783e-04, 1.3929e-06, 1.7622e-02, 5.3588e-06,
        1.2089e-04, 2.4009e-05, 2.0977e-05, 3.6914e-03, 3.5475e-05, 9.7418e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,744][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0330, 0.0012, 0.0231, 0.0008, 0.1075, 0.0013, 0.0055, 0.0025, 0.0015,
        0.0181, 0.0066, 0.7989], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,745][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([4.2550e-03, 6.1800e-07, 2.3884e-05, 1.6236e-07, 5.4715e-01, 8.0914e-08,
        4.0263e-06, 5.7335e-07, 1.8790e-08, 8.5164e-06, 1.6335e-08, 4.4855e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,747][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.1348, 0.1025, 0.1398, 0.0621, 0.1561, 0.0202, 0.0275, 0.0195, 0.0626,
        0.0675, 0.0489, 0.1585], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,748][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0857, 0.0152, 0.0182, 0.0300, 0.0187, 0.0407, 0.0149, 0.0781, 0.1210,
        0.1519, 0.2852, 0.1403], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,750][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.1880, 0.1261, 0.0413, 0.1019, 0.1138, 0.0307, 0.0295, 0.0546, 0.0680,
        0.0603, 0.0760, 0.1097], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,752][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.2001, 0.1208, 0.0862, 0.0994, 0.0124, 0.0694, 0.0568, 0.0679, 0.0846,
        0.0968, 0.0940, 0.0116], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,754][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.1268, 0.0816, 0.0598, 0.0662, 0.2239, 0.0436, 0.0297, 0.0448, 0.0456,
        0.0404, 0.0507, 0.1870], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,755][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0840, 0.0620, 0.0350, 0.0771, 0.0470, 0.1459, 0.0938, 0.0884, 0.0755,
        0.0805, 0.1459, 0.0649], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:00,757][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.3249, 0.0431, 0.0449, 0.0364, 0.0370, 0.1028, 0.0640, 0.0396, 0.0411,
        0.0331, 0.0459, 0.0462, 0.1409], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,758][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([8.6923e-04, 2.9534e-04, 7.9285e-04, 1.5249e-04, 3.7853e-03, 1.6787e-03,
        9.7348e-03, 1.3256e-04, 9.4096e-05, 1.0270e-04, 4.6067e-05, 2.5798e-03,
        9.7974e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,760][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2629, 0.0497, 0.0226, 0.0912, 0.0317, 0.0922, 0.0693, 0.0787, 0.0779,
        0.0542, 0.0700, 0.0283, 0.0714], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,761][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.0452e-04, 1.4809e-05, 5.4505e-06, 1.1869e-05, 5.8170e-06, 1.6298e-04,
        2.8483e-04, 1.0294e-04, 1.5237e-04, 5.2263e-04, 7.1335e-04, 3.2100e-04,
        9.9680e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,763][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0330, 0.0039, 0.0014, 0.0059, 0.0041, 0.0126, 0.0191, 0.0230, 0.0142,
        0.0335, 0.0200, 0.0223, 0.8069], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,764][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([5.0337e-02, 4.0884e-05, 1.2212e-04, 2.4078e-05, 5.4514e-05, 9.6157e-05,
        5.4016e-04, 1.8346e-05, 1.7625e-06, 8.6910e-06, 2.2214e-06, 2.1619e-05,
        9.4873e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,766][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1471, 0.0190, 0.1001, 0.0175, 0.1579, 0.0225, 0.0545, 0.0167, 0.0153,
        0.1453, 0.0192, 0.1899, 0.0951], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,768][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0436, 0.0124, 0.0057, 0.0209, 0.0048, 0.0246, 0.0107, 0.0686, 0.1068,
        0.0273, 0.3925, 0.0659, 0.2164], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,770][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1248, 0.0769, 0.0099, 0.1168, 0.0306, 0.1265, 0.0773, 0.0932, 0.1483,
        0.0429, 0.0918, 0.0366, 0.0243], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,771][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1620, 0.0767, 0.0627, 0.0787, 0.0506, 0.0786, 0.0716, 0.0648, 0.0679,
        0.0802, 0.0950, 0.0563, 0.0549], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,773][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1563, 0.0780, 0.0361, 0.0743, 0.0322, 0.0867, 0.0562, 0.0555, 0.0652,
        0.0429, 0.0720, 0.0292, 0.2153], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,775][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.2922, 0.0922, 0.0246, 0.0782, 0.0341, 0.0449, 0.0670, 0.1077, 0.0324,
        0.0497, 0.0839, 0.0338, 0.0593], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:00,776][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2243, 0.0224, 0.0831, 0.0188, 0.0728, 0.0685, 0.0474, 0.0175, 0.0266,
        0.0850, 0.0182, 0.0983, 0.2028, 0.0143], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,778][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.3043e-03, 1.2864e-02, 3.1174e-04, 3.6899e-02, 1.6060e-04, 2.5910e-04,
        1.2307e-03, 1.9361e-02, 1.8904e-03, 4.1481e-05, 7.7341e-03, 1.0547e-04,
        2.9472e-05, 9.1481e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,779][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1229, 0.0553, 0.0262, 0.0758, 0.0309, 0.0553, 0.0524, 0.1046, 0.0220,
        0.0236, 0.2143, 0.0318, 0.0515, 0.1335], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,780][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.7547e-03, 5.1593e-04, 2.6463e-04, 3.8463e-04, 7.3527e-05, 1.9155e-03,
        4.9563e-04, 3.5492e-03, 1.5269e-02, 3.9943e-03, 2.5334e-02, 4.1612e-03,
        1.0043e-01, 8.3886e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,781][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3815e-02, 9.6509e-04, 1.9248e-03, 1.6542e-03, 7.0759e-04, 1.0920e-02,
        2.7906e-02, 7.7423e-03, 6.1408e-03, 1.1127e-02, 1.0421e-02, 5.6918e-03,
        8.0342e-01, 9.7566e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,782][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.0572e-02, 6.8976e-02, 3.1534e-03, 8.5612e-02, 4.4653e-04, 2.0958e-02,
        2.3018e-02, 2.6302e-02, 2.2083e-01, 1.9773e-03, 2.8462e-02, 1.9463e-04,
        7.2026e-03, 4.6230e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,783][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1200, 0.0061, 0.0650, 0.0052, 0.0635, 0.0199, 0.0702, 0.0204, 0.0039,
        0.0699, 0.0062, 0.0955, 0.1494, 0.3050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,784][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0217, 0.0047, 0.0069, 0.0078, 0.0060, 0.0097, 0.0166, 0.0233, 0.0386,
        0.0367, 0.1817, 0.0810, 0.3162, 0.2491], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,786][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0091, 0.0692, 0.0042, 0.1190, 0.0033, 0.0581, 0.0115, 0.0503, 0.2209,
        0.0157, 0.1698, 0.0045, 0.0078, 0.2565], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,787][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1292, 0.0814, 0.0457, 0.0891, 0.0388, 0.0661, 0.0531, 0.0779, 0.0816,
        0.0519, 0.0812, 0.0415, 0.0571, 0.1052], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,789][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1119, 0.0935, 0.0367, 0.1093, 0.0324, 0.0691, 0.0586, 0.0859, 0.0856,
        0.0411, 0.0831, 0.0278, 0.0470, 0.1180], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,791][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1905, 0.0762, 0.0256, 0.0773, 0.0481, 0.0622, 0.0834, 0.0783, 0.0372,
        0.0419, 0.0860, 0.0489, 0.0652, 0.0790], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:00,793][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2196, 0.0227, 0.0772, 0.0237, 0.0683, 0.0419, 0.0424, 0.0155, 0.0256,
        0.1389, 0.0165, 0.0847, 0.1591, 0.0234, 0.0407], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,794][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([2.8058e-04, 5.0204e-04, 1.3089e-04, 4.3022e-04, 1.7809e-04, 1.6402e-04,
        6.5008e-04, 7.7872e-04, 2.1433e-04, 1.5176e-04, 4.8493e-05, 1.1946e-04,
        1.3325e-03, 5.6646e-04, 9.9445e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,796][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1319, 0.0361, 0.0228, 0.0455, 0.0260, 0.0737, 0.1560, 0.0680, 0.0443,
        0.0667, 0.0708, 0.0252, 0.0939, 0.0959, 0.0432], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,797][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([6.5432e-04, 6.5700e-06, 1.4415e-05, 8.2663e-06, 6.7982e-06, 3.9843e-05,
        8.2313e-05, 6.5431e-05, 2.1148e-04, 2.2779e-04, 3.5351e-04, 4.9376e-04,
        8.8126e-03, 8.6131e-03, 9.8041e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,799][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0361, 0.0050, 0.0048, 0.0064, 0.0082, 0.0162, 0.0195, 0.0212, 0.0146,
        0.0708, 0.0199, 0.0453, 0.1178, 0.1110, 0.5032], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,800][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([1.4315e-02, 6.4269e-05, 2.9829e-04, 3.0897e-05, 2.0383e-05, 3.8629e-05,
        1.7577e-04, 3.3025e-05, 2.2156e-05, 2.5733e-05, 4.5955e-06, 7.2240e-06,
        1.6418e-04, 8.3671e-06, 9.8479e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,802][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1246, 0.0131, 0.0917, 0.0116, 0.1279, 0.0148, 0.0688, 0.0114, 0.0116,
        0.2340, 0.0104, 0.1617, 0.0845, 0.0107, 0.0233], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,803][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0165, 0.0043, 0.0012, 0.0058, 0.0155, 0.0068, 0.0051, 0.0208, 0.0271,
        0.0177, 0.1061, 0.1764, 0.1255, 0.2687, 0.2026], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,805][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0627, 0.0668, 0.0197, 0.1004, 0.0215, 0.0977, 0.0419, 0.0680, 0.0977,
        0.0648, 0.0804, 0.0267, 0.0439, 0.1617, 0.0462], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,807][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1176, 0.0655, 0.0509, 0.0714, 0.0394, 0.0702, 0.0573, 0.0603, 0.0627,
        0.0658, 0.0835, 0.0441, 0.0684, 0.0895, 0.0534], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,808][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0897, 0.0610, 0.0289, 0.0710, 0.0257, 0.0569, 0.0465, 0.0693, 0.0596,
        0.0517, 0.0689, 0.0249, 0.0642, 0.0840, 0.1977], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,810][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2540, 0.0722, 0.0191, 0.0854, 0.0365, 0.0361, 0.0800, 0.0775, 0.0199,
        0.0289, 0.0728, 0.0338, 0.0486, 0.0610, 0.0742], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:00,812][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2320, 0.0185, 0.0703, 0.0145, 0.0693, 0.0212, 0.0420, 0.0112, 0.0202,
        0.1587, 0.0148, 0.0922, 0.1298, 0.0140, 0.0723, 0.0190],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,813][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.6916e-04, 2.0277e-03, 3.5606e-03, 2.2592e-03, 5.3990e-04, 7.8647e-05,
        2.3253e-04, 6.4339e-03, 2.5890e-02, 6.9173e-05, 5.0317e-04, 4.0960e-04,
        8.7769e-05, 6.8149e-03, 1.0154e-03, 9.4931e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,815][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0960, 0.0498, 0.0165, 0.0741, 0.0255, 0.0576, 0.0615, 0.1060, 0.0167,
        0.0362, 0.1472, 0.0276, 0.0606, 0.1439, 0.0638, 0.0170],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,816][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.2823e-03, 3.6787e-04, 1.3737e-04, 2.5123e-04, 1.2790e-04, 6.8925e-04,
        6.6759e-04, 1.3321e-03, 5.3451e-03, 9.7836e-04, 8.0908e-03, 5.1842e-03,
        1.7219e-02, 6.4751e-02, 1.2785e-01, 7.6273e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,818][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0246, 0.0030, 0.0042, 0.0033, 0.0044, 0.0138, 0.0269, 0.0124, 0.0097,
        0.0205, 0.0111, 0.0265, 0.2200, 0.0686, 0.3621, 0.1888],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,820][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0274, 0.0830, 0.0068, 0.0730, 0.0018, 0.0117, 0.0321, 0.0614, 0.1917,
        0.0028, 0.0245, 0.0008, 0.0055, 0.0499, 0.0100, 0.4175],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,822][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0990, 0.0024, 0.1110, 0.0022, 0.1288, 0.0145, 0.0714, 0.0043, 0.0019,
        0.1931, 0.0019, 0.1937, 0.1030, 0.0066, 0.0626, 0.0037],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,823][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0178, 0.0036, 0.0043, 0.0057, 0.0041, 0.0060, 0.0065, 0.0152, 0.0180,
        0.0191, 0.0960, 0.0420, 0.0996, 0.1417, 0.2274, 0.2932],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,824][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0082, 0.0414, 0.0045, 0.0716, 0.0039, 0.0507, 0.0101, 0.0357, 0.1870,
        0.0091, 0.1003, 0.0056, 0.0091, 0.1213, 0.0189, 0.3228],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,825][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1117, 0.0689, 0.0421, 0.0752, 0.0438, 0.0553, 0.0419, 0.0648, 0.0653,
        0.0524, 0.0678, 0.0476, 0.0475, 0.0882, 0.0548, 0.0728],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,826][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0856, 0.0679, 0.0382, 0.0789, 0.0287, 0.0389, 0.0460, 0.0778, 0.0897,
        0.0485, 0.0605, 0.0268, 0.0418, 0.0822, 0.0372, 0.1513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,827][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1808, 0.0692, 0.0234, 0.0654, 0.0463, 0.0518, 0.0751, 0.0589, 0.0383,
        0.0396, 0.0751, 0.0454, 0.0530, 0.0716, 0.0543, 0.0517],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:00,829][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1216, 0.0368, 0.0652, 0.0318, 0.0517, 0.0327, 0.0532, 0.0245, 0.0258,
        0.1859, 0.0282, 0.0536, 0.0492, 0.0320, 0.0217, 0.0312, 0.1549],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,830][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([2.7030e-04, 8.6107e-05, 5.0035e-04, 1.0128e-04, 2.0995e-04, 4.1469e-05,
        1.1293e-04, 2.2382e-04, 9.2082e-06, 3.1743e-03, 1.2098e-05, 1.3971e-04,
        5.4239e-06, 3.5821e-05, 1.1634e-04, 8.0445e-06, 9.9495e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,832][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.1395, 0.0459, 0.1183, 0.0407, 0.0289, 0.0484, 0.0606, 0.0552, 0.0581,
        0.0704, 0.0603, 0.0268, 0.0499, 0.0406, 0.0230, 0.0641, 0.0695],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,833][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([1.5377e-03, 2.4418e-06, 3.3913e-05, 1.3340e-06, 8.8735e-06, 3.4989e-06,
        2.8263e-05, 5.8591e-06, 5.0440e-06, 5.6808e-04, 2.8580e-05, 2.3911e-04,
        9.8277e-05, 3.1297e-04, 8.5469e-03, 4.0881e-04, 9.8817e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,835][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0515, 0.0024, 0.0798, 0.0019, 0.0072, 0.0012, 0.0043, 0.0028, 0.0041,
        0.0165, 0.0034, 0.0210, 0.0053, 0.0050, 0.0238, 0.0148, 0.7550],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,836][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([4.0478e-03, 7.5552e-06, 3.7923e-05, 1.3563e-06, 1.3080e-05, 3.8958e-07,
        4.5508e-06, 1.5532e-06, 3.4267e-07, 4.0115e-05, 2.3612e-07, 5.0760e-06,
        5.4413e-08, 4.3870e-08, 1.8673e-05, 4.7035e-07, 9.9582e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,838][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0981, 0.0348, 0.1250, 0.0257, 0.0855, 0.0087, 0.0483, 0.0134, 0.0157,
        0.2120, 0.0187, 0.0883, 0.0254, 0.0100, 0.0165, 0.0191, 0.1548],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,840][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0341, 0.0047, 0.0058, 0.0056, 0.0032, 0.0074, 0.0083, 0.0181, 0.0210,
        0.0218, 0.0748, 0.0179, 0.0676, 0.1179, 0.2148, 0.3296, 0.0475],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,842][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1859, 0.0683, 0.0451, 0.0664, 0.0425, 0.0456, 0.0527, 0.0472, 0.0547,
        0.0417, 0.0356, 0.0405, 0.0342, 0.0608, 0.0512, 0.0629, 0.0647],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,843][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.1337, 0.0713, 0.0557, 0.0670, 0.0425, 0.0487, 0.0469, 0.0452, 0.0518,
        0.0746, 0.0703, 0.0429, 0.0620, 0.0585, 0.0469, 0.0592, 0.0227],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,845][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0879, 0.0568, 0.0390, 0.0664, 0.0276, 0.0500, 0.0281, 0.0455, 0.0490,
        0.0739, 0.0579, 0.0233, 0.0260, 0.0513, 0.0339, 0.0398, 0.2437],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,847][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.1196, 0.0563, 0.0308, 0.0478, 0.0487, 0.0501, 0.0871, 0.0615, 0.0313,
        0.0515, 0.0792, 0.0498, 0.0575, 0.0535, 0.0715, 0.0341, 0.0698],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:00,849][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1889, 0.0169, 0.0675, 0.0142, 0.0559, 0.0545, 0.0366, 0.0130, 0.0204,
        0.0656, 0.0140, 0.0741, 0.1705, 0.0107, 0.0631, 0.0226, 0.0983, 0.0131],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,850][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.1828e-03, 5.3195e-03, 1.1054e-04, 1.5307e-02, 6.0336e-05, 1.1441e-04,
        4.8413e-04, 8.3639e-03, 8.6540e-04, 1.8611e-05, 3.8231e-03, 4.4229e-05,
        1.3164e-05, 4.5316e-01, 3.8029e-04, 5.9030e-04, 2.6308e-05, 5.0914e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,852][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1002, 0.0421, 0.0218, 0.0607, 0.0248, 0.0459, 0.0438, 0.0839, 0.0173,
        0.0191, 0.1719, 0.0259, 0.0439, 0.1075, 0.0460, 0.0171, 0.0117, 0.1164],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,853][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.3388e-03, 7.5620e-05, 3.9825e-05, 3.9532e-05, 6.5778e-06, 1.2646e-04,
        3.0054e-05, 1.6615e-04, 6.7287e-04, 1.8983e-04, 1.1462e-03, 1.9464e-04,
        4.1494e-03, 3.0088e-02, 2.6855e-01, 6.8418e-02, 2.0684e-02, 6.0409e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,855][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0155, 0.0009, 0.0016, 0.0013, 0.0004, 0.0068, 0.0153, 0.0038, 0.0029,
        0.0048, 0.0047, 0.0023, 0.3490, 0.0396, 0.1878, 0.0587, 0.1147, 0.1898],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,856][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.6213e-02, 3.8133e-02, 1.6849e-03, 5.2037e-02, 2.4308e-04, 1.3456e-02,
        1.4099e-02, 1.7186e-02, 1.3916e-01, 1.0265e-03, 1.6551e-02, 1.0501e-04,
        4.4000e-03, 2.9331e-01, 9.9769e-03, 1.0268e-01, 3.0303e-04, 2.6944e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,858][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0755, 0.0034, 0.0402, 0.0030, 0.0398, 0.0118, 0.0442, 0.0123, 0.0021,
        0.0450, 0.0035, 0.0604, 0.0963, 0.1902, 0.0512, 0.0045, 0.0784, 0.2383],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,860][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0163, 0.0025, 0.0039, 0.0037, 0.0022, 0.0033, 0.0053, 0.0059, 0.0091,
        0.0085, 0.0423, 0.0174, 0.0650, 0.0477, 0.0992, 0.1743, 0.1984, 0.2950],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,862][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0057, 0.0413, 0.0027, 0.0742, 0.0021, 0.0364, 0.0073, 0.0302, 0.1300,
        0.0101, 0.1022, 0.0029, 0.0050, 0.1539, 0.0126, 0.1714, 0.0130, 0.1989],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,864][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0974, 0.0587, 0.0354, 0.0660, 0.0301, 0.0494, 0.0406, 0.0566, 0.0592,
        0.0415, 0.0616, 0.0324, 0.0449, 0.0768, 0.0524, 0.0695, 0.0407, 0.0868],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,865][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0761, 0.0595, 0.0270, 0.0755, 0.0248, 0.0511, 0.0449, 0.0645, 0.0646,
        0.0348, 0.0680, 0.0241, 0.0405, 0.0967, 0.0494, 0.0720, 0.0266, 0.0999],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,866][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1626, 0.0633, 0.0242, 0.0643, 0.0393, 0.0513, 0.0655, 0.0624, 0.0305,
        0.0339, 0.0647, 0.0371, 0.0508, 0.0606, 0.0484, 0.0394, 0.0406, 0.0608],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:00,878][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:00,879][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,880][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,881][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,882][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,882][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,883][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,884][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,886][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,887][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,888][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,889][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,889][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:00,890][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,891][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,892][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,892][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,893][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,894][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,895][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,896][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,898][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,899][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,901][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,902][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:00,904][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.4449, 0.3965, 0.1586], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,905][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([1.1269e-05, 1.6706e-05, 9.9997e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,907][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.5495, 0.2948, 0.1557], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,908][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([1.8765e-03, 2.0354e-05, 9.9810e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,910][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.0152, 0.0018, 0.9830], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,911][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([1.3508e-04, 1.2414e-08, 9.9986e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,912][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.4201, 0.3001, 0.2798], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,914][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.6321, 0.3196, 0.0482], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,916][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.6753, 0.1948, 0.1298], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,917][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.6018, 0.3523, 0.0459], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,919][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.4312, 0.2586, 0.3101], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,920][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.3094, 0.5296, 0.1609], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:00,922][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6803, 0.0771, 0.1825, 0.0601], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,923][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3030e-03, 3.9255e-02, 2.8662e-04, 9.5816e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,925][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2326, 0.1742, 0.0573, 0.5359], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,926][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1135, 0.3881, 0.0237, 0.4747], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,928][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3402, 0.1541, 0.2265, 0.2791], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,929][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1226, 0.1962, 0.0111, 0.6702], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,930][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6344, 0.0303, 0.3123, 0.0230], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,931][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2185, 0.1662, 0.3652, 0.2502], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,932][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0670, 0.4690, 0.0244, 0.4397], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,932][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4289, 0.2395, 0.1092, 0.2225], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,934][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4208, 0.3134, 0.0590, 0.2068], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,935][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4775, 0.2085, 0.0414, 0.2725], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:00,937][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.2817, 0.2422, 0.1404, 0.1552, 0.1805], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,938][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([2.7668e-04, 2.2834e-04, 6.6521e-04, 8.2364e-05, 9.9875e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,940][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.5079, 0.2344, 0.0695, 0.1238, 0.0644], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,941][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([1.8461e-02, 3.9841e-05, 1.2212e-02, 1.0086e-04, 9.6919e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,943][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.1004, 0.0057, 0.1827, 0.0048, 0.7065], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,944][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([1.6026e-02, 2.8854e-06, 7.4145e-05, 7.1867e-07, 9.8390e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,946][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.2488, 0.2070, 0.2086, 0.1112, 0.2243], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,947][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.2732, 0.1195, 0.1690, 0.2673, 0.1711], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,949][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.3484, 0.2503, 0.0640, 0.1777, 0.1595], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,950][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.4121, 0.2391, 0.1378, 0.1883, 0.0228], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,952][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.3346, 0.2050, 0.0871, 0.1196, 0.2537], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,954][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.2758, 0.2094, 0.0860, 0.2908, 0.1379], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:00,955][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.3998, 0.0389, 0.0605, 0.0359, 0.1129, 0.3521], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,957][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0012, 0.0083, 0.0026, 0.0080, 0.0039, 0.9759], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,959][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.4199, 0.1411, 0.0661, 0.1472, 0.0637, 0.1621], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,960][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0324, 0.0157, 0.0028, 0.0295, 0.0080, 0.9116], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,962][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.3172, 0.0637, 0.0887, 0.1014, 0.0993, 0.3297], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,963][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([4.4479e-02, 3.7331e-03, 1.3379e-03, 1.0998e-03, 2.6539e-04, 9.4908e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,965][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.2509, 0.0365, 0.3159, 0.0354, 0.3316, 0.0298], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,966][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1239, 0.1006, 0.0577, 0.1902, 0.3212, 0.2063], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,968][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0883, 0.2944, 0.0187, 0.3662, 0.0308, 0.2015], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,969][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.3119, 0.1774, 0.1139, 0.1828, 0.0807, 0.1333], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,971][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2573, 0.1957, 0.0675, 0.1522, 0.0423, 0.2851], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,973][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.3655, 0.1802, 0.0346, 0.2045, 0.0860, 0.1291], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:00,975][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.2779, 0.0586, 0.1596, 0.0670, 0.2955, 0.1010, 0.0404],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,976][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([1.2292e-04, 1.0622e-03, 1.1815e-04, 2.3728e-03, 6.7404e-04, 4.5833e-04,
        9.9519e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,977][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.3380, 0.1318, 0.0366, 0.1393, 0.0887, 0.1183, 0.1473],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,979][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([5.7705e-03, 2.6504e-04, 3.3265e-04, 6.5582e-04, 2.3075e-04, 2.8413e-03,
        9.8990e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,980][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0797, 0.0211, 0.1088, 0.0225, 0.0435, 0.0349, 0.6896],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,981][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([4.9260e-03, 4.2449e-05, 4.4481e-05, 2.7747e-05, 2.8644e-04, 9.2147e-06,
        9.9466e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,981][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.3770, 0.0463, 0.1919, 0.0359, 0.1661, 0.0456, 0.1371],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,982][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.1158, 0.0758, 0.1895, 0.1620, 0.0664, 0.2960, 0.0946],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,984][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.1910, 0.1682, 0.0401, 0.2757, 0.0340, 0.2306, 0.0605],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,984][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.2836, 0.1616, 0.1204, 0.1574, 0.0919, 0.1386, 0.0464],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,985][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.2139, 0.1689, 0.0439, 0.1365, 0.0494, 0.0787, 0.3086],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,986][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.3572, 0.1440, 0.0322, 0.1490, 0.0902, 0.0661, 0.1612],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:00,988][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.3472, 0.0553, 0.1193, 0.0507, 0.1654, 0.0518, 0.1770, 0.0332],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,989][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.2498e-04, 1.9074e-03, 3.0898e-04, 4.3565e-03, 4.9669e-04, 9.0182e-05,
        4.5196e-04, 9.9166e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,991][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2798, 0.1578, 0.0437, 0.1648, 0.0541, 0.1096, 0.0423, 0.1479],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,992][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([2.9034e-03, 2.1331e-03, 3.1721e-04, 5.8236e-03, 9.4085e-03, 1.2890e-02,
        6.1578e-02, 9.0495e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,993][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0990, 0.0131, 0.0492, 0.0212, 0.0633, 0.1319, 0.3840, 0.2382],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,995][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0641, 0.0255, 0.0050, 0.0100, 0.0058, 0.0142, 0.0053, 0.8701],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,997][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2194, 0.0189, 0.2175, 0.0175, 0.2973, 0.0514, 0.1540, 0.0241],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:00,998][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0649, 0.0341, 0.0389, 0.0855, 0.0619, 0.1320, 0.2861, 0.2967],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,000][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0419, 0.2068, 0.0128, 0.3495, 0.0113, 0.1839, 0.0379, 0.1558],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,002][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2172, 0.1518, 0.0698, 0.1597, 0.0526, 0.1146, 0.0974, 0.1370],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,004][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2103, 0.1660, 0.0477, 0.1499, 0.0421, 0.0709, 0.0617, 0.2513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,005][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.3135, 0.1098, 0.0278, 0.1211, 0.0771, 0.0692, 0.1295, 0.1518],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,007][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4344, 0.0425, 0.1382, 0.0275, 0.1744, 0.0473, 0.0865, 0.0229, 0.0262],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,008][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.4368e-03, 2.5068e-02, 8.2903e-04, 5.3014e-02, 5.1605e-04, 1.0950e-03,
        5.3010e-04, 5.8399e-02, 8.5711e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,010][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2295, 0.1209, 0.0367, 0.1248, 0.0316, 0.1512, 0.0769, 0.1929, 0.0354],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,012][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0213, 0.0065, 0.0041, 0.0101, 0.0064, 0.0721, 0.0699, 0.1813, 0.6283],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,013][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1391, 0.0196, 0.0314, 0.0281, 0.0438, 0.1389, 0.2901, 0.1702, 0.1388],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,015][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1019, 0.1368, 0.0126, 0.1050, 0.0047, 0.0809, 0.0834, 0.0855, 0.3892],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,017][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2128, 0.0041, 0.3028, 0.0037, 0.3042, 0.0221, 0.1405, 0.0072, 0.0025],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,019][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0640, 0.0229, 0.0270, 0.0507, 0.0647, 0.0797, 0.1263, 0.2780, 0.2867],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,020][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0141, 0.1213, 0.0078, 0.1867, 0.0073, 0.1256, 0.0233, 0.0714, 0.4425],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,022][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2194, 0.1260, 0.0673, 0.1276, 0.0632, 0.0967, 0.0728, 0.1154, 0.1116],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,024][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2326, 0.1471, 0.0535, 0.1320, 0.0424, 0.0646, 0.0712, 0.0872, 0.1695],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,025][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2351, 0.0983, 0.0341, 0.1073, 0.1005, 0.0811, 0.1257, 0.1008, 0.1170],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,027][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.1748, 0.1474, 0.1119, 0.1127, 0.0922, 0.0654, 0.0465, 0.0978, 0.0616,
        0.0896], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,028][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([2.6545e-04, 2.8275e-04, 1.9207e-04, 2.5534e-04, 1.3429e-03, 4.0622e-05,
        3.8844e-04, 6.6268e-04, 6.6518e-05, 9.9650e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,029][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.2174, 0.0599, 0.0463, 0.0432, 0.0610, 0.0485, 0.1573, 0.0720, 0.0791,
        0.2153], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,030][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([1.1346e-03, 2.6740e-05, 4.9169e-04, 2.6078e-05, 1.5832e-03, 2.2219e-04,
        2.4698e-03, 6.6421e-04, 5.5461e-04, 9.9283e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,030][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0364, 0.0062, 0.0077, 0.0113, 0.0056, 0.0099, 0.0313, 0.0480, 0.0385,
        0.8050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,032][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([7.2120e-03, 1.0851e-05, 1.2290e-04, 2.0877e-06, 1.4039e-04, 2.3404e-07,
        5.8819e-06, 5.4532e-07, 6.7906e-07, 9.9250e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,033][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1422, 0.0688, 0.1231, 0.0447, 0.1302, 0.0108, 0.0830, 0.0231, 0.0351,
        0.3389], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,035][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0760, 0.0323, 0.0199, 0.0575, 0.0091, 0.0719, 0.0370, 0.2417, 0.2867,
        0.1679], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,036][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.1991, 0.1173, 0.0477, 0.1169, 0.0386, 0.0588, 0.0898, 0.0889, 0.1270,
        0.1160], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,038][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.2503, 0.1315, 0.1136, 0.1135, 0.0551, 0.0709, 0.0502, 0.0941, 0.0987,
        0.0222], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,040][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.1537, 0.1268, 0.0453, 0.1242, 0.0387, 0.0494, 0.0409, 0.0803, 0.0711,
        0.2697], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,041][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.2012, 0.1043, 0.0447, 0.1282, 0.0737, 0.0641, 0.0825, 0.1129, 0.0493,
        0.1389], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,043][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.5232, 0.0185, 0.0735, 0.0152, 0.1097, 0.0560, 0.0641, 0.0192, 0.0421,
        0.0666, 0.0120], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,044][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.4224e-03, 4.1823e-02, 5.9177e-05, 7.7749e-03, 1.5673e-03, 3.0465e-04,
        1.6599e-03, 1.8134e-03, 3.6500e-04, 2.2089e-04, 9.4099e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,046][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.4152, 0.0574, 0.0369, 0.0470, 0.0294, 0.2053, 0.0514, 0.0596, 0.0254,
        0.0189, 0.0534], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,048][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0231, 0.0047, 0.0017, 0.0062, 0.0053, 0.0367, 0.0374, 0.0673, 0.1786,
        0.1421, 0.4968], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,049][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0527, 0.0200, 0.0085, 0.0414, 0.0187, 0.0466, 0.0650, 0.1387, 0.1185,
        0.1473, 0.3426], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,051][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1290, 0.1979, 0.0088, 0.1200, 0.0084, 0.0831, 0.0228, 0.0711, 0.0777,
        0.0161, 0.2650], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,053][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2345, 0.0066, 0.1520, 0.0047, 0.2622, 0.0180, 0.0678, 0.0075, 0.0041,
        0.2397, 0.0029], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,055][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0312, 0.0106, 0.0175, 0.0222, 0.0278, 0.0342, 0.0453, 0.0979, 0.1470,
        0.1623, 0.4039], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,056][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0187, 0.1706, 0.0047, 0.1319, 0.0038, 0.0320, 0.0141, 0.0466, 0.1550,
        0.0074, 0.4153], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,058][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1835, 0.1053, 0.0654, 0.1071, 0.0521, 0.0849, 0.0646, 0.0871, 0.0882,
        0.0587, 0.1031], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,060][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1427, 0.1254, 0.0437, 0.1252, 0.0543, 0.0898, 0.0674, 0.0885, 0.0709,
        0.0558, 0.1363], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,062][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2486, 0.0879, 0.0307, 0.0868, 0.0644, 0.0622, 0.1042, 0.0937, 0.0427,
        0.0565, 0.1224], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,063][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.1583, 0.1082, 0.0767, 0.0723, 0.0932, 0.0138, 0.0659, 0.0568, 0.0491,
        0.0840, 0.1160, 0.1059], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,065][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([1.8715e-04, 8.2915e-05, 2.3007e-04, 3.3392e-05, 5.3767e-01, 4.7451e-05,
        4.1878e-05, 5.6372e-05, 2.6123e-05, 3.7583e-04, 5.9519e-06, 4.6124e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,066][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.3070, 0.1257, 0.0541, 0.0841, 0.0457, 0.0770, 0.0280, 0.0759, 0.0855,
        0.0166, 0.0596, 0.0408], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,068][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([3.9823e-03, 1.0999e-06, 3.1783e-04, 1.3929e-06, 1.7622e-02, 5.3588e-06,
        1.2089e-04, 2.4009e-05, 2.0977e-05, 3.6914e-03, 3.5475e-05, 9.7418e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,069][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0330, 0.0012, 0.0231, 0.0008, 0.1075, 0.0013, 0.0055, 0.0025, 0.0015,
        0.0181, 0.0066, 0.7989], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,071][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([4.2550e-03, 6.1800e-07, 2.3884e-05, 1.6236e-07, 5.4715e-01, 8.0914e-08,
        4.0263e-06, 5.7335e-07, 1.8790e-08, 8.5164e-06, 1.6335e-08, 4.4855e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,072][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.1348, 0.1025, 0.1398, 0.0621, 0.1561, 0.0202, 0.0275, 0.0195, 0.0626,
        0.0675, 0.0489, 0.1585], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,073][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0857, 0.0152, 0.0182, 0.0300, 0.0187, 0.0407, 0.0149, 0.0781, 0.1210,
        0.1519, 0.2852, 0.1403], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,074][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.1880, 0.1261, 0.0413, 0.1019, 0.1138, 0.0307, 0.0295, 0.0546, 0.0680,
        0.0603, 0.0760, 0.1097], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,075][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.2001, 0.1208, 0.0862, 0.0994, 0.0124, 0.0694, 0.0568, 0.0679, 0.0846,
        0.0968, 0.0940, 0.0116], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,076][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.1268, 0.0816, 0.0598, 0.0662, 0.2239, 0.0436, 0.0297, 0.0448, 0.0456,
        0.0404, 0.0507, 0.1870], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,078][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0840, 0.0620, 0.0350, 0.0771, 0.0470, 0.1459, 0.0938, 0.0884, 0.0755,
        0.0805, 0.1459, 0.0649], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,079][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.3249, 0.0431, 0.0449, 0.0364, 0.0370, 0.1028, 0.0640, 0.0396, 0.0411,
        0.0331, 0.0459, 0.0462, 0.1409], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,081][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([8.6923e-04, 2.9534e-04, 7.9285e-04, 1.5249e-04, 3.7853e-03, 1.6787e-03,
        9.7348e-03, 1.3256e-04, 9.4096e-05, 1.0270e-04, 4.6067e-05, 2.5798e-03,
        9.7974e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,082][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.2629, 0.0497, 0.0226, 0.0912, 0.0317, 0.0922, 0.0693, 0.0787, 0.0779,
        0.0542, 0.0700, 0.0283, 0.0714], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,084][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.0452e-04, 1.4809e-05, 5.4505e-06, 1.1869e-05, 5.8170e-06, 1.6298e-04,
        2.8483e-04, 1.0294e-04, 1.5237e-04, 5.2263e-04, 7.1335e-04, 3.2100e-04,
        9.9680e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,085][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0330, 0.0039, 0.0014, 0.0059, 0.0041, 0.0126, 0.0191, 0.0230, 0.0142,
        0.0335, 0.0200, 0.0223, 0.8069], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,087][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([5.0337e-02, 4.0884e-05, 1.2212e-04, 2.4078e-05, 5.4514e-05, 9.6157e-05,
        5.4016e-04, 1.8346e-05, 1.7625e-06, 8.6910e-06, 2.2214e-06, 2.1619e-05,
        9.4873e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,088][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1471, 0.0190, 0.1001, 0.0175, 0.1579, 0.0225, 0.0545, 0.0167, 0.0153,
        0.1453, 0.0192, 0.1899, 0.0951], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,090][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0436, 0.0124, 0.0057, 0.0209, 0.0048, 0.0246, 0.0107, 0.0686, 0.1068,
        0.0273, 0.3925, 0.0659, 0.2164], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,092][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1248, 0.0769, 0.0099, 0.1168, 0.0306, 0.1265, 0.0773, 0.0932, 0.1483,
        0.0429, 0.0918, 0.0366, 0.0243], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,094][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.1620, 0.0767, 0.0627, 0.0787, 0.0506, 0.0786, 0.0716, 0.0648, 0.0679,
        0.0802, 0.0950, 0.0563, 0.0549], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,095][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1563, 0.0780, 0.0361, 0.0743, 0.0322, 0.0867, 0.0562, 0.0555, 0.0652,
        0.0429, 0.0720, 0.0292, 0.2153], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,097][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.2922, 0.0922, 0.0246, 0.0782, 0.0341, 0.0449, 0.0670, 0.1077, 0.0324,
        0.0497, 0.0839, 0.0338, 0.0593], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,099][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2243, 0.0224, 0.0831, 0.0188, 0.0728, 0.0685, 0.0474, 0.0175, 0.0266,
        0.0850, 0.0182, 0.0983, 0.2028, 0.0143], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,100][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.3043e-03, 1.2864e-02, 3.1174e-04, 3.6899e-02, 1.6060e-04, 2.5910e-04,
        1.2307e-03, 1.9361e-02, 1.8904e-03, 4.1481e-05, 7.7341e-03, 1.0547e-04,
        2.9472e-05, 9.1481e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,102][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1229, 0.0553, 0.0262, 0.0758, 0.0309, 0.0553, 0.0524, 0.1046, 0.0220,
        0.0236, 0.2143, 0.0318, 0.0515, 0.1335], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,103][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.7547e-03, 5.1593e-04, 2.6463e-04, 3.8463e-04, 7.3527e-05, 1.9155e-03,
        4.9563e-04, 3.5492e-03, 1.5269e-02, 3.9943e-03, 2.5334e-02, 4.1612e-03,
        1.0043e-01, 8.3886e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,105][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3815e-02, 9.6509e-04, 1.9248e-03, 1.6542e-03, 7.0759e-04, 1.0920e-02,
        2.7906e-02, 7.7423e-03, 6.1408e-03, 1.1127e-02, 1.0421e-02, 5.6918e-03,
        8.0342e-01, 9.7566e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,106][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.0572e-02, 6.8976e-02, 3.1534e-03, 8.5612e-02, 4.4653e-04, 2.0958e-02,
        2.3018e-02, 2.6302e-02, 2.2083e-01, 1.9773e-03, 2.8462e-02, 1.9463e-04,
        7.2026e-03, 4.6230e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,108][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1200, 0.0061, 0.0650, 0.0052, 0.0635, 0.0199, 0.0702, 0.0204, 0.0039,
        0.0699, 0.0062, 0.0955, 0.1494, 0.3050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,109][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0217, 0.0047, 0.0069, 0.0078, 0.0060, 0.0097, 0.0166, 0.0233, 0.0386,
        0.0367, 0.1817, 0.0810, 0.3162, 0.2491], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,111][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0091, 0.0692, 0.0042, 0.1190, 0.0033, 0.0581, 0.0115, 0.0503, 0.2209,
        0.0157, 0.1698, 0.0045, 0.0078, 0.2565], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,113][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1292, 0.0814, 0.0457, 0.0891, 0.0388, 0.0661, 0.0531, 0.0779, 0.0816,
        0.0519, 0.0812, 0.0415, 0.0571, 0.1052], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,115][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1119, 0.0935, 0.0367, 0.1093, 0.0324, 0.0691, 0.0586, 0.0859, 0.0856,
        0.0411, 0.0831, 0.0278, 0.0470, 0.1180], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,117][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1905, 0.0762, 0.0256, 0.0773, 0.0481, 0.0622, 0.0834, 0.0783, 0.0372,
        0.0419, 0.0860, 0.0489, 0.0652, 0.0790], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,118][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2196, 0.0227, 0.0772, 0.0237, 0.0683, 0.0419, 0.0424, 0.0155, 0.0256,
        0.1389, 0.0165, 0.0847, 0.1591, 0.0234, 0.0407], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,119][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.8058e-04, 5.0204e-04, 1.3089e-04, 4.3022e-04, 1.7809e-04, 1.6402e-04,
        6.5008e-04, 7.7872e-04, 2.1433e-04, 1.5176e-04, 4.8493e-05, 1.1946e-04,
        1.3325e-03, 5.6646e-04, 9.9445e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,119][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1319, 0.0361, 0.0228, 0.0455, 0.0260, 0.0737, 0.1560, 0.0680, 0.0443,
        0.0667, 0.0708, 0.0252, 0.0939, 0.0959, 0.0432], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,120][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([6.5432e-04, 6.5700e-06, 1.4415e-05, 8.2663e-06, 6.7982e-06, 3.9843e-05,
        8.2313e-05, 6.5431e-05, 2.1148e-04, 2.2779e-04, 3.5351e-04, 4.9376e-04,
        8.8126e-03, 8.6131e-03, 9.8041e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,122][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0361, 0.0050, 0.0048, 0.0064, 0.0082, 0.0162, 0.0195, 0.0212, 0.0146,
        0.0708, 0.0199, 0.0453, 0.1178, 0.1110, 0.5032], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,123][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.4315e-02, 6.4269e-05, 2.9829e-04, 3.0897e-05, 2.0383e-05, 3.8629e-05,
        1.7577e-04, 3.3025e-05, 2.2156e-05, 2.5733e-05, 4.5955e-06, 7.2240e-06,
        1.6418e-04, 8.3671e-06, 9.8479e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,125][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1246, 0.0131, 0.0917, 0.0116, 0.1279, 0.0148, 0.0688, 0.0114, 0.0116,
        0.2340, 0.0104, 0.1617, 0.0845, 0.0107, 0.0233], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,127][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0165, 0.0043, 0.0012, 0.0058, 0.0155, 0.0068, 0.0051, 0.0208, 0.0271,
        0.0177, 0.1061, 0.1764, 0.1255, 0.2687, 0.2026], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,129][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0627, 0.0668, 0.0197, 0.1004, 0.0215, 0.0977, 0.0419, 0.0680, 0.0977,
        0.0648, 0.0804, 0.0267, 0.0439, 0.1617, 0.0462], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,131][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1176, 0.0655, 0.0509, 0.0714, 0.0394, 0.0702, 0.0573, 0.0603, 0.0627,
        0.0658, 0.0835, 0.0441, 0.0684, 0.0895, 0.0534], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,132][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0897, 0.0610, 0.0289, 0.0710, 0.0257, 0.0569, 0.0465, 0.0693, 0.0596,
        0.0517, 0.0689, 0.0249, 0.0642, 0.0840, 0.1977], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,134][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2540, 0.0722, 0.0191, 0.0854, 0.0365, 0.0361, 0.0800, 0.0775, 0.0199,
        0.0289, 0.0728, 0.0338, 0.0486, 0.0610, 0.0742], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,136][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2320, 0.0185, 0.0703, 0.0145, 0.0693, 0.0212, 0.0420, 0.0112, 0.0202,
        0.1587, 0.0148, 0.0922, 0.1298, 0.0140, 0.0723, 0.0190],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,137][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.6916e-04, 2.0277e-03, 3.5606e-03, 2.2592e-03, 5.3990e-04, 7.8647e-05,
        2.3253e-04, 6.4339e-03, 2.5890e-02, 6.9173e-05, 5.0317e-04, 4.0960e-04,
        8.7769e-05, 6.8149e-03, 1.0154e-03, 9.4931e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,139][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0960, 0.0498, 0.0165, 0.0741, 0.0255, 0.0576, 0.0615, 0.1060, 0.0167,
        0.0362, 0.1472, 0.0276, 0.0606, 0.1439, 0.0638, 0.0170],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,140][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.2823e-03, 3.6787e-04, 1.3737e-04, 2.5123e-04, 1.2790e-04, 6.8925e-04,
        6.6759e-04, 1.3321e-03, 5.3451e-03, 9.7836e-04, 8.0908e-03, 5.1842e-03,
        1.7219e-02, 6.4751e-02, 1.2785e-01, 7.6273e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,142][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0246, 0.0030, 0.0042, 0.0033, 0.0044, 0.0138, 0.0269, 0.0124, 0.0097,
        0.0205, 0.0111, 0.0265, 0.2200, 0.0686, 0.3621, 0.1888],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,144][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0274, 0.0830, 0.0068, 0.0730, 0.0018, 0.0117, 0.0321, 0.0614, 0.1917,
        0.0028, 0.0245, 0.0008, 0.0055, 0.0499, 0.0100, 0.4175],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,146][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0990, 0.0024, 0.1110, 0.0022, 0.1288, 0.0145, 0.0714, 0.0043, 0.0019,
        0.1931, 0.0019, 0.1937, 0.1030, 0.0066, 0.0626, 0.0037],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,147][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0178, 0.0036, 0.0043, 0.0057, 0.0041, 0.0060, 0.0065, 0.0152, 0.0180,
        0.0191, 0.0960, 0.0420, 0.0996, 0.1417, 0.2274, 0.2932],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,149][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0082, 0.0414, 0.0045, 0.0716, 0.0039, 0.0507, 0.0101, 0.0357, 0.1870,
        0.0091, 0.1003, 0.0056, 0.0091, 0.1213, 0.0189, 0.3228],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,151][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1117, 0.0689, 0.0421, 0.0752, 0.0438, 0.0553, 0.0419, 0.0648, 0.0653,
        0.0524, 0.0678, 0.0476, 0.0475, 0.0882, 0.0548, 0.0728],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,153][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0856, 0.0679, 0.0382, 0.0789, 0.0287, 0.0389, 0.0460, 0.0778, 0.0897,
        0.0485, 0.0605, 0.0268, 0.0418, 0.0822, 0.0372, 0.1513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,155][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1808, 0.0692, 0.0234, 0.0654, 0.0463, 0.0518, 0.0751, 0.0589, 0.0383,
        0.0396, 0.0751, 0.0454, 0.0530, 0.0716, 0.0543, 0.0517],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,156][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.1216, 0.0368, 0.0652, 0.0318, 0.0517, 0.0327, 0.0532, 0.0245, 0.0258,
        0.1859, 0.0282, 0.0536, 0.0492, 0.0320, 0.0217, 0.0312, 0.1549],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,158][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.7030e-04, 8.6107e-05, 5.0035e-04, 1.0128e-04, 2.0995e-04, 4.1469e-05,
        1.1293e-04, 2.2382e-04, 9.2082e-06, 3.1743e-03, 1.2098e-05, 1.3971e-04,
        5.4239e-06, 3.5821e-05, 1.1634e-04, 8.0445e-06, 9.9495e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,159][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1395, 0.0459, 0.1183, 0.0407, 0.0289, 0.0484, 0.0606, 0.0552, 0.0581,
        0.0704, 0.0603, 0.0268, 0.0499, 0.0406, 0.0230, 0.0641, 0.0695],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,161][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([1.5377e-03, 2.4418e-06, 3.3913e-05, 1.3340e-06, 8.8735e-06, 3.4989e-06,
        2.8263e-05, 5.8591e-06, 5.0440e-06, 5.6808e-04, 2.8580e-05, 2.3911e-04,
        9.8277e-05, 3.1297e-04, 8.5469e-03, 4.0881e-04, 9.8817e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,163][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0515, 0.0024, 0.0798, 0.0019, 0.0072, 0.0012, 0.0043, 0.0028, 0.0041,
        0.0165, 0.0034, 0.0210, 0.0053, 0.0050, 0.0238, 0.0148, 0.7550],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,164][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([4.0478e-03, 7.5552e-06, 3.7923e-05, 1.3563e-06, 1.3080e-05, 3.8958e-07,
        4.5508e-06, 1.5532e-06, 3.4267e-07, 4.0115e-05, 2.3612e-07, 5.0760e-06,
        5.4413e-08, 4.3870e-08, 1.8673e-05, 4.7035e-07, 9.9582e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,165][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0981, 0.0348, 0.1250, 0.0257, 0.0855, 0.0087, 0.0483, 0.0134, 0.0157,
        0.2120, 0.0187, 0.0883, 0.0254, 0.0100, 0.0165, 0.0191, 0.1548],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,166][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0341, 0.0047, 0.0058, 0.0056, 0.0032, 0.0074, 0.0083, 0.0181, 0.0210,
        0.0218, 0.0748, 0.0179, 0.0676, 0.1179, 0.2148, 0.3296, 0.0475],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,167][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1859, 0.0683, 0.0451, 0.0664, 0.0425, 0.0456, 0.0527, 0.0472, 0.0547,
        0.0417, 0.0356, 0.0405, 0.0342, 0.0608, 0.0512, 0.0629, 0.0647],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,169][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.1337, 0.0713, 0.0557, 0.0670, 0.0425, 0.0487, 0.0469, 0.0452, 0.0518,
        0.0746, 0.0703, 0.0429, 0.0620, 0.0585, 0.0469, 0.0592, 0.0227],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,171][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0879, 0.0568, 0.0390, 0.0664, 0.0276, 0.0500, 0.0281, 0.0455, 0.0490,
        0.0739, 0.0579, 0.0233, 0.0260, 0.0513, 0.0339, 0.0398, 0.2437],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,172][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.1196, 0.0563, 0.0308, 0.0478, 0.0487, 0.0501, 0.0871, 0.0615, 0.0313,
        0.0515, 0.0792, 0.0498, 0.0575, 0.0535, 0.0715, 0.0341, 0.0698],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,174][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1889, 0.0169, 0.0675, 0.0142, 0.0559, 0.0545, 0.0366, 0.0130, 0.0204,
        0.0656, 0.0140, 0.0741, 0.1705, 0.0107, 0.0631, 0.0226, 0.0983, 0.0131],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,175][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.1828e-03, 5.3195e-03, 1.1054e-04, 1.5307e-02, 6.0336e-05, 1.1441e-04,
        4.8413e-04, 8.3639e-03, 8.6540e-04, 1.8611e-05, 3.8231e-03, 4.4229e-05,
        1.3164e-05, 4.5316e-01, 3.8029e-04, 5.9030e-04, 2.6308e-05, 5.0914e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,177][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1002, 0.0421, 0.0218, 0.0607, 0.0248, 0.0459, 0.0438, 0.0839, 0.0173,
        0.0191, 0.1719, 0.0259, 0.0439, 0.1075, 0.0460, 0.0171, 0.0117, 0.1164],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,178][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.3388e-03, 7.5620e-05, 3.9825e-05, 3.9532e-05, 6.5778e-06, 1.2646e-04,
        3.0054e-05, 1.6615e-04, 6.7287e-04, 1.8983e-04, 1.1462e-03, 1.9464e-04,
        4.1494e-03, 3.0088e-02, 2.6855e-01, 6.8418e-02, 2.0684e-02, 6.0409e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,180][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0155, 0.0009, 0.0016, 0.0013, 0.0004, 0.0068, 0.0153, 0.0038, 0.0029,
        0.0048, 0.0047, 0.0023, 0.3490, 0.0396, 0.1878, 0.0587, 0.1147, 0.1898],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,181][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.6213e-02, 3.8133e-02, 1.6849e-03, 5.2037e-02, 2.4308e-04, 1.3456e-02,
        1.4099e-02, 1.7186e-02, 1.3916e-01, 1.0265e-03, 1.6551e-02, 1.0501e-04,
        4.4000e-03, 2.9331e-01, 9.9769e-03, 1.0268e-01, 3.0303e-04, 2.6944e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,183][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0755, 0.0034, 0.0402, 0.0030, 0.0398, 0.0118, 0.0442, 0.0123, 0.0021,
        0.0450, 0.0035, 0.0604, 0.0963, 0.1902, 0.0512, 0.0045, 0.0784, 0.2383],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,185][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0163, 0.0025, 0.0039, 0.0037, 0.0022, 0.0033, 0.0053, 0.0059, 0.0091,
        0.0085, 0.0423, 0.0174, 0.0650, 0.0477, 0.0992, 0.1743, 0.1984, 0.2950],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,187][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0057, 0.0413, 0.0027, 0.0742, 0.0021, 0.0364, 0.0073, 0.0302, 0.1300,
        0.0101, 0.1022, 0.0029, 0.0050, 0.1539, 0.0126, 0.1714, 0.0130, 0.1989],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,189][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0974, 0.0587, 0.0354, 0.0660, 0.0301, 0.0494, 0.0406, 0.0566, 0.0592,
        0.0415, 0.0616, 0.0324, 0.0449, 0.0768, 0.0524, 0.0695, 0.0407, 0.0868],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,191][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0761, 0.0595, 0.0270, 0.0755, 0.0248, 0.0511, 0.0449, 0.0645, 0.0646,
        0.0348, 0.0680, 0.0241, 0.0405, 0.0967, 0.0494, 0.0720, 0.0266, 0.0999],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,192][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1626, 0.0633, 0.0242, 0.0643, 0.0393, 0.0513, 0.0655, 0.0624, 0.0305,
        0.0339, 0.0647, 0.0371, 0.0508, 0.0606, 0.0484, 0.0394, 0.0406, 0.0608],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,196][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:01,198][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 2232],
        [30498],
        [    1],
        [15859],
        [  270],
        [ 6437],
        [28059],
        [14463],
        [21272],
        [38692],
        [11848],
        [  472],
        [18199],
        [17475],
        [ 3188],
        [27729],
        [15980],
        [18342]], device='cuda:0')
[2024-07-24 10:26:01,200][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[41254],
        [41884],
        [    1],
        [40458],
        [ 1012],
        [46846],
        [47817],
        [47312],
        [44353],
        [48537],
        [48078],
        [ 1041],
        [48435],
        [47217],
        [48423],
        [41866],
        [42611],
        [46996]], device='cuda:0')
[2024-07-24 10:26:01,202][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3155],
        [ 3062],
        [ 2661],
        [ 1492],
        [ 4126],
        [10566],
        [ 4248],
        [ 5343],
        [ 3222],
        [ 6908],
        [ 3405],
        [ 7488],
        [ 9568],
        [ 9479],
        [ 8242],
        [ 7161],
        [12395],
        [11839]], device='cuda:0')
[2024-07-24 10:26:01,204][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33150],
        [10303],
        [20322],
        [34794],
        [32240],
        [39998],
        [40069],
        [27375],
        [46885],
        [37560],
        [ 4040],
        [31996],
        [25902],
        [32362],
        [16849],
        [43037],
        [ 8589],
        [32384]], device='cuda:0')
[2024-07-24 10:26:01,206][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[3216],
        [5121],
        [4229],
        [3615],
        [3150],
        [3892],
        [3871],
        [3718],
        [3647],
        [4936],
        [4048],
        [1983],
        [2432],
        [3519],
        [3760],
        [3173],
        [1463],
        [3155]], device='cuda:0')
[2024-07-24 10:26:01,208][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[42119],
        [40789],
        [ 4397],
        [22059],
        [33865],
        [28221],
        [ 2381],
        [25030],
        [18549],
        [22719],
        [23551],
        [31359],
        [24162],
        [32602],
        [17210],
        [18386],
        [ 2988],
        [27950]], device='cuda:0')
[2024-07-24 10:26:01,209][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26690],
        [26530],
        [  240],
        [ 9213],
        [ 9934],
        [12517],
        [41742],
        [31368],
        [28047],
        [47653],
        [17350],
        [17305],
        [36057],
        [34479],
        [42121],
        [36796],
        [19610],
        [30696]], device='cuda:0')
[2024-07-24 10:26:01,211][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40396],
        [46144],
        [ 8275],
        [42736],
        [10599],
        [25866],
        [36301],
        [30939],
        [40205],
        [29387],
        [42888],
        [ 8877],
        [21474],
        [36106],
        [26267],
        [36099],
        [12524],
        [33057]], device='cuda:0')
[2024-07-24 10:26:01,213][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[36791],
        [36808],
        [13040],
        [ 9220],
        [11157],
        [ 3111],
        [12469],
        [ 7375],
        [ 4359],
        [30133],
        [17362],
        [14234],
        [16038],
        [34359],
        [21627],
        [16558],
        [33159],
        [37280]], device='cuda:0')
[2024-07-24 10:26:01,215][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[10367],
        [ 9893],
        [ 7835],
        [ 4160],
        [11759],
        [29452],
        [16041],
        [11344],
        [14395],
        [13992],
        [27245],
        [32891],
        [35909],
        [27100],
        [29933],
        [36277],
        [35528],
        [24743]], device='cuda:0')
[2024-07-24 10:26:01,217][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[31746],
        [32727],
        [30962],
        [32245],
        [24291],
        [31612],
        [31928],
        [30863],
        [28623],
        [24715],
        [19820],
        [11910],
        [21609],
        [25000],
        [20130],
        [27823],
        [19178],
        [28395]], device='cuda:0')
[2024-07-24 10:26:01,218][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20023],
        [24009],
        [22815],
        [21813],
        [18880],
        [18272],
        [16051],
        [23019],
        [21412],
        [17626],
        [20081],
        [17730],
        [14905],
        [20897],
        [19441],
        [19298],
        [15774],
        [20512]], device='cuda:0')
[2024-07-24 10:26:01,220][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16914],
        [12678],
        [34735],
        [10482],
        [38374],
        [ 6943],
        [ 4354],
        [ 4325],
        [16965],
        [18651],
        [ 8586],
        [45305],
        [ 7548],
        [ 7319],
        [ 4123],
        [16638],
        [ 7451],
        [ 6663]], device='cuda:0')
[2024-07-24 10:26:01,222][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[37768],
        [28927],
        [14815],
        [25092],
        [19044],
        [19899],
        [20545],
        [19638],
        [19192],
        [17022],
        [19741],
        [13172],
        [18939],
        [14939],
        [17461],
        [14570],
        [10505],
        [12904]], device='cuda:0')
[2024-07-24 10:26:01,224][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[43302],
        [34473],
        [  421],
        [47904],
        [10473],
        [38165],
        [47183],
        [33765],
        [47717],
        [48012],
        [25172],
        [ 9978],
        [47429],
        [43414],
        [31816],
        [48447],
        [37589],
        [43647]], device='cuda:0')
[2024-07-24 10:26:01,226][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[37323],
        [37729],
        [36551],
        [39799],
        [34727],
        [36778],
        [35841],
        [36683],
        [36588],
        [36086],
        [38748],
        [34115],
        [36991],
        [37200],
        [38551],
        [38199],
        [40734],
        [38719]], device='cuda:0')
[2024-07-24 10:26:01,228][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 2173],
        [ 5320],
        [14755],
        [ 1716],
        [ 9904],
        [ 2601],
        [ 8695],
        [ 2266],
        [  333],
        [ 8464],
        [ 3793],
        [10628],
        [16161],
        [ 1385],
        [13187],
        [ 1881],
        [17696],
        [ 1607]], device='cuda:0')
[2024-07-24 10:26:01,230][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[47214],
        [47068],
        [47673],
        [46007],
        [47319],
        [45929],
        [46753],
        [44895],
        [44665],
        [48733],
        [45812],
        [46717],
        [47094],
        [43734],
        [47624],
        [45322],
        [48347],
        [44768]], device='cuda:0')
[2024-07-24 10:26:01,231][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1857],
        [ 1217],
        [ 3103],
        [ 8358],
        [  716],
        [ 2894],
        [ 3064],
        [11473],
        [ 6838],
        [ 1951],
        [ 5716],
        [ 1884],
        [ 9119],
        [10074],
        [ 7979],
        [ 8115],
        [ 5943],
        [ 8766]], device='cuda:0')
[2024-07-24 10:26:01,233][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[  166],
        [  163],
        [25061],
        [  339],
        [ 2589],
        [  170],
        [  935],
        [ 1239],
        [  598],
        [   84],
        [ 2882],
        [ 2905],
        [ 1642],
        [ 2181],
        [  761],
        [  867],
        [ 7323],
        [ 1277]], device='cuda:0')
[2024-07-24 10:26:01,235][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8174],
        [22366],
        [28628],
        [22487],
        [22883],
        [19221],
        [10175],
        [25492],
        [31024],
        [ 8238],
        [26915],
        [24239],
        [18405],
        [32041],
        [22128],
        [34134],
        [21110],
        [32888]], device='cuda:0')
[2024-07-24 10:26:01,237][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[42705],
        [42560],
        [15483],
        [28332],
        [ 8018],
        [ 9991],
        [21098],
        [11707],
        [11484],
        [ 9606],
        [14481],
        [ 7222],
        [ 9401],
        [ 3369],
        [11455],
        [11689],
        [ 9178],
        [ 4453]], device='cuda:0')
[2024-07-24 10:26:01,239][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[45091],
        [44605],
        [39895],
        [28388],
        [26904],
        [16822],
        [19964],
        [12305],
        [21737],
        [28833],
        [42326],
        [33632],
        [40384],
        [26685],
        [16530],
        [15555],
        [14798],
        [ 8979]], device='cuda:0')
[2024-07-24 10:26:01,241][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42809],
        [16867],
        [37819],
        [22233],
        [37735],
        [23748],
        [32556],
        [23988],
        [14589],
        [33029],
        [10457],
        [37246],
        [29207],
        [12050],
        [24940],
        [11364],
        [32760],
        [11794]], device='cuda:0')
[2024-07-24 10:26:01,243][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[41500],
        [25685],
        [21390],
        [17695],
        [18758],
        [20364],
        [21510],
        [18385],
        [19330],
        [20639],
        [17463],
        [17662],
        [20663],
        [17922],
        [19129],
        [18985],
        [20140],
        [18140]], device='cuda:0')
[2024-07-24 10:26:01,245][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[45090],
        [49109],
        [49718],
        [49121],
        [49576],
        [49211],
        [49774],
        [49380],
        [48659],
        [49525],
        [49245],
        [49470],
        [49734],
        [49208],
        [49655],
        [48391],
        [49825],
        [49045]], device='cuda:0')
[2024-07-24 10:26:01,247][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 1863],
        [ 7241],
        [49075],
        [40335],
        [48990],
        [48455],
        [48741],
        [49309],
        [49501],
        [49709],
        [49492],
        [49724],
        [49527],
        [49683],
        [49589],
        [49630],
        [49917],
        [49580]], device='cuda:0')
[2024-07-24 10:26:01,248][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4870],
        [4374],
        [1988],
        [6495],
        [3577],
        [8819],
        [3634],
        [6956],
        [8451],
        [4134],
        [5079],
        [4124],
        [3225],
        [6230],
        [4261],
        [7756],
        [2933],
        [7150]], device='cuda:0')
[2024-07-24 10:26:01,250][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 3459],
        [12011],
        [48563],
        [ 1357],
        [33265],
        [ 8934],
        [ 2041],
        [11853],
        [ 1459],
        [ 1986],
        [20393],
        [34188],
        [ 1746],
        [ 4395],
        [13567],
        [  990],
        [ 9795],
        [ 4190]], device='cuda:0')
[2024-07-24 10:26:01,252][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540],
        [29540]], device='cuda:0')
[2024-07-24 10:26:01,273][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:01,275][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,276][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,277][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,279][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,280][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,281][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,281][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,282][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,283][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,284][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,284][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,285][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,286][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,286][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6031, 0.3969], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,287][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6140, 0.3860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,288][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3691, 0.6309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,288][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6273, 0.3727], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,289][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4108, 0.5892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,290][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9727, 0.0273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,290][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9913, 0.0087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,292][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8388, 0.1612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,293][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([8.4134e-04, 9.9916e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,295][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2397, 0.7603], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,296][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2229, 0.7771], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,298][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.3337, 0.3332, 0.3331], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,299][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.1594, 0.6882, 0.1525], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,301][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.4079, 0.2810, 0.3112], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,303][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.3195, 0.5150, 0.1655], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,304][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.5101, 0.2876, 0.2023], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,306][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.2144, 0.5877, 0.1979], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,308][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.3109, 0.2085, 0.4806], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,309][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.8270, 0.1052, 0.0678], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,311][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.8022, 0.1423, 0.0555], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,312][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([5.7094e-04, 9.4711e-01, 5.2320e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,313][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.1443, 0.3976, 0.4581], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,315][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0877, 0.7246, 0.1877], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,317][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2501, 0.2498, 0.2497, 0.2503], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,318][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0842, 0.2600, 0.5710, 0.0849], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,319][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3124, 0.2036, 0.2484, 0.2357], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,320][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2186, 0.2849, 0.1256, 0.3709], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,320][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2794, 0.1926, 0.2323, 0.2957], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,321][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1016, 0.7712, 0.0457, 0.0814], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,323][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8509, 0.0519, 0.0650, 0.0321], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,324][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4535, 0.0425, 0.2225, 0.2816], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,326][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7700, 0.1389, 0.0587, 0.0324], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,327][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.8186e-04, 7.2785e-01, 4.9296e-02, 2.2227e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,328][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1009, 0.2902, 0.3669, 0.2420], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,330][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0744, 0.2825, 0.0733, 0.5698], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,331][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.2001, 0.1999, 0.1998, 0.2002, 0.2000], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,333][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0391, 0.1797, 0.0796, 0.3797, 0.3219], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,335][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.2563, 0.1746, 0.1966, 0.1954, 0.1772], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,336][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.1826, 0.2635, 0.0947, 0.3257, 0.1334], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,338][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.3141, 0.1724, 0.1362, 0.2506, 0.1267], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,339][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0407, 0.1670, 0.5532, 0.0215, 0.2176], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,341][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0743, 0.0558, 0.7066, 0.0799, 0.0834], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,343][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.6051, 0.1128, 0.0553, 0.2006, 0.0264], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,344][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.7253, 0.1332, 0.0545, 0.0270, 0.0600], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,345][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([4.4080e-04, 7.2772e-01, 4.0535e-02, 2.2315e-01, 8.1519e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,347][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0823, 0.2207, 0.2560, 0.1819, 0.2590], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,349][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0570, 0.4198, 0.0657, 0.2532, 0.2043], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,350][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.1667, 0.1665, 0.1665, 0.1668, 0.1666, 0.1668], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,352][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0270, 0.1187, 0.1035, 0.1304, 0.5456, 0.0748], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,354][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.2087, 0.1455, 0.1681, 0.1584, 0.1563, 0.1630], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,355][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.1495, 0.2083, 0.0851, 0.2633, 0.1373, 0.1564], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,357][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.2009, 0.1520, 0.1178, 0.1872, 0.1272, 0.2148], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,359][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0712, 0.3096, 0.4544, 0.0113, 0.0784, 0.0751], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,360][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.6013, 0.0142, 0.1110, 0.0464, 0.1345, 0.0925], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,362][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.2495, 0.0522, 0.1224, 0.2089, 0.2005, 0.1666], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,363][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.7116, 0.1249, 0.0477, 0.0260, 0.0537, 0.0361], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,364][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ were] are: tensor([5.4852e-04, 7.2922e-01, 3.8428e-02, 2.1324e-01, 9.1609e-03, 9.4095e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,365][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0619, 0.1772, 0.2167, 0.1430, 0.2149, 0.1863], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,366][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.1112, 0.4148, 0.0203, 0.2077, 0.0464, 0.1997], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,367][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.1429, 0.1427, 0.1427, 0.1430, 0.1428, 0.1430, 0.1428],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,368][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0126, 0.0228, 0.0546, 0.0548, 0.4494, 0.3935, 0.0122],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,370][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.1942, 0.1279, 0.1440, 0.1341, 0.1322, 0.1367, 0.1308],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,372][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.1346, 0.1913, 0.0711, 0.2189, 0.1150, 0.1302, 0.1389],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,373][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.2127, 0.1271, 0.0853, 0.1801, 0.0986, 0.1645, 0.1317],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,375][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.1685, 0.5782, 0.0179, 0.0344, 0.0290, 0.0529, 0.1191],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,376][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0952, 0.0025, 0.0278, 0.0591, 0.0331, 0.0015, 0.7807],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,378][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.2453, 0.0754, 0.2155, 0.1479, 0.0963, 0.1889, 0.0306],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,380][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.6646, 0.1306, 0.0473, 0.0265, 0.0552, 0.0368, 0.0390],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,381][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ working] are: tensor([3.8424e-04, 7.0189e-01, 4.0258e-02, 2.0519e-01, 6.6479e-03, 7.0470e-03,
        3.8585e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,383][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0519, 0.1480, 0.1797, 0.1194, 0.1820, 0.1539, 0.1650],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,384][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0584, 0.2904, 0.0152, 0.1076, 0.0453, 0.0943, 0.3888],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,386][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1251, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,388][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0240, 0.0664, 0.1039, 0.1023, 0.3185, 0.2234, 0.1307, 0.0308],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,390][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1709, 0.1081, 0.1313, 0.1185, 0.1188, 0.1219, 0.1173, 0.1132],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,391][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1176, 0.1541, 0.0632, 0.1819, 0.1011, 0.1041, 0.1088, 0.1691],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,393][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1564, 0.1091, 0.0800, 0.1335, 0.0852, 0.1599, 0.1157, 0.1602],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,394][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([5.8472e-04, 9.9839e-04, 2.3933e-04, 1.6439e-04, 7.9683e-05, 7.6053e-05,
        3.7646e-04, 9.9748e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,396][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.4278, 0.0171, 0.1364, 0.0458, 0.0298, 0.2946, 0.0413, 0.0071],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,398][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1759, 0.0224, 0.1110, 0.1102, 0.0992, 0.2685, 0.1359, 0.0770],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,399][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.6563, 0.1202, 0.0481, 0.0272, 0.0540, 0.0377, 0.0380, 0.0185],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,401][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([4.1527e-04, 7.0070e-01, 2.8939e-02, 1.7893e-01, 6.5143e-03, 6.9229e-03,
        3.7814e-02, 3.9767e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,402][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0458, 0.1258, 0.1612, 0.1037, 0.1574, 0.1353, 0.1457, 0.1253],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,404][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0338, 0.1541, 0.0223, 0.1141, 0.0623, 0.1204, 0.1991, 0.2938],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,406][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1112, 0.1110, 0.1110, 0.1112, 0.1111, 0.1112, 0.1111, 0.1111, 0.1110],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,407][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0227, 0.0454, 0.0467, 0.0869, 0.2720, 0.1954, 0.0637, 0.2391, 0.0281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,408][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1477, 0.0972, 0.1159, 0.1082, 0.1090, 0.1127, 0.1063, 0.1005, 0.1026],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,409][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0957, 0.1157, 0.0512, 0.1496, 0.0903, 0.0895, 0.0940, 0.1284, 0.1857],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,410][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1447, 0.0974, 0.0734, 0.1119, 0.0838, 0.1232, 0.1018, 0.1299, 0.1340],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,411][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0782, 0.4018, 0.1626, 0.0089, 0.0227, 0.0151, 0.0285, 0.2645, 0.0177],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,412][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.5700, 0.0066, 0.0425, 0.0166, 0.1367, 0.0935, 0.0307, 0.0106, 0.0927],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,414][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1607, 0.0174, 0.1008, 0.0765, 0.1277, 0.1006, 0.1170, 0.0908, 0.2085],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,415][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.6092, 0.1215, 0.0472, 0.0267, 0.0541, 0.0367, 0.0384, 0.0184, 0.0477],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,417][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.9516e-04, 6.5774e-01, 2.5588e-02, 1.5968e-01, 5.3194e-03, 5.7510e-03,
        3.5506e-02, 3.5679e-02, 7.4350e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,418][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0409, 0.1129, 0.1435, 0.0934, 0.1435, 0.1227, 0.1298, 0.1111, 0.1023],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,420][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0440, 0.1305, 0.0221, 0.0723, 0.0525, 0.1004, 0.1807, 0.1716, 0.2258],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,422][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.1001, 0.0999, 0.0999, 0.1001, 0.1000, 0.1001, 0.1000, 0.1000, 0.0999,
        0.0999], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,423][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0085, 0.0242, 0.0291, 0.0366, 0.2647, 0.0788, 0.0377, 0.4406, 0.0621,
        0.0178], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,425][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1402, 0.0912, 0.1058, 0.0975, 0.0939, 0.0980, 0.0936, 0.0889, 0.0861,
        0.1050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,427][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0869, 0.1292, 0.0456, 0.1572, 0.0725, 0.0882, 0.0836, 0.1315, 0.1522,
        0.0532], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,429][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.1602, 0.0956, 0.0805, 0.0983, 0.0756, 0.1171, 0.0859, 0.1025, 0.0944,
        0.0898], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,430][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0154, 0.4446, 0.0028, 0.0032, 0.0019, 0.0032, 0.0183, 0.3821, 0.0541,
        0.0746], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,432][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.2654, 0.0176, 0.0194, 0.0455, 0.0020, 0.0100, 0.0103, 0.0048, 0.4917,
        0.1333], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,434][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.1074, 0.0177, 0.1016, 0.0455, 0.0754, 0.0691, 0.1539, 0.1651, 0.2509,
        0.0134], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,435][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.6180, 0.1146, 0.0439, 0.0227, 0.0488, 0.0326, 0.0327, 0.0159, 0.0418,
        0.0290], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,437][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([3.8320e-04, 5.9010e-01, 4.2320e-02, 1.6759e-01, 8.2061e-03, 6.5751e-03,
        4.5520e-02, 5.2437e-02, 8.2983e-02, 3.8924e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,438][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0357, 0.1014, 0.1225, 0.0819, 0.1231, 0.1070, 0.1116, 0.0976, 0.0865,
        0.1327], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,440][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0092, 0.0594, 0.0279, 0.0417, 0.0703, 0.0809, 0.2496, 0.1784, 0.1853,
        0.0973], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,442][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0910, 0.0909, 0.0908, 0.0910, 0.0909, 0.0910, 0.0909, 0.0909, 0.0908,
        0.0908, 0.0909], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,443][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0387, 0.0375, 0.0599, 0.0398, 0.1847, 0.0869, 0.1347, 0.1529, 0.0558,
        0.1848, 0.0244], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,445][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1196, 0.0773, 0.0979, 0.0868, 0.0877, 0.0912, 0.0873, 0.0800, 0.0811,
        0.1013, 0.0897], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,447][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0678, 0.0841, 0.0387, 0.1146, 0.0624, 0.0593, 0.0772, 0.0953, 0.1135,
        0.0491, 0.2380], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,449][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1027, 0.1005, 0.0775, 0.0835, 0.0712, 0.0976, 0.0864, 0.0865, 0.0759,
        0.0899, 0.1282], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,450][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1320, 0.1239, 0.1844, 0.0161, 0.1103, 0.0678, 0.0473, 0.1026, 0.0746,
        0.0472, 0.0937], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,452][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0475, 0.0289, 0.1614, 0.0217, 0.4128, 0.0626, 0.0232, 0.0158, 0.1752,
        0.0146, 0.0362], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,453][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1258, 0.0138, 0.0818, 0.0791, 0.0776, 0.0829, 0.1066, 0.0663, 0.1084,
        0.1833, 0.0744], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,454][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.6019, 0.1120, 0.0432, 0.0248, 0.0482, 0.0343, 0.0350, 0.0171, 0.0445,
        0.0275, 0.0114], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,455][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([2.9690e-04, 6.6330e-01, 2.0582e-02, 1.5757e-01, 4.2779e-03, 4.0927e-03,
        3.4505e-02, 3.2712e-02, 6.2015e-02, 1.4373e-03, 1.9210e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,457][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0318, 0.0911, 0.1144, 0.0749, 0.1149, 0.0978, 0.1044, 0.0907, 0.0798,
        0.1289, 0.0713], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,458][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0393, 0.1801, 0.0237, 0.0645, 0.0471, 0.1176, 0.1395, 0.1372, 0.1299,
        0.0156, 0.1056], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,460][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833,
        0.0833, 0.0833, 0.0833], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,462][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0104, 0.0459, 0.0227, 0.0947, 0.0940, 0.1695, 0.0453, 0.1494, 0.0704,
        0.1406, 0.0508, 0.1062], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,464][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.1137, 0.0760, 0.0857, 0.0841, 0.0777, 0.0832, 0.0768, 0.0727, 0.0730,
        0.0886, 0.0827, 0.0857], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,465][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0649, 0.0893, 0.0333, 0.1153, 0.0468, 0.0602, 0.0608, 0.0911, 0.1113,
        0.0402, 0.2372, 0.0497], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,467][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.1271, 0.0890, 0.0464, 0.0975, 0.0440, 0.0964, 0.0633, 0.0825, 0.0855,
        0.0556, 0.1668, 0.0459], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,469][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0036, 0.0340, 0.3298, 0.0074, 0.1423, 0.0039, 0.0026, 0.0146, 0.0144,
        0.0028, 0.0278, 0.4166], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,470][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0472, 0.0396, 0.4867, 0.0591, 0.0499, 0.0387, 0.0017, 0.0041, 0.0317,
        0.1404, 0.0557, 0.0453], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,472][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.1506, 0.0824, 0.0178, 0.0679, 0.0073, 0.1012, 0.1018, 0.0383, 0.1267,
        0.0580, 0.2452, 0.0029], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,474][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.6167, 0.1144, 0.0402, 0.0213, 0.0446, 0.0297, 0.0293, 0.0141, 0.0408,
        0.0271, 0.0112, 0.0105], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,475][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([3.3242e-04, 5.7800e-01, 2.6601e-02, 1.6316e-01, 4.9576e-03, 5.0900e-03,
        3.6156e-02, 4.1564e-02, 7.1578e-02, 2.7475e-03, 2.9432e-02, 4.0381e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,477][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0322, 0.0841, 0.1000, 0.0694, 0.1003, 0.0869, 0.0917, 0.0797, 0.0718,
        0.1115, 0.0639, 0.1085], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,479][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0148, 0.1486, 0.0325, 0.0714, 0.0926, 0.0804, 0.1267, 0.1708, 0.1285,
        0.0199, 0.0705, 0.0434], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,480][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0770, 0.0769, 0.0769, 0.0770, 0.0769, 0.0770, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0769, 0.0769, 0.0768], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,482][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0071, 0.0203, 0.0322, 0.0504, 0.2165, 0.1537, 0.0194, 0.0245, 0.0302,
        0.1269, 0.0488, 0.2511, 0.0191], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,484][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1038, 0.0678, 0.0777, 0.0729, 0.0709, 0.0734, 0.0722, 0.0677, 0.0657,
        0.0815, 0.0745, 0.0773, 0.0948], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,485][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0622, 0.0778, 0.0320, 0.0981, 0.0498, 0.0534, 0.0626, 0.0870, 0.1094,
        0.0384, 0.2271, 0.0533, 0.0488], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,487][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1107, 0.0936, 0.0478, 0.0835, 0.0485, 0.0707, 0.0724, 0.0747, 0.0710,
        0.0668, 0.1380, 0.0485, 0.0738], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,489][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.1463, 0.1806, 0.0368, 0.0055, 0.0121, 0.0471, 0.0357, 0.4155, 0.0602,
        0.0031, 0.0452, 0.0059, 0.0060], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,491][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1771, 0.0071, 0.0127, 0.0367, 0.0014, 0.0376, 0.0082, 0.0024, 0.0233,
        0.0083, 0.0128, 0.0014, 0.6712], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,492][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.1828, 0.0352, 0.0441, 0.0703, 0.0620, 0.1264, 0.1217, 0.0611, 0.1099,
        0.0538, 0.0970, 0.0187, 0.0170], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,494][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.6272, 0.1042, 0.0361, 0.0218, 0.0406, 0.0294, 0.0294, 0.0149, 0.0415,
        0.0253, 0.0114, 0.0094, 0.0088], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,495][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([3.3200e-04, 5.8587e-01, 2.3038e-02, 1.4636e-01, 5.5685e-03, 4.7828e-03,
        3.6647e-02, 3.5590e-02, 6.5986e-02, 2.3837e-03, 2.3077e-02, 4.4296e-02,
        2.6076e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,497][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0255, 0.0746, 0.0916, 0.0616, 0.0923, 0.0792, 0.0837, 0.0734, 0.0656,
        0.1019, 0.0577, 0.0993, 0.0936], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,498][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0169, 0.1746, 0.0149, 0.0688, 0.0279, 0.0862, 0.2200, 0.1220, 0.1181,
        0.0220, 0.0571, 0.0145, 0.0570], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,499][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0715, 0.0714, 0.0714, 0.0715, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0714, 0.0714, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,500][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0122, 0.0182, 0.0362, 0.0462, 0.1718, 0.1236, 0.0446, 0.0651, 0.0577,
        0.1025, 0.0164, 0.1938, 0.1051, 0.0066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,501][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0935, 0.0604, 0.0731, 0.0661, 0.0662, 0.0708, 0.0669, 0.0625, 0.0619,
        0.0776, 0.0692, 0.0729, 0.0885, 0.0705], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,503][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0536, 0.0638, 0.0288, 0.0815, 0.0499, 0.0546, 0.0566, 0.0816, 0.0926,
        0.0365, 0.1936, 0.0544, 0.0443, 0.1083], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,504][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0948, 0.0826, 0.0458, 0.0655, 0.0482, 0.0793, 0.0703, 0.0685, 0.0643,
        0.0656, 0.1031, 0.0449, 0.0786, 0.0884], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,505][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.5696e-03, 9.7541e-04, 1.0529e-02, 4.1171e-04, 1.6321e-02, 3.1074e-03,
        1.8869e-03, 4.0684e-03, 6.3920e-03, 1.3464e-03, 1.9633e-03, 6.0182e-03,
        5.5187e-04, 9.4286e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,507][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.6343, 0.0016, 0.0178, 0.0062, 0.0008, 0.0234, 0.0687, 0.0017, 0.0320,
        0.0029, 0.0022, 0.0009, 0.2047, 0.0028], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,509][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0966, 0.0274, 0.0701, 0.0741, 0.0541, 0.0646, 0.0803, 0.0668, 0.1141,
        0.1122, 0.0938, 0.0133, 0.0411, 0.0916], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,511][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5907, 0.1106, 0.0407, 0.0235, 0.0458, 0.0321, 0.0326, 0.0161, 0.0419,
        0.0260, 0.0116, 0.0094, 0.0094, 0.0097], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,512][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.2973e-04, 5.8326e-01, 2.5771e-02, 1.4255e-01, 5.9334e-03, 5.3393e-03,
        3.3755e-02, 3.0417e-02, 6.2611e-02, 1.9066e-03, 2.0665e-02, 5.5440e-02,
        3.1719e-02, 3.0068e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,514][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0241, 0.0687, 0.0862, 0.0559, 0.0871, 0.0745, 0.0794, 0.0689, 0.0601,
        0.0964, 0.0533, 0.0942, 0.0894, 0.0617], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,515][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0107, 0.0599, 0.0223, 0.0553, 0.0439, 0.0936, 0.1917, 0.1576, 0.1572,
        0.0289, 0.0705, 0.0321, 0.0366, 0.0397], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,517][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0667, 0.0666, 0.0666, 0.0668, 0.0667, 0.0668, 0.0667, 0.0667, 0.0666,
        0.0666, 0.0667, 0.0667, 0.0666, 0.0667, 0.0665], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,519][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0102, 0.0114, 0.0268, 0.0255, 0.1893, 0.1028, 0.0176, 0.0382, 0.0610,
        0.1072, 0.0205, 0.2078, 0.1270, 0.0193, 0.0352], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,520][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0894, 0.0584, 0.0668, 0.0628, 0.0609, 0.0635, 0.0620, 0.0575, 0.0561,
        0.0699, 0.0639, 0.0664, 0.0843, 0.0644, 0.0737], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,522][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0524, 0.0642, 0.0274, 0.0832, 0.0422, 0.0495, 0.0526, 0.0773, 0.0888,
        0.0331, 0.1825, 0.0456, 0.0414, 0.1028, 0.0570], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,524][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0923, 0.0863, 0.0367, 0.0795, 0.0415, 0.0649, 0.0512, 0.0676, 0.0569,
        0.0504, 0.1198, 0.0387, 0.0719, 0.0787, 0.0635], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,526][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0698, 0.1119, 0.0394, 0.0156, 0.0025, 0.0388, 0.1631, 0.0675, 0.0724,
        0.0975, 0.1235, 0.0015, 0.0334, 0.0499, 0.1131], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,528][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.5216, 0.0052, 0.0040, 0.0996, 0.0032, 0.0056, 0.0213, 0.0176, 0.0182,
        0.0262, 0.0357, 0.0040, 0.0283, 0.0183, 0.1910], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,530][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0545, 0.0275, 0.0543, 0.0749, 0.0688, 0.0591, 0.1238, 0.0542, 0.0908,
        0.1012, 0.1115, 0.0261, 0.0552, 0.0746, 0.0233], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,532][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.5932, 0.1081, 0.0370, 0.0224, 0.0419, 0.0300, 0.0299, 0.0149, 0.0424,
        0.0250, 0.0115, 0.0096, 0.0091, 0.0095, 0.0156], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,533][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([2.9255e-04, 6.0360e-01, 2.0666e-02, 1.6124e-01, 4.3390e-03, 4.1398e-03,
        3.0969e-02, 3.2758e-02, 5.6503e-02, 1.5997e-03, 2.0485e-02, 2.9223e-02,
        1.9306e-02, 3.0812e-04, 1.4569e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,535][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0219, 0.0635, 0.0815, 0.0517, 0.0799, 0.0686, 0.0735, 0.0628, 0.0557,
        0.0889, 0.0498, 0.0860, 0.0832, 0.0563, 0.0766], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,537][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0111, 0.1075, 0.0187, 0.0703, 0.0258, 0.0857, 0.1842, 0.1256, 0.1372,
        0.0275, 0.0508, 0.0147, 0.0572, 0.0329, 0.0508], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,538][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0626, 0.0625, 0.0625, 0.0626, 0.0625, 0.0626, 0.0625, 0.0625, 0.0625,
        0.0625, 0.0625, 0.0625, 0.0624, 0.0625, 0.0624, 0.0625],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,540][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0070, 0.0148, 0.0215, 0.0203, 0.1094, 0.0764, 0.0262, 0.0931, 0.0535,
        0.0896, 0.0422, 0.1281, 0.0700, 0.0233, 0.2128, 0.0118],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,542][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0816, 0.0533, 0.0637, 0.0589, 0.0584, 0.0609, 0.0564, 0.0539, 0.0544,
        0.0682, 0.0604, 0.0643, 0.0766, 0.0602, 0.0674, 0.0613],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,543][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0452, 0.0559, 0.0247, 0.0715, 0.0418, 0.0463, 0.0472, 0.0660, 0.0893,
        0.0299, 0.1701, 0.0455, 0.0387, 0.0841, 0.0496, 0.0942],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,544][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0884, 0.0734, 0.0332, 0.0681, 0.0361, 0.0602, 0.0452, 0.0633, 0.0651,
        0.0579, 0.1095, 0.0361, 0.0575, 0.0756, 0.0638, 0.0667],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,545][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0505, 0.1424, 0.1521, 0.0055, 0.0521, 0.0189, 0.0490, 0.1750, 0.0297,
        0.0551, 0.0278, 0.0137, 0.0600, 0.0604, 0.1015, 0.0062],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,547][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2628, 0.0076, 0.0602, 0.0144, 0.0497, 0.0450, 0.0489, 0.0062, 0.1420,
        0.0531, 0.0195, 0.0553, 0.0812, 0.0135, 0.0650, 0.0757],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,548][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0951, 0.0274, 0.0538, 0.0532, 0.0441, 0.0400, 0.0740, 0.0539, 0.1162,
        0.0736, 0.1036, 0.0103, 0.0323, 0.0733, 0.0517, 0.0975],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,550][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5728, 0.1061, 0.0363, 0.0221, 0.0420, 0.0294, 0.0300, 0.0150, 0.0399,
        0.0240, 0.0112, 0.0089, 0.0085, 0.0094, 0.0150, 0.0293],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,551][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.9012e-04, 5.6499e-01, 1.9219e-02, 1.3757e-01, 4.1352e-03, 3.9637e-03,
        3.1906e-02, 2.9366e-02, 5.7654e-02, 1.8174e-03, 1.9718e-02, 3.5651e-02,
        2.2271e-02, 2.4888e-04, 1.7010e-02, 5.4190e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,553][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0216, 0.0595, 0.0763, 0.0494, 0.0753, 0.0650, 0.0688, 0.0585, 0.0531,
        0.0848, 0.0468, 0.0817, 0.0790, 0.0532, 0.0727, 0.0540],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,555][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0100, 0.0566, 0.0218, 0.0533, 0.0354, 0.0743, 0.1910, 0.1412, 0.1661,
        0.0331, 0.0530, 0.0250, 0.0389, 0.0374, 0.0215, 0.0415],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,557][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0589, 0.0588, 0.0588, 0.0589, 0.0588, 0.0589, 0.0588, 0.0588, 0.0588,
        0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0587, 0.0588, 0.0589],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,558][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0082, 0.0140, 0.0292, 0.0524, 0.1514, 0.0704, 0.0229, 0.0508, 0.0372,
        0.0729, 0.0248, 0.1775, 0.0822, 0.0167, 0.1023, 0.0675, 0.0194],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,560][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0808, 0.0517, 0.0593, 0.0549, 0.0538, 0.0561, 0.0533, 0.0499, 0.0491,
        0.0616, 0.0564, 0.0589, 0.0719, 0.0559, 0.0637, 0.0542, 0.0686],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,562][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0453, 0.0634, 0.0231, 0.0773, 0.0396, 0.0457, 0.0439, 0.0663, 0.0738,
        0.0285, 0.1830, 0.0425, 0.0362, 0.0825, 0.0501, 0.0764, 0.0224],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,564][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0962, 0.0662, 0.0320, 0.0630, 0.0338, 0.0575, 0.0423, 0.0590, 0.0539,
        0.0472, 0.1051, 0.0363, 0.0641, 0.0727, 0.0600, 0.0584, 0.0525],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,565][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([1.0306e-02, 8.6890e-02, 6.0109e-02, 1.2366e-03, 5.7030e-04, 2.3714e-03,
        7.5996e-02, 1.9700e-02, 2.4690e-02, 5.8091e-01, 3.0720e-02, 3.8800e-04,
        3.1768e-03, 3.9989e-02, 1.0992e-02, 2.7995e-02, 2.3957e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,566][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([1.9513e-02, 7.8433e-03, 9.5913e-02, 9.5521e-03, 1.0451e-03, 8.0855e-03,
        2.6536e-07, 4.0176e-04, 1.1010e-01, 3.9754e-02, 1.5996e-02, 8.8558e-04,
        7.5483e-05, 1.6870e-02, 4.2974e-05, 3.9331e-01, 2.8061e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,568][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0700, 0.0232, 0.0191, 0.0327, 0.0236, 0.0365, 0.2123, 0.0566, 0.1048,
        0.0258, 0.0958, 0.0077, 0.0264, 0.0645, 0.0636, 0.1307, 0.0066],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,570][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.6168, 0.0985, 0.0333, 0.0185, 0.0368, 0.0248, 0.0240, 0.0120, 0.0348,
        0.0218, 0.0093, 0.0085, 0.0074, 0.0079, 0.0133, 0.0263, 0.0060],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,571][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([2.6016e-04, 5.3426e-01, 2.3796e-02, 1.4968e-01, 3.7022e-03, 4.1696e-03,
        2.9944e-02, 3.8558e-02, 5.8847e-02, 1.9071e-03, 2.2840e-02, 2.9225e-02,
        1.8587e-02, 3.6394e-04, 1.2985e-02, 4.6630e-02, 2.4248e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,573][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0209, 0.0565, 0.0694, 0.0461, 0.0688, 0.0592, 0.0628, 0.0536, 0.0488,
        0.0759, 0.0434, 0.0744, 0.0713, 0.0487, 0.0653, 0.0484, 0.0865],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,575][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0072, 0.0932, 0.0271, 0.0695, 0.0329, 0.0683, 0.1875, 0.1161, 0.1242,
        0.0247, 0.0436, 0.0155, 0.0500, 0.0279, 0.0355, 0.0435, 0.0333],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,577][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0556, 0.0555, 0.0555, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555,
        0.0555, 0.0555, 0.0556, 0.0555, 0.0556, 0.0554, 0.0555, 0.0556, 0.0556],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,578][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0090, 0.0135, 0.0269, 0.0343, 0.1312, 0.0914, 0.0332, 0.0494, 0.0433,
        0.0772, 0.0124, 0.1484, 0.0789, 0.0050, 0.1096, 0.0643, 0.0677, 0.0044],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,580][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0698, 0.0461, 0.0567, 0.0500, 0.0514, 0.0545, 0.0517, 0.0477, 0.0473,
        0.0603, 0.0527, 0.0566, 0.0681, 0.0539, 0.0615, 0.0534, 0.0664, 0.0517],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,582][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0411, 0.0482, 0.0220, 0.0619, 0.0384, 0.0418, 0.0434, 0.0624, 0.0707,
        0.0279, 0.1490, 0.0419, 0.0338, 0.0833, 0.0462, 0.0747, 0.0246, 0.0887],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,584][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0835, 0.0687, 0.0313, 0.0572, 0.0360, 0.0585, 0.0493, 0.0554, 0.0496,
        0.0481, 0.0868, 0.0318, 0.0542, 0.0658, 0.0592, 0.0532, 0.0441, 0.0671],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,585][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.8508e-04, 3.7377e-04, 3.3295e-03, 9.6806e-05, 7.1515e-03, 9.6174e-04,
        6.6927e-04, 2.8833e-03, 2.8647e-03, 1.0154e-03, 9.6632e-04, 4.8443e-03,
        2.3918e-04, 3.6824e-01, 5.1328e-04, 3.2347e-03, 2.1981e-04, 6.0171e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,587][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3754, 0.0009, 0.0100, 0.0036, 0.0004, 0.0129, 0.0380, 0.0009, 0.0198,
        0.0013, 0.0013, 0.0005, 0.1091, 0.0016, 0.3849, 0.0343, 0.0038, 0.0013],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,588][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0701, 0.0263, 0.0520, 0.0545, 0.0361, 0.0434, 0.0592, 0.0536, 0.0894,
        0.0773, 0.0825, 0.0076, 0.0268, 0.0652, 0.0472, 0.0959, 0.0538, 0.0591],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,589][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5742, 0.1028, 0.0361, 0.0216, 0.0405, 0.0285, 0.0287, 0.0143, 0.0380,
        0.0229, 0.0104, 0.0083, 0.0082, 0.0086, 0.0143, 0.0272, 0.0065, 0.0090],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,590][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.8267e-04, 5.6732e-01, 2.1534e-02, 1.2692e-01, 4.6798e-03, 4.7508e-03,
        2.9674e-02, 2.6935e-02, 5.3424e-02, 1.4735e-03, 1.7603e-02, 3.9719e-02,
        2.5133e-02, 2.7128e-04, 1.4733e-02, 5.0502e-02, 1.4976e-02, 6.9432e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,591][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0186, 0.0519, 0.0658, 0.0424, 0.0664, 0.0568, 0.0605, 0.0523, 0.0458,
        0.0735, 0.0406, 0.0719, 0.0681, 0.0472, 0.0632, 0.0465, 0.0839, 0.0447],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,593][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0072, 0.0426, 0.0201, 0.0620, 0.0347, 0.0710, 0.1863, 0.1288, 0.1310,
        0.0373, 0.0420, 0.0230, 0.0454, 0.0469, 0.0330, 0.0371, 0.0168, 0.0351],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,612][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:01,613][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,614][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,614][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,615][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,616][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,616][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,617][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,618][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,619][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,620][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,620][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,621][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:01,622][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9988, 0.0012], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,622][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1672, 0.8328], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,623][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5033, 0.4967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,624][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3691, 0.6309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,625][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6210, 0.3790], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,626][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8869, 0.1131], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,628][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9723, 0.0277], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,630][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4000, 0.6000], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,631][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,633][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1016, 0.8984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,634][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2403, 0.7597], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,636][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7816, 0.2184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:01,637][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.1146, 0.8480, 0.0373], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,639][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.0622, 0.7128, 0.2249], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,641][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.3601, 0.3554, 0.2846], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,642][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.3195, 0.5150, 0.1655], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,644][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.4119, 0.3261, 0.2620], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,646][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.6329, 0.2983, 0.0688], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,647][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.2210, 0.2043, 0.5748], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,649][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.1630, 0.4717, 0.3653], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,650][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.8941, 0.0022, 0.1037], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,651][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.0629, 0.6040, 0.3331], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,652][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.1446, 0.3974, 0.4580], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,653][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.1448, 0.0710, 0.7843], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:01,653][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2588, 0.1754, 0.4927, 0.0730], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,655][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0521, 0.3382, 0.2478, 0.3619], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,656][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2749, 0.2714, 0.2159, 0.2378], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,658][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2186, 0.2849, 0.1256, 0.3709], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,660][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2435, 0.2189, 0.2097, 0.3279], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,661][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4696, 0.3460, 0.0215, 0.1629], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,663][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8445, 0.0617, 0.0595, 0.0343], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,665][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1658, 0.2612, 0.3371, 0.2360], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,666][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9168, 0.0020, 0.0701, 0.0111], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,668][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0792, 0.4412, 0.2842, 0.1954], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,670][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1012, 0.2901, 0.3667, 0.2420], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,671][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3601, 0.1964, 0.0036, 0.4400], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:01,673][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.2478, 0.2348, 0.1906, 0.3092, 0.0175], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,674][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0219, 0.2378, 0.1007, 0.3731, 0.2664], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,676][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.2233, 0.2202, 0.1747, 0.1914, 0.1905], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,678][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.1826, 0.2635, 0.0947, 0.3257, 0.1334], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,679][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.2040, 0.1922, 0.1649, 0.2691, 0.1698], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,681][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.3342, 0.2317, 0.1852, 0.0942, 0.1548], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,683][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0411, 0.0480, 0.7607, 0.0780, 0.0722], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,684][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.1035, 0.2549, 0.2480, 0.2087, 0.1849], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,686][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.6791, 0.0025, 0.1407, 0.0128, 0.1650], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,687][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0362, 0.3572, 0.1999, 0.2802, 0.1266], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,689][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0825, 0.2206, 0.2560, 0.1819, 0.2591], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,691][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.1524, 0.0669, 0.0201, 0.0531, 0.7076], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:01,692][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.9525, 0.0055, 0.0021, 0.0336, 0.0053, 0.0011], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,693][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0216, 0.1628, 0.1019, 0.2107, 0.2422, 0.2609], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,694][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1839, 0.1815, 0.1430, 0.1581, 0.1572, 0.1764], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,695][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1495, 0.2083, 0.0851, 0.2633, 0.1373, 0.1564], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,695][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.1391, 0.1420, 0.1355, 0.2089, 0.1372, 0.2373], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,697][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.4042, 0.2491, 0.1448, 0.0583, 0.0625, 0.0811], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,698][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.4979, 0.0146, 0.1622, 0.0592, 0.1641, 0.1020], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,700][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1051, 0.1472, 0.1655, 0.1512, 0.2384, 0.1927], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,701][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([6.0263e-01, 3.4039e-03, 1.6514e-01, 1.0244e-02, 2.1850e-01, 7.4503e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,703][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0672, 0.3468, 0.2296, 0.1557, 0.0888, 0.1118], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,704][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0621, 0.1772, 0.2165, 0.1430, 0.2148, 0.1863], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,706][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0762, 0.0550, 0.0022, 0.0528, 0.0023, 0.8115], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:01,708][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.1447, 0.0100, 0.0516, 0.0063, 0.0129, 0.7549, 0.0197],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,709][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.0126, 0.1086, 0.0659, 0.1685, 0.1982, 0.3149, 0.1314],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,711][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.1576, 0.1554, 0.1239, 0.1350, 0.1361, 0.1487, 0.1432],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,713][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.1346, 0.1913, 0.0711, 0.2189, 0.1150, 0.1302, 0.1389],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,714][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.1196, 0.1169, 0.1098, 0.1763, 0.1158, 0.1993, 0.1622],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,716][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.4622, 0.2444, 0.0110, 0.0811, 0.0203, 0.0550, 0.1261],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,717][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([3.8381e-02, 1.1834e-03, 2.2157e-02, 4.4550e-02, 2.5265e-02, 7.3099e-04,
        8.6773e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,719][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0683, 0.1361, 0.1961, 0.1103, 0.1720, 0.2300, 0.0873],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,720][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([4.7977e-03, 1.3564e-05, 8.0413e-04, 5.8525e-05, 6.5495e-04, 2.2614e-07,
        9.9367e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,722][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0310, 0.2840, 0.1669, 0.1799, 0.0887, 0.1103, 0.1392],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,723][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0521, 0.1479, 0.1796, 0.1194, 0.1820, 0.1539, 0.1651],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,724][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([1.0822e-01, 1.0905e-01, 6.5945e-04, 4.8457e-02, 2.6945e-03, 3.1234e-03,
        7.2779e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:01,726][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0213, 0.0259, 0.0021, 0.0244, 0.0047, 0.3605, 0.5587, 0.0025],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,728][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0150, 0.1035, 0.0717, 0.1412, 0.1565, 0.2158, 0.1544, 0.1420],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,730][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1372, 0.1354, 0.1075, 0.1178, 0.1182, 0.1317, 0.1259, 0.1263],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,731][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1176, 0.1541, 0.0632, 0.1819, 0.1011, 0.1041, 0.1088, 0.1691],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,733][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0810, 0.0927, 0.0948, 0.1439, 0.0963, 0.1651, 0.1291, 0.1971],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,735][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0399, 0.0207, 0.0032, 0.0150, 0.0023, 0.0032, 0.0122, 0.9034],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,736][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.4141, 0.0172, 0.1704, 0.0483, 0.0275, 0.2715, 0.0445, 0.0064],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,736][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0670, 0.1074, 0.1381, 0.0927, 0.1762, 0.1662, 0.1342, 0.1183],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,737][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.0456e-02, 1.9972e-05, 1.6747e-03, 6.2711e-05, 1.7619e-03, 4.9718e-07,
        8.1207e-01, 1.7396e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,738][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0445, 0.2524, 0.1640, 0.1068, 0.0584, 0.0767, 0.1294, 0.1679],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,740][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0459, 0.1257, 0.1611, 0.1036, 0.1573, 0.1353, 0.1458, 0.1252],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,741][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0702, 0.0947, 0.0010, 0.0566, 0.0021, 0.0091, 0.0029, 0.7634],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:01,743][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0175, 0.0053, 0.0012, 0.0230, 0.0232, 0.4269, 0.2462, 0.2526, 0.0041],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,744][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0134, 0.0834, 0.0515, 0.1163, 0.1228, 0.1759, 0.1191, 0.1793, 0.1384],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,746][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1219, 0.1203, 0.0960, 0.1050, 0.1056, 0.1170, 0.1128, 0.1130, 0.1085],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,747][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0957, 0.1157, 0.0512, 0.1496, 0.0903, 0.0895, 0.0940, 0.1284, 0.1857],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,749][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0686, 0.0771, 0.0799, 0.1206, 0.0813, 0.1375, 0.1087, 0.1684, 0.1581],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,751][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2281, 0.2497, 0.0467, 0.0586, 0.0195, 0.0239, 0.0531, 0.1948, 0.1256],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,753][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.5294, 0.0055, 0.0529, 0.0152, 0.1635, 0.0945, 0.0382, 0.0110, 0.0898],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,754][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0572, 0.0792, 0.1162, 0.0775, 0.1536, 0.1330, 0.1011, 0.1051, 0.1771],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,755][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.9981e-03, 1.7258e-05, 9.2346e-04, 7.6633e-05, 1.0157e-03, 1.8144e-07,
        8.0331e-01, 1.8466e-01, 2.3925e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,757][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0373, 0.2274, 0.1404, 0.1065, 0.0561, 0.0725, 0.1125, 0.1439, 0.1033],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,759][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0411, 0.1128, 0.1434, 0.0934, 0.1435, 0.1227, 0.1298, 0.1110, 0.1023],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,760][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1322, 0.0589, 0.0045, 0.0728, 0.0054, 0.0140, 0.0060, 0.0161, 0.6902],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:01,762][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0044, 0.0289, 0.0139, 0.0207, 0.0098, 0.1664, 0.4545, 0.1407, 0.0706,
        0.0902], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,764][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0063, 0.0639, 0.0325, 0.0914, 0.1072, 0.1474, 0.0928, 0.2002, 0.1622,
        0.0961], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,766][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.1120, 0.1103, 0.0866, 0.0952, 0.0943, 0.1048, 0.0996, 0.1006, 0.0965,
        0.1002], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,767][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0869, 0.1292, 0.0456, 0.1572, 0.0725, 0.0882, 0.0836, 0.1315, 0.1522,
        0.0532], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,769][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0627, 0.0680, 0.0700, 0.1045, 0.0727, 0.1257, 0.1005, 0.1464, 0.1384,
        0.1111], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,771][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.1064, 0.2086, 0.0046, 0.0264, 0.0063, 0.0106, 0.0385, 0.3135, 0.1693,
        0.1159], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,772][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1430, 0.0105, 0.0199, 0.0312, 0.0016, 0.0068, 0.0114, 0.0041, 0.3648,
        0.4066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,774][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0376, 0.0895, 0.1210, 0.0762, 0.1197, 0.1335, 0.1184, 0.1041, 0.1671,
        0.0330], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,775][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([1.3407e-03, 3.7307e-06, 2.5773e-04, 1.2685e-05, 3.9032e-04, 4.7564e-08,
        8.3613e-01, 1.2472e-01, 4.6025e-07, 3.7146e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,777][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0231, 0.2098, 0.1227, 0.1517, 0.0755, 0.0890, 0.1049, 0.1142, 0.0930,
        0.0161], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,777][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0357, 0.1013, 0.1225, 0.0819, 0.1231, 0.1071, 0.1116, 0.0976, 0.0865,
        0.1327], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,778][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0968, 0.0525, 0.0037, 0.0376, 0.0100, 0.0069, 0.0107, 0.0227, 0.0112,
        0.7480], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:01,779][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0827, 0.0122, 0.0397, 0.0350, 0.0279, 0.5169, 0.0825, 0.1325, 0.0213,
        0.0278, 0.0213], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,780][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0127, 0.0638, 0.0419, 0.0771, 0.0903, 0.1166, 0.1043, 0.1251, 0.1210,
        0.1277, 0.1193], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,782][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0995, 0.0981, 0.0780, 0.0855, 0.0860, 0.0959, 0.0925, 0.0925, 0.0887,
        0.0913, 0.0920], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,783][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0678, 0.0841, 0.0387, 0.1146, 0.0624, 0.0593, 0.0772, 0.0953, 0.1135,
        0.0491, 0.2380], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,785][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0488, 0.0576, 0.0631, 0.0898, 0.0620, 0.1030, 0.0828, 0.1263, 0.1159,
        0.0928, 0.1580], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,787][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.2409, 0.0730, 0.0266, 0.0412, 0.0310, 0.0307, 0.0408, 0.0738, 0.1517,
        0.0447, 0.2457], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,788][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0379, 0.0287, 0.1948, 0.0201, 0.4895, 0.0521, 0.0231, 0.0139, 0.1052,
        0.0123, 0.0224], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,790][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0479, 0.0744, 0.0900, 0.0821, 0.1126, 0.0855, 0.0814, 0.0936, 0.1542,
        0.0710, 0.1074], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,791][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([5.5595e-03, 1.0078e-05, 1.1459e-03, 2.2941e-05, 1.7731e-03, 2.9308e-07,
        8.7975e-01, 5.0353e-02, 7.4115e-07, 6.1367e-02, 1.3200e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,793][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0349, 0.2054, 0.1316, 0.0969, 0.0532, 0.0648, 0.0999, 0.1272, 0.0865,
        0.0145, 0.0851], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,794][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0320, 0.0911, 0.1143, 0.0749, 0.1148, 0.0979, 0.1045, 0.0907, 0.0798,
        0.1288, 0.0712], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,796][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2406, 0.1060, 0.0181, 0.1162, 0.0306, 0.0880, 0.0211, 0.0411, 0.1350,
        0.0229, 0.1804], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:01,798][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0230, 0.0223, 0.0136, 0.0302, 0.0009, 0.1310, 0.2055, 0.1687, 0.0602,
        0.2946, 0.0481, 0.0020], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,800][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0046, 0.0536, 0.0222, 0.0823, 0.0606, 0.1289, 0.0712, 0.1296, 0.1312,
        0.1102, 0.1295, 0.0761], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,801][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0931, 0.0917, 0.0723, 0.0792, 0.0789, 0.0870, 0.0829, 0.0838, 0.0803,
        0.0839, 0.0836, 0.0834], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,803][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0649, 0.0893, 0.0333, 0.1153, 0.0468, 0.0602, 0.0608, 0.0911, 0.1113,
        0.0402, 0.2372, 0.0497], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,805][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0438, 0.0551, 0.0541, 0.0837, 0.0540, 0.0956, 0.0755, 0.1157, 0.1081,
        0.0817, 0.1489, 0.0837], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,807][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0656, 0.0279, 0.0818, 0.0400, 0.0877, 0.0151, 0.0155, 0.0558, 0.1127,
        0.0233, 0.2275, 0.2470], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,808][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0210, 0.0243, 0.5181, 0.0402, 0.0474, 0.0354, 0.0015, 0.0034, 0.0095,
        0.2299, 0.0354, 0.0338], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,810][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0361, 0.0973, 0.0862, 0.0797, 0.0640, 0.1099, 0.0881, 0.0778, 0.1331,
        0.0568, 0.1126, 0.0584], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,811][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([1.6249e-03, 6.4740e-06, 3.5363e-04, 3.0985e-05, 3.9895e-04, 5.6793e-08,
        7.8070e-01, 1.2371e-01, 1.3965e-06, 9.2697e-02, 1.8424e-05, 4.5600e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,813][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0142, 0.1868, 0.0956, 0.1508, 0.0641, 0.0811, 0.0823, 0.0904, 0.0786,
        0.0098, 0.0998, 0.0464], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,815][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0322, 0.0841, 0.0999, 0.0694, 0.1003, 0.0869, 0.0918, 0.0797, 0.0718,
        0.1115, 0.0638, 0.1085], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,816][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0132, 0.0216, 0.0070, 0.0061, 0.4247, 0.0015, 0.0033, 0.0037, 0.0032,
        0.0059, 0.1139, 0.3960], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:01,818][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.1134, 0.0017, 0.0043, 0.0179, 0.0034, 0.7048, 0.0289, 0.0897, 0.0057,
        0.0076, 0.0138, 0.0080, 0.0009], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,819][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0052, 0.0468, 0.0292, 0.0745, 0.0805, 0.1263, 0.0628, 0.0851, 0.1131,
        0.0979, 0.1316, 0.1012, 0.0456], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,820][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0847, 0.0835, 0.0659, 0.0723, 0.0721, 0.0806, 0.0771, 0.0775, 0.0743,
        0.0767, 0.0771, 0.0765, 0.0819], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,821][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0622, 0.0778, 0.0320, 0.0981, 0.0498, 0.0534, 0.0626, 0.0870, 0.1094,
        0.0384, 0.2271, 0.0533, 0.0488], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,822][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0351, 0.0447, 0.0464, 0.0710, 0.0482, 0.0819, 0.0705, 0.1057, 0.0979,
        0.0790, 0.1380, 0.0802, 0.1014], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,823][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.3769, 0.0879, 0.0147, 0.0204, 0.0123, 0.0362, 0.0422, 0.1399, 0.1100,
        0.0070, 0.1228, 0.0109, 0.0188], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,825][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0687, 0.0033, 0.0100, 0.0239, 0.0009, 0.0258, 0.0067, 0.0017, 0.0174,
        0.0092, 0.0119, 0.0011, 0.8194], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,827][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0418, 0.0589, 0.0682, 0.0494, 0.0985, 0.1064, 0.0861, 0.0749, 0.1024,
        0.0480, 0.0796, 0.0883, 0.0975], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,828][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([3.5202e-03, 1.5636e-05, 8.7457e-04, 5.0459e-05, 1.1715e-03, 4.4499e-07,
        7.3232e-01, 9.5352e-02, 2.9908e-06, 1.6142e-01, 3.6945e-05, 1.3000e-03,
        3.9317e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,830][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0216, 0.1810, 0.1077, 0.1177, 0.0568, 0.0692, 0.0859, 0.1035, 0.0775,
        0.0118, 0.0865, 0.0448, 0.0360], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,831][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0256, 0.0746, 0.0916, 0.0616, 0.0923, 0.0792, 0.0838, 0.0734, 0.0656,
        0.1018, 0.0576, 0.0994, 0.0936], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,833][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([9.2698e-02, 3.2417e-02, 5.9291e-04, 3.0497e-02, 3.8861e-03, 9.1911e-03,
        1.6824e-02, 4.4117e-03, 2.0122e-02, 5.0052e-03, 9.2212e-02, 8.0744e-04,
        6.9134e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:01,834][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.9844e-03, 6.3782e-04, 8.4712e-04, 4.0416e-04, 1.9170e-05, 3.1667e-01,
        1.9314e-01, 2.0374e-02, 1.3732e-03, 3.5673e-03, 2.7327e-03, 4.8857e-05,
        4.5519e-01, 3.7170e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,836][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0074, 0.0458, 0.0322, 0.0674, 0.0737, 0.1004, 0.0712, 0.0954, 0.1049,
        0.0873, 0.0963, 0.0905, 0.0576, 0.0699], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,838][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0788, 0.0775, 0.0609, 0.0666, 0.0667, 0.0740, 0.0705, 0.0710, 0.0680,
        0.0710, 0.0706, 0.0707, 0.0752, 0.0786], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,839][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0536, 0.0638, 0.0288, 0.0815, 0.0499, 0.0546, 0.0566, 0.0816, 0.0926,
        0.0365, 0.1936, 0.0544, 0.0443, 0.1083], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,841][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0314, 0.0422, 0.0458, 0.0662, 0.0448, 0.0752, 0.0602, 0.0965, 0.0878,
        0.0679, 0.1201, 0.0695, 0.0874, 0.1048], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,843][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1134, 0.0134, 0.0142, 0.0149, 0.0243, 0.0153, 0.0227, 0.0334, 0.1067,
        0.0216, 0.0862, 0.0199, 0.0111, 0.5027], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,845][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4448, 0.0010, 0.0166, 0.0036, 0.0005, 0.0167, 0.1055, 0.0012, 0.0137,
        0.0044, 0.0012, 0.0006, 0.3882, 0.0021], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,846][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0349, 0.0611, 0.0755, 0.0552, 0.0798, 0.0740, 0.0609, 0.0596, 0.1054,
        0.0452, 0.0882, 0.0728, 0.1205, 0.0669], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,848][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.6472e-03, 1.5555e-05, 8.6050e-04, 4.1809e-05, 8.8024e-04, 2.5294e-07,
        6.6130e-01, 2.2070e-01, 2.0108e-06, 9.8302e-02, 2.6935e-05, 9.5565e-04,
        5.8758e-03, 4.3860e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,849][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0287, 0.1869, 0.1161, 0.0893, 0.0472, 0.0588, 0.0879, 0.1145, 0.0799,
        0.0122, 0.0755, 0.0402, 0.0391, 0.0237], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,851][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0242, 0.0687, 0.0861, 0.0559, 0.0871, 0.0746, 0.0794, 0.0689, 0.0601,
        0.0964, 0.0532, 0.0942, 0.0894, 0.0617], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,853][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1314, 0.0597, 0.0008, 0.0612, 0.0034, 0.0085, 0.0042, 0.0135, 0.0156,
        0.0033, 0.1417, 0.0010, 0.0104, 0.5453], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:01,854][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.3739e-03, 1.5836e-03, 2.7094e-04, 4.3038e-04, 7.7587e-04, 2.1866e-02,
        1.5291e-01, 1.1626e-02, 1.1453e-04, 3.8014e-03, 1.6581e-02, 1.7851e-03,
        1.3483e-01, 6.3197e-01, 2.0078e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,856][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0054, 0.0372, 0.0244, 0.0532, 0.0679, 0.0960, 0.0537, 0.0785, 0.1001,
        0.0802, 0.0949, 0.0866, 0.0576, 0.0742, 0.0902], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,858][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0734, 0.0722, 0.0566, 0.0619, 0.0619, 0.0688, 0.0651, 0.0657, 0.0630,
        0.0660, 0.0654, 0.0656, 0.0698, 0.0728, 0.0718], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,859][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0524, 0.0642, 0.0274, 0.0832, 0.0422, 0.0495, 0.0526, 0.0773, 0.0888,
        0.0331, 0.1825, 0.0456, 0.0414, 0.1028, 0.0570], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,860][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0273, 0.0362, 0.0386, 0.0585, 0.0391, 0.0663, 0.0541, 0.0875, 0.0792,
        0.0618, 0.1125, 0.0645, 0.0826, 0.0982, 0.0936], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,861][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1569, 0.0554, 0.0131, 0.0341, 0.0035, 0.0246, 0.0910, 0.0499, 0.1260,
        0.0592, 0.2126, 0.0034, 0.0332, 0.0693, 0.0678], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,862][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.3015, 0.0036, 0.0035, 0.0882, 0.0027, 0.0040, 0.0266, 0.0198, 0.0133,
        0.0418, 0.0439, 0.0036, 0.0336, 0.0256, 0.3883], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,863][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0300, 0.0560, 0.0754, 0.0444, 0.0790, 0.0887, 0.0776, 0.0590, 0.0843,
        0.0385, 0.0620, 0.0710, 0.1399, 0.0430, 0.0511], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,864][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([6.0563e-03, 1.8558e-05, 6.7962e-04, 7.0663e-05, 5.7431e-04, 4.3274e-07,
        6.8465e-01, 1.9509e-01, 3.3880e-06, 8.8689e-02, 3.1374e-05, 6.1230e-04,
        5.4897e-03, 3.8168e-03, 1.4224e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,866][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0246, 0.1788, 0.1093, 0.0956, 0.0489, 0.0599, 0.0834, 0.1045, 0.0757,
        0.0115, 0.0761, 0.0398, 0.0360, 0.0217, 0.0342], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,868][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0220, 0.0635, 0.0815, 0.0517, 0.0799, 0.0686, 0.0735, 0.0628, 0.0557,
        0.0889, 0.0497, 0.0860, 0.0832, 0.0563, 0.0767], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,869][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([5.4326e-02, 5.4653e-02, 1.4606e-03, 2.9644e-02, 4.2402e-04, 2.6374e-03,
        1.4631e-03, 3.3195e-03, 6.2935e-03, 3.7747e-03, 8.5837e-02, 5.5152e-05,
        4.8960e-03, 1.8278e-02, 7.3294e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:01,870][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.9255e-03, 1.0811e-03, 5.2753e-05, 2.6920e-03, 2.1524e-03, 5.5798e-01,
        1.2148e-02, 1.3202e-02, 6.1137e-03, 1.5275e-03, 5.2469e-03, 4.9542e-03,
        3.8543e-02, 9.7482e-03, 3.4054e-01, 2.0868e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,872][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0052, 0.0350, 0.0229, 0.0464, 0.0566, 0.0788, 0.0531, 0.0827, 0.0848,
        0.0755, 0.0926, 0.0718, 0.0475, 0.0665, 0.1038, 0.0767],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,874][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0686, 0.0675, 0.0530, 0.0578, 0.0580, 0.0643, 0.0608, 0.0614, 0.0588,
        0.0618, 0.0610, 0.0614, 0.0652, 0.0679, 0.0670, 0.0656],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,876][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0452, 0.0559, 0.0247, 0.0715, 0.0418, 0.0463, 0.0472, 0.0660, 0.0893,
        0.0299, 0.1701, 0.0455, 0.0387, 0.0841, 0.0496, 0.0942],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,878][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0241, 0.0325, 0.0351, 0.0532, 0.0349, 0.0602, 0.0477, 0.0803, 0.0739,
        0.0565, 0.1035, 0.0582, 0.0734, 0.0904, 0.0858, 0.0904],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,880][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0909, 0.0758, 0.0283, 0.0257, 0.0180, 0.0171, 0.0451, 0.1050, 0.1081,
        0.0561, 0.1406, 0.0125, 0.0497, 0.0752, 0.0759, 0.0761],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,881][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1649, 0.0050, 0.0788, 0.0096, 0.0589, 0.0410, 0.0714, 0.0056, 0.0741,
        0.1054, 0.0134, 0.0651, 0.1325, 0.0111, 0.1120, 0.0511],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,883][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0373, 0.0513, 0.0576, 0.0466, 0.0754, 0.0631, 0.0668, 0.0583, 0.0951,
        0.0409, 0.0763, 0.0698, 0.0881, 0.0556, 0.0484, 0.0693],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,884][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.6167e-02, 3.2107e-05, 1.3449e-03, 1.2785e-04, 1.1621e-03, 5.6891e-07,
        6.5352e-01, 2.1768e-01, 4.7278e-06, 7.8986e-02, 4.4418e-05, 1.2175e-03,
        1.0439e-02, 6.3194e-03, 1.2950e-02, 6.1723e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,886][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0286, 0.1755, 0.1075, 0.0816, 0.0434, 0.0534, 0.0808, 0.1059, 0.0746,
        0.0106, 0.0691, 0.0377, 0.0357, 0.0219, 0.0354, 0.0382],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,888][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0217, 0.0595, 0.0763, 0.0494, 0.0753, 0.0651, 0.0689, 0.0585, 0.0531,
        0.0848, 0.0468, 0.0817, 0.0790, 0.0532, 0.0727, 0.0539],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,890][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0561, 0.0268, 0.0038, 0.0183, 0.0020, 0.0038, 0.0031, 0.0103, 0.0213,
        0.0047, 0.0650, 0.0010, 0.0094, 0.0354, 0.0025, 0.7364],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:01,891][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([1.5495e-04, 2.3692e-04, 3.7841e-03, 4.2070e-04, 3.1198e-04, 1.7310e-02,
        7.2865e-03, 3.7559e-04, 1.2779e-03, 3.2733e-02, 3.8535e-03, 6.2888e-04,
        9.1874e-04, 9.0852e-03, 9.0438e-01, 4.7330e-03, 1.2509e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,893][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0032, 0.0314, 0.0170, 0.0509, 0.0506, 0.0766, 0.0458, 0.0717, 0.0784,
        0.0640, 0.0847, 0.0646, 0.0433, 0.0604, 0.0947, 0.1053, 0.0572],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,894][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0638, 0.0627, 0.0492, 0.0535, 0.0540, 0.0600, 0.0562, 0.0569, 0.0543,
        0.0579, 0.0566, 0.0572, 0.0605, 0.0630, 0.0623, 0.0611, 0.0708],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,896][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0453, 0.0634, 0.0231, 0.0773, 0.0396, 0.0457, 0.0439, 0.0663, 0.0738,
        0.0285, 0.1830, 0.0425, 0.0362, 0.0825, 0.0501, 0.0764, 0.0224],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,898][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0238, 0.0300, 0.0319, 0.0476, 0.0320, 0.0548, 0.0451, 0.0731, 0.0663,
        0.0524, 0.0946, 0.0539, 0.0704, 0.0832, 0.0806, 0.0828, 0.0774],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,900][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0632, 0.0384, 0.0204, 0.0113, 0.0018, 0.0069, 0.0673, 0.0348, 0.0872,
        0.2956, 0.1133, 0.0017, 0.0092, 0.0615, 0.0259, 0.1238, 0.0378],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,901][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([3.1626e-03, 1.6348e-03, 5.4733e-02, 1.9969e-03, 4.6794e-04, 2.7382e-03,
        7.7835e-08, 1.2772e-04, 1.1544e-02, 6.9359e-02, 3.9725e-03, 5.1919e-04,
        4.5573e-05, 6.6808e-03, 1.7258e-05, 9.6557e-02, 7.4644e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,902][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0265, 0.0544, 0.0485, 0.0402, 0.0655, 0.0781, 0.0897, 0.0548, 0.0840,
        0.0280, 0.0666, 0.0581, 0.1281, 0.0410, 0.0590, 0.0593, 0.0182],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,903][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([1.6777e-03, 2.8008e-06, 2.9803e-04, 1.0017e-05, 4.1483e-04, 4.5652e-08,
        8.6479e-01, 6.4914e-02, 2.6688e-07, 4.3212e-02, 8.1193e-06, 4.5982e-04,
        3.5323e-03, 5.7353e-04, 7.4391e-03, 6.8721e-07, 1.2666e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,904][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0158, 0.1623, 0.0888, 0.1228, 0.0561, 0.0681, 0.0736, 0.0846, 0.0694,
        0.0099, 0.0838, 0.0424, 0.0300, 0.0183, 0.0257, 0.0289, 0.0195],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,905][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0210, 0.0565, 0.0693, 0.0461, 0.0688, 0.0592, 0.0628, 0.0536, 0.0488,
        0.0759, 0.0433, 0.0745, 0.0713, 0.0487, 0.0654, 0.0483, 0.0865],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,906][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0313, 0.0297, 0.0016, 0.0109, 0.0034, 0.0054, 0.0088, 0.0029, 0.0046,
        0.0530, 0.0725, 0.0012, 0.0071, 0.0080, 0.0078, 0.0046, 0.7471],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:01,908][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.0508e-04, 1.1131e-04, 1.5911e-04, 7.1453e-05, 3.0774e-06, 5.7847e-02,
        3.5262e-02, 3.3708e-03, 2.2939e-04, 7.3685e-04, 5.1321e-04, 7.7856e-06,
        8.1110e-02, 6.2193e-07, 7.0730e-01, 9.1707e-04, 1.1166e-01, 5.1518e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,910][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0056, 0.0334, 0.0230, 0.0476, 0.0526, 0.0704, 0.0514, 0.0678, 0.0720,
        0.0624, 0.0705, 0.0642, 0.0409, 0.0490, 0.0820, 0.0945, 0.0632, 0.0496],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,911][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0596, 0.0586, 0.0463, 0.0504, 0.0507, 0.0563, 0.0532, 0.0537, 0.0514,
        0.0541, 0.0533, 0.0537, 0.0570, 0.0593, 0.0585, 0.0573, 0.0655, 0.0613],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,913][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0411, 0.0482, 0.0220, 0.0619, 0.0384, 0.0418, 0.0434, 0.0624, 0.0707,
        0.0279, 0.1490, 0.0419, 0.0338, 0.0833, 0.0462, 0.0747, 0.0246, 0.0887],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,915][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0210, 0.0295, 0.0323, 0.0476, 0.0314, 0.0528, 0.0417, 0.0698, 0.0625,
        0.0471, 0.0868, 0.0485, 0.0608, 0.0747, 0.0702, 0.0733, 0.0641, 0.0860],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,917][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0364, 0.0048, 0.0053, 0.0061, 0.0113, 0.0066, 0.0106, 0.0222, 0.0621,
        0.0162, 0.0548, 0.0145, 0.0062, 0.2526, 0.0134, 0.1074, 0.0091, 0.3602],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,918][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.3929e-01, 3.1715e-04, 5.9054e-03, 1.1011e-03, 1.6455e-04, 6.0439e-03,
        3.7442e-02, 3.7173e-04, 3.4139e-03, 1.3117e-03, 3.5682e-04, 2.2191e-04,
        1.5345e-01, 5.9519e-04, 6.3292e-01, 1.1489e-02, 5.0369e-03, 5.6908e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,920][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0286, 0.0492, 0.0589, 0.0448, 0.0641, 0.0592, 0.0484, 0.0480, 0.0879,
        0.0348, 0.0724, 0.0584, 0.0933, 0.0550, 0.0479, 0.0653, 0.0369, 0.0470],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,921][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.1339e-03, 1.2876e-05, 7.6163e-04, 3.3989e-05, 8.0881e-04, 2.1717e-07,
        6.6115e-01, 1.9710e-01, 1.5725e-06, 9.2386e-02, 2.2007e-05, 8.7832e-04,
        5.4782e-03, 3.6426e-03, 8.8795e-03, 3.3615e-06, 1.8693e-02, 4.0114e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,923][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0293, 0.1685, 0.1015, 0.0718, 0.0385, 0.0485, 0.0757, 0.1016, 0.0695,
        0.0103, 0.0620, 0.0336, 0.0340, 0.0207, 0.0340, 0.0362, 0.0253, 0.0389],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,925][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0187, 0.0520, 0.0658, 0.0424, 0.0664, 0.0568, 0.0605, 0.0523, 0.0458,
        0.0734, 0.0405, 0.0719, 0.0681, 0.0472, 0.0632, 0.0465, 0.0838, 0.0447],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,927][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0767, 0.0370, 0.0004, 0.0354, 0.0021, 0.0050, 0.0023, 0.0089, 0.0092,
        0.0019, 0.0942, 0.0009, 0.0066, 0.3152, 0.0017, 0.0194, 0.0008, 0.3824],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:01,930][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:01,932][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4957],
        [10850],
        [   82],
        [ 6790],
        [ 1193],
        [ 5887],
        [18976],
        [ 8010],
        [13875],
        [19466],
        [13984],
        [  888],
        [11763],
        [ 6944],
        [ 2447],
        [19847],
        [21170],
        [10754]], device='cuda:0')
[2024-07-24 10:26:01,934][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 1212],
        [35873],
        [    4],
        [24508],
        [  233],
        [ 6938],
        [30816],
        [20143],
        [19826],
        [35811],
        [19973],
        [  274],
        [17275],
        [10309],
        [ 2060],
        [23806],
        [27068],
        [13128]], device='cuda:0')
[2024-07-24 10:26:01,936][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[7],
        [7],
        [6],
        [6],
        [6],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7],
        [7]], device='cuda:0')
[2024-07-24 10:26:01,938][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[37748],
        [40709],
        [40513],
        [33616],
        [33832],
        [34279],
        [35946],
        [38951],
        [33332],
        [28084],
        [33909],
        [33834],
        [33297],
        [34323],
        [34408],
        [37394],
        [37871],
        [38648]], device='cuda:0')
[2024-07-24 10:26:01,940][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11946],
        [12950],
        [15427],
        [16029],
        [15188],
        [15114],
        [15455],
        [15897],
        [16515],
        [16374],
        [16266],
        [15955],
        [16105],
        [16312],
        [16281],
        [16566],
        [16808],
        [16997]], device='cuda:0')
[2024-07-24 10:26:01,942][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[3221],
        [7350],
        [6743],
        [7797],
        [8356],
        [6960],
        [6414],
        [6156],
        [5800],
        [6383],
        [7440],
        [7642],
        [7339],
        [7899],
        [7887],
        [7635],
        [8020],
        [8502]], device='cuda:0')
[2024-07-24 10:26:01,944][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18154],
        [24258],
        [21099],
        [16058],
        [16946],
        [12834],
        [14442],
        [15840],
        [16170],
        [18037],
        [21185],
        [20208],
        [19359],
        [17986],
        [19167],
        [18895],
        [19442],
        [19179]], device='cuda:0')
[2024-07-24 10:26:01,945][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16752],
        [16158],
        [28279],
        [16002],
        [35928],
        [35261],
        [14698],
        [18475],
        [24532],
        [11159],
        [17486],
        [24675],
        [ 8657],
        [ 9692],
        [ 2799],
        [12901],
        [17478],
        [11437]], device='cuda:0')
[2024-07-24 10:26:01,947][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 6978],
        [ 6971],
        [  529],
        [ 5459],
        [  257],
        [ 5338],
        [37010],
        [ 5617],
        [ 7971],
        [13410],
        [11151],
        [ 2279],
        [26265],
        [12216],
        [ 6613],
        [11120],
        [10099],
        [ 6727]], device='cuda:0')
[2024-07-24 10:26:01,948][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8775],
        [ 9072],
        [ 3437],
        [ 5306],
        [28477],
        [10994],
        [ 1671],
        [ 6214],
        [ 9225],
        [10645],
        [21460],
        [32779],
        [18437],
        [21338],
        [20980],
        [22754],
        [23829],
        [24479]], device='cuda:0')
[2024-07-24 10:26:01,950][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16656],
        [19255],
        [20349],
        [21344],
        [22041],
        [22189],
        [23006],
        [23258],
        [24344],
        [23921],
        [24307],
        [23966],
        [23832],
        [24559],
        [24568],
        [25268],
        [24324],
        [25256]], device='cuda:0')
[2024-07-24 10:26:01,952][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[35684],
        [26705],
        [25970],
        [21902],
        [21908],
        [21936],
        [21636],
        [21678],
        [20671],
        [19693],
        [20849],
        [19570],
        [19703],
        [19693],
        [20011],
        [19421],
        [18864],
        [19444]], device='cuda:0')
[2024-07-24 10:26:01,954][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25991],
        [22992],
        [20577],
        [21073],
        [20048],
        [20090],
        [19990],
        [19825],
        [19465],
        [19083],
        [19325],
        [19238],
        [19073],
        [19144],
        [19224],
        [18791],
        [18786],
        [18856]], device='cuda:0')
[2024-07-24 10:26:01,956][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27342],
        [21297],
        [21335],
        [24710],
        [23303],
        [24023],
        [23696],
        [25810],
        [26609],
        [26385],
        [25985],
        [26095],
        [25647],
        [26627],
        [26102],
        [26513],
        [25884],
        [26221]], device='cuda:0')
[2024-07-24 10:26:01,957][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10653],
        [18190],
        [18553],
        [17821],
        [31649],
        [21379],
        [39098],
        [18728],
        [23498],
        [36857],
        [18743],
        [36366],
        [28038],
        [25408],
        [28216],
        [33377],
        [19482],
        [26250]], device='cuda:0')
[2024-07-24 10:26:01,959][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43122],
        [43109],
        [ 3553],
        [24880],
        [25541],
        [42925],
        [ 8620],
        [ 2909],
        [ 5919],
        [ 3623],
        [ 7731],
        [ 8188],
        [ 8319],
        [12296],
        [21221],
        [ 7074],
        [10258],
        [ 9063]], device='cuda:0')
[2024-07-24 10:26:01,961][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[1392],
        [1520],
        [1721],
        [1373],
        [1640],
        [2308],
        [2460],
        [2481],
        [1940],
        [1916],
        [1722],
        [1705],
        [1828],
        [1948],
        [1984],
        [1796],
        [1760],
        [1826]], device='cuda:0')
[2024-07-24 10:26:01,963][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18648],
        [19579],
        [24655],
        [25863],
        [28954],
        [31016],
        [32441],
        [33275],
        [33657],
        [34414],
        [34417],
        [34917],
        [35092],
        [35010],
        [34927],
        [34821],
        [34783],
        [34825]], device='cuda:0')
[2024-07-24 10:26:01,965][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21139],
        [11319],
        [ 9606],
        [12479],
        [11263],
        [10246],
        [10424],
        [10812],
        [10660],
        [10306],
        [13377],
        [13174],
        [12999],
        [12879],
        [13071],
        [12804],
        [12464],
        [12207]], device='cuda:0')
[2024-07-24 10:26:01,967][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[1221],
        [1372],
        [1884],
        [2079],
        [2155],
        [2391],
        [2407],
        [2345],
        [2324],
        [2279],
        [2269],
        [2280],
        [2341],
        [2336],
        [2320],
        [2328],
        [2301],
        [2297]], device='cuda:0')
[2024-07-24 10:26:01,969][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[35539],
        [31538],
        [21878],
        [16861],
        [19970],
        [17478],
        [15819],
        [27670],
        [16473],
        [14365],
        [20694],
        [13838],
        [23006],
        [25886],
        [21433],
        [19096],
        [12042],
        [30177]], device='cuda:0')
[2024-07-24 10:26:01,970][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29889],
        [30123],
        [20602],
        [29670],
        [20279],
        [24590],
        [21151],
        [23340],
        [27696],
        [32700],
        [15922],
        [13898],
        [21652],
        [30837],
        [31465],
        [24366],
        [ 4004],
        [34357]], device='cuda:0')
[2024-07-24 10:26:01,972][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22753],
        [20568],
        [37364],
        [33840],
        [39094],
        [43949],
        [45478],
        [44363],
        [44538],
        [44574],
        [42988],
        [43426],
        [44416],
        [42672],
        [43503],
        [42262],
        [42809],
        [41275]], device='cuda:0')
[2024-07-24 10:26:01,974][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[16908],
        [16903],
        [17653],
        [17302],
        [17027],
        [16748],
        [37717],
        [33727],
        [33435],
        [34964],
        [36458],
        [34574],
        [34799],
        [31051],
        [31680],
        [30575],
        [35771],
        [31090]], device='cuda:0')
[2024-07-24 10:26:01,976][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14658],
        [40547],
        [42598],
        [43443],
        [44771],
        [44386],
        [45494],
        [45591],
        [45944],
        [46264],
        [46241],
        [46563],
        [46474],
        [46368],
        [46466],
        [46439],
        [46677],
        [46500]], device='cuda:0')
[2024-07-24 10:26:01,978][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[7236],
        [7763],
        [7636],
        [7909],
        [7689],
        [7820],
        [7980],
        [8182],
        [8190],
        [8082],
        [7995],
        [7885],
        [7890],
        [7930],
        [7926],
        [7996],
        [8005],
        [8039]], device='cuda:0')
[2024-07-24 10:26:01,980][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16053],
        [16366],
        [22537],
        [10614],
        [25382],
        [18229],
        [22925],
        [17645],
        [ 6183],
        [27254],
        [ 9112],
        [25146],
        [15065],
        [ 9486],
        [14743],
        [ 5301],
        [29067],
        [ 9889]], device='cuda:0')
[2024-07-24 10:26:01,982][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25283],
        [26162],
        [37481],
        [32624],
        [31923],
        [20970],
        [32310],
        [32582],
        [33116],
        [30823],
        [33941],
        [33218],
        [27042],
        [24827],
        [22703],
        [33403],
        [38837],
        [26687]], device='cuda:0')
[2024-07-24 10:26:01,984][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23704],
        [17687],
        [36335],
        [23776],
        [13235],
        [16240],
        [ 3888],
        [17043],
        [13612],
        [ 5076],
        [12712],
        [ 3704],
        [13322],
        [15102],
        [ 3761],
        [ 7868],
        [14524],
        [13776]], device='cuda:0')
[2024-07-24 10:26:01,986][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604],
        [29604]], device='cuda:0')
[2024-07-24 10:26:02,016][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:02,017][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,019][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,020][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,021][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,022][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,023][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,024][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,024][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,025][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,026][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,026][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,027][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,028][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4262, 0.5738], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,028][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6901, 0.3099], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,029][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,030][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4066, 0.5934], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,030][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1779, 0.8221], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,032][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,034][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2500, 0.7500], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,035][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5696, 0.4304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,037][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3367, 0.6633], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,039][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,040][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1913, 0.8087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,041][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([4.4902e-08, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,043][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.2274, 0.4274, 0.3452], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,044][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.0348, 0.6713, 0.2939], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,045][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([2.9889e-06, 1.1303e-01, 8.8697e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,047][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.1756, 0.3527, 0.4717], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,049][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.0366, 0.3237, 0.6398], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,050][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.0010, 0.4404, 0.5586], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,052][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.0909, 0.3497, 0.5594], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,053][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.3369, 0.3153, 0.3478], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,054][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.1706, 0.3544, 0.4750], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,054][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([1.6206e-04, 3.5418e-01, 6.4566e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,055][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.0786, 0.3775, 0.5439], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,056][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([4.3854e-05, 9.3067e-01, 6.9291e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,057][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1746, 0.2916, 0.2863, 0.2476], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,059][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2493, 0.1877, 0.5182, 0.0448], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,060][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([8.2221e-07, 5.8919e-03, 5.6737e-01, 4.2674e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,061][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1204, 0.2096, 0.4478, 0.2222], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,063][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0381, 0.2260, 0.4387, 0.2972], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,064][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.1721e-04, 5.9777e-02, 3.6649e-01, 5.7341e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,066][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0887, 0.2565, 0.3709, 0.2840], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,067][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1835, 0.1213, 0.2339, 0.4613], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,069][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1289, 0.2853, 0.4210, 0.1648], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,070][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.1262e-05, 3.1338e-02, 4.2426e-01, 5.4438e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,072][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0648, 0.2637, 0.3563, 0.3152], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,073][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.0551e-08, 6.8494e-01, 3.2468e-03, 3.1182e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,074][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.1103, 0.2001, 0.2433, 0.2696, 0.1767], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,076][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0484, 0.2846, 0.4782, 0.0340, 0.1548], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,077][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([4.3789e-08, 8.4774e-04, 4.2950e-02, 3.6773e-01, 5.8847e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,079][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0840, 0.1774, 0.3543, 0.2155, 0.1688], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,080][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0127, 0.1308, 0.2726, 0.2400, 0.3440], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,081][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([4.8797e-05, 1.8413e-02, 7.9740e-02, 6.9968e-01, 2.0212e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,083][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0426, 0.1664, 0.2523, 0.1787, 0.3600], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,085][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.1145, 0.1009, 0.1342, 0.3711, 0.2792], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,086][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0565, 0.1296, 0.1771, 0.0771, 0.5598], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,087][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([4.4916e-06, 1.3458e-02, 1.1959e-01, 4.2082e-01, 4.4613e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,089][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0372, 0.1850, 0.2690, 0.2267, 0.2822], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,090][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([2.0255e-07, 9.4842e-02, 8.0829e-03, 1.3374e-01, 7.6333e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,092][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0994, 0.1659, 0.1551, 0.1834, 0.3152, 0.0810], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,094][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.4161, 0.0504, 0.1654, 0.0733, 0.1706, 0.1242], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,095][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ were] are: tensor([2.3080e-08, 1.1207e-04, 5.9834e-03, 4.9920e-02, 4.7380e-01, 4.7019e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,096][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0833, 0.1471, 0.2683, 0.1814, 0.1533, 0.1665], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,096][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0166, 0.1112, 0.2370, 0.1532, 0.2757, 0.2063], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,097][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ were] are: tensor([2.9000e-05, 4.7905e-03, 2.6095e-02, 1.3231e-01, 2.9957e-01, 5.3720e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,098][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0395, 0.1323, 0.1838, 0.1517, 0.2617, 0.2310], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,099][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0918, 0.0842, 0.1253, 0.3137, 0.2168, 0.1682], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,101][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0618, 0.1142, 0.1561, 0.0711, 0.4156, 0.1813], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,102][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ were] are: tensor([2.2370e-06, 3.0925e-03, 2.4548e-02, 1.0322e-01, 4.2794e-01, 4.4120e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,104][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0325, 0.1450, 0.1983, 0.1762, 0.2112, 0.2367], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,105][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ were] are: tensor([5.9091e-07, 4.1241e-01, 9.0350e-03, 1.1096e-01, 4.0722e-01, 6.0378e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,106][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0914, 0.1373, 0.1498, 0.1493, 0.2611, 0.1056, 0.1054],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,108][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0555, 0.1393, 0.3366, 0.0235, 0.3133, 0.0390, 0.0928],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,109][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ working] are: tensor([1.6115e-08, 2.6722e-05, 8.6224e-04, 1.2620e-02, 6.2164e-02, 6.7592e-01,
        2.4840e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,111][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0580, 0.1078, 0.2400, 0.1355, 0.1299, 0.1406, 0.1883],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,112][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0068, 0.0518, 0.0833, 0.0804, 0.0992, 0.1124, 0.5661],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,114][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ working] are: tensor([1.1366e-05, 1.3248e-03, 1.1819e-02, 5.4278e-02, 8.8747e-02, 5.2000e-01,
        3.2382e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,115][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0273, 0.0984, 0.1449, 0.1087, 0.2019, 0.1724, 0.2464],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,117][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0811, 0.0575, 0.0977, 0.2957, 0.1816, 0.1451, 0.1412],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,119][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0477, 0.0851, 0.1149, 0.0435, 0.2892, 0.1275, 0.2921],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,120][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ working] are: tensor([1.7943e-06, 1.5601e-03, 1.4824e-02, 6.3870e-02, 1.5355e-01, 5.4059e-01,
        2.2561e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,121][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0266, 0.1168, 0.1617, 0.1425, 0.1711, 0.1950, 0.1863],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,123][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ working] are: tensor([3.3518e-08, 3.6542e-02, 1.4485e-03, 1.0506e-02, 6.1391e-02, 8.5916e-03,
        8.8152e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,124][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0660, 0.1194, 0.1137, 0.1198, 0.2020, 0.0862, 0.1461, 0.1469],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,126][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1998, 0.1103, 0.2615, 0.1656, 0.0541, 0.0735, 0.0951, 0.0401],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,127][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([6.4156e-09, 1.3428e-06, 1.0305e-04, 8.6990e-04, 7.0219e-03, 4.9342e-02,
        4.5933e-01, 4.8333e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,129][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0504, 0.0847, 0.1897, 0.1067, 0.0985, 0.1461, 0.2165, 0.1073],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,130][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0124, 0.0500, 0.0960, 0.0603, 0.1093, 0.0816, 0.4389, 0.1515],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,132][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.0335e-05, 5.7972e-04, 2.7549e-03, 1.6596e-02, 2.4957e-02, 2.3814e-01,
        1.9748e-01, 5.1949e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,133][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0263, 0.0833, 0.1165, 0.0957, 0.1650, 0.1496, 0.2057, 0.1579],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,135][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0744, 0.0438, 0.0796, 0.1749, 0.1733, 0.1190, 0.1270, 0.2080],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,137][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0286, 0.0613, 0.0976, 0.0412, 0.2540, 0.1169, 0.2928, 0.1075],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,137][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([5.9011e-07, 2.5404e-04, 3.4392e-03, 9.9967e-03, 5.3996e-02, 1.5825e-01,
        2.8960e-01, 4.8446e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,138][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0238, 0.0998, 0.1346, 0.1214, 0.1448, 0.1634, 0.1596, 0.1526],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,139][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([8.2240e-09, 1.8015e-02, 8.3933e-04, 3.1328e-03, 5.2509e-02, 2.6503e-03,
        7.7154e-01, 1.5131e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,140][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0604, 0.0974, 0.0872, 0.1187, 0.1481, 0.0774, 0.1240, 0.2126, 0.0740],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,142][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.3377, 0.0277, 0.2085, 0.0695, 0.0903, 0.0919, 0.1057, 0.0263, 0.0424],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,143][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.8778e-10, 4.6764e-08, 3.7212e-06, 5.0348e-05, 2.3654e-04, 2.3923e-03,
        1.2037e-02, 9.1140e-01, 7.3876e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,144][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0436, 0.0766, 0.1281, 0.0985, 0.0809, 0.1051, 0.1730, 0.1420, 0.1522],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,146][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0081, 0.0405, 0.0731, 0.0514, 0.0853, 0.0672, 0.3857, 0.1357, 0.1531],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,147][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([3.5597e-06, 1.4207e-04, 8.4934e-04, 5.1802e-03, 1.1231e-02, 6.8678e-02,
        6.9080e-02, 4.2048e-01, 4.2435e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,149][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0213, 0.0707, 0.1025, 0.0836, 0.1476, 0.1308, 0.1866, 0.1379, 0.1190],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,151][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0499, 0.0348, 0.0524, 0.1583, 0.1241, 0.0935, 0.1007, 0.1817, 0.2046],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,152][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0246, 0.0509, 0.0801, 0.0411, 0.2177, 0.1039, 0.2666, 0.1011, 0.1141],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,153][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.9920e-07, 1.1903e-04, 1.1235e-03, 2.7772e-03, 1.5528e-02, 3.8727e-02,
        7.5475e-02, 3.8962e-01, 4.7663e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,155][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0202, 0.0859, 0.1162, 0.1037, 0.1239, 0.1381, 0.1360, 0.1299, 0.1461],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,156][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.7105e-09, 4.4345e-03, 2.8172e-04, 5.7396e-04, 2.0574e-02, 9.3376e-04,
        4.9954e-01, 5.2144e-02, 4.2152e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,158][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0455, 0.0821, 0.1135, 0.0997, 0.1317, 0.0640, 0.1039, 0.1729, 0.0701,
        0.1165], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,159][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0748, 0.0265, 0.2537, 0.0097, 0.0488, 0.0207, 0.0911, 0.0214, 0.0185,
        0.4348], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,161][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([4.7759e-10, 2.1956e-07, 4.4277e-06, 5.6367e-05, 4.6705e-04, 2.4402e-03,
        5.8091e-03, 2.7073e-01, 4.3026e-01, 2.9024e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,162][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0266, 0.0550, 0.1270, 0.0667, 0.0602, 0.0951, 0.1338, 0.1042, 0.1649,
        0.1666], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,164][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0034, 0.0268, 0.0484, 0.0426, 0.0558, 0.0605, 0.2944, 0.1159, 0.1312,
        0.2210], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,165][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([1.2036e-06, 5.2580e-05, 4.6651e-04, 2.0548e-03, 5.4055e-03, 2.2686e-02,
        3.7378e-02, 1.6929e-01, 5.1743e-01, 2.4524e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,167][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0127, 0.0529, 0.0818, 0.0601, 0.1149, 0.0950, 0.1425, 0.1077, 0.0899,
        0.2424], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,169][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0468, 0.0345, 0.0571, 0.1564, 0.1161, 0.0879, 0.0941, 0.1650, 0.1558,
        0.0863], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,170][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0251, 0.0384, 0.0540, 0.0234, 0.1443, 0.0577, 0.1684, 0.0567, 0.0572,
        0.3747], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,172][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([2.3618e-07, 8.4972e-05, 5.4996e-04, 1.8278e-03, 6.7338e-03, 2.3774e-02,
        2.2232e-02, 2.2275e-01, 5.1720e-01, 2.0485e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,173][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0146, 0.0706, 0.0998, 0.0863, 0.1060, 0.1206, 0.1166, 0.1146, 0.1260,
        0.1449], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,174][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([1.3106e-06, 3.8908e-02, 5.0894e-03, 5.7715e-03, 5.4090e-02, 7.7030e-03,
        4.3917e-01, 7.5544e-02, 3.0760e-01, 6.6127e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,176][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0495, 0.0746, 0.0908, 0.0840, 0.1165, 0.0641, 0.0900, 0.1525, 0.0791,
        0.0968, 0.1022], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,178][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1736, 0.0307, 0.1877, 0.1005, 0.0115, 0.0578, 0.0237, 0.0647, 0.2846,
        0.0144, 0.0508], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,179][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([9.0096e-11, 2.5542e-09, 8.6003e-07, 3.3416e-06, 5.6762e-05, 1.5370e-04,
        7.2653e-04, 8.6283e-03, 3.3482e-02, 9.1511e-02, 8.6544e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,180][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0338, 0.0615, 0.1125, 0.0735, 0.0677, 0.1008, 0.1176, 0.1010, 0.1224,
        0.1670, 0.0422], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,181][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0135, 0.0414, 0.0486, 0.0413, 0.0506, 0.0449, 0.2031, 0.0961, 0.1137,
        0.1667, 0.1802], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,182][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([3.2700e-07, 1.3657e-05, 5.5552e-05, 3.3911e-04, 6.2115e-04, 5.0474e-03,
        3.5171e-03, 5.2211e-02, 8.6816e-02, 1.3882e-01, 7.1256e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,183][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0162, 0.0497, 0.0749, 0.0611, 0.1039, 0.0946, 0.1313, 0.0984, 0.0875,
        0.2019, 0.0805], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,184][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0336, 0.0249, 0.0480, 0.1108, 0.0960, 0.0579, 0.0847, 0.1228, 0.1371,
        0.0841, 0.2001], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,186][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0132, 0.0258, 0.0442, 0.0225, 0.1169, 0.0589, 0.1383, 0.0509, 0.0570,
        0.4072, 0.0651], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,187][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([3.2858e-08, 6.2456e-06, 1.1072e-04, 5.1274e-04, 1.3884e-03, 4.5920e-03,
        7.5359e-03, 4.6437e-02, 1.2512e-01, 1.6404e-01, 6.5026e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,189][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0168, 0.0674, 0.0901, 0.0802, 0.0957, 0.1043, 0.1038, 0.0984, 0.1097,
        0.1262, 0.1074], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,190][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([2.3641e-09, 9.4297e-03, 5.0027e-04, 3.0477e-04, 2.5107e-02, 5.6463e-04,
        4.9573e-01, 9.6544e-03, 1.1013e-01, 2.1906e-02, 3.2667e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,192][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0358, 0.0685, 0.0844, 0.0904, 0.0604, 0.0535, 0.0945, 0.1649, 0.0753,
        0.1145, 0.1050, 0.0528], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,193][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0613, 0.1763, 0.2497, 0.0252, 0.0720, 0.0281, 0.0285, 0.0168, 0.0056,
        0.2136, 0.0750, 0.0480], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,194][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([4.0214e-12, 4.2608e-10, 2.7634e-08, 1.8197e-07, 3.1310e-07, 9.5283e-06,
        2.4517e-05, 3.0950e-04, 1.5799e-03, 6.0552e-03, 1.0003e-01, 8.9199e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,196][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0199, 0.0477, 0.0953, 0.0572, 0.0447, 0.0815, 0.1221, 0.1034, 0.1370,
        0.2016, 0.0313, 0.0583], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,198][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0033, 0.0217, 0.0353, 0.0384, 0.0413, 0.0487, 0.1643, 0.0900, 0.1036,
        0.1657, 0.1981, 0.0896], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,199][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([7.2957e-08, 2.8726e-06, 1.2199e-05, 1.0803e-04, 2.9333e-05, 1.5294e-03,
        1.5382e-03, 1.0089e-02, 3.3153e-02, 3.0824e-02, 5.8947e-01, 3.3325e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,201][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0109, 0.0443, 0.0692, 0.0487, 0.0988, 0.0792, 0.1164, 0.0886, 0.0727,
        0.2012, 0.0718, 0.0981], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,203][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0321, 0.0275, 0.0360, 0.1054, 0.0752, 0.0676, 0.0610, 0.1140, 0.1185,
        0.0590, 0.2000, 0.1038], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,204][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0088, 0.0172, 0.0240, 0.0125, 0.0731, 0.0322, 0.0909, 0.0322, 0.0321,
        0.2454, 0.0472, 0.3845], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,206][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([6.5262e-09, 1.3708e-06, 1.2650e-05, 4.3367e-05, 5.5138e-05, 7.1841e-04,
        5.3238e-04, 6.0671e-03, 1.5754e-02, 2.1054e-02, 3.0116e-01, 6.5460e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,207][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0106, 0.0556, 0.0822, 0.0686, 0.0863, 0.0996, 0.0950, 0.0946, 0.1046,
        0.1209, 0.0974, 0.0846], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,209][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([7.2387e-07, 3.6271e-03, 2.7432e-03, 8.7011e-04, 3.2808e-02, 2.6860e-03,
        3.2382e-01, 4.0422e-02, 1.7895e-01, 7.5403e-02, 3.2378e-01, 1.4891e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,210][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0305, 0.0706, 0.0568, 0.0730, 0.1027, 0.0518, 0.0868, 0.1403, 0.0569,
        0.0922, 0.1129, 0.0920, 0.0335], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,212][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.2542, 0.0430, 0.0254, 0.0458, 0.0697, 0.1093, 0.0156, 0.0145, 0.0016,
        0.0086, 0.0248, 0.0370, 0.3505], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,213][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([2.2461e-12, 9.9195e-11, 5.0773e-09, 7.6739e-08, 1.3807e-07, 4.6741e-06,
        3.3826e-06, 2.7652e-04, 4.1410e-04, 1.0784e-03, 8.5231e-02, 5.2979e-01,
        3.8320e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,215][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0238, 0.0414, 0.1015, 0.0532, 0.0508, 0.0556, 0.0856, 0.0838, 0.1241,
        0.1622, 0.0276, 0.0624, 0.1279], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,217][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0012, 0.0118, 0.0232, 0.0184, 0.0297, 0.0277, 0.1816, 0.0602, 0.0764,
        0.1791, 0.2036, 0.1083, 0.0787], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,218][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.8246e-08, 5.9509e-07, 4.4164e-06, 1.9020e-05, 2.9030e-05, 1.5569e-04,
        2.0947e-04, 1.4964e-03, 4.5931e-03, 5.5636e-03, 1.3795e-01, 5.8344e-01,
        2.6654e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,220][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0111, 0.0407, 0.0629, 0.0480, 0.0877, 0.0753, 0.1052, 0.0828, 0.0694,
        0.1704, 0.0671, 0.0890, 0.0904], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,221][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0238, 0.0296, 0.0327, 0.1118, 0.0693, 0.0461, 0.0642, 0.1077, 0.1092,
        0.0537, 0.2255, 0.0963, 0.0301], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,222][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0146, 0.0204, 0.0285, 0.0140, 0.0690, 0.0314, 0.0749, 0.0292, 0.0274,
        0.1822, 0.0442, 0.2998, 0.1645], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,223][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([2.6888e-09, 3.5660e-07, 4.7440e-06, 1.0515e-05, 5.4828e-05, 6.6142e-05,
        1.4839e-04, 1.1048e-03, 2.9624e-03, 4.2326e-03, 1.0083e-01, 7.8579e-01,
        1.0479e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,224][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0117, 0.0535, 0.0739, 0.0655, 0.0783, 0.0896, 0.0867, 0.0852, 0.0939,
        0.1050, 0.0891, 0.0752, 0.0924], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,225][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([2.0803e-08, 6.7110e-03, 6.1749e-04, 1.5939e-04, 6.3894e-03, 3.7792e-04,
        1.0566e-01, 4.3788e-03, 3.8008e-02, 1.2768e-02, 2.3427e-01, 8.2024e-04,
        5.8985e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,227][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0393, 0.0593, 0.0596, 0.0721, 0.0730, 0.0572, 0.0812, 0.1318, 0.0485,
        0.0925, 0.0888, 0.0683, 0.0568, 0.0715], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,228][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2333, 0.0193, 0.1167, 0.0557, 0.0206, 0.0374, 0.0258, 0.0079, 0.0889,
        0.0220, 0.0385, 0.0168, 0.2944, 0.0226], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,230][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.0417e-12, 4.7655e-12, 3.2167e-10, 2.0987e-09, 9.5471e-09, 1.1175e-07,
        3.5069e-07, 6.6466e-06, 2.1966e-05, 3.7929e-05, 6.6938e-04, 3.5159e-02,
        7.9413e-02, 8.8469e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,231][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0228, 0.0407, 0.0784, 0.0529, 0.0429, 0.0577, 0.0952, 0.0657, 0.1043,
        0.1445, 0.0351, 0.0570, 0.1467, 0.0561], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,233][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0034, 0.0173, 0.0290, 0.0205, 0.0344, 0.0266, 0.1677, 0.0573, 0.0679,
        0.1403, 0.1591, 0.1317, 0.0676, 0.0772], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,234][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.4582e-08, 1.0762e-07, 4.0361e-07, 3.1452e-06, 6.4906e-06, 3.1107e-05,
        3.3511e-05, 1.8596e-04, 6.8628e-04, 1.2068e-03, 1.9151e-02, 1.0871e-01,
        1.0791e-01, 7.6207e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,236][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0116, 0.0397, 0.0560, 0.0468, 0.0814, 0.0729, 0.1013, 0.0756, 0.0660,
        0.1478, 0.0632, 0.0832, 0.0846, 0.0700], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,238][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0227, 0.0167, 0.0280, 0.0735, 0.0617, 0.0430, 0.0554, 0.0954, 0.0995,
        0.0527, 0.1563, 0.0904, 0.0339, 0.1707], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,239][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0066, 0.0117, 0.0204, 0.0122, 0.0485, 0.0291, 0.0674, 0.0260, 0.0337,
        0.1804, 0.0435, 0.2802, 0.1674, 0.0729], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,241][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.3511e-09, 9.0045e-08, 1.1869e-06, 2.0518e-06, 1.3088e-05, 1.8510e-05,
        6.0104e-05, 1.0410e-04, 6.4570e-04, 1.5821e-03, 1.2585e-02, 1.5515e-01,
        6.7183e-02, 7.6266e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,242][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0126, 0.0508, 0.0690, 0.0605, 0.0743, 0.0812, 0.0808, 0.0758, 0.0849,
        0.0981, 0.0824, 0.0733, 0.0856, 0.0709], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,243][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.9129e-09, 5.3876e-03, 3.5048e-04, 6.5369e-05, 9.9749e-03, 1.9824e-04,
        1.6059e-01, 1.9701e-03, 1.9272e-02, 9.3514e-03, 7.8864e-02, 2.8422e-04,
        7.1247e-01, 1.2262e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,245][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0324, 0.0501, 0.0547, 0.0538, 0.0796, 0.0428, 0.0895, 0.0980, 0.0494,
        0.1054, 0.0778, 0.0720, 0.0753, 0.0886, 0.0305], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,246][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([3.9609e-02, 1.4019e-02, 3.0545e-02, 7.8848e-03, 3.6607e-02, 2.2978e-02,
        6.2330e-02, 2.5154e-03, 3.2726e-03, 4.9294e-02, 9.1961e-03, 2.9441e-02,
        6.0997e-01, 2.3277e-04, 8.2101e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,248][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([2.9340e-14, 8.1365e-14, 6.1602e-12, 5.7719e-11, 3.6825e-10, 1.8487e-09,
        5.8801e-09, 1.5123e-07, 3.8795e-07, 1.4599e-06, 7.2299e-05, 1.5984e-03,
        2.3595e-03, 8.1736e-01, 1.7860e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,249][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0225, 0.0384, 0.0746, 0.0477, 0.0371, 0.0580, 0.0906, 0.0658, 0.1091,
        0.1165, 0.0284, 0.0479, 0.1375, 0.0580, 0.0681], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,251][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0033, 0.0157, 0.0253, 0.0199, 0.0294, 0.0275, 0.1513, 0.0547, 0.0640,
        0.1189, 0.1357, 0.0915, 0.0675, 0.0778, 0.1173], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,252][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([3.3044e-09, 2.9694e-08, 1.3808e-07, 8.1444e-07, 3.2564e-06, 7.9013e-06,
        1.2330e-05, 4.1672e-05, 2.3138e-04, 4.7131e-04, 8.5688e-03, 5.4450e-02,
        4.5374e-02, 6.1973e-01, 2.7111e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,254][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0094, 0.0340, 0.0503, 0.0403, 0.0710, 0.0648, 0.0881, 0.0696, 0.0584,
        0.1400, 0.0560, 0.0723, 0.0765, 0.0617, 0.1077], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,256][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0227, 0.0220, 0.0271, 0.0851, 0.0522, 0.0416, 0.0481, 0.0903, 0.0903,
        0.0370, 0.1532, 0.0707, 0.0348, 0.1709, 0.0541], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,258][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0066, 0.0116, 0.0175, 0.0101, 0.0455, 0.0221, 0.0580, 0.0204, 0.0212,
        0.1315, 0.0318, 0.2331, 0.1330, 0.0836, 0.1740], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,259][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([4.3750e-10, 3.2964e-08, 2.8562e-07, 8.2389e-07, 4.0326e-06, 7.2095e-06,
        1.2540e-05, 1.3286e-04, 2.7911e-04, 4.0324e-04, 7.2782e-03, 5.0265e-02,
        1.6321e-02, 6.0784e-01, 3.1745e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,261][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0106, 0.0465, 0.0631, 0.0565, 0.0668, 0.0757, 0.0740, 0.0724, 0.0795,
        0.0888, 0.0760, 0.0642, 0.0783, 0.0646, 0.0830], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,262][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([3.9143e-08, 1.3244e-02, 8.5593e-04, 3.2932e-04, 1.2364e-02, 5.2475e-04,
        1.0078e-01, 5.4460e-03, 3.4935e-02, 1.0449e-02, 1.5639e-01, 9.5942e-04,
        5.7055e-01, 5.6891e-03, 8.7486e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,264][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0301, 0.0505, 0.0435, 0.0697, 0.0677, 0.0340, 0.0675, 0.1104, 0.0490,
        0.0895, 0.0926, 0.0617, 0.0644, 0.0845, 0.0473, 0.0377],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,265][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1202, 0.0157, 0.0452, 0.0197, 0.0249, 0.0412, 0.0394, 0.0107, 0.0104,
        0.0333, 0.0342, 0.0273, 0.5041, 0.0032, 0.0644, 0.0060],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,266][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.6829e-14, 4.1739e-14, 1.9018e-12, 2.4922e-11, 6.5499e-11, 7.0405e-10,
        6.4308e-09, 2.2637e-07, 1.1421e-07, 5.4092e-07, 8.9208e-06, 1.5479e-04,
        3.9981e-04, 1.2947e-01, 6.8383e-01, 1.8614e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,267][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0179, 0.0334, 0.0596, 0.0435, 0.0384, 0.0441, 0.0716, 0.0586, 0.0829,
        0.1167, 0.0267, 0.0509, 0.1238, 0.0603, 0.0988, 0.0729],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,268][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0043, 0.0182, 0.0234, 0.0195, 0.0267, 0.0230, 0.1299, 0.0530, 0.0576,
        0.0931, 0.1208, 0.0904, 0.0577, 0.0680, 0.1050, 0.1093],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,270][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.4586e-09, 1.7918e-08, 1.0089e-07, 4.2535e-07, 1.1408e-06, 3.4740e-06,
        3.0754e-06, 1.6411e-05, 7.6290e-05, 1.6486e-04, 2.8955e-03, 1.4012e-02,
        1.1057e-02, 3.1440e-01, 2.7766e-01, 3.7971e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,271][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0093, 0.0310, 0.0471, 0.0382, 0.0689, 0.0626, 0.0862, 0.0631, 0.0541,
        0.1287, 0.0514, 0.0711, 0.0721, 0.0592, 0.0959, 0.0610],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,273][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0207, 0.0180, 0.0258, 0.0692, 0.0593, 0.0397, 0.0476, 0.0776, 0.0893,
        0.0565, 0.1410, 0.0828, 0.0254, 0.1312, 0.0451, 0.0707],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,274][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0036, 0.0072, 0.0123, 0.0087, 0.0332, 0.0189, 0.0472, 0.0171, 0.0210,
        0.1279, 0.0329, 0.2138, 0.1310, 0.0730, 0.1709, 0.0813],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,276][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.6297e-10, 1.1586e-08, 1.0188e-07, 2.1788e-07, 1.4960e-06, 1.6252e-06,
        4.7342e-06, 1.9374e-05, 2.5548e-05, 2.0699e-04, 1.5913e-03, 1.5681e-02,
        7.7597e-03, 2.0964e-01, 3.9582e-01, 3.6925e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,278][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0107, 0.0441, 0.0595, 0.0530, 0.0629, 0.0692, 0.0687, 0.0657, 0.0732,
        0.0833, 0.0709, 0.0614, 0.0730, 0.0608, 0.0769, 0.0666],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,279][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.4031e-09, 6.8192e-03, 4.5307e-04, 9.8552e-05, 7.3564e-03, 2.0834e-04,
        1.0425e-01, 2.4233e-03, 2.0793e-02, 8.1681e-03, 1.1694e-01, 4.1792e-04,
        5.6225e-01, 3.1419e-03, 7.5146e-02, 9.1533e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,281][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0248, 0.0458, 0.0652, 0.0553, 0.0769, 0.0361, 0.0631, 0.0920, 0.0450,
        0.0715, 0.0768, 0.0676, 0.0656, 0.0778, 0.0558, 0.0339, 0.0468],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,283][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.1661, 0.0153, 0.1205, 0.0139, 0.0179, 0.0064, 0.0130, 0.0020, 0.0019,
        0.2801, 0.0030, 0.0170, 0.0467, 0.0021, 0.0532, 0.0047, 0.2363],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,284][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([5.9137e-15, 2.5180e-14, 1.2091e-12, 8.6769e-12, 4.3529e-11, 3.2685e-10,
        2.8870e-10, 1.0071e-08, 2.8801e-08, 8.2764e-08, 6.7494e-06, 9.1107e-05,
        7.8138e-05, 4.0568e-02, 5.8474e-02, 3.3280e-01, 5.6799e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,286][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0125, 0.0265, 0.0517, 0.0341, 0.0262, 0.0437, 0.0615, 0.0475, 0.0797,
        0.0936, 0.0177, 0.0343, 0.1271, 0.0478, 0.0857, 0.1200, 0.0904],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,287][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0017, 0.0115, 0.0162, 0.0166, 0.0187, 0.0198, 0.1063, 0.0405, 0.0486,
        0.0913, 0.0989, 0.0404, 0.0526, 0.0656, 0.0919, 0.0985, 0.1808],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,289][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([7.7759e-10, 4.0075e-09, 3.2014e-08, 1.3819e-07, 4.7328e-07, 1.1647e-06,
        1.6856e-06, 6.7258e-06, 2.3627e-05, 3.0032e-05, 7.8049e-04, 5.2860e-03,
        4.6609e-03, 8.9040e-02, 1.0261e-01, 5.2260e-01, 2.7496e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,290][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0067, 0.0269, 0.0427, 0.0311, 0.0604, 0.0522, 0.0730, 0.0570, 0.0480,
        0.1265, 0.0462, 0.0601, 0.0619, 0.0496, 0.0935, 0.0602, 0.1038],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,292][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0200, 0.0173, 0.0245, 0.0778, 0.0523, 0.0373, 0.0404, 0.0740, 0.0757,
        0.0355, 0.1584, 0.0730, 0.0264, 0.1457, 0.0441, 0.0696, 0.0279],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,294][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0074, 0.0112, 0.0157, 0.0088, 0.0379, 0.0169, 0.0477, 0.0162, 0.0170,
        0.0935, 0.0279, 0.1783, 0.1015, 0.0781, 0.1458, 0.0727, 0.1236],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,295][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([1.2057e-10, 5.1918e-09, 4.6672e-08, 7.5292e-08, 5.9660e-07, 8.6676e-07,
        1.8113e-06, 1.7076e-05, 2.5642e-05, 5.5000e-05, 6.7396e-04, 5.0856e-03,
        2.3648e-03, 8.1672e-02, 1.6198e-01, 3.8967e-01, 3.5845e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,297][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0083, 0.0396, 0.0561, 0.0482, 0.0591, 0.0671, 0.0640, 0.0635, 0.0700,
        0.0793, 0.0656, 0.0564, 0.0686, 0.0548, 0.0725, 0.0607, 0.0661],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,298][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([5.9410e-07, 1.3545e-02, 3.2411e-03, 3.5159e-04, 1.4114e-02, 8.0220e-04,
        8.8859e-02, 4.3461e-03, 2.2358e-02, 1.8261e-02, 1.0042e-01, 1.9043e-03,
        3.9697e-01, 7.4493e-03, 1.0429e-01, 1.2684e-01, 9.6246e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,300][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0306, 0.0474, 0.0464, 0.0568, 0.0556, 0.0460, 0.0627, 0.1060, 0.0377,
        0.0723, 0.0702, 0.0518, 0.0440, 0.0566, 0.0464, 0.0395, 0.0782, 0.0518],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,302][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2233, 0.0157, 0.0853, 0.0375, 0.0138, 0.0409, 0.0194, 0.0052, 0.0719,
        0.0134, 0.0259, 0.0107, 0.2824, 0.0146, 0.0544, 0.0332, 0.0406, 0.0117],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,303][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([6.9516e-15, 1.2336e-15, 8.0052e-14, 4.0213e-13, 1.7990e-12, 1.6590e-11,
        5.7589e-11, 7.5277e-10, 2.7427e-09, 6.5835e-09, 9.2307e-08, 3.5111e-06,
        6.5755e-06, 6.2640e-05, 1.0368e-02, 3.2669e-02, 2.5640e-01, 7.0049e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,305][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0148, 0.0272, 0.0529, 0.0348, 0.0285, 0.0395, 0.0642, 0.0449, 0.0677,
        0.0979, 0.0236, 0.0385, 0.0978, 0.0379, 0.0904, 0.0955, 0.1154, 0.0284],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,307][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0023, 0.0113, 0.0150, 0.0129, 0.0187, 0.0156, 0.1025, 0.0351, 0.0405,
        0.0754, 0.0893, 0.0627, 0.0425, 0.0489, 0.0782, 0.0843, 0.1858, 0.0789],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,308][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.3253e-10, 8.8034e-10, 2.8432e-09, 2.1918e-08, 4.3390e-08, 1.9280e-07,
        2.0430e-07, 1.0302e-06, 3.0328e-06, 8.6529e-06, 1.2756e-04, 4.4343e-04,
        4.7971e-04, 3.0922e-03, 1.6836e-02, 6.6933e-02, 1.5791e-01, 7.5416e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,310][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0085, 0.0285, 0.0397, 0.0340, 0.0597, 0.0544, 0.0747, 0.0551, 0.0477,
        0.1085, 0.0451, 0.0616, 0.0622, 0.0512, 0.0812, 0.0532, 0.0878, 0.0467],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,311][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0164, 0.0121, 0.0204, 0.0539, 0.0455, 0.0308, 0.0400, 0.0698, 0.0719,
        0.0383, 0.1140, 0.0665, 0.0242, 0.1244, 0.0391, 0.0576, 0.0310, 0.1442],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,312][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0032, 0.0058, 0.0108, 0.0073, 0.0237, 0.0156, 0.0371, 0.0147, 0.0227,
        0.1021, 0.0328, 0.1734, 0.1083, 0.0476, 0.1387, 0.0848, 0.1313, 0.0401],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,313][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.2796e-11, 5.5142e-10, 6.0015e-09, 9.4710e-09, 6.5104e-08, 8.8768e-08,
        2.5342e-07, 4.9288e-07, 2.3115e-06, 7.5370e-06, 5.3522e-05, 5.1522e-04,
        2.1673e-04, 2.8426e-03, 1.5889e-02, 5.6657e-02, 1.8223e-01, 7.4159e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,314][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0099, 0.0390, 0.0527, 0.0464, 0.0565, 0.0613, 0.0614, 0.0575, 0.0644,
        0.0741, 0.0624, 0.0556, 0.0645, 0.0537, 0.0671, 0.0584, 0.0629, 0.0523],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,315][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0094e-08, 1.5610e-02, 8.1032e-04, 1.0612e-04, 1.4312e-02, 2.6904e-04,
        1.5367e-01, 1.4260e-03, 1.4266e-02, 1.1687e-02, 7.3403e-02, 2.6739e-04,
        5.8051e-01, 9.2808e-04, 4.4414e-02, 3.6253e-02, 4.7435e-02, 4.6265e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,357][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:02,358][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,359][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,359][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,360][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,361][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,361][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,362][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,363][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,363][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,364][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,365][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,365][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,366][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4549, 0.5451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,367][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7789, 0.2211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,368][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,369][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,370][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,371][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,372][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,374][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2481, 0.7519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,375][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,376][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,376][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2425, 0.7575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,377][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,378][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.1427, 0.5436, 0.3137], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,379][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.2414, 0.4930, 0.2656], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,379][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([2.9889e-06, 1.1303e-01, 8.8697e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,381][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.0012, 0.1947, 0.8041], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,382][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.0010, 0.1540, 0.8450], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,384][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.0010, 0.4404, 0.5586], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,385][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.0761, 0.2005, 0.7234], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,387][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.0199, 0.0826, 0.8975], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,388][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.0020, 0.2009, 0.7971], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,390][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([1.6206e-04, 3.5418e-01, 6.4566e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,391][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.0851, 0.4550, 0.4600], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,393][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.0231, 0.5852, 0.3917], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,394][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0496, 0.1760, 0.2137, 0.5607], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,396][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3855, 0.2148, 0.1685, 0.2313], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,397][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([8.2221e-07, 5.8919e-03, 5.6737e-01, 4.2674e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,398][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.3906e-04, 3.6812e-02, 5.9575e-01, 3.6690e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,399][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([5.1902e-04, 3.3848e-02, 8.1151e-01, 1.5412e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,401][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.1721e-04, 5.9777e-02, 3.6649e-01, 5.7341e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,402][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0672, 0.0788, 0.3650, 0.4891], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,404][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0028, 0.0052, 0.0851, 0.9069], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,405][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0018, 0.0850, 0.5326, 0.3807], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,407][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.1262e-05, 3.1338e-02, 4.2426e-01, 5.4438e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,408][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0469, 0.2672, 0.2738, 0.4121], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,410][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0213, 0.4443, 0.2832, 0.2511], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,411][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0163, 0.0835, 0.1218, 0.6289, 0.1495], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,413][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.1179, 0.4199, 0.0903, 0.2974, 0.0746], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,414][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([4.3789e-08, 8.4774e-04, 4.2950e-02, 3.6773e-01, 5.8847e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,415][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([9.5812e-05, 1.6416e-02, 1.2934e-01, 3.6758e-01, 4.8657e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,417][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([5.9567e-05, 1.5542e-02, 2.5921e-01, 2.6525e-01, 4.5994e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,418][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([4.8797e-05, 1.8413e-02, 7.9740e-02, 6.9968e-01, 2.0212e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,419][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0231, 0.0609, 0.1671, 0.3576, 0.3912], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,419][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0013, 0.0045, 0.0517, 0.6395, 0.3031], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,420][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([1.1183e-04, 1.4125e-02, 1.5198e-01, 2.2061e-01, 6.1317e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,421][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([4.4916e-06, 1.3458e-02, 1.1959e-01, 4.2082e-01, 4.4613e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,422][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0334, 0.1451, 0.1675, 0.3413, 0.3127], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,423][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0116, 0.2574, 0.1596, 0.2424, 0.3290], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,425][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0114, 0.0596, 0.0384, 0.3275, 0.2488, 0.3142], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,426][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.2545, 0.2544, 0.0681, 0.2140, 0.0519, 0.1572], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,428][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([2.3080e-08, 1.1207e-04, 5.9834e-03, 4.9920e-02, 4.7380e-01, 4.7019e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,429][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([7.4548e-05, 7.7039e-03, 6.0440e-02, 1.3922e-01, 5.0103e-01, 2.9153e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,430][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([1.0366e-04, 1.8745e-02, 4.3562e-02, 2.6185e-01, 2.0326e-01, 4.7247e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,431][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([2.9000e-05, 4.7905e-03, 2.6095e-02, 1.3231e-01, 2.9957e-01, 5.3720e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,433][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0196, 0.0406, 0.1309, 0.2300, 0.2960, 0.2829], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,434][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0007, 0.0020, 0.0233, 0.2669, 0.1207, 0.5865], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,436][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([2.6405e-04, 1.5449e-02, 5.3499e-02, 1.6659e-01, 2.8826e-01, 4.7594e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,437][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([2.2370e-06, 3.0925e-03, 2.4548e-02, 1.0322e-01, 4.2794e-01, 4.4120e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,438][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0178, 0.1079, 0.1133, 0.2020, 0.2084, 0.3505], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,440][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0120, 0.2364, 0.1374, 0.1259, 0.2851, 0.2032], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,442][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0126, 0.0436, 0.0523, 0.2052, 0.1775, 0.3590, 0.1498],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,443][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.1632, 0.1733, 0.1178, 0.1127, 0.1604, 0.1506, 0.1219],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,444][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([1.6115e-08, 2.6722e-05, 8.6224e-04, 1.2620e-02, 6.2164e-02, 6.7592e-01,
        2.4840e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,446][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([5.3598e-05, 4.2583e-03, 3.2804e-02, 9.1233e-02, 2.0810e-01, 2.6559e-01,
        3.9796e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,447][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([4.0836e-05, 2.5282e-03, 1.1228e-02, 6.9090e-02, 8.8675e-02, 5.9045e-01,
        2.3799e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,448][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([1.1366e-05, 1.3248e-03, 1.1819e-02, 5.4278e-02, 8.8747e-02, 5.2000e-01,
        3.2382e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,450][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0209, 0.0267, 0.1008, 0.1676, 0.2355, 0.1774, 0.2712],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,451][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0007, 0.0014, 0.0150, 0.1874, 0.0794, 0.3759, 0.3402],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,452][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([7.9457e-05, 3.7486e-03, 2.0459e-02, 5.4503e-02, 1.6171e-01, 6.2910e-01,
        1.3040e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,454][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([1.7943e-06, 1.5601e-03, 1.4824e-02, 6.3870e-02, 1.5355e-01, 5.4059e-01,
        2.2561e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,455][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0179, 0.0803, 0.0784, 0.1597, 0.1463, 0.2433, 0.2740],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,457][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0127, 0.1642, 0.0978, 0.1271, 0.2038, 0.1951, 0.1993],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,459][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0055, 0.0181, 0.0259, 0.0955, 0.1193, 0.1286, 0.1740, 0.4332],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,460][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2851, 0.1481, 0.0765, 0.1084, 0.0513, 0.1238, 0.1058, 0.1010],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,461][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([6.4156e-09, 1.3428e-06, 1.0305e-04, 8.6990e-04, 7.0219e-03, 4.9342e-02,
        4.5933e-01, 4.8333e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,462][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([2.5782e-05, 6.6762e-04, 1.2866e-02, 1.7167e-02, 7.1905e-02, 1.2875e-01,
        3.6429e-01, 4.0434e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,463][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([9.5997e-06, 3.3355e-04, 2.5377e-03, 6.5884e-03, 5.1907e-02, 8.6966e-02,
        6.2584e-01, 2.2582e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,463][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.0335e-05, 5.7972e-04, 2.7549e-03, 1.6596e-02, 2.4957e-02, 2.3814e-01,
        1.9748e-01, 5.1949e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,465][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0200, 0.0177, 0.0637, 0.0937, 0.1187, 0.1522, 0.1814, 0.3526],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,466][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([2.2989e-04, 3.5882e-04, 4.3605e-03, 4.9912e-02, 2.3524e-02, 1.1458e-01,
        1.0134e-01, 7.0569e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,467][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([3.6214e-05, 5.3814e-04, 7.2551e-03, 9.0612e-03, 6.1863e-02, 2.0296e-01,
        5.3141e-01, 1.8687e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,468][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([5.9011e-07, 2.5404e-04, 3.4392e-03, 9.9967e-03, 5.3996e-02, 1.5825e-01,
        2.8960e-01, 4.8446e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,470][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0144, 0.0551, 0.0653, 0.1023, 0.1026, 0.1644, 0.2011, 0.2949],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,471][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0118, 0.1306, 0.0827, 0.0872, 0.1798, 0.1369, 0.1768, 0.1942],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,473][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0040, 0.0092, 0.0141, 0.0477, 0.0673, 0.0542, 0.1350, 0.4616, 0.2068],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,475][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2485, 0.1397, 0.0698, 0.1132, 0.0532, 0.0939, 0.0860, 0.0757, 0.1199],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,476][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.8778e-10, 4.6764e-08, 3.7212e-06, 5.0348e-05, 2.3654e-04, 2.3923e-03,
        1.2037e-02, 9.1140e-01, 7.3876e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,477][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.1303e-06, 2.1513e-04, 3.4676e-03, 6.7060e-03, 2.8329e-02, 3.1493e-02,
        1.3332e-01, 4.5157e-01, 3.4490e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,478][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([5.4647e-06, 2.8387e-04, 4.0292e-03, 3.8225e-03, 3.0449e-02, 2.2196e-02,
        4.1669e-01, 3.3295e-01, 1.8957e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,480][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.5597e-06, 1.4207e-04, 8.4934e-04, 5.1802e-03, 1.1231e-02, 6.8678e-02,
        6.9080e-02, 4.2048e-01, 4.2435e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,481][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0100, 0.0100, 0.0428, 0.0591, 0.0912, 0.0881, 0.1221, 0.2560, 0.3208],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,483][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.3419e-04, 2.0418e-04, 2.3971e-03, 3.1200e-02, 1.3195e-02, 6.6206e-02,
        5.6928e-02, 4.0411e-01, 4.2562e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,484][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.2801e-05, 4.1169e-04, 3.2478e-03, 5.5318e-03, 1.5933e-02, 1.0426e-01,
        1.3659e-01, 4.7714e-01, 2.5687e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,485][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.9920e-07, 1.1903e-04, 1.1235e-03, 2.7772e-03, 1.5528e-02, 3.8727e-02,
        7.5475e-02, 3.8962e-01, 4.7663e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,487][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0102, 0.0409, 0.0484, 0.0786, 0.0822, 0.1251, 0.1503, 0.2167, 0.2476],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,488][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0102, 0.1064, 0.0686, 0.0659, 0.1430, 0.1208, 0.1428, 0.1487, 0.1935],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,490][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0030, 0.0077, 0.0155, 0.0336, 0.0479, 0.0420, 0.0823, 0.3925, 0.1969,
        0.1786], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,492][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0998, 0.1499, 0.0625, 0.0805, 0.0258, 0.1651, 0.1077, 0.0992, 0.1365,
        0.0731], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,493][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([4.7759e-10, 2.1956e-07, 4.4277e-06, 5.6367e-05, 4.6705e-04, 2.4402e-03,
        5.8091e-03, 2.7073e-01, 4.3026e-01, 2.9024e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,494][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([2.8474e-06, 8.9365e-05, 1.2914e-03, 1.6368e-03, 5.3701e-03, 1.7923e-02,
        3.0630e-02, 1.8195e-01, 5.2544e-01, 2.3567e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,496][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([4.3202e-06, 3.1312e-04, 2.0313e-03, 4.3032e-03, 4.2891e-03, 2.8653e-02,
        7.6890e-02, 1.6267e-01, 3.6740e-01, 3.5344e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,497][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([1.2036e-06, 5.2580e-05, 4.6651e-04, 2.0548e-03, 5.4055e-03, 2.2686e-02,
        3.7378e-02, 1.6929e-01, 5.1743e-01, 2.4524e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,498][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0080, 0.0098, 0.0276, 0.0396, 0.0711, 0.0677, 0.1092, 0.2062, 0.2478,
        0.2130], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,500][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([1.1527e-04, 3.9811e-04, 2.9916e-03, 3.5212e-02, 1.4237e-02, 6.1641e-02,
        5.7567e-02, 3.6625e-01, 3.3735e-01, 1.2424e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,501][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([1.8997e-05, 3.2286e-04, 1.7579e-03, 2.9798e-03, 8.9820e-03, 3.3777e-02,
        3.6773e-02, 3.9631e-01, 3.4899e-01, 1.7008e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,502][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([2.3618e-07, 8.4972e-05, 5.4996e-04, 1.8278e-03, 6.7338e-03, 2.3774e-02,
        2.2232e-02, 2.2275e-01, 5.1720e-01, 2.0485e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,503][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0067, 0.0309, 0.0300, 0.0580, 0.0535, 0.0987, 0.1077, 0.1853, 0.1983,
        0.2309], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,504][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0091, 0.0913, 0.0518, 0.0623, 0.1044, 0.1011, 0.1108, 0.1316, 0.1591,
        0.1785], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,504][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0040, 0.0046, 0.0088, 0.0347, 0.0240, 0.0984, 0.0929, 0.1864, 0.1649,
        0.1971, 0.1840], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,505][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1550, 0.0908, 0.0562, 0.0779, 0.0482, 0.1289, 0.0834, 0.0742, 0.0883,
        0.0676, 0.1294], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,506][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([9.0096e-11, 2.5542e-09, 8.6003e-07, 3.3416e-06, 5.6762e-05, 1.5370e-04,
        7.2653e-04, 8.6283e-03, 3.3482e-02, 9.1511e-02, 8.6544e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,508][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([2.6489e-06, 5.0791e-05, 8.3940e-04, 1.5551e-03, 3.9009e-03, 8.2201e-03,
        1.4135e-02, 6.9805e-02, 1.1585e-01, 1.6464e-01, 6.2101e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,509][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([3.5279e-06, 8.3360e-05, 2.0694e-03, 2.0849e-03, 7.6733e-03, 1.7871e-02,
        2.5328e-02, 3.8482e-02, 1.9746e-01, 2.3965e-01, 4.6929e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,510][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([3.2700e-07, 1.3657e-05, 5.5552e-05, 3.3911e-04, 6.2115e-04, 5.0474e-03,
        3.5171e-03, 5.2211e-02, 8.6816e-02, 1.3882e-01, 7.1256e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,512][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0055, 0.0050, 0.0313, 0.0418, 0.0571, 0.0653, 0.0807, 0.1473, 0.1722,
        0.1586, 0.2352], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,513][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.9572e-05, 1.0936e-04, 1.2834e-03, 1.4818e-02, 7.2002e-03, 3.0488e-02,
        2.9329e-02, 1.7144e-01, 1.7359e-01, 6.6685e-02, 5.0501e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,514][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.0726e-05, 1.6720e-04, 1.0133e-03, 2.2904e-03, 2.4566e-03, 4.2520e-02,
        1.5506e-02, 6.7226e-02, 1.4864e-01, 1.5114e-01, 5.6903e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,515][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.2858e-08, 6.2456e-06, 1.1072e-04, 5.1274e-04, 1.3884e-03, 4.5920e-03,
        7.5359e-03, 4.6437e-02, 1.2512e-01, 1.6404e-01, 6.5026e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,517][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0073, 0.0250, 0.0309, 0.0437, 0.0504, 0.0715, 0.0924, 0.1141, 0.1332,
        0.1790, 0.2525], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,519][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0090, 0.0737, 0.0548, 0.0464, 0.1174, 0.0738, 0.1037, 0.0875, 0.1210,
        0.1733, 0.1393], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,520][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0017, 0.0029, 0.0039, 0.0204, 0.0050, 0.0462, 0.0274, 0.1408, 0.1423,
        0.0434, 0.3049, 0.2612], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,522][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0750, 0.1609, 0.0336, 0.1411, 0.0211, 0.1082, 0.0718, 0.0462, 0.0554,
        0.0311, 0.2226, 0.0329], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,523][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([4.0214e-12, 4.2608e-10, 2.7634e-08, 1.8197e-07, 3.1310e-07, 9.5283e-06,
        2.4517e-05, 3.0950e-04, 1.5799e-03, 6.0552e-03, 1.0003e-01, 8.9199e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,525][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([2.8932e-07, 7.5918e-06, 6.3180e-05, 1.6680e-04, 2.2512e-04, 1.6945e-03,
        3.4127e-03, 1.7158e-02, 3.5781e-02, 4.1032e-02, 2.7984e-01, 6.2062e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,526][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([5.3098e-07, 1.6704e-05, 1.5842e-04, 2.4523e-04, 3.1564e-04, 1.8649e-03,
        2.1530e-03, 5.5405e-03, 3.8110e-02, 3.3793e-02, 2.3669e-01, 6.8112e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,527][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([7.2957e-08, 2.8726e-06, 1.2199e-05, 1.0803e-04, 2.9333e-05, 1.5294e-03,
        1.5382e-03, 1.0089e-02, 3.3153e-02, 3.0824e-02, 5.8947e-01, 3.3325e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,529][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0017, 0.0043, 0.0100, 0.0257, 0.0242, 0.0469, 0.0468, 0.1176, 0.1000,
        0.1057, 0.2233, 0.2936], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,530][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([5.0071e-05, 1.7976e-04, 1.2884e-03, 1.5950e-02, 6.2566e-03, 2.9261e-02,
        2.2014e-02, 1.5068e-01, 1.4066e-01, 4.8679e-02, 4.0203e-01, 1.8295e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,531][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([9.1128e-07, 1.3159e-05, 1.2656e-04, 2.1043e-04, 4.3459e-04, 4.0681e-03,
        2.0905e-03, 1.4247e-02, 2.4420e-02, 7.4028e-02, 2.0688e-01, 6.7348e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,533][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([6.5262e-09, 1.3708e-06, 1.2650e-05, 4.3367e-05, 5.5138e-05, 7.1841e-04,
        5.3238e-04, 6.0671e-03, 1.5754e-02, 2.1054e-02, 3.0116e-01, 6.5460e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,534][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0031, 0.0158, 0.0172, 0.0372, 0.0287, 0.0579, 0.0514, 0.0927, 0.1118,
        0.1018, 0.2385, 0.2439], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,536][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0048, 0.0525, 0.0296, 0.0435, 0.0531, 0.0557, 0.0693, 0.0919, 0.1029,
        0.0833, 0.1289, 0.2847], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,538][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0010, 0.0021, 0.0024, 0.0105, 0.0099, 0.0280, 0.0286, 0.0578, 0.0537,
        0.0516, 0.1627, 0.4416, 0.1500], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,540][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0772, 0.1128, 0.0193, 0.1074, 0.0184, 0.1473, 0.0921, 0.0558, 0.0477,
        0.0304, 0.1932, 0.0191, 0.0794], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,541][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([2.2461e-12, 9.9195e-11, 5.0773e-09, 7.6739e-08, 1.3807e-07, 4.6741e-06,
        3.3826e-06, 2.7652e-04, 4.1410e-04, 1.0784e-03, 8.5231e-02, 5.2979e-01,
        3.8320e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,542][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([1.3952e-07, 3.0237e-06, 3.0988e-05, 6.2498e-05, 1.9252e-04, 9.6480e-05,
        6.4643e-04, 3.1214e-03, 4.9434e-03, 1.1049e-02, 9.7241e-02, 7.3366e-01,
        1.4896e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,543][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([8.2191e-07, 1.1692e-05, 2.3652e-05, 2.1093e-04, 1.3920e-04, 8.0190e-04,
        2.1863e-03, 3.6012e-03, 1.0812e-02, 1.5415e-02, 1.2750e-01, 2.2282e-01,
        6.1648e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,544][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.8246e-08, 5.9509e-07, 4.4164e-06, 1.9020e-05, 2.9030e-05, 1.5569e-04,
        2.0947e-04, 1.4964e-03, 4.5931e-03, 5.5636e-03, 1.3795e-01, 5.8344e-01,
        2.6654e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,545][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0012, 0.0021, 0.0122, 0.0131, 0.0277, 0.0153, 0.0313, 0.0636, 0.0655,
        0.0706, 0.1434, 0.3833, 0.1708], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,546][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([4.9089e-05, 1.2431e-04, 9.4497e-04, 1.1430e-02, 4.5325e-03, 1.8706e-02,
        1.8662e-02, 1.2119e-01, 1.1193e-01, 3.8967e-02, 3.4911e-01, 1.4014e-01,
        1.8422e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,547][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([9.5161e-07, 1.3625e-05, 9.4488e-05, 1.2981e-04, 3.6492e-04, 1.4789e-03,
        4.4737e-04, 2.9796e-03, 8.9661e-03, 1.0994e-02, 1.6997e-01, 5.5478e-01,
        2.4978e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,548][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([2.6888e-09, 3.5660e-07, 4.7440e-06, 1.0515e-05, 5.4828e-05, 6.6142e-05,
        1.4839e-04, 1.1048e-03, 2.9624e-03, 4.2326e-03, 1.0083e-01, 7.8579e-01,
        1.0479e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,550][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0022, 0.0136, 0.0128, 0.0262, 0.0220, 0.0384, 0.0457, 0.0713, 0.0779,
        0.0758, 0.1896, 0.1924, 0.2321], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,551][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0067, 0.0629, 0.0306, 0.0332, 0.0545, 0.0456, 0.0574, 0.0653, 0.0768,
        0.0778, 0.1073, 0.2585, 0.1235], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,553][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.1363e-04, 6.8789e-04, 6.2333e-04, 3.5322e-03, 2.2018e-03, 6.0396e-03,
        1.0107e-02, 2.2090e-02, 1.5195e-02, 1.8953e-02, 7.9266e-02, 9.0237e-02,
        1.1276e-01, 6.3769e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,554][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2173, 0.0837, 0.0349, 0.0672, 0.0240, 0.0380, 0.0499, 0.0436, 0.0852,
        0.0346, 0.0885, 0.0181, 0.0354, 0.1795], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,556][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.0417e-12, 4.7655e-12, 3.2167e-10, 2.0987e-09, 9.5471e-09, 1.1175e-07,
        3.5069e-07, 6.6466e-06, 2.1966e-05, 3.7929e-05, 6.6938e-04, 3.5159e-02,
        7.9413e-02, 8.8469e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,557][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.7314e-07, 1.1307e-06, 1.2564e-05, 1.7119e-05, 9.5366e-05, 6.2300e-05,
        4.9990e-04, 1.3359e-03, 2.7152e-03, 5.4927e-03, 3.3216e-02, 3.0176e-01,
        1.5383e-01, 5.0097e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,558][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.8075e-08, 5.8793e-07, 6.5304e-06, 5.4006e-06, 9.1268e-06, 5.7484e-05,
        7.8356e-04, 2.7174e-04, 3.7926e-04, 1.0541e-03, 2.7129e-03, 1.7333e-02,
        7.6163e-01, 2.1576e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,560][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.4582e-08, 1.0762e-07, 4.0361e-07, 3.1452e-06, 6.4906e-06, 3.1107e-05,
        3.3511e-05, 1.8596e-04, 6.8628e-04, 1.2068e-03, 1.9151e-02, 1.0871e-01,
        1.0791e-01, 7.6207e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,561][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0018, 0.0019, 0.0063, 0.0097, 0.0141, 0.0140, 0.0177, 0.0398, 0.0584,
        0.0425, 0.0952, 0.1528, 0.1329, 0.4128], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,563][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.2152e-05, 4.0833e-05, 2.9772e-04, 3.9372e-03, 1.3709e-03, 6.7139e-03,
        5.8885e-03, 4.1644e-02, 3.9052e-02, 1.1695e-02, 1.2097e-01, 4.0796e-02,
        6.2021e-02, 6.6555e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,564][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.7315e-07, 4.4316e-06, 6.3201e-05, 3.4450e-05, 3.5848e-05, 7.4888e-04,
        1.2958e-03, 1.7712e-03, 3.3837e-03, 3.3016e-03, 4.3435e-02, 4.5667e-02,
        4.9566e-01, 4.0460e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,565][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3511e-09, 9.0045e-08, 1.1869e-06, 2.0518e-06, 1.3088e-05, 1.8510e-05,
        6.0104e-05, 1.0410e-04, 6.4570e-04, 1.5821e-03, 1.2585e-02, 1.5515e-01,
        6.7183e-02, 7.6266e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,567][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0022, 0.0104, 0.0094, 0.0172, 0.0151, 0.0272, 0.0312, 0.0423, 0.0504,
        0.0520, 0.1142, 0.1110, 0.1729, 0.3446], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,569][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0075, 0.0486, 0.0256, 0.0250, 0.0459, 0.0409, 0.0448, 0.0474, 0.0628,
        0.0671, 0.0783, 0.1955, 0.1170, 0.1936], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,570][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.8031e-04, 3.8701e-04, 5.3703e-04, 2.1652e-03, 1.1898e-03, 3.1073e-03,
        6.2764e-03, 1.1737e-02, 1.1592e-02, 1.2462e-02, 4.0635e-02, 4.8271e-02,
        7.2237e-02, 6.8045e-01, 1.0868e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,572][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1043, 0.1227, 0.0292, 0.0627, 0.0303, 0.0377, 0.0652, 0.0287, 0.0586,
        0.0454, 0.1526, 0.0346, 0.0572, 0.1020, 0.0689], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,573][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([2.9340e-14, 8.1365e-14, 6.1602e-12, 5.7719e-11, 3.6825e-10, 1.8487e-09,
        5.8801e-09, 1.5123e-07, 3.8795e-07, 1.4599e-06, 7.2299e-05, 1.5984e-03,
        2.3595e-03, 8.1736e-01, 1.7860e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,574][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.8422e-08, 3.0785e-07, 2.3880e-06, 7.4930e-06, 1.7590e-05, 3.6152e-05,
        1.3680e-04, 3.7224e-04, 1.1831e-03, 1.1316e-03, 1.2635e-02, 5.5806e-02,
        5.4792e-02, 2.9966e-01, 5.7422e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,576][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([4.9607e-08, 7.6074e-07, 3.1301e-06, 8.4546e-06, 8.3840e-06, 4.6990e-05,
        1.9498e-04, 2.1772e-04, 6.3100e-04, 1.2473e-03, 6.2140e-03, 1.4529e-02,
        5.6463e-02, 4.4755e-01, 4.7289e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,577][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.3044e-09, 2.9694e-08, 1.3808e-07, 8.1444e-07, 3.2564e-06, 7.9013e-06,
        1.2330e-05, 4.1672e-05, 2.3138e-04, 4.7131e-04, 8.5688e-03, 5.4450e-02,
        4.5374e-02, 6.1973e-01, 2.7111e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,579][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0013, 0.0011, 0.0035, 0.0061, 0.0093, 0.0081, 0.0110, 0.0292, 0.0330,
        0.0282, 0.0641, 0.1089, 0.0931, 0.3427, 0.2602], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,580][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([1.4758e-05, 3.7351e-05, 2.3837e-04, 3.1722e-03, 1.0469e-03, 4.9292e-03,
        4.5320e-03, 3.2477e-02, 2.9301e-02, 8.9202e-03, 9.7894e-02, 3.0473e-02,
        4.9706e-02, 5.1520e-01, 2.2206e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,581][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([1.8812e-07, 9.1671e-07, 6.8375e-06, 7.7712e-06, 1.9893e-05, 9.8898e-05,
        9.1823e-05, 2.5791e-04, 1.0721e-03, 8.1784e-04, 1.5557e-02, 3.2117e-02,
        1.0598e-01, 5.8398e-01, 2.6000e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,582][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([4.3750e-10, 3.2964e-08, 2.8562e-07, 8.2389e-07, 4.0326e-06, 7.2095e-06,
        1.2540e-05, 1.3286e-04, 2.7911e-04, 4.0324e-04, 7.2782e-03, 5.0265e-02,
        1.6321e-02, 6.0784e-01, 3.1745e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,584][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0010, 0.0064, 0.0054, 0.0121, 0.0090, 0.0165, 0.0189, 0.0328, 0.0350,
        0.0329, 0.0916, 0.0758, 0.1123, 0.2776, 0.2729], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,586][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0060, 0.0374, 0.0173, 0.0216, 0.0315, 0.0272, 0.0348, 0.0425, 0.0485,
        0.0447, 0.0704, 0.1461, 0.0844, 0.1753, 0.2121], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,587][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.7289e-04, 2.6537e-04, 2.3866e-04, 1.0990e-03, 9.2469e-04, 6.1372e-04,
        3.0864e-03, 8.3210e-03, 3.4964e-03, 8.6700e-03, 2.6512e-02, 3.2765e-02,
        3.2975e-02, 3.2328e-01, 3.4408e-01, 2.1340e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,588][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1436, 0.0763, 0.0262, 0.0664, 0.0194, 0.0372, 0.0436, 0.0349, 0.0811,
        0.0280, 0.0951, 0.0163, 0.0407, 0.1324, 0.0661, 0.0925],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,589][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.6829e-14, 4.1739e-14, 1.9018e-12, 2.4922e-11, 6.5499e-11, 7.0405e-10,
        6.4308e-09, 2.2637e-07, 1.1421e-07, 5.4092e-07, 8.9208e-06, 1.5479e-04,
        3.9981e-04, 1.2947e-01, 6.8383e-01, 1.8614e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,590][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.8930e-08, 1.0294e-07, 1.4482e-06, 2.1092e-06, 1.1272e-05, 4.8144e-06,
        3.2174e-05, 1.0557e-04, 2.5931e-04, 5.3797e-04, 2.9706e-03, 3.3267e-02,
        1.5564e-02, 1.4504e-01, 4.8409e-01, 3.1811e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,591][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.2179e-08, 2.5610e-07, 1.4040e-06, 2.4579e-06, 8.4758e-06, 1.1043e-05,
        6.0169e-05, 9.5964e-05, 1.0746e-04, 1.7315e-04, 2.1372e-03, 8.4279e-03,
        1.7595e-02, 1.0499e-01, 6.7798e-01, 1.8841e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,592][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.4586e-09, 1.7918e-08, 1.0089e-07, 4.2535e-07, 1.1408e-06, 3.4740e-06,
        3.0754e-06, 1.6411e-05, 7.6290e-05, 1.6486e-04, 2.8955e-03, 1.4012e-02,
        1.1057e-02, 3.1440e-01, 2.7766e-01, 3.7971e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,594][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0008, 0.0009, 0.0031, 0.0048, 0.0068, 0.0057, 0.0087, 0.0192, 0.0241,
        0.0217, 0.0409, 0.0759, 0.0620, 0.2162, 0.1967, 0.3126],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,595][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.3091e-05, 2.3751e-05, 1.7185e-04, 2.2906e-03, 7.6334e-04, 3.5434e-03,
        3.0979e-03, 2.1980e-02, 2.2027e-02, 6.9613e-03, 6.6392e-02, 2.1749e-02,
        3.0096e-02, 3.2905e-01, 1.4661e-01, 3.4523e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,597][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.0443e-08, 1.1106e-07, 8.3312e-07, 1.6960e-06, 3.0801e-06, 1.3444e-05,
        3.6663e-05, 1.0342e-04, 1.2473e-04, 1.5617e-04, 1.5914e-03, 4.0081e-03,
        1.5698e-02, 8.6214e-02, 8.0237e-01, 8.9677e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,598][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.6297e-10, 1.1586e-08, 1.0188e-07, 2.1788e-07, 1.4960e-06, 1.6252e-06,
        4.7342e-06, 1.9374e-05, 2.5548e-05, 2.0699e-04, 1.5913e-03, 1.5681e-02,
        7.7597e-03, 2.0964e-01, 3.9582e-01, 3.6925e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,600][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0012, 0.0058, 0.0058, 0.0103, 0.0088, 0.0153, 0.0174, 0.0267, 0.0296,
        0.0343, 0.0624, 0.0627, 0.0843, 0.1944, 0.2029, 0.2380],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,602][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0057, 0.0313, 0.0160, 0.0168, 0.0300, 0.0268, 0.0294, 0.0317, 0.0385,
        0.0429, 0.0525, 0.1271, 0.0674, 0.1260, 0.1725, 0.1853],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:02,603][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([2.1142e-04, 1.5412e-04, 2.7724e-04, 6.7313e-04, 5.2046e-04, 8.2857e-04,
        2.0142e-03, 5.4900e-03, 3.2381e-03, 4.4393e-03, 1.9664e-02, 1.6332e-02,
        1.4928e-02, 2.0984e-01, 3.2269e-01, 1.9150e-01, 2.0720e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,605][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.1015, 0.1063, 0.0364, 0.0640, 0.0158, 0.0262, 0.0436, 0.0255, 0.0559,
        0.0805, 0.0929, 0.0226, 0.0215, 0.1044, 0.0629, 0.1003, 0.0396],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,606][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([5.9137e-15, 2.5180e-14, 1.2091e-12, 8.6769e-12, 4.3529e-11, 3.2685e-10,
        2.8870e-10, 1.0071e-08, 2.8801e-08, 8.2764e-08, 6.7494e-06, 9.1107e-05,
        7.8138e-05, 4.0568e-02, 5.8474e-02, 3.3280e-01, 5.6799e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,607][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([4.9354e-09, 2.7740e-08, 2.1141e-07, 5.3834e-07, 1.3758e-06, 2.4624e-06,
        8.1127e-06, 3.3944e-05, 8.1492e-05, 1.0086e-04, 1.0305e-03, 3.6532e-03,
        4.0762e-03, 2.4278e-02, 1.5268e-01, 5.2338e-01, 2.9067e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,609][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([1.5311e-08, 1.0765e-07, 2.0423e-06, 1.1959e-06, 2.1861e-06, 1.2076e-05,
        9.8981e-06, 4.3773e-05, 1.3107e-04, 2.6435e-04, 8.9439e-04, 2.3927e-03,
        9.5210e-03, 5.4871e-02, 1.3623e-01, 3.0322e-01, 4.9241e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,610][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([7.7759e-10, 4.0075e-09, 3.2014e-08, 1.3819e-07, 4.7328e-07, 1.1647e-06,
        1.6856e-06, 6.7258e-06, 2.3627e-05, 3.0032e-05, 7.8049e-04, 5.2860e-03,
        4.6609e-03, 8.9040e-02, 1.0261e-01, 5.2260e-01, 2.7496e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,612][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0010, 0.0009, 0.0016, 0.0034, 0.0049, 0.0044, 0.0061, 0.0148, 0.0169,
        0.0126, 0.0424, 0.0553, 0.0404, 0.1719, 0.1323, 0.3082, 0.1827],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,613][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([1.6829e-05, 3.5909e-05, 2.1135e-04, 2.6412e-03, 8.3523e-04, 3.6890e-03,
        3.0854e-03, 2.1202e-02, 1.9779e-02, 6.1462e-03, 6.7391e-02, 1.9970e-02,
        2.8175e-02, 3.0448e-01, 1.2773e-01, 2.8698e-01, 1.0763e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,614][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([7.4584e-08, 2.4069e-07, 1.8337e-06, 1.9240e-06, 5.0395e-06, 1.6170e-05,
        1.2114e-05, 1.2649e-04, 2.5843e-04, 1.6899e-04, 3.7109e-03, 6.5983e-03,
        6.3639e-03, 1.2905e-01, 3.4706e-01, 2.1347e-01, 2.9315e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,616][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([1.2057e-10, 5.1918e-09, 4.6672e-08, 7.5292e-08, 5.9660e-07, 8.6676e-07,
        1.8113e-06, 1.7076e-05, 2.5642e-05, 5.5000e-05, 6.7396e-04, 5.0856e-03,
        2.3648e-03, 8.1672e-02, 1.6198e-01, 3.8967e-01, 3.5845e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,617][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0008, 0.0041, 0.0037, 0.0079, 0.0060, 0.0115, 0.0116, 0.0213, 0.0222,
        0.0220, 0.0557, 0.0442, 0.0633, 0.1549, 0.1590, 0.1864, 0.2253],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,619][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0063, 0.0287, 0.0141, 0.0176, 0.0249, 0.0209, 0.0264, 0.0300, 0.0324,
        0.0356, 0.0528, 0.0959, 0.0584, 0.1085, 0.1402, 0.1568, 0.1505],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:02,620][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0067e-04, 7.1200e-05, 5.8266e-05, 3.1200e-04, 1.7417e-04, 3.4010e-04,
        6.7563e-04, 1.8895e-03, 1.1093e-03, 1.3224e-03, 9.2729e-03, 5.6451e-03,
        5.7451e-03, 4.4206e-02, 6.0579e-02, 9.1088e-02, 3.0154e-01, 4.7587e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,622][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1626, 0.0577, 0.0222, 0.0490, 0.0156, 0.0236, 0.0305, 0.0313, 0.0748,
        0.0191, 0.0590, 0.0105, 0.0206, 0.1295, 0.0538, 0.0838, 0.0228, 0.1337],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,624][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.9516e-15, 1.2336e-15, 8.0052e-14, 4.0213e-13, 1.7990e-12, 1.6590e-11,
        5.7589e-11, 7.5277e-10, 2.7427e-09, 6.5835e-09, 9.2307e-08, 3.5111e-06,
        6.5755e-06, 6.2640e-05, 1.0368e-02, 3.2669e-02, 2.5640e-01, 7.0049e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,625][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.8125e-09, 1.1816e-08, 1.2996e-07, 1.6520e-07, 1.0002e-06, 5.5270e-07,
        4.6857e-06, 1.2527e-05, 2.2989e-05, 5.0716e-05, 2.6467e-04, 2.3212e-03,
        1.0500e-03, 3.5670e-03, 5.0299e-02, 1.4002e-01, 3.4604e-01, 4.5634e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,626][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([6.3464e-09, 2.0331e-08, 1.6808e-07, 1.4412e-07, 2.2837e-07, 1.5777e-06,
        1.5809e-05, 6.4628e-06, 8.6635e-06, 2.5933e-05, 7.3176e-05, 2.9595e-04,
        9.3186e-03, 3.8503e-03, 1.1843e-01, 3.7278e-02, 5.2439e-01, 3.0631e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,628][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.3253e-10, 8.8034e-10, 2.8432e-09, 2.1918e-08, 4.3390e-08, 1.9280e-07,
        2.0430e-07, 1.0302e-06, 3.0328e-06, 8.6529e-06, 1.2756e-04, 4.4343e-04,
        4.7971e-04, 3.0922e-03, 1.6836e-02, 6.6933e-02, 1.5791e-01, 7.5416e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,629][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0008, 0.0006, 0.0012, 0.0025, 0.0028, 0.0033, 0.0035, 0.0087, 0.0128,
        0.0079, 0.0272, 0.0275, 0.0267, 0.0879, 0.0841, 0.1754, 0.1134, 0.4137],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,630][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.3670e-06, 1.1430e-05, 6.9916e-05, 9.7636e-04, 2.9589e-04, 1.4426e-03,
        1.2139e-03, 8.9687e-03, 8.2973e-03, 2.3776e-03, 2.8017e-02, 7.7046e-03,
        1.1620e-02, 1.2833e-01, 5.5475e-02, 1.2154e-01, 4.6215e-02, 5.7744e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,631][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.5610e-08, 4.9514e-08, 5.2469e-07, 3.2085e-07, 2.9480e-07, 5.6266e-06,
        1.2347e-05, 1.9454e-05, 3.0443e-05, 2.6545e-05, 4.0850e-04, 2.7273e-04,
        2.7926e-03, 2.7761e-03, 2.3982e-01, 7.5208e-02, 3.5053e-01, 3.2809e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,631][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.2796e-11, 5.5142e-10, 6.0015e-09, 9.4710e-09, 6.5104e-08, 8.8768e-08,
        2.5342e-07, 4.9288e-07, 2.3115e-06, 7.5370e-06, 5.3522e-05, 5.1522e-04,
        2.1673e-04, 2.8426e-03, 1.5889e-02, 5.6657e-02, 1.8223e-01, 7.4159e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,633][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0007, 0.0031, 0.0027, 0.0055, 0.0043, 0.0077, 0.0085, 0.0127, 0.0147,
        0.0149, 0.0368, 0.0299, 0.0460, 0.1017, 0.1079, 0.1143, 0.1517, 0.3370],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,635][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0057, 0.0252, 0.0114, 0.0125, 0.0197, 0.0181, 0.0186, 0.0207, 0.0267,
        0.0274, 0.0377, 0.0735, 0.0447, 0.0767, 0.1069, 0.1194, 0.1252, 0.2299],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:02,638][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:02,640][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[9032],
        [6591],
        [ 137],
        [ 317],
        [  42],
        [1086],
        [ 380],
        [ 750],
        [1300],
        [4032],
        [2072],
        [ 204],
        [2385],
        [ 987],
        [ 148],
        [1269],
        [4767],
        [1689]], device='cuda:0')
[2024-07-24 10:26:02,642][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6224],
        [ 7175],
        [   85],
        [ 4238],
        [  460],
        [ 2581],
        [11526],
        [ 3910],
        [ 5368],
        [ 8550],
        [ 5576],
        [  209],
        [ 4925],
        [ 2700],
        [ 1005],
        [ 7707],
        [ 9642],
        [ 4147]], device='cuda:0')
[2024-07-24 10:26:02,644][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[23807],
        [21354],
        [19291],
        [22832],
        [24236],
        [24512],
        [24616],
        [24651],
        [25308],
        [24819],
        [24577],
        [24754],
        [24836],
        [25113],
        [25364],
        [26168],
        [26250],
        [26712]], device='cuda:0')
[2024-07-24 10:26:02,646][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33314],
        [39751],
        [ 5826],
        [   85],
        [   63],
        [ 5786],
        [  534],
        [ 5969],
        [ 7540],
        [29673],
        [18201],
        [14521],
        [ 3097],
        [ 3192],
        [ 2337],
        [ 2263],
        [31496],
        [ 4601]], device='cuda:0')
[2024-07-24 10:26:02,647][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[47248],
        [45024],
        [ 8181],
        [17059],
        [11165],
        [ 6466],
        [14024],
        [ 3713],
        [ 4143],
        [20294],
        [43541],
        [ 5643],
        [13579],
        [ 3087],
        [ 4044],
        [22623],
        [16082],
        [ 3821]], device='cuda:0')
[2024-07-24 10:26:02,649][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5859],
        [7496],
        [6873],
        [6094],
        [6631],
        [8226],
        [9243],
        [9629],
        [9044],
        [8233],
        [8046],
        [7928],
        [8540],
        [8999],
        [9669],
        [9513],
        [9267],
        [9043]], device='cuda:0')
[2024-07-24 10:26:02,651][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[27287],
        [25687],
        [25876],
        [25728],
        [22578],
        [22598],
        [22033],
        [22687],
        [23330],
        [24868],
        [25067],
        [24494],
        [24321],
        [24167],
        [24809],
        [25405],
        [25847],
        [25860]], device='cuda:0')
[2024-07-24 10:26:02,653][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 9735],
        [11123],
        [ 7090],
        [ 6106],
        [ 8071],
        [ 3704],
        [  762],
        [ 2298],
        [ 2782],
        [ 2273],
        [ 3002],
        [ 6013],
        [15157],
        [21021],
        [12762],
        [ 5937],
        [ 5239],
        [16093]], device='cuda:0')
[2024-07-24 10:26:02,655][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14699],
        [12072],
        [ 7716],
        [ 8285],
        [ 6324],
        [ 7440],
        [ 6541],
        [ 7224],
        [ 7417],
        [ 5422],
        [ 5811],
        [ 5412],
        [ 5765],
        [ 5973],
        [ 6135],
        [ 6377],
        [ 5873],
        [ 6079]], device='cuda:0')
[2024-07-24 10:26:02,657][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[44380],
        [34634],
        [18907],
        [27211],
        [22374],
        [19657],
        [17662],
        [17249],
        [17360],
        [16758],
        [17440],
        [17017],
        [16914],
        [17609],
        [18921],
        [18258],
        [19261],
        [19787]], device='cuda:0')
[2024-07-24 10:26:02,659][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[27980],
        [30541],
        [27903],
        [30130],
        [29109],
        [31045],
        [33043],
        [33845],
        [34799],
        [32948],
        [33180],
        [32194],
        [32071],
        [32598],
        [32317],
        [32664],
        [32456],
        [32822]], device='cuda:0')
[2024-07-24 10:26:02,661][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 3252],
        [ 4761],
        [18765],
        [ 5754],
        [ 9775],
        [ 4714],
        [ 1007],
        [ 1091],
        [ 2587],
        [ 3506],
        [ 5311],
        [18607],
        [20041],
        [ 2185],
        [ 1095],
        [  902],
        [ 2829],
        [ 2792]], device='cuda:0')
[2024-07-24 10:26:02,663][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27855],
        [22864],
        [19566],
        [19382],
        [18400],
        [17477],
        [16717],
        [16415],
        [16206],
        [15694],
        [15737],
        [15830],
        [15788],
        [15903],
        [15637],
        [15540],
        [15209],
        [15270]], device='cuda:0')
[2024-07-24 10:26:02,664][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10190],
        [ 7299],
        [ 7795],
        [ 8574],
        [13940],
        [10678],
        [34037],
        [34245],
        [30830],
        [30481],
        [35825],
        [34808],
        [39261],
        [39223],
        [37920],
        [38555],
        [38509],
        [38812]], device='cuda:0')
[2024-07-24 10:26:02,666][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10694],
        [28974],
        [  345],
        [ 5971],
        [ 1560],
        [  560],
        [   24],
        [  483],
        [ 2262],
        [  763],
        [  390],
        [ 5775],
        [  423],
        [ 3751],
        [   89],
        [ 1205],
        [  413],
        [16917]], device='cuda:0')
[2024-07-24 10:26:02,668][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43284],
        [41138],
        [41437],
        [40457],
        [39711],
        [39022],
        [38566],
        [39967],
        [40875],
        [40790],
        [40304],
        [39691],
        [37272],
        [40301],
        [40259],
        [41153],
        [40534],
        [38819]], device='cuda:0')
[2024-07-24 10:26:02,670][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10432],
        [ 7782],
        [ 2125],
        [ 5032],
        [10585],
        [ 7526],
        [19786],
        [10933],
        [ 7397],
        [11867],
        [14937],
        [15700],
        [23414],
        [11232],
        [15028],
        [10484],
        [10134],
        [ 9432]], device='cuda:0')
[2024-07-24 10:26:02,672][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[26914],
        [21760],
        [20089],
        [27668],
        [20642],
        [25384],
        [22332],
        [25056],
        [39913],
        [27626],
        [22054],
        [18002],
        [28170],
        [26568],
        [25574],
        [18517],
        [25545],
        [21310]], device='cuda:0')
[2024-07-24 10:26:02,674][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[38718],
        [32571],
        [39017],
        [40249],
        [33724],
        [36005],
        [39337],
        [43352],
        [44633],
        [37770],
        [24748],
        [27754],
        [29423],
        [43600],
        [45174],
        [40370],
        [31599],
        [40140]], device='cuda:0')
[2024-07-24 10:26:02,676][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16437],
        [13198],
        [24947],
        [24294],
        [33153],
        [17442],
        [12192],
        [20572],
        [10056],
        [10459],
        [ 8441],
        [33570],
        [20796],
        [19097],
        [ 8233],
        [ 6913],
        [ 8701],
        [ 8941]], device='cuda:0')
[2024-07-24 10:26:02,677][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14206],
        [14071],
        [ 2334],
        [ 6122],
        [11238],
        [13041],
        [12415],
        [10420],
        [10320],
        [ 7176],
        [13118],
        [ 8309],
        [ 2846],
        [19404],
        [13232],
        [10019],
        [ 4847],
        [13614]], device='cuda:0')
[2024-07-24 10:26:02,679][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[17513],
        [ 8929],
        [22359],
        [ 7062],
        [11937],
        [19373],
        [27554],
        [17100],
        [12904],
        [14516],
        [11858],
        [17144],
        [26728],
        [15878],
        [17539],
        [13884],
        [20696],
        [13102]], device='cuda:0')
[2024-07-24 10:26:02,681][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9497],
        [11883],
        [15132],
        [13729],
        [17482],
        [13132],
        [18732],
        [20805],
        [23571],
        [22910],
        [14450],
        [10400],
        [13342],
        [22664],
        [23534],
        [27138],
        [25938],
        [21993]], device='cuda:0')
[2024-07-24 10:26:02,682][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32301],
        [33921],
        [38927],
        [35982],
        [38914],
        [42041],
        [45375],
        [46447],
        [31981],
        [27972],
        [30768],
        [38718],
        [42063],
        [41758],
        [32268],
        [24701],
        [29148],
        [28695]], device='cuda:0')
[2024-07-24 10:26:02,684][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14624],
        [13753],
        [12127],
        [14694],
        [16852],
        [14274],
        [12621],
        [14381],
        [11999],
        [12002],
        [15033],
        [19933],
        [21677],
        [16158],
        [15046],
        [12488],
        [12842],
        [14984]], device='cuda:0')
[2024-07-24 10:26:02,686][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8509],
        [ 9178],
        [10978],
        [ 9993],
        [10830],
        [11677],
        [12015],
        [12489],
        [12262],
        [12176],
        [10298],
        [10931],
        [10736],
        [10652],
        [10509],
        [10505],
        [11493],
        [11589]], device='cuda:0')
[2024-07-24 10:26:02,688][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17746],
        [ 9011],
        [ 8625],
        [ 9574],
        [10572],
        [ 9238],
        [10122],
        [10571],
        [ 9296],
        [ 9412],
        [ 9830],
        [ 9362],
        [ 8897],
        [ 9645],
        [ 8749],
        [ 8400],
        [ 7708],
        [ 8552]], device='cuda:0')
[2024-07-24 10:26:02,690][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 8789],
        [10214],
        [10407],
        [ 6880],
        [ 5511],
        [ 8159],
        [ 8163],
        [ 6467],
        [ 9898],
        [12597],
        [12560],
        [ 7618],
        [ 8877],
        [ 4747],
        [ 7794],
        [12243],
        [13194],
        [ 9538]], device='cuda:0')
[2024-07-24 10:26:02,692][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[29817],
        [23225],
        [16105],
        [25866],
        [20596],
        [23674],
        [19011],
        [25310],
        [25848],
        [25890],
        [22356],
        [ 9158],
        [11896],
        [20701],
        [21487],
        [25851],
        [26451],
        [21301]], device='cuda:0')
[2024-07-24 10:26:02,693][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895]], device='cuda:0')
[2024-07-24 10:26:02,735][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:02,736][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,738][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,739][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,741][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,742][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,744][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,745][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,746][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,748][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,749][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,750][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,752][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:02,753][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0689, 0.9311], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,755][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7864, 0.2136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,757][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9686, 0.0314], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,758][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1334, 0.8666], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,760][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9817, 0.0183], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,761][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8421, 0.1579], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,763][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9743, 0.0257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,765][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6428, 0.3572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,766][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8720, 0.1280], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,767][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9338, 0.0662], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,768][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,768][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9574, 0.0426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:02,769][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([2.4796e-04, 3.2871e-03, 9.9646e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,770][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.3676, 0.5643, 0.0681], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,771][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.7174, 0.1665, 0.1161], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,773][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.0705, 0.6166, 0.3129], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,774][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.7907, 0.2049, 0.0045], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,776][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.5808, 0.1640, 0.2552], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,777][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.7462, 0.1342, 0.1196], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,779][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.1453, 0.7302, 0.1245], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,781][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.6616, 0.2736, 0.0648], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,782][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.6898, 0.1537, 0.1565], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,784][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.9455, 0.0170, 0.0375], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,785][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.7673, 0.1487, 0.0840], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:02,787][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0045, 0.0807, 0.6871, 0.2277], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,789][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4766, 0.2211, 0.0369, 0.2654], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,790][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4521, 0.0526, 0.1502, 0.3451], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,792][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0623, 0.0554, 0.3370, 0.5453], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,793][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9051, 0.0444, 0.0063, 0.0442], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,795][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5010, 0.1419, 0.1962, 0.1609], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,797][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7972, 0.0179, 0.0954, 0.0895], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,798][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1420, 0.0264, 0.2358, 0.5959], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,800][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4185, 0.0529, 0.0265, 0.5021], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,802][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5499, 0.1348, 0.0720, 0.2432], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,803][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9570, 0.0101, 0.0107, 0.0222], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,805][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.7110, 0.0602, 0.0488, 0.1800], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:02,806][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([5.3931e-04, 6.8135e-03, 4.1208e-01, 1.8907e-02, 5.6167e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,808][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.1087, 0.2535, 0.0355, 0.5795, 0.0229], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,809][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0467, 0.0419, 0.0884, 0.7783, 0.0447], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,810][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0018, 0.0555, 0.0807, 0.8385, 0.0236], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,810][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.5686, 0.1909, 0.0587, 0.1746, 0.0071], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,811][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.3745, 0.1295, 0.1822, 0.1550, 0.1588], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,812][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.2312, 0.0984, 0.1604, 0.4571, 0.0529], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,813][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0068, 0.0721, 0.1055, 0.7894, 0.0262], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,815][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0340, 0.0417, 0.0424, 0.8630, 0.0189], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,816][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.1812, 0.1549, 0.1574, 0.4622, 0.0442], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,818][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.7812, 0.0239, 0.0483, 0.0978, 0.0489], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,820][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.2218, 0.1387, 0.1643, 0.4252, 0.0500], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:02,821][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0010, 0.0310, 0.7237, 0.0575, 0.0679, 0.1190], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,823][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1747, 0.2601, 0.0150, 0.4670, 0.0091, 0.0741], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,824][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1462, 0.0625, 0.0968, 0.5509, 0.0725, 0.0712], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,826][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0123, 0.0378, 0.0817, 0.6966, 0.0298, 0.1418], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,828][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.7162, 0.0863, 0.0114, 0.0787, 0.0098, 0.0976], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,829][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.3762, 0.1127, 0.1407, 0.1441, 0.1255, 0.1008], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,831][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3212, 0.0612, 0.1120, 0.3371, 0.0766, 0.0919], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,832][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0240, 0.0239, 0.1244, 0.4531, 0.1697, 0.2048], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,834][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0961, 0.0699, 0.0274, 0.7177, 0.0148, 0.0741], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,836][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2565, 0.2404, 0.0365, 0.3052, 0.0157, 0.1458], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,837][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.8217, 0.0168, 0.0166, 0.0423, 0.0154, 0.0873], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,839][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.3607, 0.1126, 0.0687, 0.3609, 0.0123, 0.0847], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:02,841][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0035, 0.0373, 0.4101, 0.0880, 0.2549, 0.0348, 0.1715],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,842][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0672, 0.1776, 0.0362, 0.5928, 0.0290, 0.0879, 0.0093],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,844][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0135, 0.0111, 0.1021, 0.4563, 0.0347, 0.3271, 0.0551],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,845][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ working] are: tensor([5.7423e-04, 1.3070e-02, 4.7577e-02, 7.0188e-01, 2.5443e-02, 2.0448e-01,
        6.9780e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,847][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.3381, 0.2220, 0.0449, 0.1763, 0.0219, 0.1929, 0.0041],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,849][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.2985, 0.1063, 0.1377, 0.1277, 0.1211, 0.0932, 0.1155],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,850][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0716, 0.0213, 0.1137, 0.3704, 0.1063, 0.2855, 0.0312],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,851][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0011, 0.0147, 0.0421, 0.5223, 0.0843, 0.3160, 0.0195],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,852][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0077, 0.0235, 0.0295, 0.6709, 0.0144, 0.2422, 0.0118],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,853][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.1119, 0.0643, 0.0312, 0.3817, 0.0075, 0.3728, 0.0307],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,854][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.5947, 0.0427, 0.0521, 0.1097, 0.0363, 0.1021, 0.0624],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,855][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.1691, 0.0837, 0.1652, 0.3614, 0.0363, 0.1547, 0.0295],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:02,856][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0034, 0.0434, 0.3402, 0.0622, 0.2780, 0.0400, 0.0459, 0.1869],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,858][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1278, 0.1391, 0.0188, 0.4705, 0.0100, 0.1377, 0.0174, 0.0787],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,859][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0361, 0.0058, 0.0241, 0.2983, 0.0193, 0.2306, 0.1998, 0.1861],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,861][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0015, 0.0043, 0.0185, 0.2985, 0.0059, 0.2048, 0.0725, 0.3941],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,863][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.3764, 0.2219, 0.0567, 0.1625, 0.0306, 0.1405, 0.0061, 0.0053],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,864][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2770, 0.0900, 0.1272, 0.1089, 0.1106, 0.0776, 0.1180, 0.0908],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,866][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2567, 0.0146, 0.0742, 0.2263, 0.0498, 0.1943, 0.0327, 0.1513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,868][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0067, 0.0026, 0.0203, 0.1533, 0.0176, 0.1769, 0.0590, 0.5635],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,869][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0460, 0.0116, 0.0246, 0.4238, 0.0078, 0.1598, 0.0105, 0.3160],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,871][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1477, 0.0441, 0.0384, 0.3075, 0.0216, 0.3063, 0.0918, 0.0426],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,873][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.7133, 0.0179, 0.0187, 0.0550, 0.0184, 0.0800, 0.0134, 0.0832],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,874][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2102, 0.0449, 0.0899, 0.3040, 0.0257, 0.1746, 0.0611, 0.0895],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:02,876][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0007, 0.0283, 0.4902, 0.0466, 0.2233, 0.0399, 0.0440, 0.0513, 0.0757],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,878][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1095, 0.1056, 0.0235, 0.3462, 0.0109, 0.1234, 0.0140, 0.0792, 0.1876],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,879][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.5522e-02, 6.8726e-04, 5.2791e-03, 6.0610e-02, 4.1885e-03, 5.0987e-02,
        1.5203e-02, 7.1707e-01, 1.3046e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,880][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([3.3829e-04, 5.8655e-04, 7.5198e-03, 4.5962e-02, 2.6993e-03, 4.4080e-02,
        1.3745e-02, 8.3275e-01, 5.2319e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,882][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4341, 0.1839, 0.0383, 0.1480, 0.0167, 0.1600, 0.0032, 0.0039, 0.0119],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,884][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2840, 0.0791, 0.1190, 0.0989, 0.1031, 0.0680, 0.1032, 0.0865, 0.0582],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,885][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1982, 0.0080, 0.0458, 0.1454, 0.0361, 0.1130, 0.0449, 0.2922, 0.1163],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,887][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0032, 0.0015, 0.0080, 0.0631, 0.0085, 0.1086, 0.0194, 0.6164, 0.1713],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,889][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0227, 0.0025, 0.0047, 0.1380, 0.0032, 0.0589, 0.0052, 0.6521, 0.1127],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,890][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1007, 0.0365, 0.0591, 0.2884, 0.0237, 0.1539, 0.0424, 0.1911, 0.1041],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,892][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.7313, 0.0120, 0.0214, 0.0399, 0.0168, 0.0566, 0.0151, 0.0550, 0.0519],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,894][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2346, 0.0275, 0.0814, 0.1909, 0.0228, 0.1396, 0.0367, 0.2063, 0.0602],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:02,894][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0011, 0.0308, 0.3890, 0.0390, 0.1837, 0.0179, 0.0362, 0.0488, 0.0435,
        0.2100], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,895][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0338, 0.0878, 0.0217, 0.3405, 0.0098, 0.1309, 0.0181, 0.0627, 0.2815,
        0.0131], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,896][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([1.7318e-03, 3.2409e-04, 2.1427e-03, 3.4327e-02, 1.0228e-03, 1.6169e-02,
        3.7172e-03, 3.5476e-01, 5.6728e-01, 1.8528e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,897][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([1.5129e-04, 8.4255e-04, 3.1102e-03, 4.7545e-02, 1.6823e-03, 5.0653e-02,
        9.1117e-03, 6.9594e-01, 1.7871e-01, 1.2254e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,899][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.3847, 0.2116, 0.0302, 0.1852, 0.0231, 0.1278, 0.0097, 0.0063, 0.0168,
        0.0045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,900][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.2100, 0.0857, 0.1069, 0.1042, 0.0927, 0.0728, 0.0938, 0.0813, 0.0706,
        0.0821], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,902][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0392, 0.0113, 0.0273, 0.1431, 0.0148, 0.0868, 0.0201, 0.3611, 0.2476,
        0.0486], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,903][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([3.0337e-04, 7.7245e-04, 2.8083e-03, 3.3354e-02, 2.2511e-03, 3.6925e-02,
        6.3922e-03, 5.9328e-01, 3.0324e-01, 2.0676e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,905][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0029, 0.0013, 0.0038, 0.0808, 0.0049, 0.0436, 0.0059, 0.7258, 0.1238,
        0.0073], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,906][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0323, 0.0128, 0.0234, 0.1083, 0.0063, 0.0428, 0.0106, 0.6353, 0.1187,
        0.0097], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,908][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.5476, 0.0169, 0.0268, 0.0708, 0.0252, 0.0743, 0.0183, 0.0929, 0.0628,
        0.0645], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,910][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0725, 0.0268, 0.0714, 0.2082, 0.0173, 0.1245, 0.0270, 0.2721, 0.1456,
        0.0346], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:02,911][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0006, 0.0246, 0.5732, 0.0283, 0.1709, 0.0234, 0.0272, 0.0257, 0.0547,
        0.0422, 0.0292], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,913][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0603, 0.0577, 0.0135, 0.2749, 0.0079, 0.0956, 0.0056, 0.0986, 0.2771,
        0.0081, 0.1007], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,915][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0058, 0.0015, 0.0053, 0.0756, 0.0038, 0.0423, 0.0096, 0.2495, 0.5035,
        0.0544, 0.0487], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,917][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0007, 0.0004, 0.0059, 0.0374, 0.0026, 0.0385, 0.0078, 0.3084, 0.2060,
        0.0598, 0.3325], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,918][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.3217, 0.2286, 0.0477, 0.2131, 0.0212, 0.1250, 0.0033, 0.0048, 0.0113,
        0.0045, 0.0188], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,920][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.2138, 0.0883, 0.0997, 0.0941, 0.0757, 0.0614, 0.0847, 0.0757, 0.0649,
        0.0727, 0.0690], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,922][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0353, 0.0052, 0.0553, 0.1335, 0.0247, 0.0652, 0.0241, 0.2490, 0.1687,
        0.1039, 0.1351], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,923][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([7.0853e-04, 3.3298e-04, 2.5352e-03, 2.6125e-02, 3.0661e-03, 3.5099e-02,
        9.9540e-03, 3.6152e-01, 2.6227e-01, 9.6558e-02, 2.0183e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,925][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0093, 0.0020, 0.0032, 0.0964, 0.0018, 0.0371, 0.0050, 0.4212, 0.2045,
        0.0510, 0.1684], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,926][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0817, 0.0314, 0.0587, 0.2152, 0.0299, 0.1283, 0.0153, 0.1147, 0.1191,
        0.0428, 0.1629], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,928][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.6019, 0.0210, 0.0271, 0.0499, 0.0232, 0.0629, 0.0153, 0.0483, 0.0496,
        0.0348, 0.0661], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,930][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0583, 0.0180, 0.0498, 0.1718, 0.0129, 0.0846, 0.0307, 0.2027, 0.1064,
        0.0980, 0.1669], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:02,932][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0008, 0.0116, 0.2146, 0.0184, 0.4676, 0.0114, 0.0263, 0.0234, 0.0211,
        0.0262, 0.0227, 0.1559], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,933][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0265, 0.0481, 0.0087, 0.2531, 0.0071, 0.0627, 0.0114, 0.0761, 0.2320,
        0.0259, 0.2375, 0.0109], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,935][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0021, 0.0011, 0.0064, 0.0936, 0.0036, 0.0622, 0.0124, 0.1686, 0.4405,
        0.0366, 0.1399, 0.0331], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,936][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([1.3640e-04, 9.8571e-04, 3.8766e-03, 5.6263e-02, 1.3510e-03, 3.2977e-02,
        7.0835e-03, 3.4832e-01, 1.0142e-01, 2.2884e-02, 3.8305e-01, 4.1652e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,937][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.1252, 0.2779, 0.1120, 0.2260, 0.0133, 0.1692, 0.0058, 0.0135, 0.0214,
        0.0118, 0.0209, 0.0030], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,938][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.1826, 0.0769, 0.0898, 0.0838, 0.0740, 0.0634, 0.0807, 0.0737, 0.0590,
        0.0770, 0.0689, 0.0702], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,939][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0361, 0.0098, 0.0340, 0.1185, 0.0119, 0.0356, 0.0313, 0.1442, 0.0721,
        0.0385, 0.3745, 0.0935], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,940][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([2.8779e-04, 1.2063e-03, 3.2131e-03, 3.6215e-02, 6.8473e-04, 5.3100e-02,
        6.4707e-03, 2.7048e-01, 2.4990e-01, 7.2692e-02, 2.9850e-01, 7.2503e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,942][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0039, 0.0028, 0.0090, 0.1345, 0.0026, 0.0688, 0.0074, 0.3494, 0.1036,
        0.0605, 0.2358, 0.0217], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,943][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0564, 0.0234, 0.0504, 0.2074, 0.0151, 0.1000, 0.0099, 0.1026, 0.1538,
        0.0144, 0.2161, 0.0504], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,945][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.3937, 0.0193, 0.0537, 0.0706, 0.0526, 0.0875, 0.0184, 0.0499, 0.0642,
        0.0194, 0.0894, 0.0813], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,946][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0474, 0.0168, 0.0455, 0.1299, 0.0110, 0.0847, 0.0364, 0.1685, 0.1326,
        0.0945, 0.2062, 0.0267], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:02,948][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0008, 0.0211, 0.2839, 0.0440, 0.0908, 0.0191, 0.0330, 0.0413, 0.0982,
        0.0408, 0.0452, 0.0595, 0.2224], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,950][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0571, 0.1236, 0.0126, 0.3727, 0.0048, 0.0649, 0.0034, 0.0188, 0.1337,
        0.0046, 0.1285, 0.0058, 0.0697], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,952][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0062, 0.0024, 0.0087, 0.0878, 0.0105, 0.0610, 0.0051, 0.1309, 0.3038,
        0.0240, 0.0971, 0.0965, 0.1659], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,953][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0017, 0.0026, 0.0101, 0.1360, 0.0028, 0.0507, 0.0050, 0.1166, 0.0922,
        0.0094, 0.4301, 0.0293, 0.1135], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,955][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.2714, 0.2246, 0.0232, 0.2019, 0.0377, 0.1620, 0.0089, 0.0047, 0.0133,
        0.0083, 0.0291, 0.0053, 0.0095], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,957][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.1779, 0.0692, 0.0781, 0.0887, 0.0703, 0.0685, 0.0787, 0.0691, 0.0516,
        0.0606, 0.0608, 0.0618, 0.0648], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,959][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0518, 0.0072, 0.0455, 0.1168, 0.0268, 0.0667, 0.0224, 0.0847, 0.0620,
        0.0368, 0.2015, 0.1607, 0.1172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,960][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0013, 0.0016, 0.0078, 0.0678, 0.0092, 0.0435, 0.0068, 0.2288, 0.1028,
        0.0397, 0.2273, 0.0992, 0.1643], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,962][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0164, 0.0101, 0.0146, 0.3466, 0.0038, 0.0814, 0.0067, 0.1090, 0.0753,
        0.0401, 0.2084, 0.0169, 0.0707], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,964][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0517, 0.0530, 0.0134, 0.2282, 0.0093, 0.1221, 0.0060, 0.0439, 0.0647,
        0.0127, 0.2515, 0.0135, 0.1299], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,966][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.5084, 0.0165, 0.0213, 0.0446, 0.0154, 0.0909, 0.0157, 0.0275, 0.0365,
        0.0156, 0.0564, 0.0286, 0.1226], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,967][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.1258, 0.0336, 0.0334, 0.2121, 0.0069, 0.0900, 0.0111, 0.0760, 0.0443,
        0.0321, 0.1521, 0.0079, 0.1746], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:02,969][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0006, 0.0286, 0.2773, 0.0426, 0.1951, 0.0376, 0.0474, 0.0409, 0.0492,
        0.0469, 0.0268, 0.0724, 0.0825, 0.0520], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,971][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2175, 0.0377, 0.0078, 0.1178, 0.0022, 0.0332, 0.0019, 0.0134, 0.0488,
        0.0029, 0.0495, 0.0027, 0.0617, 0.4028], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,972][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.5948e-02, 2.8438e-04, 1.6688e-03, 1.4500e-02, 7.1783e-04, 1.1840e-02,
        1.5544e-03, 1.5812e-02, 3.8597e-02, 1.5970e-03, 6.9842e-03, 6.1418e-03,
        8.1917e-02, 7.9244e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,973][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.8292e-04, 2.6454e-05, 2.2866e-04, 1.8585e-03, 3.6225e-05, 2.3768e-03,
        1.1466e-04, 2.0505e-03, 1.2120e-03, 1.8797e-04, 3.3021e-03, 3.7962e-04,
        4.2043e-02, 9.4540e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,975][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3725, 0.1517, 0.0337, 0.1577, 0.0190, 0.1926, 0.0031, 0.0043, 0.0105,
        0.0042, 0.0149, 0.0024, 0.0206, 0.0126], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,977][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1936, 0.0602, 0.0756, 0.0710, 0.0630, 0.0505, 0.0682, 0.0594, 0.0470,
        0.0557, 0.0627, 0.0688, 0.0621, 0.0620], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,978][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1275, 0.0010, 0.0045, 0.0179, 0.0036, 0.0081, 0.0024, 0.0103, 0.0079,
        0.0060, 0.0169, 0.0149, 0.0237, 0.7552], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,979][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.7591e-03, 4.5248e-05, 2.2023e-04, 1.9786e-03, 1.9451e-04, 2.4959e-03,
        3.9489e-04, 5.1069e-03, 3.2789e-03, 1.6146e-03, 5.3132e-03, 2.1104e-03,
        3.1078e-02, 9.4441e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,980][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.4099e-02, 3.8248e-04, 2.9071e-04, 1.4033e-02, 1.9406e-04, 5.8611e-03,
        2.8508e-04, 6.2656e-03, 3.9920e-03, 1.1449e-03, 8.2184e-03, 1.0187e-03,
        2.4428e-02, 9.0979e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,981][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1738, 0.0113, 0.0227, 0.0768, 0.0051, 0.0671, 0.0085, 0.0114, 0.0260,
        0.0069, 0.0566, 0.0092, 0.2653, 0.2594], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,982][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.6828, 0.0067, 0.0075, 0.0163, 0.0059, 0.0355, 0.0050, 0.0186, 0.0111,
        0.0053, 0.0174, 0.0084, 0.0400, 0.1395], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,984][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1654, 0.0061, 0.0100, 0.0490, 0.0017, 0.0196, 0.0062, 0.0258, 0.0147,
        0.0040, 0.0312, 0.0030, 0.1917, 0.4713], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:02,986][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0008, 0.0235, 0.4796, 0.0406, 0.1127, 0.0183, 0.0275, 0.0179, 0.0441,
        0.0510, 0.0269, 0.0298, 0.0479, 0.0319, 0.0473], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,988][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1322, 0.0192, 0.0031, 0.0672, 0.0013, 0.0186, 0.0010, 0.0066, 0.0270,
        0.0016, 0.0303, 0.0018, 0.0536, 0.4236, 0.2130], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,989][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([3.8927e-03, 2.2293e-05, 1.4991e-04, 1.3900e-03, 1.0391e-04, 7.6222e-04,
        6.3199e-05, 2.8726e-03, 3.7862e-03, 2.6765e-04, 9.1231e-04, 8.3917e-04,
        5.0536e-03, 7.9615e-01, 1.8374e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,990][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([2.5098e-04, 1.2200e-05, 2.6233e-05, 8.1078e-04, 1.1893e-05, 3.5359e-04,
        1.1017e-05, 5.4776e-04, 2.5993e-04, 5.6571e-05, 1.0982e-03, 6.9550e-05,
        2.4647e-03, 8.2212e-01, 1.7191e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,992][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.3164, 0.1900, 0.0310, 0.1438, 0.0137, 0.2215, 0.0046, 0.0035, 0.0105,
        0.0111, 0.0123, 0.0017, 0.0251, 0.0095, 0.0055], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,994][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.1573, 0.0544, 0.0695, 0.0677, 0.0616, 0.0507, 0.0688, 0.0580, 0.0436,
        0.0556, 0.0614, 0.0663, 0.0572, 0.0591, 0.0689], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,995][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([3.9075e-02, 2.7856e-04, 1.2680e-03, 4.3194e-03, 8.4485e-04, 2.6238e-03,
        7.3388e-04, 4.5067e-03, 1.7841e-03, 1.7880e-03, 5.8796e-03, 4.8099e-03,
        1.0800e-02, 8.1083e-01, 1.1046e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,996][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([8.3334e-04, 1.9455e-05, 1.0742e-04, 7.3453e-04, 7.3265e-05, 9.2710e-04,
        1.1778e-04, 1.4627e-03, 8.4288e-04, 3.0142e-04, 2.5510e-03, 5.8206e-04,
        7.2681e-03, 6.2260e-01, 3.6158e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,998][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([4.3795e-03, 9.8601e-05, 6.9237e-05, 3.2979e-03, 4.4525e-05, 1.4659e-03,
        1.2045e-04, 3.5806e-03, 1.4271e-03, 1.1362e-03, 3.3453e-03, 2.6336e-04,
        1.7108e-02, 7.9103e-01, 1.7263e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:02,999][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0766, 0.0067, 0.0042, 0.0328, 0.0024, 0.0257, 0.0020, 0.0172, 0.0103,
        0.0017, 0.0277, 0.0047, 0.0948, 0.5157, 0.1775], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,001][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.6139, 0.0103, 0.0119, 0.0252, 0.0067, 0.0431, 0.0061, 0.0151, 0.0160,
        0.0077, 0.0205, 0.0102, 0.0446, 0.0783, 0.0904], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,003][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0981, 0.0037, 0.0039, 0.0212, 0.0013, 0.0117, 0.0033, 0.0155, 0.0051,
        0.0032, 0.0158, 0.0021, 0.0739, 0.4810, 0.2600], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,004][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0007, 0.0147, 0.6402, 0.0140, 0.0683, 0.0137, 0.0148, 0.0232, 0.0420,
        0.0383, 0.0153, 0.0375, 0.0215, 0.0252, 0.0118, 0.0189],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,006][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0935, 0.0107, 0.0018, 0.0381, 0.0008, 0.0089, 0.0008, 0.0035, 0.0160,
        0.0009, 0.0191, 0.0011, 0.0180, 0.2605, 0.1914, 0.3348],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,008][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.3212e-03, 4.9717e-06, 4.4404e-05, 4.4364e-04, 1.6446e-05, 2.9687e-04,
        5.6619e-05, 1.7685e-03, 1.3882e-03, 1.9812e-04, 3.2644e-04, 1.7677e-04,
        2.6711e-03, 2.7649e-01, 4.7815e-01, 2.3464e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,009][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([6.7886e-05, 1.3112e-06, 5.7474e-06, 9.2849e-05, 2.0068e-06, 1.1282e-04,
        1.7628e-05, 4.2071e-04, 5.4898e-05, 2.3202e-05, 2.1753e-04, 2.3474e-05,
        1.2760e-03, 2.0517e-01, 6.0480e-01, 1.8772e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,011][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4372, 0.1781, 0.0344, 0.1455, 0.0170, 0.1132, 0.0034, 0.0038, 0.0099,
        0.0042, 0.0133, 0.0021, 0.0121, 0.0089, 0.0066, 0.0105],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,012][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1738, 0.0493, 0.0663, 0.0599, 0.0559, 0.0428, 0.0607, 0.0499, 0.0376,
        0.0498, 0.0543, 0.0615, 0.0554, 0.0502, 0.0649, 0.0676],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,014][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([4.6582e-02, 1.5121e-04, 8.7993e-04, 3.0204e-03, 5.2419e-04, 2.1445e-03,
        4.5995e-04, 2.5815e-03, 1.0335e-03, 2.2190e-03, 4.7809e-03, 2.6534e-03,
        6.7506e-03, 3.9093e-01, 2.2034e-01, 3.1495e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,015][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.0020e-04, 1.1348e-06, 4.7676e-06, 6.5141e-05, 5.5999e-06, 1.0388e-04,
        1.4198e-05, 3.7050e-04, 1.8273e-04, 1.1469e-04, 2.8865e-04, 8.3388e-05,
        3.0427e-03, 1.2966e-01, 6.3634e-01, 2.2952e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,016][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([3.8629e-03, 2.1115e-05, 2.6205e-05, 8.9938e-04, 1.1962e-05, 3.9720e-04,
        1.4361e-05, 1.9424e-03, 2.8456e-04, 1.2463e-04, 9.7381e-04, 1.1605e-04,
        4.0521e-03, 3.7387e-01, 4.3380e-01, 1.7961e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,018][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.4379e-02, 9.7701e-04, 1.8131e-03, 1.0155e-02, 4.7688e-04, 4.7390e-03,
        1.0138e-03, 6.2636e-03, 2.7734e-03, 1.0832e-03, 6.4359e-03, 8.6963e-04,
        1.8108e-02, 1.3581e-01, 6.9051e-01, 9.4588e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,019][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6200, 0.0058, 0.0068, 0.0146, 0.0045, 0.0156, 0.0038, 0.0123, 0.0105,
        0.0067, 0.0127, 0.0066, 0.0238, 0.0677, 0.0564, 0.1320],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,020][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0919, 0.0010, 0.0017, 0.0078, 0.0004, 0.0036, 0.0011, 0.0052, 0.0031,
        0.0008, 0.0072, 0.0008, 0.0304, 0.2909, 0.3852, 0.1689],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,021][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0066, 0.0260, 0.5183, 0.0256, 0.0893, 0.0117, 0.0164, 0.0253, 0.0338,
        0.1060, 0.0163, 0.0479, 0.0144, 0.0286, 0.0123, 0.0136, 0.0079],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,022][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0428, 0.0095, 0.0028, 0.0322, 0.0012, 0.0105, 0.0006, 0.0038, 0.0181,
        0.0012, 0.0195, 0.0017, 0.0154, 0.2402, 0.1283, 0.4159, 0.0563],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,023][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([5.3981e-04, 3.1870e-06, 1.7322e-05, 2.8493e-04, 5.5800e-06, 2.3947e-04,
        9.4978e-06, 6.8875e-04, 6.9690e-04, 4.3952e-05, 1.9816e-04, 4.9463e-05,
        1.1552e-03, 1.7586e-01, 2.0315e-01, 5.6619e-01, 5.0862e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,024][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([2.6539e-05, 3.9390e-06, 8.8894e-06, 1.3818e-04, 2.9780e-06, 1.5616e-04,
        8.6346e-06, 3.0846e-04, 1.7641e-04, 2.0134e-05, 4.9774e-04, 3.2430e-05,
        1.4994e-03, 2.3365e-01, 2.4524e-01, 4.5384e-01, 6.4380e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,026][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.5038, 0.1987, 0.0125, 0.1452, 0.0149, 0.0528, 0.0069, 0.0036, 0.0104,
        0.0042, 0.0091, 0.0018, 0.0041, 0.0092, 0.0083, 0.0132, 0.0012],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,028][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.1278, 0.0497, 0.0621, 0.0619, 0.0539, 0.0487, 0.0611, 0.0495, 0.0428,
        0.0450, 0.0460, 0.0551, 0.0472, 0.0496, 0.0642, 0.0676, 0.0679],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,029][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([1.4264e-02, 1.6760e-04, 7.4524e-04, 2.3451e-03, 3.5734e-04, 1.3899e-03,
        4.7869e-04, 2.7715e-03, 8.6753e-04, 1.3463e-03, 3.4021e-03, 1.3121e-03,
        4.2968e-03, 3.2721e-01, 1.5834e-01, 3.5771e-01, 1.2299e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,030][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([6.2435e-05, 3.4172e-06, 1.3675e-05, 1.2376e-04, 6.3598e-06, 1.6652e-04,
        1.1650e-05, 7.0303e-04, 4.5315e-04, 7.8610e-05, 5.3942e-04, 5.3007e-05,
        1.0082e-03, 1.0478e-01, 4.0483e-01, 4.3362e-01, 5.3549e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,032][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([8.6254e-04, 2.9263e-05, 5.1041e-05, 1.0986e-03, 3.2854e-05, 7.7868e-04,
        3.3348e-05, 1.9620e-03, 3.5196e-04, 6.2144e-05, 8.3546e-04, 2.1814e-04,
        2.8006e-03, 2.3097e-01, 5.8678e-01, 1.4553e-01, 2.7606e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,033][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0255, 0.0011, 0.0026, 0.0086, 0.0008, 0.0039, 0.0006, 0.0040, 0.0060,
        0.0007, 0.0103, 0.0018, 0.0092, 0.1675, 0.4460, 0.2282, 0.0831],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,035][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.5055, 0.0070, 0.0099, 0.0163, 0.0046, 0.0287, 0.0041, 0.0125, 0.0102,
        0.0075, 0.0162, 0.0068, 0.0251, 0.0520, 0.1099, 0.1051, 0.0785],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,037][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0173, 0.0010, 0.0018, 0.0078, 0.0005, 0.0021, 0.0008, 0.0048, 0.0035,
        0.0007, 0.0074, 0.0009, 0.0222, 0.1484, 0.3284, 0.3241, 0.1281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,039][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0036, 0.0272, 0.4045, 0.0290, 0.1221, 0.0205, 0.0246, 0.0338, 0.0390,
        0.0592, 0.0245, 0.0621, 0.0393, 0.0595, 0.0212, 0.0188, 0.0038, 0.0073],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,040][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3928e-01, 8.6289e-03, 1.7963e-03, 2.7745e-02, 5.1653e-04, 7.9770e-03,
        3.2379e-04, 2.4469e-03, 1.0351e-02, 5.3205e-04, 9.8823e-03, 5.0796e-04,
        1.0805e-02, 8.8410e-02, 1.0146e-01, 2.0715e-01, 4.9738e-02, 3.3245e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,041][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.5353e-03, 2.6415e-06, 1.7672e-05, 1.7317e-04, 7.7688e-06, 1.6429e-04,
        1.7351e-05, 1.8432e-04, 4.4839e-04, 1.9299e-05, 5.5488e-05, 5.4580e-05,
        8.5028e-04, 9.1383e-03, 2.2446e-01, 2.5595e-01, 7.0813e-02, 4.3511e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,043][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.6059e-04, 3.3528e-07, 2.1882e-06, 2.6414e-05, 3.3893e-07, 3.7505e-05,
        1.2926e-06, 2.6607e-05, 1.6817e-05, 2.1808e-06, 3.3175e-05, 2.9219e-06,
        4.2678e-04, 1.0934e-02, 1.0059e-01, 9.5002e-02, 3.4053e-02, 7.5869e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,044][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4914, 0.1336, 0.0260, 0.1202, 0.0119, 0.1336, 0.0023, 0.0035, 0.0082,
        0.0033, 0.0108, 0.0015, 0.0171, 0.0097, 0.0085, 0.0088, 0.0026, 0.0068],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,046][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1499, 0.0444, 0.0564, 0.0583, 0.0472, 0.0429, 0.0521, 0.0463, 0.0396,
        0.0401, 0.0436, 0.0496, 0.0429, 0.0480, 0.0588, 0.0647, 0.0640, 0.0513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,048][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.5031e-02, 6.4595e-05, 3.5655e-04, 1.2118e-03, 2.9009e-04, 5.6775e-04,
        1.7765e-04, 6.7967e-04, 4.7460e-04, 5.4565e-04, 9.7211e-04, 9.2997e-04,
        1.3919e-03, 4.6311e-02, 2.8869e-02, 1.5807e-01, 9.9759e-02, 6.1430e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,049][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.2965e-04, 4.1200e-07, 1.8910e-06, 2.2359e-05, 1.5023e-06, 3.6133e-05,
        3.8112e-06, 5.5259e-05, 3.4278e-05, 1.9956e-05, 3.9853e-05, 1.2347e-05,
        3.2982e-04, 9.6172e-03, 1.4341e-01, 8.5385e-02, 9.9719e-02, 6.6108e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,050][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([6.6326e-03, 1.6815e-05, 1.5982e-05, 6.0120e-04, 9.7885e-06, 3.0695e-04,
        1.0494e-05, 2.8405e-04, 1.6033e-04, 4.4713e-05, 2.6480e-04, 3.7017e-05,
        8.3474e-04, 3.4372e-02, 1.2005e-01, 6.2154e-02, 7.9509e-02, 6.9470e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,052][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.1220e-02, 9.9167e-04, 2.0146e-03, 7.8773e-03, 4.0171e-04, 6.5445e-03,
        8.3303e-04, 1.0142e-03, 2.6025e-03, 5.5726e-04, 4.6976e-03, 6.5867e-04,
        1.5474e-02, 2.0829e-02, 5.8316e-01, 1.1230e-01, 7.7325e-02, 1.1150e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,054][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.5872, 0.0031, 0.0031, 0.0070, 0.0021, 0.0123, 0.0018, 0.0074, 0.0044,
        0.0019, 0.0066, 0.0027, 0.0114, 0.0517, 0.0468, 0.0461, 0.0300, 0.1744],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,055][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.4655e-02, 5.5398e-04, 8.2836e-04, 5.2648e-03, 1.6130e-04, 1.8003e-03,
        6.3074e-04, 2.4671e-03, 1.4285e-03, 3.5921e-04, 2.7045e-03, 2.1654e-04,
        1.4524e-02, 4.0696e-02, 2.2812e-01, 1.6057e-01, 1.3637e-01, 3.3864e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,106][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:03,107][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,108][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,109][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,109][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,110][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,111][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,111][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,113][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,114][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,115][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,116][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,118][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,119][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8080, 0.1920], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,121][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7864, 0.2136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,123][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9686, 0.0314], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,124][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1334, 0.8666], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,126][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9817, 0.0183], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,127][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9750, 0.0250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,129][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9743, 0.0257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,130][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6428, 0.3572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,132][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8720, 0.1280], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,134][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9338, 0.0662], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,135][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,137][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9574, 0.0426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,138][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.1300, 0.0846, 0.7854], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,140][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.3676, 0.5643, 0.0681], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,142][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.7174, 0.1665, 0.1161], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,143][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.0705, 0.6166, 0.3129], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,145][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.7907, 0.2049, 0.0045], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,146][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.7936, 0.1100, 0.0964], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,148][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.7462, 0.1342, 0.1196], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,149][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.1453, 0.7302, 0.1245], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,150][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.6616, 0.2736, 0.0648], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,150][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.6898, 0.1537, 0.1565], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,151][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.9455, 0.0170, 0.0375], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,153][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.7673, 0.1487, 0.0840], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,154][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6286, 0.2185, 0.0315, 0.1215], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,156][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4766, 0.2211, 0.0369, 0.2654], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,157][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4521, 0.0526, 0.1502, 0.3451], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,159][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0623, 0.0554, 0.3370, 0.5453], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,160][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9051, 0.0444, 0.0063, 0.0442], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,162][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8699, 0.0575, 0.0300, 0.0427], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,164][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7972, 0.0179, 0.0954, 0.0895], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,165][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1420, 0.0264, 0.2358, 0.5959], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,167][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4185, 0.0529, 0.0265, 0.5021], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,169][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5499, 0.1348, 0.0720, 0.2432], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,170][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9570, 0.0101, 0.0107, 0.0222], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,172][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7110, 0.0602, 0.0488, 0.1800], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,173][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.1968, 0.1445, 0.0275, 0.0661, 0.5651], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,175][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.1087, 0.2535, 0.0355, 0.5795, 0.0229], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,177][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0467, 0.0419, 0.0884, 0.7783, 0.0447], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,178][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0018, 0.0555, 0.0807, 0.8385, 0.0236], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,180][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.5686, 0.1909, 0.0587, 0.1746, 0.0071], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,182][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.5841, 0.0978, 0.1346, 0.1237, 0.0598], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,183][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.2312, 0.0984, 0.1604, 0.4571, 0.0529], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,185][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0068, 0.0721, 0.1055, 0.7894, 0.0262], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,187][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0340, 0.0417, 0.0424, 0.8630, 0.0189], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,188][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.1812, 0.1549, 0.1574, 0.4622, 0.0442], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,190][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.7812, 0.0239, 0.0483, 0.0978, 0.0489], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,191][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.2218, 0.1387, 0.1643, 0.4252, 0.0500], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,192][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.3272, 0.1423, 0.0216, 0.0695, 0.0059, 0.4334], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,192][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.1747, 0.2601, 0.0150, 0.4670, 0.0091, 0.0741], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,193][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1462, 0.0625, 0.0968, 0.5509, 0.0725, 0.0712], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,195][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0123, 0.0378, 0.0817, 0.6966, 0.0298, 0.1418], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,196][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.7162, 0.0863, 0.0114, 0.0787, 0.0098, 0.0976], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,198][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.6112, 0.0896, 0.0437, 0.1510, 0.0257, 0.0788], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,200][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.3212, 0.0612, 0.1120, 0.3371, 0.0766, 0.0919], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,201][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0240, 0.0239, 0.1244, 0.4531, 0.1697, 0.2048], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,203][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0961, 0.0699, 0.0274, 0.7177, 0.0148, 0.0741], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,205][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.2565, 0.2404, 0.0365, 0.3052, 0.0157, 0.1458], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,206][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.8217, 0.0168, 0.0166, 0.0423, 0.0154, 0.0873], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,208][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.3607, 0.1126, 0.0687, 0.3609, 0.0123, 0.0847], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,210][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.1611, 0.2554, 0.0077, 0.0987, 0.0284, 0.1288, 0.3199],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,211][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.0672, 0.1776, 0.0362, 0.5928, 0.0290, 0.0879, 0.0093],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,213][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0135, 0.0111, 0.1021, 0.4563, 0.0347, 0.3271, 0.0551],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,214][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([5.7423e-04, 1.3070e-02, 4.7577e-02, 7.0188e-01, 2.5443e-02, 2.0448e-01,
        6.9780e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,216][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.3381, 0.2220, 0.0449, 0.1763, 0.0219, 0.1929, 0.0041],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,217][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.5624, 0.0784, 0.0822, 0.1216, 0.0337, 0.0960, 0.0257],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,219][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0716, 0.0213, 0.1137, 0.3704, 0.1063, 0.2855, 0.0312],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,221][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0011, 0.0147, 0.0421, 0.5223, 0.0843, 0.3160, 0.0195],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,222][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0077, 0.0235, 0.0295, 0.6709, 0.0144, 0.2422, 0.0118],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,224][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.1119, 0.0643, 0.0312, 0.3817, 0.0075, 0.3728, 0.0307],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,226][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.5947, 0.0427, 0.0521, 0.1097, 0.0363, 0.1021, 0.0624],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,227][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.1691, 0.0837, 0.1652, 0.3614, 0.0363, 0.1547, 0.0295],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,229][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1100, 0.3192, 0.0336, 0.1448, 0.0697, 0.1084, 0.0217, 0.1926],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,231][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1278, 0.1391, 0.0188, 0.4705, 0.0100, 0.1377, 0.0174, 0.0787],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,232][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0361, 0.0058, 0.0241, 0.2983, 0.0193, 0.2306, 0.1998, 0.1861],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,233][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0015, 0.0043, 0.0185, 0.2985, 0.0059, 0.2048, 0.0725, 0.3941],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,234][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3764, 0.2219, 0.0567, 0.1625, 0.0306, 0.1405, 0.0061, 0.0053],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,235][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.6008, 0.0667, 0.0677, 0.0924, 0.0389, 0.0571, 0.0400, 0.0365],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,236][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2567, 0.0146, 0.0742, 0.2263, 0.0498, 0.1943, 0.0327, 0.1513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,237][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0067, 0.0026, 0.0203, 0.1533, 0.0176, 0.1769, 0.0590, 0.5635],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,239][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0460, 0.0116, 0.0246, 0.4238, 0.0078, 0.1598, 0.0105, 0.3160],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,241][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1477, 0.0441, 0.0384, 0.3075, 0.0216, 0.3063, 0.0918, 0.0426],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,242][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.7133, 0.0179, 0.0187, 0.0550, 0.0184, 0.0800, 0.0134, 0.0832],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,244][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2102, 0.0449, 0.0899, 0.3040, 0.0257, 0.1746, 0.0611, 0.0895],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,245][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0868, 0.2595, 0.0681, 0.1547, 0.0436, 0.2623, 0.0145, 0.0236, 0.0869],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,247][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1095, 0.1056, 0.0235, 0.3462, 0.0109, 0.1234, 0.0140, 0.0792, 0.1876],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,248][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.5522e-02, 6.8726e-04, 5.2791e-03, 6.0610e-02, 4.1885e-03, 5.0987e-02,
        1.5203e-02, 7.1707e-01, 1.3046e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,249][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.3829e-04, 5.8655e-04, 7.5198e-03, 4.5962e-02, 2.6993e-03, 4.4080e-02,
        1.3745e-02, 8.3275e-01, 5.2319e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,251][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4341, 0.1839, 0.0383, 0.1480, 0.0167, 0.1600, 0.0032, 0.0039, 0.0119],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,253][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5224, 0.0709, 0.0540, 0.1074, 0.0330, 0.0678, 0.0259, 0.0483, 0.0702],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,255][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1982, 0.0080, 0.0458, 0.1454, 0.0361, 0.1130, 0.0449, 0.2922, 0.1163],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,256][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0032, 0.0015, 0.0080, 0.0631, 0.0085, 0.1086, 0.0194, 0.6164, 0.1713],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,258][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0227, 0.0025, 0.0047, 0.1380, 0.0032, 0.0589, 0.0052, 0.6521, 0.1127],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,260][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1007, 0.0365, 0.0591, 0.2884, 0.0237, 0.1539, 0.0424, 0.1911, 0.1041],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,261][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.7313, 0.0120, 0.0214, 0.0399, 0.0168, 0.0566, 0.0151, 0.0550, 0.0519],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,263][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2346, 0.0275, 0.0814, 0.1909, 0.0228, 0.1396, 0.0367, 0.2063, 0.0602],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,265][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0523, 0.2589, 0.0279, 0.1039, 0.0285, 0.0539, 0.0268, 0.0203, 0.0348,
        0.3926], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,267][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0338, 0.0878, 0.0217, 0.3405, 0.0098, 0.1309, 0.0181, 0.0627, 0.2815,
        0.0131], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,268][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([1.7318e-03, 3.2409e-04, 2.1427e-03, 3.4327e-02, 1.0228e-03, 1.6169e-02,
        3.7172e-03, 3.5476e-01, 5.6728e-01, 1.8528e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,269][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([1.5129e-04, 8.4255e-04, 3.1102e-03, 4.7545e-02, 1.6823e-03, 5.0653e-02,
        9.1117e-03, 6.9594e-01, 1.7871e-01, 1.2254e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,271][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.3847, 0.2116, 0.0302, 0.1852, 0.0231, 0.1278, 0.0097, 0.0063, 0.0168,
        0.0045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,272][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.2846, 0.0954, 0.0797, 0.1449, 0.0416, 0.0935, 0.0433, 0.0617, 0.1263,
        0.0290], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,274][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0392, 0.0113, 0.0273, 0.1431, 0.0148, 0.0868, 0.0201, 0.3611, 0.2476,
        0.0486], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,275][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([3.0337e-04, 7.7245e-04, 2.8083e-03, 3.3354e-02, 2.2511e-03, 3.6925e-02,
        6.3922e-03, 5.9328e-01, 3.0324e-01, 2.0676e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,276][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0029, 0.0013, 0.0038, 0.0808, 0.0049, 0.0436, 0.0059, 0.7258, 0.1238,
        0.0073], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,277][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0323, 0.0128, 0.0234, 0.1083, 0.0063, 0.0428, 0.0106, 0.6353, 0.1187,
        0.0097], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,278][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.5476, 0.0169, 0.0268, 0.0708, 0.0252, 0.0743, 0.0183, 0.0929, 0.0628,
        0.0645], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,279][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0725, 0.0268, 0.0714, 0.2082, 0.0173, 0.1245, 0.0270, 0.2721, 0.1456,
        0.0346], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,281][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0448, 0.2579, 0.2388, 0.1575, 0.0765, 0.1043, 0.0174, 0.0127, 0.0249,
        0.0087, 0.0565], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,282][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0603, 0.0577, 0.0135, 0.2749, 0.0079, 0.0956, 0.0056, 0.0986, 0.2771,
        0.0081, 0.1007], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,284][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0058, 0.0015, 0.0053, 0.0756, 0.0038, 0.0423, 0.0096, 0.2495, 0.5035,
        0.0544, 0.0487], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,286][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0007, 0.0004, 0.0059, 0.0374, 0.0026, 0.0385, 0.0078, 0.3084, 0.2060,
        0.0598, 0.3325], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,287][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3217, 0.2286, 0.0477, 0.2131, 0.0212, 0.1250, 0.0033, 0.0048, 0.0113,
        0.0045, 0.0188], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,289][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.4758, 0.0734, 0.0417, 0.1085, 0.0180, 0.0663, 0.0233, 0.0458, 0.0773,
        0.0217, 0.0482], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,291][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0353, 0.0052, 0.0553, 0.1335, 0.0247, 0.0652, 0.0241, 0.2490, 0.1687,
        0.1039, 0.1351], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,292][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([7.0853e-04, 3.3298e-04, 2.5352e-03, 2.6125e-02, 3.0661e-03, 3.5099e-02,
        9.9540e-03, 3.6152e-01, 2.6227e-01, 9.6558e-02, 2.0183e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,294][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0093, 0.0020, 0.0032, 0.0964, 0.0018, 0.0371, 0.0050, 0.4212, 0.2045,
        0.0510, 0.1684], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,296][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0817, 0.0314, 0.0587, 0.2152, 0.0299, 0.1283, 0.0153, 0.1147, 0.1191,
        0.0428, 0.1629], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,297][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.6019, 0.0210, 0.0271, 0.0499, 0.0232, 0.0629, 0.0153, 0.0483, 0.0496,
        0.0348, 0.0661], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,299][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0583, 0.0180, 0.0498, 0.1718, 0.0129, 0.0846, 0.0307, 0.2027, 0.1064,
        0.0980, 0.1669], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,301][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0179, 0.0845, 0.0277, 0.0387, 0.6137, 0.0125, 0.0031, 0.0034, 0.0059,
        0.0023, 0.0235, 0.1669], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,302][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0265, 0.0481, 0.0087, 0.2531, 0.0071, 0.0627, 0.0114, 0.0761, 0.2320,
        0.0259, 0.2375, 0.0109], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,304][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0021, 0.0011, 0.0064, 0.0936, 0.0036, 0.0622, 0.0124, 0.1686, 0.4405,
        0.0366, 0.1399, 0.0331], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,305][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([1.3640e-04, 9.8571e-04, 3.8766e-03, 5.6263e-02, 1.3510e-03, 3.2977e-02,
        7.0835e-03, 3.4832e-01, 1.0142e-01, 2.2884e-02, 3.8305e-01, 4.1652e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,307][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.1252, 0.2779, 0.1120, 0.2260, 0.0133, 0.1692, 0.0058, 0.0135, 0.0214,
        0.0118, 0.0209, 0.0030], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,309][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.3475, 0.0435, 0.0712, 0.0943, 0.0211, 0.0916, 0.0195, 0.0663, 0.0934,
        0.0351, 0.0992, 0.0172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,311][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0361, 0.0098, 0.0340, 0.1185, 0.0119, 0.0356, 0.0313, 0.1442, 0.0721,
        0.0385, 0.3745, 0.0935], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,312][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([2.8779e-04, 1.2063e-03, 3.2131e-03, 3.6215e-02, 6.8473e-04, 5.3100e-02,
        6.4707e-03, 2.7048e-01, 2.4990e-01, 7.2692e-02, 2.9850e-01, 7.2503e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,313][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0039, 0.0028, 0.0090, 0.1345, 0.0026, 0.0688, 0.0074, 0.3494, 0.1036,
        0.0605, 0.2358, 0.0217], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,315][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0564, 0.0234, 0.0504, 0.2074, 0.0151, 0.1000, 0.0099, 0.1026, 0.1538,
        0.0144, 0.2161, 0.0504], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,317][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.3937, 0.0193, 0.0537, 0.0706, 0.0526, 0.0875, 0.0184, 0.0499, 0.0642,
        0.0194, 0.0894, 0.0813], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,317][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0474, 0.0168, 0.0455, 0.1299, 0.0110, 0.0847, 0.0364, 0.1685, 0.1326,
        0.0945, 0.2062, 0.0267], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,318][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0363, 0.0895, 0.0078, 0.0593, 0.0089, 0.0427, 0.0039, 0.0091, 0.0110,
        0.0023, 0.0210, 0.0020, 0.7063], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,319][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0571, 0.1236, 0.0126, 0.3727, 0.0048, 0.0649, 0.0034, 0.0188, 0.1337,
        0.0046, 0.1285, 0.0058, 0.0697], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,321][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0062, 0.0024, 0.0087, 0.0878, 0.0105, 0.0610, 0.0051, 0.1309, 0.3038,
        0.0240, 0.0971, 0.0965, 0.1659], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,322][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0017, 0.0026, 0.0101, 0.1360, 0.0028, 0.0507, 0.0050, 0.1166, 0.0922,
        0.0094, 0.4301, 0.0293, 0.1135], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,324][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.2714, 0.2246, 0.0232, 0.2019, 0.0377, 0.1620, 0.0089, 0.0047, 0.0133,
        0.0083, 0.0291, 0.0053, 0.0095], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,326][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.2885, 0.0640, 0.0426, 0.1180, 0.0150, 0.1193, 0.0277, 0.0578, 0.0791,
        0.0150, 0.0705, 0.0053, 0.0974], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,327][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0518, 0.0072, 0.0455, 0.1168, 0.0268, 0.0667, 0.0224, 0.0847, 0.0620,
        0.0368, 0.2015, 0.1607, 0.1172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,329][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0013, 0.0016, 0.0078, 0.0678, 0.0092, 0.0435, 0.0068, 0.2288, 0.1028,
        0.0397, 0.2273, 0.0992, 0.1643], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,331][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0164, 0.0101, 0.0146, 0.3466, 0.0038, 0.0814, 0.0067, 0.1090, 0.0753,
        0.0401, 0.2084, 0.0169, 0.0707], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,333][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0517, 0.0530, 0.0134, 0.2282, 0.0093, 0.1221, 0.0060, 0.0439, 0.0647,
        0.0127, 0.2515, 0.0135, 0.1299], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,334][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.5084, 0.0165, 0.0213, 0.0446, 0.0154, 0.0909, 0.0157, 0.0275, 0.0365,
        0.0156, 0.0564, 0.0286, 0.1226], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,336][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.1258, 0.0336, 0.0334, 0.2121, 0.0069, 0.0900, 0.0111, 0.0760, 0.0443,
        0.0321, 0.1521, 0.0079, 0.1746], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,338][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0623, 0.2143, 0.0501, 0.1514, 0.0412, 0.0969, 0.0234, 0.0154, 0.0235,
        0.0134, 0.0577, 0.0142, 0.1754, 0.0608], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,340][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2175, 0.0377, 0.0078, 0.1178, 0.0022, 0.0332, 0.0019, 0.0134, 0.0488,
        0.0029, 0.0495, 0.0027, 0.0617, 0.4028], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,341][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.5948e-02, 2.8438e-04, 1.6688e-03, 1.4500e-02, 7.1783e-04, 1.1840e-02,
        1.5544e-03, 1.5812e-02, 3.8597e-02, 1.5970e-03, 6.9842e-03, 6.1418e-03,
        8.1917e-02, 7.9244e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,342][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.8292e-04, 2.6454e-05, 2.2866e-04, 1.8585e-03, 3.6225e-05, 2.3768e-03,
        1.1466e-04, 2.0505e-03, 1.2120e-03, 1.8797e-04, 3.3021e-03, 3.7962e-04,
        4.2043e-02, 9.4540e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,344][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3725, 0.1517, 0.0337, 0.1577, 0.0190, 0.1926, 0.0031, 0.0043, 0.0105,
        0.0042, 0.0149, 0.0024, 0.0206, 0.0126], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,346][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5679, 0.0379, 0.0205, 0.0561, 0.0078, 0.0380, 0.0083, 0.0204, 0.0385,
        0.0068, 0.0280, 0.0044, 0.0324, 0.1329], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,347][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1275, 0.0010, 0.0045, 0.0179, 0.0036, 0.0081, 0.0024, 0.0103, 0.0079,
        0.0060, 0.0169, 0.0149, 0.0237, 0.7552], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,349][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.7591e-03, 4.5248e-05, 2.2023e-04, 1.9786e-03, 1.9451e-04, 2.4959e-03,
        3.9489e-04, 5.1069e-03, 3.2789e-03, 1.6146e-03, 5.3132e-03, 2.1104e-03,
        3.1078e-02, 9.4441e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,350][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.4099e-02, 3.8248e-04, 2.9071e-04, 1.4033e-02, 1.9406e-04, 5.8611e-03,
        2.8508e-04, 6.2656e-03, 3.9920e-03, 1.1449e-03, 8.2184e-03, 1.0187e-03,
        2.4428e-02, 9.0979e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,352][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1738, 0.0113, 0.0227, 0.0768, 0.0051, 0.0671, 0.0085, 0.0114, 0.0260,
        0.0069, 0.0566, 0.0092, 0.2653, 0.2594], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,353][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6828, 0.0067, 0.0075, 0.0163, 0.0059, 0.0355, 0.0050, 0.0186, 0.0111,
        0.0053, 0.0174, 0.0084, 0.0400, 0.1395], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,355][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1654, 0.0061, 0.0100, 0.0490, 0.0017, 0.0196, 0.0062, 0.0258, 0.0147,
        0.0040, 0.0312, 0.0030, 0.1917, 0.4713], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,357][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0842, 0.2296, 0.0088, 0.1305, 0.0070, 0.0423, 0.0357, 0.0148, 0.0217,
        0.0354, 0.0605, 0.0023, 0.0486, 0.0319, 0.2467], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,359][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1322, 0.0192, 0.0031, 0.0672, 0.0013, 0.0186, 0.0010, 0.0066, 0.0270,
        0.0016, 0.0303, 0.0018, 0.0536, 0.4236, 0.2130], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,360][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([3.8927e-03, 2.2293e-05, 1.4991e-04, 1.3900e-03, 1.0391e-04, 7.6222e-04,
        6.3199e-05, 2.8726e-03, 3.7862e-03, 2.6765e-04, 9.1231e-04, 8.3917e-04,
        5.0536e-03, 7.9615e-01, 1.8374e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,360][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([2.5098e-04, 1.2200e-05, 2.6233e-05, 8.1078e-04, 1.1893e-05, 3.5359e-04,
        1.1017e-05, 5.4776e-04, 2.5993e-04, 5.6571e-05, 1.0982e-03, 6.9550e-05,
        2.4647e-03, 8.2212e-01, 1.7191e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,361][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.3164, 0.1900, 0.0310, 0.1438, 0.0137, 0.2215, 0.0046, 0.0035, 0.0105,
        0.0111, 0.0123, 0.0017, 0.0251, 0.0095, 0.0055], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,362][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.5148, 0.0416, 0.0253, 0.0745, 0.0107, 0.0396, 0.0106, 0.0246, 0.0238,
        0.0088, 0.0316, 0.0048, 0.0251, 0.1272, 0.0370], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,363][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([3.9075e-02, 2.7856e-04, 1.2680e-03, 4.3194e-03, 8.4485e-04, 2.6238e-03,
        7.3388e-04, 4.5067e-03, 1.7841e-03, 1.7880e-03, 5.8796e-03, 4.8099e-03,
        1.0800e-02, 8.1083e-01, 1.1046e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,365][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([8.3334e-04, 1.9455e-05, 1.0742e-04, 7.3453e-04, 7.3265e-05, 9.2710e-04,
        1.1778e-04, 1.4627e-03, 8.4288e-04, 3.0142e-04, 2.5510e-03, 5.8206e-04,
        7.2681e-03, 6.2260e-01, 3.6158e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,366][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([4.3795e-03, 9.8601e-05, 6.9237e-05, 3.2979e-03, 4.4525e-05, 1.4659e-03,
        1.2045e-04, 3.5806e-03, 1.4271e-03, 1.1362e-03, 3.3453e-03, 2.6336e-04,
        1.7108e-02, 7.9103e-01, 1.7263e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,368][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0766, 0.0067, 0.0042, 0.0328, 0.0024, 0.0257, 0.0020, 0.0172, 0.0103,
        0.0017, 0.0277, 0.0047, 0.0948, 0.5157, 0.1775], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,370][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.6139, 0.0103, 0.0119, 0.0252, 0.0067, 0.0431, 0.0061, 0.0151, 0.0160,
        0.0077, 0.0205, 0.0102, 0.0446, 0.0783, 0.0904], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,371][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0981, 0.0037, 0.0039, 0.0212, 0.0013, 0.0117, 0.0033, 0.0155, 0.0051,
        0.0032, 0.0158, 0.0021, 0.0739, 0.4810, 0.2600], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,373][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0429, 0.1506, 0.3758, 0.0952, 0.0225, 0.0847, 0.0085, 0.0179, 0.0179,
        0.0172, 0.0311, 0.0071, 0.0532, 0.0134, 0.0063, 0.0558],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,375][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0935, 0.0107, 0.0018, 0.0381, 0.0008, 0.0089, 0.0008, 0.0035, 0.0160,
        0.0009, 0.0191, 0.0011, 0.0180, 0.2605, 0.1914, 0.3348],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,376][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.3212e-03, 4.9717e-06, 4.4404e-05, 4.4364e-04, 1.6446e-05, 2.9687e-04,
        5.6619e-05, 1.7685e-03, 1.3882e-03, 1.9812e-04, 3.2644e-04, 1.7677e-04,
        2.6711e-03, 2.7649e-01, 4.7815e-01, 2.3464e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,378][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.7886e-05, 1.3112e-06, 5.7474e-06, 9.2849e-05, 2.0068e-06, 1.1282e-04,
        1.7628e-05, 4.2071e-04, 5.4898e-05, 2.3202e-05, 2.1753e-04, 2.3474e-05,
        1.2760e-03, 2.0517e-01, 6.0480e-01, 1.8772e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,379][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4372, 0.1781, 0.0344, 0.1455, 0.0170, 0.1132, 0.0034, 0.0038, 0.0099,
        0.0042, 0.0133, 0.0021, 0.0121, 0.0089, 0.0066, 0.0105],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,381][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5079, 0.0348, 0.0181, 0.0476, 0.0074, 0.0299, 0.0073, 0.0158, 0.0304,
        0.0080, 0.0251, 0.0052, 0.0264, 0.1142, 0.0397, 0.0820],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,382][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.6582e-02, 1.5121e-04, 8.7993e-04, 3.0204e-03, 5.2419e-04, 2.1445e-03,
        4.5995e-04, 2.5815e-03, 1.0335e-03, 2.2190e-03, 4.7809e-03, 2.6534e-03,
        6.7506e-03, 3.9093e-01, 2.2034e-01, 3.1495e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,384][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.0020e-04, 1.1348e-06, 4.7676e-06, 6.5141e-05, 5.5999e-06, 1.0388e-04,
        1.4198e-05, 3.7050e-04, 1.8273e-04, 1.1469e-04, 2.8865e-04, 8.3388e-05,
        3.0427e-03, 1.2966e-01, 6.3634e-01, 2.2952e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,385][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.8629e-03, 2.1115e-05, 2.6205e-05, 8.9938e-04, 1.1962e-05, 3.9720e-04,
        1.4361e-05, 1.9424e-03, 2.8456e-04, 1.2463e-04, 9.7381e-04, 1.1605e-04,
        4.0521e-03, 3.7387e-01, 4.3380e-01, 1.7961e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,386][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.4379e-02, 9.7701e-04, 1.8131e-03, 1.0155e-02, 4.7688e-04, 4.7390e-03,
        1.0138e-03, 6.2636e-03, 2.7734e-03, 1.0832e-03, 6.4359e-03, 8.6963e-04,
        1.8108e-02, 1.3581e-01, 6.9051e-01, 9.4588e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,388][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6200, 0.0058, 0.0068, 0.0146, 0.0045, 0.0156, 0.0038, 0.0123, 0.0105,
        0.0067, 0.0127, 0.0066, 0.0238, 0.0677, 0.0564, 0.1320],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,390][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0919, 0.0010, 0.0017, 0.0078, 0.0004, 0.0036, 0.0011, 0.0052, 0.0031,
        0.0008, 0.0072, 0.0008, 0.0304, 0.2909, 0.3852, 0.1689],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,391][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0539, 0.2496, 0.0332, 0.1230, 0.0114, 0.0506, 0.0108, 0.0091, 0.0237,
        0.0753, 0.0393, 0.0041, 0.0121, 0.0182, 0.0116, 0.0278, 0.2462],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,393][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0428, 0.0095, 0.0028, 0.0322, 0.0012, 0.0105, 0.0006, 0.0038, 0.0181,
        0.0012, 0.0195, 0.0017, 0.0154, 0.2402, 0.1283, 0.4159, 0.0563],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,395][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([5.3981e-04, 3.1870e-06, 1.7322e-05, 2.8493e-04, 5.5800e-06, 2.3947e-04,
        9.4978e-06, 6.8875e-04, 6.9690e-04, 4.3952e-05, 1.9816e-04, 4.9463e-05,
        1.1552e-03, 1.7586e-01, 2.0315e-01, 5.6619e-01, 5.0862e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,396][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([2.6539e-05, 3.9390e-06, 8.8894e-06, 1.3818e-04, 2.9780e-06, 1.5616e-04,
        8.6346e-06, 3.0846e-04, 1.7641e-04, 2.0134e-05, 4.9774e-04, 3.2430e-05,
        1.4994e-03, 2.3365e-01, 2.4524e-01, 4.5384e-01, 6.4380e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,398][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.5038, 0.1987, 0.0125, 0.1452, 0.0149, 0.0528, 0.0069, 0.0036, 0.0104,
        0.0042, 0.0091, 0.0018, 0.0041, 0.0092, 0.0083, 0.0132, 0.0012],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,399][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.3757, 0.0410, 0.0408, 0.0595, 0.0144, 0.0429, 0.0119, 0.0192, 0.0305,
        0.0081, 0.0173, 0.0084, 0.0335, 0.1240, 0.0665, 0.0920, 0.0142],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,401][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([1.4264e-02, 1.6760e-04, 7.4524e-04, 2.3451e-03, 3.5734e-04, 1.3899e-03,
        4.7869e-04, 2.7715e-03, 8.6753e-04, 1.3463e-03, 3.4021e-03, 1.3121e-03,
        4.2968e-03, 3.2721e-01, 1.5834e-01, 3.5771e-01, 1.2299e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,402][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([6.2435e-05, 3.4172e-06, 1.3675e-05, 1.2376e-04, 6.3598e-06, 1.6652e-04,
        1.1650e-05, 7.0303e-04, 4.5315e-04, 7.8610e-05, 5.3942e-04, 5.3007e-05,
        1.0082e-03, 1.0478e-01, 4.0483e-01, 4.3362e-01, 5.3549e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,403][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([8.6254e-04, 2.9263e-05, 5.1041e-05, 1.0986e-03, 3.2854e-05, 7.7868e-04,
        3.3348e-05, 1.9620e-03, 3.5196e-04, 6.2144e-05, 8.3546e-04, 2.1814e-04,
        2.8006e-03, 2.3097e-01, 5.8678e-01, 1.4553e-01, 2.7606e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,403][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0255, 0.0011, 0.0026, 0.0086, 0.0008, 0.0039, 0.0006, 0.0040, 0.0060,
        0.0007, 0.0103, 0.0018, 0.0092, 0.1675, 0.4460, 0.2282, 0.0831],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,405][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.5055, 0.0070, 0.0099, 0.0163, 0.0046, 0.0287, 0.0041, 0.0125, 0.0102,
        0.0075, 0.0162, 0.0068, 0.0251, 0.0520, 0.1099, 0.1051, 0.0785],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,407][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0173, 0.0010, 0.0018, 0.0078, 0.0005, 0.0021, 0.0008, 0.0048, 0.0035,
        0.0007, 0.0074, 0.0009, 0.0222, 0.1484, 0.3284, 0.3241, 0.1281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,409][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0758, 0.1812, 0.0309, 0.1462, 0.0228, 0.0811, 0.0207, 0.0170, 0.0230,
        0.0129, 0.0582, 0.0080, 0.1413, 0.0647, 0.0444, 0.0233, 0.0074, 0.0410],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,410][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3928e-01, 8.6289e-03, 1.7963e-03, 2.7745e-02, 5.1653e-04, 7.9770e-03,
        3.2379e-04, 2.4469e-03, 1.0351e-02, 5.3205e-04, 9.8823e-03, 5.0796e-04,
        1.0805e-02, 8.8410e-02, 1.0146e-01, 2.0715e-01, 4.9738e-02, 3.3245e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,412][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.5353e-03, 2.6415e-06, 1.7672e-05, 1.7317e-04, 7.7688e-06, 1.6429e-04,
        1.7351e-05, 1.8432e-04, 4.4839e-04, 1.9299e-05, 5.5488e-05, 5.4580e-05,
        8.5028e-04, 9.1383e-03, 2.2446e-01, 2.5595e-01, 7.0813e-02, 4.3511e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,413][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6059e-04, 3.3528e-07, 2.1882e-06, 2.6414e-05, 3.3893e-07, 3.7505e-05,
        1.2926e-06, 2.6607e-05, 1.6817e-05, 2.1808e-06, 3.3175e-05, 2.9219e-06,
        4.2678e-04, 1.0934e-02, 1.0059e-01, 9.5002e-02, 3.4053e-02, 7.5869e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,415][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4914, 0.1336, 0.0260, 0.1202, 0.0119, 0.1336, 0.0023, 0.0035, 0.0082,
        0.0033, 0.0108, 0.0015, 0.0171, 0.0097, 0.0085, 0.0088, 0.0026, 0.0068],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,417][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5760, 0.0224, 0.0136, 0.0308, 0.0043, 0.0209, 0.0043, 0.0105, 0.0212,
        0.0033, 0.0130, 0.0024, 0.0164, 0.0765, 0.0341, 0.0643, 0.0086, 0.0774],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,418][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.5031e-02, 6.4595e-05, 3.5655e-04, 1.2118e-03, 2.9009e-04, 5.6775e-04,
        1.7765e-04, 6.7967e-04, 4.7460e-04, 5.4565e-04, 9.7211e-04, 9.2997e-04,
        1.3919e-03, 4.6311e-02, 2.8869e-02, 1.5807e-01, 9.9759e-02, 6.1430e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,419][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.2965e-04, 4.1200e-07, 1.8910e-06, 2.2359e-05, 1.5023e-06, 3.6133e-05,
        3.8112e-06, 5.5259e-05, 3.4278e-05, 1.9956e-05, 3.9853e-05, 1.2347e-05,
        3.2982e-04, 9.6172e-03, 1.4341e-01, 8.5385e-02, 9.9719e-02, 6.6108e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,421][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.6326e-03, 1.6815e-05, 1.5982e-05, 6.0120e-04, 9.7885e-06, 3.0695e-04,
        1.0494e-05, 2.8405e-04, 1.6033e-04, 4.4713e-05, 2.6480e-04, 3.7017e-05,
        8.3474e-04, 3.4372e-02, 1.2005e-01, 6.2154e-02, 7.9509e-02, 6.9470e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,422][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.1220e-02, 9.9167e-04, 2.0146e-03, 7.8773e-03, 4.0171e-04, 6.5445e-03,
        8.3303e-04, 1.0142e-03, 2.6025e-03, 5.5726e-04, 4.6976e-03, 6.5867e-04,
        1.5474e-02, 2.0829e-02, 5.8316e-01, 1.1230e-01, 7.7325e-02, 1.1150e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,424][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5872, 0.0031, 0.0031, 0.0070, 0.0021, 0.0123, 0.0018, 0.0074, 0.0044,
        0.0019, 0.0066, 0.0027, 0.0114, 0.0517, 0.0468, 0.0461, 0.0300, 0.1744],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,425][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.4655e-02, 5.5398e-04, 8.2836e-04, 5.2648e-03, 1.6130e-04, 1.8003e-03,
        6.3074e-04, 2.4671e-03, 1.4285e-03, 3.5921e-04, 2.7045e-03, 2.1654e-04,
        1.4524e-02, 4.0696e-02, 2.2812e-01, 1.6057e-01, 1.3637e-01, 3.3864e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,429][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:03,431][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8793],
        [18422],
        [17812],
        [23363],
        [11639],
        [19560],
        [35865],
        [19286],
        [17486],
        [21981],
        [19498],
        [ 4471],
        [20346],
        [ 9332],
        [11465],
        [13757],
        [23787],
        [ 8098]], device='cuda:0')
[2024-07-24 10:26:03,433][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11329],
        [11374],
        [11100],
        [13589],
        [ 3505],
        [ 8566],
        [23797],
        [10853],
        [ 9997],
        [18538],
        [12505],
        [ 1590],
        [11764],
        [ 5960],
        [ 6005],
        [ 7972],
        [18782],
        [ 5334]], device='cuda:0')
[2024-07-24 10:26:03,434][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40594],
        [31686],
        [33861],
        [32749],
        [30247],
        [32362],
        [29995],
        [31002],
        [31620],
        [31262],
        [32336],
        [31149],
        [32730],
        [31957],
        [32619],
        [33324],
        [32934],
        [32824]], device='cuda:0')
[2024-07-24 10:26:03,436][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13777],
        [27065],
        [41395],
        [35492],
        [39033],
        [38114],
        [37573],
        [37346],
        [37819],
        [37910],
        [36102],
        [33313],
        [36476],
        [22927],
        [22086],
        [31050],
        [33877],
        [26140]], device='cuda:0')
[2024-07-24 10:26:03,438][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[47016],
        [46831],
        [45287],
        [48514],
        [49018],
        [48606],
        [47492],
        [41371],
        [26507],
        [32972],
        [39660],
        [44679],
        [40264],
        [21665],
        [21961],
        [28764],
        [29014],
        [25534]], device='cuda:0')
[2024-07-24 10:26:03,440][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8313],
        [41423],
        [41656],
        [31812],
        [26968],
        [24411],
        [22878],
        [18126],
        [14659],
        [14881],
        [14008],
        [13490],
        [17824],
        [ 9857],
        [11003],
        [17659],
        [ 9816],
        [ 9086]], device='cuda:0')
[2024-07-24 10:26:03,442][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9776],
        [10981],
        [24849],
        [14263],
        [28011],
        [23771],
        [34161],
        [33481],
        [31920],
        [32444],
        [33467],
        [35806],
        [34580],
        [32133],
        [33992],
        [31398],
        [30092],
        [29802]], device='cuda:0')
[2024-07-24 10:26:03,444][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24038],
        [22546],
        [23790],
        [23175],
        [23506],
        [22575],
        [21049],
        [20530],
        [20447],
        [19669],
        [19522],
        [19695],
        [20079],
        [20237],
        [20358],
        [20451],
        [20536],
        [20720]], device='cuda:0')
[2024-07-24 10:26:03,446][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 7876],
        [ 7737],
        [10393],
        [ 7021],
        [ 2082],
        [ 2796],
        [ 3182],
        [ 1595],
        [  735],
        [  443],
        [  961],
        [ 1419],
        [ 2394],
        [ 2155],
        [ 2906],
        [ 5274],
        [ 5955],
        [ 2683]], device='cuda:0')
[2024-07-24 10:26:03,447][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[1311],
        [1480],
        [2674],
        [6336],
        [6698],
        [3222],
        [2459],
        [1592],
        [1412],
        [1319],
        [ 782],
        [ 633],
        [ 564],
        [1098],
        [ 961],
        [1009],
        [ 817],
        [1527]], device='cuda:0')
[2024-07-24 10:26:03,449][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[8104],
        [4469],
        [1042],
        [ 505],
        [ 192],
        [ 169],
        [  76],
        [ 148],
        [ 450],
        [ 572],
        [ 234],
        [ 217],
        [ 169],
        [1306],
        [1101],
        [ 820],
        [1112],
        [ 663]], device='cuda:0')
[2024-07-24 10:26:03,451][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17314],
        [14795],
        [ 6971],
        [ 9728],
        [ 7682],
        [ 8235],
        [11556],
        [11054],
        [ 7735],
        [ 8276],
        [ 5116],
        [ 5422],
        [ 6752],
        [ 7232],
        [ 6683],
        [18588],
        [11715],
        [16238]], device='cuda:0')
[2024-07-24 10:26:03,453][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[36619],
        [36654],
        [35929],
        [36366],
        [33825],
        [36410],
        [37032],
        [38745],
        [38699],
        [39270],
        [38208],
        [35605],
        [40744],
        [42188],
        [40949],
        [42944],
        [43938],
        [45533]], device='cuda:0')
[2024-07-24 10:26:03,455][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[46235],
        [46417],
        [47109],
        [47601],
        [48583],
        [47759],
        [47512],
        [47338],
        [47827],
        [48315],
        [48166],
        [48009],
        [47394],
        [46025],
        [45116],
        [43457],
        [43521],
        [45663]], device='cuda:0')
[2024-07-24 10:26:03,456][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16050],
        [18730],
        [22014],
        [24372],
        [24954],
        [27423],
        [27659],
        [22794],
        [23585],
        [23781],
        [21926],
        [20889],
        [22112],
        [18111],
        [21596],
        [19116],
        [19735],
        [15081]], device='cuda:0')
[2024-07-24 10:26:03,458][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43511],
        [44197],
        [30147],
        [44698],
        [30419],
        [46561],
        [43827],
        [44753],
        [45804],
        [32315],
        [43589],
        [25780],
        [36770],
        [45107],
        [43981],
        [40093],
        [42047],
        [45238]], device='cuda:0')
[2024-07-24 10:26:03,460][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 3209],
        [ 5257],
        [19492],
        [12349],
        [18049],
        [17554],
        [16530],
        [15653],
        [17545],
        [19209],
        [20859],
        [22973],
        [21213],
        [15152],
        [15642],
        [18469],
        [21886],
        [18341]], device='cuda:0')
[2024-07-24 10:26:03,462][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 47],
        [ 45],
        [ 69],
        [ 91],
        [105],
        [ 98],
        [ 87],
        [109],
        [492],
        [240],
        [158],
        [114],
        [102],
        [510],
        [416],
        [164],
        [399],
        [362]], device='cuda:0')
[2024-07-24 10:26:03,464][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1864],
        [3500],
        [6384],
        [4003],
        [ 822],
        [1037],
        [ 904],
        [2555],
        [6514],
        [5749],
        [3564],
        [3562],
        [1809],
        [4572],
        [4874],
        [3995],
        [5176],
        [3536]], device='cuda:0')
[2024-07-24 10:26:03,466][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[11609],
        [11878],
        [15224],
        [13510],
        [22497],
        [21176],
        [31257],
        [30057],
        [29289],
        [29797],
        [30295],
        [33371],
        [31502],
        [30664],
        [32071],
        [28456],
        [25739],
        [27637]], device='cuda:0')
[2024-07-24 10:26:03,468][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[39909],
        [40221],
        [39971],
        [39771],
        [35918],
        [39157],
        [38729],
        [38318],
        [36760],
        [33132],
        [35746],
        [33638],
        [33356],
        [35292],
        [34912],
        [31666],
        [29706],
        [30746]], device='cuda:0')
[2024-07-24 10:26:03,469][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10380],
        [10301],
        [10647],
        [11013],
        [11130],
        [11759],
        [13315],
        [14488],
        [16902],
        [16998],
        [15223],
        [11519],
        [16332],
        [10631],
        [11239],
        [13555],
        [12917],
        [11329]], device='cuda:0')
[2024-07-24 10:26:03,471][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9098],
        [ 8865],
        [ 8751],
        [10274],
        [ 9766],
        [12297],
        [12957],
        [14433],
        [13171],
        [12219],
        [13652],
        [13828],
        [14567],
        [13671],
        [19136],
        [18315],
        [15116],
        [16998]], device='cuda:0')
[2024-07-24 10:26:03,473][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 7940],
        [ 7122],
        [ 6289],
        [10488],
        [12748],
        [12266],
        [12266],
        [ 9667],
        [ 7479],
        [ 6914],
        [ 7808],
        [ 6948],
        [ 8265],
        [10284],
        [ 9213],
        [ 7050],
        [ 5340],
        [10510]], device='cuda:0')
[2024-07-24 10:26:03,475][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 7663],
        [ 7793],
        [11761],
        [ 5404],
        [ 4984],
        [ 5981],
        [ 7006],
        [ 6568],
        [ 9018],
        [17466],
        [ 6979],
        [ 6713],
        [ 5812],
        [ 6980],
        [ 6851],
        [15318],
        [16060],
        [16154]], device='cuda:0')
[2024-07-24 10:26:03,477][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13920],
        [14004],
        [14610],
        [16054],
        [26115],
        [20262],
        [24011],
        [17221],
        [16415],
        [14498],
        [16080],
        [20093],
        [17487],
        [11057],
        [ 9632],
        [ 7723],
        [ 5716],
        [ 5296]], device='cuda:0')
[2024-07-24 10:26:03,479][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5118],
        [ 5411],
        [ 6935],
        [ 7341],
        [11246],
        [10116],
        [12292],
        [11939],
        [11041],
        [10655],
        [ 9584],
        [ 9141],
        [11335],
        [17879],
        [22047],
        [25678],
        [26738],
        [24374]], device='cuda:0')
[2024-07-24 10:26:03,481][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[40675],
        [40649],
        [39352],
        [38393],
        [39582],
        [37466],
        [36061],
        [35982],
        [31574],
        [32566],
        [35117],
        [37872],
        [37361],
        [32168],
        [31636],
        [34983],
        [34045],
        [31587]], device='cuda:0')
[2024-07-24 10:26:03,483][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12770],
        [29203],
        [14315],
        [26791],
        [36325],
        [31249],
        [37046],
        [36066],
        [35444],
        [26734],
        [33761],
        [27542],
        [27184],
        [36385],
        [34177],
        [26302],
        [29344],
        [32303]], device='cuda:0')
[2024-07-24 10:26:03,485][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565],
        [18565]], device='cuda:0')
[2024-07-24 10:26:03,546][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:03,547][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,549][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,550][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,551][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,551][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,552][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,553][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,553][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,554][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,555][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,555][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,556][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,557][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8866, 0.1134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,557][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2550, 0.7450], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,558][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2789, 0.7211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,559][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9834, 0.0166], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,560][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([9.9990e-01, 9.6799e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,561][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5309, 0.4691], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,562][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9347, 0.0653], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,562][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3014, 0.6986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,563][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9270, 0.0730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,564][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9778, 0.0222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,565][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9974, 0.0026], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,565][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.0000e+00, 1.5959e-22], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,566][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.0151, 0.9565, 0.0284], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,567][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.1280, 0.4099, 0.4620], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,567][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.2395, 0.5762, 0.1843], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,569][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.0578, 0.8649, 0.0773], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,571][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.9264, 0.0046, 0.0690], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,572][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.1579, 0.5407, 0.3014], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,574][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.4270, 0.5567, 0.0162], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,576][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.0042, 0.9458, 0.0500], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,577][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.5091, 0.3152, 0.1757], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,579][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.2555, 0.5669, 0.1776], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,580][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.6615, 0.1396, 0.1989], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,582][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0183, 0.9705, 0.0113], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,583][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0555, 0.7329, 0.0162, 0.1954], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,585][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0892, 0.2738, 0.3154, 0.3217], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,587][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1327, 0.4301, 0.1452, 0.2921], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,588][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2280, 0.2990, 0.1481, 0.3249], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,589][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([9.8721e-01, 8.5828e-04, 1.1470e-02, 4.6600e-04], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,591][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1119, 0.1937, 0.5125, 0.1820], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,593][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4585, 0.1981, 0.3005, 0.0429], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,594][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0018, 0.3308, 0.0070, 0.6604], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,596][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7195, 0.1108, 0.0911, 0.0785], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,598][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6278, 0.2019, 0.1022, 0.0681], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,599][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7398, 0.0634, 0.0413, 0.1555], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,600][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([8.6894e-01, 1.6005e-10, 1.3106e-01, 4.7685e-13], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,601][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([6.8428e-04, 7.2459e-01, 2.2866e-03, 2.7163e-01, 8.0479e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,603][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0580, 0.1917, 0.2201, 0.2324, 0.2979], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,604][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0846, 0.2602, 0.1270, 0.2485, 0.2797], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,605][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0090, 0.4142, 0.0170, 0.5525, 0.0073], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,605][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.9000, 0.0095, 0.0680, 0.0060, 0.0165], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,606][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0735, 0.2236, 0.2209, 0.2875, 0.1945], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,607][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.2278, 0.3836, 0.0490, 0.3333, 0.0064], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,608][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0009, 0.3120, 0.0103, 0.4742, 0.2026], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,610][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.1272, 0.3038, 0.1463, 0.2382, 0.1846], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,612][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0989, 0.4205, 0.0837, 0.3620, 0.0349], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,613][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.2449, 0.2475, 0.1048, 0.3852, 0.0176], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,614][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([5.2142e-01, 2.8351e-04, 4.7698e-01, 1.3147e-03, 2.5821e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,616][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0036, 0.6493, 0.0117, 0.3038, 0.0156, 0.0161], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,618][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0487, 0.1596, 0.1840, 0.1907, 0.2489, 0.1680], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,619][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0753, 0.2261, 0.1024, 0.2268, 0.2141, 0.1553], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,621][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0018, 0.3511, 0.0158, 0.5586, 0.0579, 0.0147], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,622][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.7928, 0.0087, 0.0711, 0.0125, 0.0107, 0.1042], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,624][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0649, 0.1332, 0.3210, 0.3158, 0.1338, 0.0313], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,626][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3875, 0.1981, 0.1604, 0.1404, 0.1066, 0.0069], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,627][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ were] are: tensor([2.2510e-04, 4.1730e-01, 4.6979e-03, 4.6134e-01, 1.0642e-01, 1.0019e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,628][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.3236, 0.1226, 0.1150, 0.1467, 0.1185, 0.1735], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,630][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0604, 0.3727, 0.0799, 0.2822, 0.1106, 0.0941], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,632][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2703, 0.1037, 0.0893, 0.2216, 0.0498, 0.2653], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,633][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ were] are: tensor([1.0002e-05, 1.2912e-01, 1.5136e-02, 4.4658e-02, 8.0826e-01, 2.8226e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,634][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ working] are: tensor([2.9653e-05, 4.4328e-01, 4.0110e-04, 5.5350e-01, 6.2348e-04, 1.2592e-03,
        9.1178e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,636][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0366, 0.1353, 0.1516, 0.1664, 0.2145, 0.1443, 0.1513],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,637][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0605, 0.2112, 0.0867, 0.1737, 0.2102, 0.1814, 0.0763],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,639][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ working] are: tensor([2.0272e-04, 1.9824e-01, 4.8459e-03, 7.1214e-01, 7.6070e-02, 5.1315e-03,
        3.3689e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,640][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.7920, 0.0191, 0.0537, 0.0122, 0.0061, 0.1032, 0.0137],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,642][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0439, 0.1536, 0.2565, 0.2365, 0.1152, 0.0403, 0.1540],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,643][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.1646, 0.1897, 0.3080, 0.1215, 0.0948, 0.1188, 0.0027],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,645][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ working] are: tensor([5.1007e-05, 4.3360e-01, 1.7319e-03, 4.1457e-01, 5.1873e-02, 2.7146e-03,
        9.5456e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,646][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.1833, 0.1402, 0.0890, 0.1467, 0.1042, 0.1352, 0.2014],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,647][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0110, 0.5325, 0.0204, 0.3246, 0.0430, 0.0491, 0.0193],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,648][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0147, 0.5604, 0.0111, 0.3742, 0.0084, 0.0298, 0.0015],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,648][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ working] are: tensor([8.4715e-06, 4.5505e-04, 9.2149e-02, 4.7652e-03, 1.7870e-02, 8.8475e-01,
        3.3476e-08], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:03,650][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([2.4435e-04, 6.0771e-01, 1.1354e-03, 3.6328e-01, 5.1344e-04, 3.5108e-03,
        9.0486e-03, 1.4552e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,651][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0349, 0.1190, 0.1219, 0.1424, 0.1771, 0.1187, 0.1186, 0.1673],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,653][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0506, 0.1852, 0.0679, 0.1561, 0.1635, 0.1675, 0.0618, 0.1474],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,654][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0031, 0.2281, 0.0194, 0.6203, 0.0407, 0.0209, 0.0151, 0.0523],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,656][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.7553, 0.0317, 0.0706, 0.0159, 0.0153, 0.1013, 0.0023, 0.0076],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,658][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0408, 0.1403, 0.2260, 0.2215, 0.0847, 0.0466, 0.1287, 0.1114],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,659][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2697, 0.1311, 0.2472, 0.1248, 0.0831, 0.0889, 0.0481, 0.0071],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,661][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.3299e-04, 3.1639e-01, 1.6499e-03, 2.2204e-01, 2.6702e-02, 3.1313e-03,
        7.1423e-02, 3.5853e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,662][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1517, 0.1072, 0.0790, 0.1082, 0.0935, 0.0864, 0.1664, 0.2075],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,664][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0471, 0.4675, 0.0420, 0.2687, 0.0244, 0.0852, 0.0243, 0.0408],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,666][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0181, 0.3864, 0.0159, 0.5029, 0.0128, 0.0546, 0.0012, 0.0081],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,667][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([7.8259e-04, 3.0349e-07, 3.6503e-01, 3.4940e-06, 5.8911e-04, 6.3360e-01,
        5.8855e-07, 2.3530e-07], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:03,669][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0006, 0.3357, 0.0019, 0.3825, 0.0004, 0.0062, 0.0027, 0.1882, 0.0817],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,670][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0298, 0.1022, 0.1104, 0.1223, 0.1507, 0.1047, 0.1036, 0.1509, 0.1254],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,672][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0546, 0.1593, 0.0683, 0.1265, 0.1189, 0.1610, 0.0517, 0.1240, 0.1357],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,674][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0070, 0.1881, 0.0213, 0.6011, 0.0174, 0.0255, 0.0052, 0.0866, 0.0478],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,675][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7327, 0.0307, 0.0735, 0.0177, 0.0120, 0.1167, 0.0014, 0.0047, 0.0107],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,677][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0277, 0.0986, 0.1303, 0.1369, 0.0914, 0.0385, 0.1287, 0.1451, 0.2030],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,679][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2593, 0.1249, 0.2039, 0.1514, 0.0781, 0.0607, 0.0663, 0.0193, 0.0360],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,680][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.5834e-04, 2.1827e-01, 1.3501e-03, 1.4489e-01, 1.9998e-02, 3.1804e-03,
        5.2415e-02, 3.2906e-01, 2.3069e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,682][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0748, 0.0952, 0.0578, 0.1147, 0.0792, 0.0891, 0.1372, 0.2031, 0.1491],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,683][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0707, 0.3966, 0.0496, 0.2447, 0.0308, 0.0945, 0.0159, 0.0759, 0.0212],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,685][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0165, 0.2509, 0.0167, 0.6039, 0.0137, 0.0703, 0.0006, 0.0073, 0.0200],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,686][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.7871e-03, 4.3440e-08, 3.2313e-02, 2.5280e-06, 3.8957e-06, 9.6357e-01,
        2.2326e-09, 3.2032e-04, 2.4877e-10], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:03,688][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([1.1758e-04, 1.6602e-01, 1.4043e-03, 2.0450e-01, 8.0206e-03, 1.7932e-03,
        1.1873e-02, 4.0205e-01, 2.0272e-01, 1.5073e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,689][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0232, 0.0838, 0.0991, 0.1041, 0.1393, 0.0940, 0.0966, 0.1467, 0.1160,
        0.0972], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,689][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0347, 0.1104, 0.0508, 0.1033, 0.1557, 0.1505, 0.0670, 0.1457, 0.1484,
        0.0334], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,690][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0008, 0.2268, 0.0066, 0.3656, 0.0316, 0.0090, 0.0236, 0.1326, 0.1986,
        0.0047], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,691][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.6283, 0.0175, 0.0686, 0.0201, 0.0102, 0.0918, 0.0073, 0.0140, 0.0138,
        0.1284], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,693][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0138, 0.0928, 0.1124, 0.1461, 0.0596, 0.0212, 0.0986, 0.2153, 0.2033,
        0.0370], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,694][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0961, 0.1607, 0.1028, 0.1798, 0.0731, 0.2049, 0.0617, 0.0089, 0.1066,
        0.0055], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,696][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([4.3994e-05, 2.0319e-01, 1.3705e-03, 1.6317e-01, 4.4543e-02, 1.9699e-03,
        4.0293e-02, 2.4627e-01, 2.9650e-01, 2.6589e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,697][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0672, 0.0817, 0.0487, 0.0845, 0.0707, 0.0843, 0.1104, 0.1839, 0.1694,
        0.0992], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,699][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0101, 0.2069, 0.0279, 0.2315, 0.0533, 0.0387, 0.0669, 0.2125, 0.1341,
        0.0183], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,700][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0698, 0.2596, 0.0609, 0.2487, 0.0800, 0.1058, 0.0203, 0.0398, 0.0578,
        0.0572], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,702][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([9.5149e-11, 1.7344e-02, 5.3039e-06, 8.7165e-02, 1.4733e-03, 6.0781e-06,
        2.8984e-05, 8.4134e-01, 5.2636e-02, 1.8795e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:03,703][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0062, 0.2428, 0.0040, 0.3539, 0.0005, 0.0164, 0.0026, 0.1199, 0.1709,
        0.0030, 0.0799], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,705][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0217, 0.0770, 0.0922, 0.0948, 0.1285, 0.0862, 0.0895, 0.1265, 0.1028,
        0.0900, 0.0908], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,707][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0399, 0.1339, 0.0523, 0.1055, 0.1075, 0.1327, 0.0448, 0.1197, 0.1004,
        0.0222, 0.1410], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,709][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0260, 0.1389, 0.0562, 0.3418, 0.0215, 0.0576, 0.0070, 0.0834, 0.1648,
        0.0189, 0.0838], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,710][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.7512, 0.0213, 0.0639, 0.0109, 0.0098, 0.0879, 0.0016, 0.0026, 0.0052,
        0.0250, 0.0206], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,712][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0424, 0.0804, 0.1374, 0.0972, 0.0685, 0.0221, 0.0863, 0.1254, 0.2367,
        0.0398, 0.0639], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,714][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.3247, 0.0780, 0.1300, 0.0537, 0.0889, 0.0593, 0.0173, 0.0148, 0.0753,
        0.1413, 0.0166], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,715][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([6.1765e-05, 1.2823e-01, 7.2267e-04, 1.0171e-01, 1.1839e-02, 1.3120e-03,
        3.4374e-02, 1.8548e-01, 1.8106e-01, 1.6370e-03, 3.5356e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,717][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0686, 0.0734, 0.0475, 0.0880, 0.0644, 0.0655, 0.1088, 0.1542, 0.1241,
        0.0817, 0.1236], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,718][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1282, 0.2396, 0.0648, 0.2306, 0.0163, 0.1346, 0.0128, 0.0795, 0.0268,
        0.0308, 0.0361], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,720][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.4989e-02, 2.6312e-01, 2.0414e-02, 5.3446e-01, 9.4167e-03, 8.8144e-02,
        5.0459e-04, 5.4183e-03, 2.4161e-02, 2.2058e-03, 2.7166e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,721][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([3.3234e-03, 2.5796e-09, 2.3702e-01, 2.5216e-08, 1.6911e-04, 4.4077e-01,
        3.0836e-07, 4.4632e-05, 3.1910e-08, 3.1868e-01, 1.7843e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:03,722][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([5.6979e-05, 2.9548e-01, 5.1370e-04, 2.9289e-01, 4.0692e-04, 1.6320e-03,
        2.3117e-03, 7.4137e-02, 1.4079e-01, 1.6334e-04, 1.9131e-01, 3.1821e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,724][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0213, 0.0707, 0.0826, 0.0871, 0.1132, 0.0784, 0.0770, 0.1121, 0.0911,
        0.0773, 0.0842, 0.1051], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,725][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0266, 0.0877, 0.0423, 0.0842, 0.1028, 0.1058, 0.0421, 0.1097, 0.0924,
        0.0326, 0.1605, 0.1133], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,727][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0009, 0.2208, 0.0046, 0.5098, 0.0052, 0.0062, 0.0025, 0.0519, 0.0640,
        0.0017, 0.1276, 0.0048], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,729][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.3416, 0.0658, 0.0973, 0.0319, 0.0798, 0.0737, 0.0023, 0.0103, 0.0137,
        0.0324, 0.1246, 0.1267], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,730][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0170, 0.0787, 0.0620, 0.0894, 0.0658, 0.0309, 0.0786, 0.1794, 0.1900,
        0.0518, 0.0880, 0.0684], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,731][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.1142, 0.2259, 0.0271, 0.2031, 0.0031, 0.1188, 0.0263, 0.0159, 0.1055,
        0.1028, 0.0543, 0.0030], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,731][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([5.1686e-05, 8.1733e-02, 1.1333e-03, 5.8936e-02, 2.8549e-02, 1.0867e-03,
        4.2251e-02, 1.5578e-01, 2.1201e-01, 1.9086e-03, 3.3153e-01, 8.5034e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,733][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0177, 0.0874, 0.0419, 0.0981, 0.0566, 0.0724, 0.0764, 0.1405, 0.1341,
        0.0580, 0.1465, 0.0704], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,734][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0082, 0.2487, 0.0159, 0.2976, 0.0168, 0.0343, 0.0189, 0.1660, 0.0541,
        0.0153, 0.1087, 0.0156], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,736][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0243, 0.2832, 0.0286, 0.4397, 0.0220, 0.0781, 0.0019, 0.0166, 0.0511,
        0.0055, 0.0481, 0.0010], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,737][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([1.1731e-03, 1.1209e-03, 2.8173e-01, 2.8518e-03, 2.2568e-06, 5.7391e-01,
        3.2492e-07, 1.0034e-03, 3.9415e-05, 1.3429e-01, 3.8844e-03, 5.9616e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:03,738][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([8.1477e-05, 5.0977e-01, 6.0358e-04, 3.0685e-01, 2.7134e-04, 1.8170e-03,
        9.7004e-04, 3.6076e-02, 5.7168e-02, 1.6734e-04, 7.9761e-02, 7.3401e-05,
        6.3886e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,740][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0206, 0.0695, 0.0753, 0.0823, 0.1014, 0.0736, 0.0712, 0.1001, 0.0850,
        0.0689, 0.0807, 0.0918, 0.0797], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,742][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0473, 0.0896, 0.0421, 0.0859, 0.0768, 0.0914, 0.0398, 0.0840, 0.1129,
        0.0235, 0.1528, 0.0907, 0.0632], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,743][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([5.9414e-05, 3.4327e-01, 4.0003e-03, 5.0239e-01, 4.2174e-02, 2.0881e-03,
        3.9280e-03, 3.0849e-02, 1.6311e-02, 1.9940e-04, 4.4644e-02, 6.6094e-03,
        3.4715e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,745][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.5930, 0.0568, 0.0509, 0.0192, 0.0154, 0.1265, 0.0028, 0.0038, 0.0066,
        0.0170, 0.0521, 0.0175, 0.0385], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,746][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0204, 0.0738, 0.1101, 0.1126, 0.0682, 0.0283, 0.0612, 0.1659, 0.1509,
        0.0422, 0.0858, 0.0623, 0.0185], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,748][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1159, 0.0845, 0.0855, 0.0617, 0.1418, 0.0555, 0.0595, 0.0192, 0.0347,
        0.1347, 0.0310, 0.1661, 0.0100], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,749][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([1.9411e-05, 1.8282e-01, 7.0385e-04, 8.7791e-02, 1.8837e-02, 1.3324e-03,
        3.5032e-02, 7.0244e-02, 7.9522e-02, 6.6947e-04, 2.8817e-01, 2.8107e-02,
        2.0676e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,751][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0777, 0.0590, 0.0400, 0.0763, 0.0489, 0.0651, 0.1020, 0.1412, 0.1094,
        0.0513, 0.1131, 0.0751, 0.0408], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,753][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0044, 0.5047, 0.0106, 0.2479, 0.0161, 0.0178, 0.0064, 0.0429, 0.0270,
        0.0026, 0.0469, 0.0059, 0.0668], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,754][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([1.0616e-02, 3.3024e-01, 6.4083e-03, 5.0039e-01, 4.2115e-03, 7.6228e-02,
        3.4125e-04, 1.2894e-02, 2.2035e-02, 2.1216e-03, 2.1746e-02, 2.2828e-04,
        1.2543e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,755][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([5.1296e-04, 2.8883e-05, 2.0598e-01, 1.4747e-04, 4.0935e-04, 7.0767e-01,
        1.0928e-06, 6.1018e-04, 1.3019e-06, 6.0085e-02, 3.6731e-04, 2.8191e-04,
        2.3906e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:03,757][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([4.3867e-03, 3.4212e-01, 4.5946e-03, 2.4552e-01, 2.3738e-04, 1.4126e-02,
        1.3143e-03, 1.4554e-02, 5.0702e-02, 7.5120e-04, 4.4312e-02, 5.2199e-05,
        1.6205e-02, 2.6112e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,758][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0201, 0.0636, 0.0707, 0.0740, 0.0939, 0.0647, 0.0641, 0.0890, 0.0765,
        0.0670, 0.0717, 0.0853, 0.0762, 0.0830], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,760][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0322, 0.1059, 0.0289, 0.0844, 0.0664, 0.0739, 0.0356, 0.0800, 0.0723,
        0.0208, 0.1273, 0.0731, 0.0781, 0.1209], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,762][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0090, 0.1093, 0.0179, 0.2235, 0.0074, 0.0271, 0.0022, 0.0206, 0.0175,
        0.0024, 0.0341, 0.0031, 0.0141, 0.5118], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,764][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7294, 0.0313, 0.0543, 0.0145, 0.0079, 0.0888, 0.0012, 0.0023, 0.0047,
        0.0209, 0.0270, 0.0064, 0.0033, 0.0079], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,765][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0219, 0.0682, 0.1244, 0.0927, 0.0572, 0.0264, 0.0840, 0.0948, 0.1946,
        0.0485, 0.0662, 0.0538, 0.0261, 0.0413], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,767][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1194, 0.1051, 0.0490, 0.1498, 0.0278, 0.0914, 0.0746, 0.0321, 0.0688,
        0.1643, 0.0187, 0.0321, 0.0545, 0.0125], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,768][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.1068e-05, 7.1972e-02, 3.0611e-04, 2.9231e-02, 3.9166e-03, 6.4200e-04,
        9.0264e-03, 3.3998e-02, 2.3133e-02, 3.6493e-04, 5.0053e-02, 8.0390e-03,
        4.5789e-02, 7.2350e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,770][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0759, 0.0512, 0.0389, 0.0716, 0.0472, 0.0529, 0.0770, 0.1155, 0.0874,
        0.0672, 0.0911, 0.0666, 0.0478, 0.1098], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,771][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0893, 0.2088, 0.0315, 0.1452, 0.0101, 0.0823, 0.0063, 0.0456, 0.0124,
        0.0110, 0.0336, 0.0048, 0.1242, 0.1948], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,772][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.3406e-02, 2.4929e-01, 1.4856e-02, 5.6735e-01, 6.9715e-03, 6.9610e-02,
        4.2806e-04, 7.2965e-03, 2.2164e-02, 1.6659e-03, 1.5828e-02, 2.2202e-04,
        2.4613e-03, 1.8455e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,773][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.1967e-02, 1.8581e-09, 4.2116e-01, 1.8534e-09, 9.2661e-06, 4.9408e-01,
        9.5369e-09, 3.7764e-09, 2.1272e-12, 3.8674e-02, 1.5836e-08, 4.4614e-06,
        6.0171e-03, 8.0880e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:03,774][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([2.1446e-03, 9.0696e-02, 8.0186e-04, 8.2807e-02, 5.0754e-05, 4.5117e-03,
        8.1804e-05, 1.0927e-02, 1.5720e-02, 3.1609e-04, 1.2187e-02, 1.7063e-05,
        3.8069e-03, 6.1885e-01, 1.5708e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,775][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0169, 0.0558, 0.0649, 0.0678, 0.0896, 0.0607, 0.0624, 0.0878, 0.0736,
        0.0637, 0.0660, 0.0810, 0.0712, 0.0796, 0.0590], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,777][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0284, 0.0850, 0.0291, 0.0631, 0.0698, 0.0679, 0.0281, 0.0627, 0.0884,
        0.0175, 0.1137, 0.0862, 0.0745, 0.0994, 0.0861], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,779][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0010, 0.1213, 0.0068, 0.2102, 0.0094, 0.0073, 0.0009, 0.0192, 0.0080,
        0.0007, 0.0199, 0.0043, 0.0027, 0.4957, 0.0926], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,780][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.6104, 0.0461, 0.0767, 0.0237, 0.0103, 0.0941, 0.0040, 0.0036, 0.0154,
        0.0456, 0.0371, 0.0091, 0.0030, 0.0133, 0.0076], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,782][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0223, 0.0771, 0.0911, 0.1001, 0.0458, 0.0175, 0.0639, 0.1128, 0.1414,
        0.0291, 0.0699, 0.0386, 0.0258, 0.1013, 0.0633], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,784][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1176, 0.1074, 0.0640, 0.0969, 0.0502, 0.1476, 0.0754, 0.0180, 0.0545,
        0.0754, 0.0470, 0.0517, 0.0554, 0.0283, 0.0104], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,785][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([1.7051e-05, 6.9909e-02, 2.6827e-04, 3.6946e-02, 4.0983e-03, 6.6397e-04,
        8.1427e-03, 3.5228e-02, 2.9200e-02, 3.1460e-04, 7.1552e-02, 7.3198e-03,
        3.2499e-02, 5.3454e-01, 1.6930e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,787][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0664, 0.0499, 0.0356, 0.0616, 0.0368, 0.0484, 0.0645, 0.1123, 0.0839,
        0.0724, 0.0905, 0.0623, 0.0388, 0.0985, 0.0781], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,788][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0674, 0.2391, 0.0261, 0.1663, 0.0059, 0.0486, 0.0033, 0.0204, 0.0064,
        0.0100, 0.0158, 0.0024, 0.0952, 0.2492, 0.0439], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,790][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0155, 0.2890, 0.0154, 0.5248, 0.0143, 0.0431, 0.0006, 0.0202, 0.0240,
        0.0017, 0.0168, 0.0005, 0.0022, 0.0243, 0.0077], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,792][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([4.8025e-06, 1.4986e-10, 1.4305e-04, 3.6658e-09, 2.0135e-06, 9.9907e-04,
        2.3376e-12, 8.1522e-09, 2.2125e-12, 2.3246e-05, 6.8739e-09, 6.9628e-07,
        3.8528e-05, 2.1632e-01, 7.8246e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:03,793][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([6.3436e-04, 1.3512e-02, 4.2492e-04, 1.2836e-02, 1.5809e-05, 1.3642e-03,
        1.5007e-04, 3.1577e-03, 2.3192e-03, 1.3632e-04, 3.3694e-03, 4.9948e-06,
        1.7589e-03, 1.4902e-01, 6.4790e-01, 1.6339e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,794][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0168, 0.0542, 0.0610, 0.0653, 0.0816, 0.0573, 0.0572, 0.0798, 0.0675,
        0.0599, 0.0638, 0.0744, 0.0670, 0.0743, 0.0560, 0.0639],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,796][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0320, 0.0818, 0.0343, 0.0641, 0.0667, 0.1047, 0.0245, 0.0604, 0.0744,
        0.0173, 0.1126, 0.0786, 0.0599, 0.0703, 0.0650, 0.0535],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,798][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0032, 0.0240, 0.0045, 0.0926, 0.0017, 0.0067, 0.0007, 0.0081, 0.0049,
        0.0008, 0.0077, 0.0008, 0.0032, 0.2915, 0.1160, 0.4334],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,800][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7104, 0.0277, 0.0598, 0.0127, 0.0087, 0.0972, 0.0022, 0.0018, 0.0059,
        0.0219, 0.0233, 0.0066, 0.0020, 0.0042, 0.0022, 0.0135],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,802][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0123, 0.0709, 0.0725, 0.0755, 0.0578, 0.0324, 0.0667, 0.0820, 0.1386,
        0.0373, 0.0686, 0.0507, 0.0243, 0.0697, 0.0658, 0.0750],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,803][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0987, 0.0939, 0.0743, 0.1055, 0.0536, 0.0625, 0.0389, 0.0172, 0.0608,
        0.0989, 0.0395, 0.0610, 0.1163, 0.0256, 0.0446, 0.0085],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,805][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.8680e-05, 6.4269e-02, 2.2189e-04, 2.4070e-02, 1.8988e-03, 4.7367e-04,
        5.5273e-03, 2.2155e-02, 1.9310e-02, 3.4490e-04, 3.7439e-02, 3.3257e-03,
        2.9941e-02, 4.1883e-01, 1.2385e-01, 2.4832e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,807][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0517, 0.0432, 0.0290, 0.0573, 0.0352, 0.0424, 0.0612, 0.0877, 0.0688,
        0.0500, 0.0737, 0.0488, 0.0377, 0.0832, 0.0748, 0.1552],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,808][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0809, 0.0971, 0.0233, 0.0756, 0.0051, 0.0544, 0.0037, 0.0212, 0.0068,
        0.0084, 0.0191, 0.0028, 0.0906, 0.3091, 0.1301, 0.0719],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,810][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.0385e-02, 2.5925e-01, 1.5890e-02, 5.3135e-01, 9.7250e-03, 7.6788e-02,
        2.9486e-04, 8.8650e-03, 1.7869e-02, 2.2094e-03, 1.5017e-02, 3.6746e-04,
        1.7692e-03, 1.8766e-02, 3.4536e-03, 8.0050e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,811][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.2938e-04, 1.4376e-13, 4.6575e-05, 7.0467e-13, 3.3278e-11, 1.1849e-03,
        1.5691e-14, 2.3430e-11, 2.5771e-16, 8.8848e-06, 1.5299e-12, 5.4603e-12,
        7.6642e-07, 2.1975e-04, 9.9841e-01, 6.9337e-07], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:03,812][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([7.4659e-05, 2.5671e-02, 1.3709e-04, 2.8185e-02, 2.5365e-05, 6.7593e-04,
        5.2040e-05, 3.0854e-03, 3.4799e-03, 2.0097e-05, 7.2952e-03, 6.4352e-06,
        2.0247e-03, 1.2629e-01, 5.2829e-01, 2.6326e-01, 1.1427e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,814][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0154, 0.0497, 0.0545, 0.0601, 0.0761, 0.0541, 0.0543, 0.0776, 0.0636,
        0.0555, 0.0599, 0.0690, 0.0623, 0.0716, 0.0545, 0.0605, 0.0612],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,815][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0185, 0.0706, 0.0294, 0.0620, 0.0614, 0.0673, 0.0310, 0.0690, 0.0780,
        0.0194, 0.1088, 0.0736, 0.0710, 0.0725, 0.0711, 0.0523, 0.0444],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,815][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([2.2204e-04, 2.1997e-02, 7.6839e-04, 4.0840e-02, 1.3723e-03, 1.4218e-03,
        3.3104e-04, 5.5610e-03, 4.9719e-03, 1.5604e-04, 1.3894e-02, 5.4385e-04,
        1.4428e-03, 2.5518e-01, 8.6025e-02, 5.5250e-01, 1.2773e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,817][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([7.3237e-01, 2.0294e-02, 5.9998e-02, 9.0265e-03, 6.0118e-03, 6.8255e-02,
        8.2489e-04, 1.2067e-03, 5.8473e-03, 5.3245e-02, 2.1161e-02, 4.8068e-03,
        6.3865e-04, 4.1584e-03, 3.1578e-03, 6.8881e-03, 2.1070e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,818][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0085, 0.0750, 0.0609, 0.0852, 0.0466, 0.0160, 0.0562, 0.1366, 0.1016,
        0.0298, 0.0669, 0.0397, 0.0215, 0.0812, 0.0612, 0.0826, 0.0304],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,820][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0392, 0.1381, 0.0173, 0.1500, 0.0448, 0.0654, 0.1712, 0.0171, 0.0847,
        0.0369, 0.0511, 0.0448, 0.0738, 0.0315, 0.0144, 0.0192, 0.0006],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,821][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([3.1794e-05, 9.4188e-02, 4.6282e-04, 2.6035e-02, 5.4421e-03, 7.2759e-04,
        1.0708e-02, 2.1808e-02, 1.7446e-02, 4.6817e-04, 2.8659e-02, 7.5315e-03,
        3.1531e-02, 2.7122e-01, 1.8488e-01, 1.7376e-01, 1.2509e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,823][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0395, 0.0488, 0.0270, 0.0473, 0.0342, 0.0442, 0.0466, 0.0998, 0.0823,
        0.0527, 0.0861, 0.0545, 0.0242, 0.0818, 0.0614, 0.1350, 0.0346],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,824][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0136, 0.0602, 0.0081, 0.0672, 0.0044, 0.0136, 0.0011, 0.0143, 0.0105,
        0.0028, 0.0092, 0.0029, 0.0337, 0.4321, 0.1044, 0.2011, 0.0206],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,826][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0454, 0.2586, 0.0444, 0.4082, 0.0131, 0.0768, 0.0008, 0.0177, 0.0374,
        0.0072, 0.0211, 0.0005, 0.0024, 0.0287, 0.0186, 0.0178, 0.0013],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,828][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([5.2474e-08, 4.5112e-09, 5.0719e-06, 2.6052e-09, 1.9747e-09, 2.2358e-05,
        2.7811e-13, 2.5544e-09, 1.3117e-11, 1.8100e-07, 3.5046e-09, 1.8412e-09,
        2.3018e-05, 4.0667e-02, 9.0925e-01, 3.4548e-02, 1.5481e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:03,829][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.6983e-03, 3.5395e-02, 1.3083e-03, 2.6974e-02, 2.5747e-05, 4.5737e-03,
        1.0763e-04, 1.2759e-03, 4.2989e-03, 1.2287e-04, 3.1984e-03, 4.3241e-06,
        1.6047e-03, 2.3513e-02, 4.4841e-01, 2.0342e-01, 4.5953e-02, 1.9711e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,831][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0158, 0.0482, 0.0544, 0.0561, 0.0719, 0.0503, 0.0505, 0.0698, 0.0591,
        0.0525, 0.0545, 0.0659, 0.0598, 0.0634, 0.0493, 0.0580, 0.0600, 0.0605],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,833][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0269, 0.0788, 0.0236, 0.0623, 0.0505, 0.0570, 0.0265, 0.0600, 0.0541,
        0.0166, 0.0935, 0.0570, 0.0563, 0.0872, 0.0739, 0.0471, 0.0408, 0.0879],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,834][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.4826e-03, 1.6894e-02, 3.9186e-03, 3.6597e-02, 7.2205e-04, 6.4953e-03,
        3.0041e-04, 2.5138e-03, 2.5479e-03, 4.1910e-04, 3.0827e-03, 2.6000e-04,
        1.6427e-03, 6.0717e-02, 5.3492e-02, 3.0251e-01, 2.2945e-02, 4.8146e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,835][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.6394e-01, 2.7894e-02, 4.4101e-02, 1.2451e-02, 4.7952e-03, 7.8422e-02,
        9.4226e-04, 1.4344e-03, 3.5985e-03, 1.7758e-02, 2.0339e-02, 3.8307e-03,
        1.8431e-03, 5.5801e-03, 2.2792e-03, 6.7704e-03, 3.0550e-04, 3.7189e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,837][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0154, 0.0505, 0.0887, 0.0686, 0.0423, 0.0174, 0.0585, 0.0693, 0.1422,
        0.0359, 0.0460, 0.0393, 0.0189, 0.0285, 0.0721, 0.1167, 0.0641, 0.0257],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,839][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0894, 0.0728, 0.0375, 0.1119, 0.0210, 0.0683, 0.0588, 0.0242, 0.0487,
        0.1480, 0.0132, 0.0241, 0.0427, 0.0091, 0.0627, 0.0211, 0.1374, 0.0089],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,840][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.8862e-05, 1.9177e-02, 1.2289e-04, 6.9947e-03, 9.1012e-04, 2.6323e-04,
        1.9259e-03, 8.4297e-03, 5.6079e-03, 1.5638e-04, 1.1721e-02, 1.7127e-03,
        9.1470e-03, 1.7632e-01, 5.4934e-02, 8.2178e-02, 5.1016e-02, 5.6936e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,842][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0722, 0.0363, 0.0270, 0.0475, 0.0289, 0.0359, 0.0453, 0.0751, 0.0561,
        0.0411, 0.0539, 0.0390, 0.0286, 0.0698, 0.0651, 0.1280, 0.0513, 0.0990],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,844][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1134, 0.0819, 0.0234, 0.0812, 0.0047, 0.0729, 0.0028, 0.0201, 0.0066,
        0.0073, 0.0107, 0.0019, 0.0503, 0.1099, 0.0836, 0.0840, 0.0317, 0.2135],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,845][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.1327e-02, 2.3040e-01, 2.2273e-02, 5.0387e-01, 7.4837e-03, 8.7945e-02,
        4.4543e-04, 8.8893e-03, 2.6817e-02, 1.9791e-03, 1.3676e-02, 2.1212e-04,
        2.1422e-03, 1.7142e-02, 3.7526e-03, 1.1276e-02, 1.0111e-04, 1.0269e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,846][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1792e-03, 4.8853e-15, 2.6747e-04, 3.4172e-15, 1.9473e-11, 3.6273e-04,
        4.3915e-14, 1.0462e-14, 1.6153e-17, 2.0950e-05, 8.4086e-15, 5.0574e-12,
        1.3837e-08, 1.0858e-08, 1.4351e-01, 1.4985e-06, 8.5337e-01, 1.2932e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:03,907][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:03,907][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,908][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,909][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,910][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,911][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,911][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,912][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,913][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,914][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,914][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,915][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,916][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:03,916][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8866, 0.1134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,917][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9482, 0.0518], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,918][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,918][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9834, 0.0166], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,919][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9990e-01, 9.6799e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,921][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9782, 0.0218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,922][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8502, 0.1498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,924][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3014, 0.6986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,925][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9918, 0.0082], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,927][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9778, 0.0222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,929][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9974, 0.0026], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,930][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.0000e+00, 1.5959e-22], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:03,932][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.0151, 0.9565, 0.0284], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,933][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.0174, 0.9548, 0.0278], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,935][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.4247, 0.3963, 0.1790], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,936][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.0578, 0.8649, 0.0773], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,938][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.9264, 0.0046, 0.0690], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,940][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.0833, 0.7982, 0.1185], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,941][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.0571, 0.8912, 0.0518], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,943][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.0042, 0.9458, 0.0500], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,944][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.3314, 0.3629, 0.3056], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,946][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.2555, 0.5669, 0.1776], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,947][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.6615, 0.1396, 0.1989], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,949][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.0183, 0.9705, 0.0113], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:03,951][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0555, 0.7329, 0.0162, 0.1954], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,952][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0970, 0.7302, 0.0186, 0.1541], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,954][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7520, 0.0948, 0.0703, 0.0830], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,956][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2280, 0.2990, 0.1481, 0.3249], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,957][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.8721e-01, 8.5828e-04, 1.1470e-02, 4.6600e-04], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,958][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3900, 0.3256, 0.0802, 0.2041], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,958][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1192, 0.5675, 0.0546, 0.2587], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,959][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0018, 0.3308, 0.0070, 0.6604], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,960][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3706, 0.1270, 0.2082, 0.2941], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,961][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6278, 0.2019, 0.1022, 0.0681], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,963][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7398, 0.0634, 0.0413, 0.1555], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,964][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([8.6894e-01, 1.6005e-10, 1.3106e-01, 4.7685e-13], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:03,965][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([6.8428e-04, 7.2459e-01, 2.2866e-03, 2.7163e-01, 8.0479e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,967][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0008, 0.6114, 0.0025, 0.3818, 0.0034], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,968][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.4068, 0.2221, 0.1057, 0.2294, 0.0360], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,970][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0090, 0.4142, 0.0170, 0.5525, 0.0073], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,972][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.9000, 0.0095, 0.0680, 0.0060, 0.0165], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,973][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0184, 0.4299, 0.0278, 0.5036, 0.0204], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,975][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0066, 0.6404, 0.0090, 0.3394, 0.0046], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,976][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0009, 0.3120, 0.0103, 0.4742, 0.2026], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,978][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0668, 0.2584, 0.1863, 0.4561, 0.0324], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,980][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0989, 0.4205, 0.0837, 0.3620, 0.0349], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,981][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.2449, 0.2475, 0.1048, 0.3852, 0.0176], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,982][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([5.2142e-01, 2.8351e-04, 4.7698e-01, 1.3147e-03, 2.5821e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:03,984][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0036, 0.6493, 0.0117, 0.3038, 0.0156, 0.0161], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,986][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0037, 0.6114, 0.0139, 0.3128, 0.0419, 0.0163], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,988][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1571, 0.1843, 0.0896, 0.2447, 0.0808, 0.2435], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,989][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0018, 0.3511, 0.0158, 0.5586, 0.0579, 0.0147], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,991][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.7928, 0.0087, 0.0711, 0.0125, 0.0107, 0.1042], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,993][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0154, 0.3180, 0.0311, 0.5803, 0.0269, 0.0283], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,994][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0152, 0.4664, 0.0371, 0.3526, 0.0872, 0.0416], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,995][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([2.2510e-04, 4.1730e-01, 4.6979e-03, 4.6134e-01, 1.0642e-01, 1.0019e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,997][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0718, 0.1657, 0.1156, 0.3758, 0.0947, 0.1764], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:03,999][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0604, 0.3727, 0.0799, 0.2822, 0.1106, 0.0941], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,000][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2703, 0.1037, 0.0893, 0.2216, 0.0498, 0.2653], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,000][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([1.0002e-05, 1.2912e-01, 1.5136e-02, 4.4658e-02, 8.0826e-01, 2.8226e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,001][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([2.9653e-05, 4.4328e-01, 4.0110e-04, 5.5350e-01, 6.2348e-04, 1.2592e-03,
        9.1178e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,002][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([9.2900e-05, 6.2264e-01, 1.0322e-03, 3.6778e-01, 4.6535e-03, 1.6053e-03,
        2.1923e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,003][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0176, 0.3750, 0.0319, 0.4134, 0.0687, 0.0839, 0.0095],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,004][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([2.0272e-04, 1.9824e-01, 4.8459e-03, 7.1214e-01, 7.6070e-02, 5.1315e-03,
        3.3689e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,006][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.7920, 0.0191, 0.0537, 0.0122, 0.0061, 0.1032, 0.0137],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,008][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0008, 0.3428, 0.0039, 0.6444, 0.0053, 0.0019, 0.0008],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,009][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0008, 0.5309, 0.0060, 0.4325, 0.0222, 0.0067, 0.0009],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,011][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([5.1007e-05, 4.3360e-01, 1.7319e-03, 4.1457e-01, 5.1873e-02, 2.7146e-03,
        9.5456e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,012][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0190, 0.3156, 0.0721, 0.3685, 0.0513, 0.0647, 0.1088],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,014][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0110, 0.5325, 0.0204, 0.3246, 0.0430, 0.0491, 0.0193],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,016][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0147, 0.5604, 0.0111, 0.3742, 0.0084, 0.0298, 0.0015],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,017][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([8.4715e-06, 4.5505e-04, 9.2149e-02, 4.7652e-03, 1.7870e-02, 8.8475e-01,
        3.3476e-08], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,018][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.4435e-04, 6.0771e-01, 1.1354e-03, 3.6328e-01, 5.1344e-04, 3.5108e-03,
        9.0486e-03, 1.4552e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,019][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0012, 0.5140, 0.0029, 0.4617, 0.0050, 0.0071, 0.0027, 0.0054],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,021][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0453, 0.3007, 0.0454, 0.3647, 0.0373, 0.1436, 0.0089, 0.0543],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,023][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0031, 0.2281, 0.0194, 0.6203, 0.0407, 0.0209, 0.0151, 0.0523],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,024][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.7553, 0.0317, 0.0706, 0.0159, 0.0153, 0.1013, 0.0023, 0.0076],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,026][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0022, 0.3968, 0.0052, 0.5810, 0.0038, 0.0052, 0.0015, 0.0043],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,028][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0056, 0.5134, 0.0141, 0.3901, 0.0133, 0.0196, 0.0036, 0.0403],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,029][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.3299e-04, 3.1639e-01, 1.6499e-03, 2.2204e-01, 2.6702e-02, 3.1313e-03,
        7.1423e-02, 3.5853e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,031][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0062, 0.2601, 0.0359, 0.4871, 0.0446, 0.0331, 0.0753, 0.0576],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,032][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0471, 0.4675, 0.0420, 0.2687, 0.0244, 0.0852, 0.0243, 0.0408],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,034][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0181, 0.3864, 0.0159, 0.5029, 0.0128, 0.0546, 0.0012, 0.0081],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,035][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([7.8259e-04, 3.0349e-07, 3.6503e-01, 3.4940e-06, 5.8911e-04, 6.3360e-01,
        5.8855e-07, 2.3530e-07], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,037][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0006, 0.3357, 0.0019, 0.3825, 0.0004, 0.0062, 0.0027, 0.1882, 0.0817],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,039][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0010, 0.4776, 0.0035, 0.4663, 0.0045, 0.0067, 0.0020, 0.0143, 0.0241],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,040][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0531, 0.2603, 0.0396, 0.2894, 0.0306, 0.1517, 0.0066, 0.0632, 0.1055],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,041][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0070, 0.1881, 0.0213, 0.6011, 0.0174, 0.0255, 0.0052, 0.0866, 0.0478],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,042][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.7327, 0.0307, 0.0735, 0.0177, 0.0120, 0.1167, 0.0014, 0.0047, 0.0107],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,043][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0078, 0.3131, 0.0082, 0.5980, 0.0055, 0.0117, 0.0020, 0.0300, 0.0238],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,044][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0109, 0.4534, 0.0157, 0.3809, 0.0154, 0.0311, 0.0038, 0.0586, 0.0301],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,045][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.5834e-04, 2.1827e-01, 1.3501e-03, 1.4489e-01, 1.9998e-02, 3.1804e-03,
        5.2415e-02, 3.2906e-01, 2.3069e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,046][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0034, 0.1632, 0.0220, 0.5433, 0.0306, 0.0296, 0.0587, 0.0663, 0.0829],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,048][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0707, 0.3966, 0.0496, 0.2447, 0.0308, 0.0945, 0.0159, 0.0759, 0.0212],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,050][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0165, 0.2509, 0.0167, 0.6039, 0.0137, 0.0703, 0.0006, 0.0073, 0.0200],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,051][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.7871e-03, 4.3440e-08, 3.2313e-02, 2.5280e-06, 3.8957e-06, 9.6357e-01,
        2.2326e-09, 3.2032e-04, 2.4877e-10], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,052][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([1.1758e-04, 1.6602e-01, 1.4043e-03, 2.0450e-01, 8.0206e-03, 1.7932e-03,
        1.1873e-02, 4.0205e-01, 2.0272e-01, 1.5073e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,053][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([3.0294e-04, 3.2709e-01, 3.5364e-03, 3.2230e-01, 4.2195e-02, 4.6266e-03,
        2.2954e-02, 1.0054e-01, 1.7416e-01, 2.2951e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,055][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0274, 0.2081, 0.0382, 0.2949, 0.0872, 0.0816, 0.0217, 0.1062, 0.1122,
        0.0224], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,057][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0008, 0.2268, 0.0066, 0.3656, 0.0316, 0.0090, 0.0236, 0.1326, 0.1986,
        0.0047], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,058][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.6283, 0.0175, 0.0686, 0.0201, 0.0102, 0.0918, 0.0073, 0.0140, 0.0138,
        0.1284], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,060][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0012, 0.2065, 0.0062, 0.4199, 0.0135, 0.0065, 0.0238, 0.1293, 0.1891,
        0.0041], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,062][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0026, 0.2977, 0.0126, 0.2929, 0.0531, 0.0166, 0.0232, 0.1527, 0.1435,
        0.0051], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,063][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([4.3994e-05, 2.0319e-01, 1.3705e-03, 1.6317e-01, 4.4543e-02, 1.9699e-03,
        4.0293e-02, 2.4627e-01, 2.9650e-01, 2.6589e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,064][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0148, 0.1543, 0.0534, 0.2062, 0.0728, 0.0519, 0.1364, 0.1348, 0.1417,
        0.0337], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,066][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0101, 0.2069, 0.0279, 0.2315, 0.0533, 0.0387, 0.0669, 0.2125, 0.1341,
        0.0183], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,068][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0698, 0.2596, 0.0609, 0.2487, 0.0800, 0.1058, 0.0203, 0.0398, 0.0578,
        0.0572], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,069][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([9.5149e-11, 1.7344e-02, 5.3039e-06, 8.7165e-02, 1.4733e-03, 6.0781e-06,
        2.8984e-05, 8.4134e-01, 5.2636e-02, 1.8795e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,071][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0062, 0.2428, 0.0040, 0.3539, 0.0005, 0.0164, 0.0026, 0.1199, 0.1709,
        0.0030, 0.0799], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,073][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0046, 0.5449, 0.0056, 0.3183, 0.0049, 0.0115, 0.0016, 0.0171, 0.0485,
        0.0017, 0.0413], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,074][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0632, 0.1804, 0.0423, 0.3366, 0.0235, 0.1419, 0.0050, 0.0491, 0.0758,
        0.0126, 0.0695], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,076][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0260, 0.1389, 0.0562, 0.3418, 0.0215, 0.0576, 0.0070, 0.0834, 0.1648,
        0.0189, 0.0838], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,078][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.7512, 0.0213, 0.0639, 0.0109, 0.0098, 0.0879, 0.0016, 0.0026, 0.0052,
        0.0250, 0.0206], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,079][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0177, 0.1424, 0.0153, 0.5351, 0.0070, 0.0155, 0.0017, 0.0281, 0.0831,
        0.0057, 0.1484], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,081][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0201, 0.3901, 0.0230, 0.3001, 0.0196, 0.0399, 0.0034, 0.0704, 0.0478,
        0.0067, 0.0791], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,082][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([6.1765e-05, 1.2823e-01, 7.2267e-04, 1.0171e-01, 1.1839e-02, 1.3120e-03,
        3.4374e-02, 1.8548e-01, 1.8106e-01, 1.6370e-03, 3.5356e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,084][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0028, 0.1421, 0.0234, 0.4490, 0.0449, 0.0241, 0.0661, 0.0503, 0.0902,
        0.0089, 0.0981], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,084][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1282, 0.2396, 0.0648, 0.2306, 0.0163, 0.1346, 0.0128, 0.0795, 0.0268,
        0.0308, 0.0361], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,085][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.4989e-02, 2.6312e-01, 2.0414e-02, 5.3446e-01, 9.4167e-03, 8.8144e-02,
        5.0459e-04, 5.4183e-03, 2.4161e-02, 2.2058e-03, 2.7166e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,086][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([3.3234e-03, 2.5796e-09, 2.3702e-01, 2.5216e-08, 1.6911e-04, 4.4077e-01,
        3.0836e-07, 4.4632e-05, 3.1910e-08, 3.1868e-01, 1.7843e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,087][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([5.6979e-05, 2.9548e-01, 5.1370e-04, 2.9289e-01, 4.0692e-04, 1.6320e-03,
        2.3117e-03, 7.4137e-02, 1.4079e-01, 1.6334e-04, 1.9131e-01, 3.1821e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,088][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([7.9016e-05, 3.4134e-01, 7.6002e-04, 4.0859e-01, 2.6846e-03, 2.1613e-03,
        2.8806e-03, 2.1786e-02, 6.1016e-02, 3.4818e-04, 1.5633e-01, 2.0242e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,090][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0297, 0.1995, 0.0287, 0.2580, 0.0298, 0.0785, 0.0044, 0.0567, 0.1485,
        0.0145, 0.1362, 0.0154], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,092][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0009, 0.2208, 0.0046, 0.5098, 0.0052, 0.0062, 0.0025, 0.0519, 0.0640,
        0.0017, 0.1276, 0.0048], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,094][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.3416, 0.0658, 0.0973, 0.0319, 0.0798, 0.0737, 0.0023, 0.0103, 0.0137,
        0.0324, 0.1246, 0.1267], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,095][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0005, 0.1621, 0.0025, 0.3879, 0.0042, 0.0026, 0.0014, 0.0143, 0.0860,
        0.0007, 0.3364, 0.0013], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,097][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0008, 0.4195, 0.0032, 0.2825, 0.0051, 0.0073, 0.0039, 0.0729, 0.0571,
        0.0018, 0.1440, 0.0019], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,099][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([5.1686e-05, 8.1733e-02, 1.1333e-03, 5.8936e-02, 2.8549e-02, 1.0867e-03,
        4.2251e-02, 1.5578e-01, 2.1201e-01, 1.9086e-03, 3.3153e-01, 8.5034e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,100][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0077, 0.1264, 0.0510, 0.3467, 0.0240, 0.0407, 0.0267, 0.0764, 0.1227,
        0.0161, 0.1568, 0.0046], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,102][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0082, 0.2487, 0.0159, 0.2976, 0.0168, 0.0343, 0.0189, 0.1660, 0.0541,
        0.0153, 0.1087, 0.0156], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,104][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0243, 0.2832, 0.0286, 0.4397, 0.0220, 0.0781, 0.0019, 0.0166, 0.0511,
        0.0055, 0.0481, 0.0010], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,105][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([1.1731e-03, 1.1209e-03, 2.8173e-01, 2.8518e-03, 2.2568e-06, 5.7391e-01,
        3.2492e-07, 1.0034e-03, 3.9415e-05, 1.3429e-01, 3.8844e-03, 5.9616e-07],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,106][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([8.1477e-05, 5.0977e-01, 6.0358e-04, 3.0685e-01, 2.7134e-04, 1.8170e-03,
        9.7004e-04, 3.6076e-02, 5.7168e-02, 1.6734e-04, 7.9761e-02, 7.3401e-05,
        6.3886e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,108][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([1.9571e-04, 6.1108e-01, 5.9995e-04, 2.9534e-01, 1.0846e-03, 2.6771e-03,
        8.4836e-04, 5.0310e-03, 1.7782e-02, 1.0641e-04, 5.7542e-02, 2.9492e-04,
        7.4243e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,109][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0223, 0.2140, 0.0269, 0.3537, 0.0240, 0.0980, 0.0027, 0.0454, 0.0845,
        0.0051, 0.0810, 0.0082, 0.0344], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,110][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([5.9414e-05, 3.4327e-01, 4.0003e-03, 5.0239e-01, 4.2174e-02, 2.0881e-03,
        3.9280e-03, 3.0849e-02, 1.6311e-02, 1.9940e-04, 4.4644e-02, 6.6094e-03,
        3.4715e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,112][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.5930, 0.0568, 0.0509, 0.0192, 0.0154, 0.1265, 0.0028, 0.0038, 0.0066,
        0.0170, 0.0521, 0.0175, 0.0385], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,114][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([5.4209e-04, 2.9329e-01, 2.8370e-03, 5.5660e-01, 3.8055e-03, 2.9310e-03,
        5.5929e-04, 3.1946e-03, 2.4043e-02, 5.2672e-04, 1.0775e-01, 1.0733e-03,
        2.8424e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,115][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0008, 0.5908, 0.0041, 0.2504, 0.0151, 0.0064, 0.0035, 0.0337, 0.0221,
        0.0010, 0.0603, 0.0043, 0.0076], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,116][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([1.9411e-05, 1.8282e-01, 7.0385e-04, 8.7791e-02, 1.8837e-02, 1.3324e-03,
        3.5032e-02, 7.0244e-02, 7.9522e-02, 6.6947e-04, 2.8817e-01, 2.8107e-02,
        2.0676e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,118][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0051, 0.0807, 0.0273, 0.4102, 0.0200, 0.0313, 0.1963, 0.0400, 0.0506,
        0.0061, 0.0854, 0.0026, 0.0443], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,120][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0044, 0.5047, 0.0106, 0.2479, 0.0161, 0.0178, 0.0064, 0.0429, 0.0270,
        0.0026, 0.0469, 0.0059, 0.0668], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,121][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([1.0616e-02, 3.3024e-01, 6.4083e-03, 5.0039e-01, 4.2115e-03, 7.6228e-02,
        3.4125e-04, 1.2894e-02, 2.2035e-02, 2.1216e-03, 2.1746e-02, 2.2828e-04,
        1.2543e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,123][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([5.1296e-04, 2.8883e-05, 2.0598e-01, 1.4747e-04, 4.0935e-04, 7.0767e-01,
        1.0928e-06, 6.1018e-04, 1.3019e-06, 6.0085e-02, 3.6731e-04, 2.8191e-04,
        2.3906e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,124][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.3867e-03, 3.4212e-01, 4.5946e-03, 2.4552e-01, 2.3738e-04, 1.4126e-02,
        1.3143e-03, 1.4554e-02, 5.0702e-02, 7.5120e-04, 4.4312e-02, 5.2199e-05,
        1.6205e-02, 2.6112e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,125][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0136, 0.3426, 0.0098, 0.2355, 0.0029, 0.0237, 0.0016, 0.0090, 0.0195,
        0.0017, 0.0299, 0.0009, 0.0324, 0.2768], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,126][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0765, 0.1567, 0.0346, 0.2070, 0.0196, 0.1611, 0.0043, 0.0324, 0.0555,
        0.0109, 0.0638, 0.0095, 0.0259, 0.1424], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,127][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0090, 0.1093, 0.0179, 0.2235, 0.0074, 0.0271, 0.0022, 0.0206, 0.0175,
        0.0024, 0.0341, 0.0031, 0.0141, 0.5118], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,128][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7294, 0.0313, 0.0543, 0.0145, 0.0079, 0.0888, 0.0012, 0.0023, 0.0047,
        0.0209, 0.0270, 0.0064, 0.0033, 0.0079], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,130][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0165, 0.2203, 0.0130, 0.5368, 0.0036, 0.0124, 0.0010, 0.0057, 0.0244,
        0.0019, 0.1004, 0.0009, 0.0082, 0.0548], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,131][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0201, 0.3410, 0.0152, 0.2092, 0.0084, 0.0307, 0.0014, 0.0294, 0.0199,
        0.0031, 0.0421, 0.0026, 0.0239, 0.2530], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,132][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.1068e-05, 7.1972e-02, 3.0611e-04, 2.9231e-02, 3.9166e-03, 6.4200e-04,
        9.0264e-03, 3.3998e-02, 2.3133e-02, 3.6493e-04, 5.0053e-02, 8.0390e-03,
        4.5789e-02, 7.2350e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,134][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0038, 0.0691, 0.0180, 0.4381, 0.0225, 0.0244, 0.0402, 0.0427, 0.0702,
        0.0100, 0.0981, 0.0030, 0.0581, 0.1017], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,136][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0893, 0.2088, 0.0315, 0.1452, 0.0101, 0.0823, 0.0063, 0.0456, 0.0124,
        0.0110, 0.0336, 0.0048, 0.1242, 0.1948], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,137][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.3406e-02, 2.4929e-01, 1.4856e-02, 5.6735e-01, 6.9715e-03, 6.9610e-02,
        4.2806e-04, 7.2965e-03, 2.2164e-02, 1.6659e-03, 1.5828e-02, 2.2202e-04,
        2.4613e-03, 1.8455e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,138][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.1967e-02, 1.8581e-09, 4.2116e-01, 1.8534e-09, 9.2661e-06, 4.9408e-01,
        9.5369e-09, 3.7764e-09, 2.1272e-12, 3.8674e-02, 1.5836e-08, 4.4614e-06,
        6.0171e-03, 8.0880e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,140][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.1446e-03, 9.0696e-02, 8.0186e-04, 8.2807e-02, 5.0754e-05, 4.5117e-03,
        8.1804e-05, 1.0927e-02, 1.5720e-02, 3.1609e-04, 1.2187e-02, 1.7063e-05,
        3.8069e-03, 6.1885e-01, 1.5708e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,141][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.5151e-03, 2.1297e-01, 2.2989e-03, 1.4323e-01, 2.3605e-03, 7.5515e-03,
        6.5590e-04, 1.7046e-03, 9.2240e-03, 3.8527e-04, 1.8138e-02, 5.3246e-04,
        1.4594e-02, 5.0177e-01, 8.2065e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,143][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0757, 0.1889, 0.0426, 0.1605, 0.0319, 0.1281, 0.0044, 0.0434, 0.0544,
        0.0109, 0.0704, 0.0142, 0.0292, 0.1206, 0.0247], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,145][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0010, 0.1213, 0.0068, 0.2102, 0.0094, 0.0073, 0.0009, 0.0192, 0.0080,
        0.0007, 0.0199, 0.0043, 0.0027, 0.4957, 0.0926], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,146][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.6104, 0.0461, 0.0767, 0.0237, 0.0103, 0.0941, 0.0040, 0.0036, 0.0154,
        0.0456, 0.0371, 0.0091, 0.0030, 0.0133, 0.0076], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,148][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0073, 0.1765, 0.0078, 0.3544, 0.0025, 0.0072, 0.0004, 0.0057, 0.0165,
        0.0011, 0.1024, 0.0007, 0.0085, 0.2329, 0.0758], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,150][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0119, 0.3408, 0.0128, 0.1920, 0.0064, 0.0244, 0.0013, 0.0228, 0.0171,
        0.0024, 0.0510, 0.0024, 0.0179, 0.2590, 0.0378], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,151][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([1.7051e-05, 6.9909e-02, 2.6827e-04, 3.6946e-02, 4.0983e-03, 6.6397e-04,
        8.1427e-03, 3.5228e-02, 2.9200e-02, 3.1460e-04, 7.1552e-02, 7.3198e-03,
        3.2499e-02, 5.3454e-01, 1.6930e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,153][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0052, 0.1053, 0.0259, 0.4167, 0.0154, 0.0269, 0.0448, 0.0537, 0.0502,
        0.0177, 0.0909, 0.0031, 0.0442, 0.0779, 0.0221], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,155][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0674, 0.2391, 0.0261, 0.1663, 0.0059, 0.0486, 0.0033, 0.0204, 0.0064,
        0.0100, 0.0158, 0.0024, 0.0952, 0.2492, 0.0439], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,156][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0155, 0.2890, 0.0154, 0.5248, 0.0143, 0.0431, 0.0006, 0.0202, 0.0240,
        0.0017, 0.0168, 0.0005, 0.0022, 0.0243, 0.0077], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,158][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([4.8025e-06, 1.4986e-10, 1.4305e-04, 3.6658e-09, 2.0135e-06, 9.9907e-04,
        2.3376e-12, 8.1522e-09, 2.2125e-12, 2.3246e-05, 6.8739e-09, 6.9628e-07,
        3.8528e-05, 2.1632e-01, 7.8246e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,159][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.3436e-04, 1.3512e-02, 4.2492e-04, 1.2836e-02, 1.5809e-05, 1.3642e-03,
        1.5007e-04, 3.1577e-03, 2.3192e-03, 1.3632e-04, 3.3694e-03, 4.9948e-06,
        1.7589e-03, 1.4902e-01, 6.4790e-01, 1.6339e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,160][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.7454e-03, 8.9423e-02, 2.5659e-03, 1.1082e-01, 9.8686e-04, 6.4110e-03,
        3.6123e-04, 1.9566e-03, 4.9458e-03, 4.4299e-04, 1.3840e-02, 2.6235e-04,
        1.3079e-02, 4.0169e-01, 1.3987e-01, 2.0960e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,162][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0632, 0.1375, 0.0254, 0.1396, 0.0132, 0.1055, 0.0032, 0.0326, 0.0452,
        0.0082, 0.0476, 0.0073, 0.0248, 0.1157, 0.0246, 0.2065],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,164][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0032, 0.0240, 0.0045, 0.0926, 0.0017, 0.0067, 0.0007, 0.0081, 0.0049,
        0.0008, 0.0077, 0.0008, 0.0032, 0.2915, 0.1160, 0.4334],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,166][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.7104, 0.0277, 0.0598, 0.0127, 0.0087, 0.0972, 0.0022, 0.0018, 0.0059,
        0.0219, 0.0233, 0.0066, 0.0020, 0.0042, 0.0022, 0.0135],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,167][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.8004e-02, 1.1821e-01, 8.1983e-03, 2.4994e-01, 1.1077e-03, 9.3910e-03,
        1.9915e-04, 2.2350e-03, 1.5934e-02, 1.5611e-03, 5.8726e-02, 2.9800e-04,
        5.1734e-03, 1.3219e-01, 1.5840e-01, 2.2043e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,168][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0196, 0.2028, 0.0138, 0.1499, 0.0063, 0.0278, 0.0012, 0.0218, 0.0163,
        0.0028, 0.0323, 0.0021, 0.0245, 0.2612, 0.0896, 0.1279],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,169][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.8680e-05, 6.4269e-02, 2.2189e-04, 2.4070e-02, 1.8988e-03, 4.7367e-04,
        5.5273e-03, 2.2155e-02, 1.9310e-02, 3.4490e-04, 3.7439e-02, 3.3257e-03,
        2.9941e-02, 4.1883e-01, 1.2385e-01, 2.4832e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,170][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0048, 0.0762, 0.0187, 0.3143, 0.0163, 0.0267, 0.0443, 0.0395, 0.0576,
        0.0117, 0.1027, 0.0028, 0.0438, 0.0739, 0.0310, 0.1358],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,172][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0809, 0.0971, 0.0233, 0.0756, 0.0051, 0.0544, 0.0037, 0.0212, 0.0068,
        0.0084, 0.0191, 0.0028, 0.0906, 0.3091, 0.1301, 0.0719],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,173][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.0385e-02, 2.5925e-01, 1.5890e-02, 5.3135e-01, 9.7250e-03, 7.6788e-02,
        2.9486e-04, 8.8650e-03, 1.7869e-02, 2.2094e-03, 1.5017e-02, 3.6746e-04,
        1.7692e-03, 1.8766e-02, 3.4536e-03, 8.0050e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,174][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.2938e-04, 1.4376e-13, 4.6575e-05, 7.0467e-13, 3.3278e-11, 1.1849e-03,
        1.5691e-14, 2.3430e-11, 2.5771e-16, 8.8848e-06, 1.5299e-12, 5.4603e-12,
        7.6642e-07, 2.1975e-04, 9.9841e-01, 6.9337e-07], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,175][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([7.4659e-05, 2.5671e-02, 1.3709e-04, 2.8185e-02, 2.5365e-05, 6.7593e-04,
        5.2040e-05, 3.0854e-03, 3.4799e-03, 2.0097e-05, 7.2952e-03, 6.4352e-06,
        2.0247e-03, 1.2629e-01, 5.2829e-01, 2.6326e-01, 1.1427e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,177][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.4302e-04, 4.2428e-02, 4.5659e-04, 5.1303e-02, 6.2303e-04, 1.1466e-03,
        2.9298e-04, 1.9710e-03, 6.6322e-03, 1.0979e-04, 1.2912e-02, 2.6775e-04,
        3.9679e-03, 2.7192e-01, 9.5896e-02, 4.4946e-01, 6.0371e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,178][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0417, 0.1266, 0.0188, 0.1863, 0.0113, 0.0862, 0.0024, 0.0291, 0.0514,
        0.0087, 0.0450, 0.0057, 0.0281, 0.1167, 0.0234, 0.2178, 0.0009],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,180][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([2.2204e-04, 2.1997e-02, 7.6839e-04, 4.0840e-02, 1.3723e-03, 1.4218e-03,
        3.3104e-04, 5.5610e-03, 4.9719e-03, 1.5604e-04, 1.3894e-02, 5.4385e-04,
        1.4428e-03, 2.5518e-01, 8.6025e-02, 5.5250e-01, 1.2773e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,181][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([7.3237e-01, 2.0294e-02, 5.9998e-02, 9.0265e-03, 6.0118e-03, 6.8255e-02,
        8.2489e-04, 1.2067e-03, 5.8473e-03, 5.3245e-02, 2.1161e-02, 4.8068e-03,
        6.3865e-04, 4.1584e-03, 3.1578e-03, 6.8881e-03, 2.1070e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,182][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([8.4517e-04, 4.0232e-02, 1.1283e-03, 9.7104e-02, 3.7425e-04, 1.7915e-03,
        1.7577e-04, 1.7610e-03, 8.9834e-03, 2.1120e-04, 4.2810e-02, 1.5702e-04,
        6.3726e-03, 2.1130e-01, 4.0433e-02, 5.3218e-01, 1.4141e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,184][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0064, 0.2231, 0.0073, 0.1361, 0.0092, 0.0156, 0.0032, 0.0342, 0.0188,
        0.0016, 0.0437, 0.0034, 0.0148, 0.2010, 0.0572, 0.2199, 0.0046],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,185][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([3.1794e-05, 9.4188e-02, 4.6282e-04, 2.6035e-02, 5.4421e-03, 7.2759e-04,
        1.0708e-02, 2.1808e-02, 1.7446e-02, 4.6817e-04, 2.8659e-02, 7.5315e-03,
        3.1531e-02, 2.7122e-01, 1.8488e-01, 1.7376e-01, 1.2509e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,187][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0074, 0.0866, 0.0292, 0.1688, 0.0181, 0.0329, 0.0343, 0.0734, 0.0586,
        0.0246, 0.1153, 0.0043, 0.0494, 0.0806, 0.0395, 0.1645, 0.0124],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,189][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0136, 0.0602, 0.0081, 0.0672, 0.0044, 0.0136, 0.0011, 0.0143, 0.0105,
        0.0028, 0.0092, 0.0029, 0.0337, 0.4321, 0.1044, 0.2011, 0.0206],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,191][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0454, 0.2586, 0.0444, 0.4082, 0.0131, 0.0768, 0.0008, 0.0177, 0.0374,
        0.0072, 0.0211, 0.0005, 0.0024, 0.0287, 0.0186, 0.0178, 0.0013],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,192][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([5.2474e-08, 4.5112e-09, 5.0719e-06, 2.6052e-09, 1.9747e-09, 2.2358e-05,
        2.7811e-13, 2.5544e-09, 1.3117e-11, 1.8100e-07, 3.5046e-09, 1.8412e-09,
        2.3018e-05, 4.0667e-02, 9.0925e-01, 3.4548e-02, 1.5481e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,193][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.6983e-03, 3.5395e-02, 1.3083e-03, 2.6974e-02, 2.5747e-05, 4.5737e-03,
        1.0763e-04, 1.2759e-03, 4.2989e-03, 1.2287e-04, 3.1984e-03, 4.3241e-06,
        1.6047e-03, 2.3513e-02, 4.4841e-01, 2.0342e-01, 4.5953e-02, 1.9711e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,195][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.1810e-02, 7.6969e-02, 4.0945e-03, 5.3276e-02, 5.9237e-04, 1.0980e-02,
        2.7539e-04, 1.9703e-03, 4.6206e-03, 5.9680e-04, 4.8433e-03, 1.5482e-04,
        5.9943e-03, 7.0820e-02, 6.1807e-02, 2.8417e-01, 3.7117e-02, 3.6991e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,197][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1173, 0.0978, 0.0252, 0.1204, 0.0101, 0.1439, 0.0021, 0.0192, 0.0403,
        0.0101, 0.0353, 0.0050, 0.0198, 0.0923, 0.0212, 0.1519, 0.0005, 0.0878],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,198][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.4826e-03, 1.6894e-02, 3.9186e-03, 3.6597e-02, 7.2205e-04, 6.4953e-03,
        3.0041e-04, 2.5138e-03, 2.5479e-03, 4.1910e-04, 3.0827e-03, 2.6000e-04,
        1.6427e-03, 6.0717e-02, 5.3492e-02, 3.0251e-01, 2.2945e-02, 4.8146e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,199][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.6394e-01, 2.7894e-02, 4.4101e-02, 1.2451e-02, 4.7952e-03, 7.8422e-02,
        9.4226e-04, 1.4344e-03, 3.5985e-03, 1.7758e-02, 2.0339e-02, 3.8307e-03,
        1.8431e-03, 5.5801e-03, 2.2792e-03, 6.7704e-03, 3.0550e-04, 3.7189e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,200][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.1010e-02, 8.5043e-02, 8.7119e-03, 2.1950e-01, 1.0652e-03, 9.2246e-03,
        2.7508e-04, 1.4876e-03, 1.0186e-02, 9.1664e-04, 3.0437e-02, 2.1916e-04,
        2.7224e-03, 1.8011e-02, 1.0443e-01, 3.3649e-01, 2.7339e-02, 1.2293e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,202][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0259, 0.1998, 0.0129, 0.1145, 0.0049, 0.0265, 0.0006, 0.0138, 0.0099,
        0.0020, 0.0162, 0.0011, 0.0116, 0.1193, 0.0399, 0.1036, 0.0111, 0.2864],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,203][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.8862e-05, 1.9177e-02, 1.2289e-04, 6.9947e-03, 9.1012e-04, 2.6323e-04,
        1.9259e-03, 8.4297e-03, 5.6079e-03, 1.5638e-04, 1.1721e-02, 1.7127e-03,
        9.1470e-03, 1.7632e-01, 5.4934e-02, 8.2178e-02, 5.1016e-02, 5.6936e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,205][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0070, 0.0638, 0.0204, 0.3560, 0.0137, 0.0291, 0.0250, 0.0323, 0.0517,
        0.0108, 0.0572, 0.0017, 0.0316, 0.0741, 0.0324, 0.1232, 0.0141, 0.0558],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,207][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1134, 0.0819, 0.0234, 0.0812, 0.0047, 0.0729, 0.0028, 0.0201, 0.0066,
        0.0073, 0.0107, 0.0019, 0.0503, 0.1099, 0.0836, 0.0840, 0.0317, 0.2135],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,208][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.1327e-02, 2.3040e-01, 2.2273e-02, 5.0387e-01, 7.4837e-03, 8.7945e-02,
        4.4543e-04, 8.8893e-03, 2.6817e-02, 1.9791e-03, 1.3676e-02, 2.1212e-04,
        2.1422e-03, 1.7142e-02, 3.7526e-03, 1.1276e-02, 1.0111e-04, 1.0269e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,209][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1792e-03, 4.8853e-15, 2.6747e-04, 3.4172e-15, 1.9473e-11, 3.6273e-04,
        4.3915e-14, 1.0462e-14, 1.6153e-17, 2.0950e-05, 8.4086e-15, 5.0574e-12,
        1.3837e-08, 1.0858e-08, 1.4351e-01, 1.4985e-06, 8.5337e-01, 1.2932e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,213][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:04,215][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11012],
        [27073],
        [29489],
        [41652],
        [25989],
        [31230],
        [45774],
        [32874],
        [31590],
        [29092],
        [28971],
        [ 8369],
        [32003],
        [20834],
        [26365],
        [26971],
        [28261],
        [17152]], device='cuda:0')
[2024-07-24 10:26:04,217][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12216],
        [25394],
        [28325],
        [40902],
        [25801],
        [30466],
        [45447],
        [32309],
        [32203],
        [30721],
        [28712],
        [ 9556],
        [31013],
        [22850],
        [29163],
        [27717],
        [30225],
        [17912]], device='cuda:0')
[2024-07-24 10:26:04,219][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[28124],
        [35390],
        [42676],
        [44564],
        [45077],
        [45078],
        [46482],
        [45513],
        [44158],
        [37123],
        [43113],
        [42460],
        [44585],
        [40495],
        [33213],
        [42385],
        [42667],
        [41763]], device='cuda:0')
[2024-07-24 10:26:04,220][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[27657],
        [26616],
        [27970],
        [29399],
        [32137],
        [31513],
        [32420],
        [32861],
        [33069],
        [33377],
        [33333],
        [33476],
        [33345],
        [33793],
        [33478],
        [33469],
        [33599],
        [33769]], device='cuda:0')
[2024-07-24 10:26:04,222][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[41464],
        [40624],
        [39501],
        [39107],
        [36325],
        [35455],
        [35606],
        [36430],
        [36597],
        [36416],
        [37702],
        [36902],
        [37766],
        [37153],
        [36920],
        [36716],
        [37070],
        [36436]], device='cuda:0')
[2024-07-24 10:26:04,224][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 2171],
        [ 2275],
        [19639],
        [16950],
        [14968],
        [16754],
        [16542],
        [15787],
        [15331],
        [17603],
        [15893],
        [13575],
        [16034],
        [ 9507],
        [10235],
        [11981],
        [12524],
        [ 7765]], device='cuda:0')
[2024-07-24 10:26:04,226][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18373],
        [18366],
        [ 6839],
        [15854],
        [ 6318],
        [ 8719],
        [ 9951],
        [ 7467],
        [ 7490],
        [ 6891],
        [ 8159],
        [ 6996],
        [ 8143],
        [ 8898],
        [ 7186],
        [ 8519],
        [ 7751],
        [ 9871]], device='cuda:0')
[2024-07-24 10:26:04,228][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 2561],
        [16215],
        [18119],
        [13802],
        [22162],
        [19156],
        [19247],
        [19076],
        [18886],
        [18644],
        [18638],
        [21405],
        [21367],
        [20973],
        [23343],
        [24203],
        [24654],
        [23421]], device='cuda:0')
[2024-07-24 10:26:04,230][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44754],
        [42459],
        [19064],
        [27955],
        [20535],
        [29269],
        [26249],
        [28055],
        [28987],
        [27221],
        [33146],
        [24287],
        [33852],
        [28202],
        [29015],
        [32598],
        [28874],
        [31979]], device='cuda:0')
[2024-07-24 10:26:04,232][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13512],
        [20908],
        [23305],
        [11660],
        [12705],
        [13804],
        [13642],
        [11948],
        [10023],
        [ 9796],
        [ 9013],
        [ 8507],
        [11921],
        [ 6057],
        [ 6512],
        [ 6880],
        [ 8864],
        [ 7815]], device='cuda:0')
[2024-07-24 10:26:04,233][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19714],
        [16702],
        [16517],
        [15681],
        [14383],
        [12506],
        [10924],
        [10044],
        [ 9344],
        [ 9853],
        [10053],
        [10327],
        [10075],
        [10199],
        [ 9664],
        [ 9432],
        [ 9571],
        [ 9358]], device='cuda:0')
[2024-07-24 10:26:04,235][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 9467],
        [ 8924],
        [10343],
        [ 7170],
        [ 6751],
        [ 5998],
        [ 7282],
        [ 6988],
        [ 6113],
        [ 3211],
        [ 4901],
        [ 3462],
        [ 7410],
        [ 7875],
        [ 7944],
        [ 7944],
        [ 6836],
        [ 6851]], device='cuda:0')
[2024-07-24 10:26:04,237][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[42467],
        [42630],
        [43647],
        [47707],
        [46858],
        [46731],
        [44966],
        [46280],
        [47252],
        [47286],
        [47074],
        [47102],
        [46633],
        [47220],
        [47179],
        [47167],
        [47266],
        [47305]], device='cuda:0')
[2024-07-24 10:26:04,239][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29364],
        [29364],
        [28635],
        [31281],
        [36019],
        [31477],
        [16159],
        [24148],
        [14045],
        [12590],
        [29900],
        [25725],
        [20305],
        [27632],
        [24938],
        [27607],
        [26473],
        [38756]], device='cuda:0')
[2024-07-24 10:26:04,241][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25294],
        [23503],
        [24111],
        [19893],
        [21757],
        [20192],
        [19567],
        [19349],
        [18406],
        [17925],
        [19954],
        [21398],
        [19263],
        [14483],
        [13169],
        [13726],
        [13133],
        [15638]], device='cuda:0')
[2024-07-24 10:26:04,243][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19860],
        [19500],
        [11194],
        [13653],
        [14069],
        [14934],
        [16652],
        [14996],
        [14612],
        [11284],
        [17112],
        [17330],
        [15982],
        [14317],
        [ 8587],
        [ 6970],
        [ 7740],
        [ 8194]], device='cuda:0')
[2024-07-24 10:26:04,245][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[  867],
        [ 1072],
        [14664],
        [13097],
        [13625],
        [12802],
        [13669],
        [13320],
        [12751],
        [ 8852],
        [11695],
        [ 9926],
        [12488],
        [ 8607],
        [ 7391],
        [ 7903],
        [ 7543],
        [ 7181]], device='cuda:0')
[2024-07-24 10:26:04,247][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21836],
        [21613],
        [18711],
        [17976],
        [16479],
        [18261],
        [16048],
        [16107],
        [17352],
        [17878],
        [17254],
        [19164],
        [17545],
        [20911],
        [21902],
        [27111],
        [26432],
        [27002]], device='cuda:0')
[2024-07-24 10:26:04,249][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1195],
        [ 1250],
        [ 9163],
        [ 5914],
        [ 5110],
        [ 5486],
        [ 4843],
        [ 5211],
        [ 5633],
        [ 9582],
        [ 8896],
        [ 6155],
        [ 6095],
        [12572],
        [15418],
        [25520],
        [26720],
        [21562]], device='cuda:0')
[2024-07-24 10:26:04,250][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18058],
        [18051],
        [11125],
        [16319],
        [10462],
        [ 9715],
        [10657],
        [ 9690],
        [ 9336],
        [ 7291],
        [ 8781],
        [10642],
        [10767],
        [ 9448],
        [ 8777],
        [ 9073],
        [ 8401],
        [ 9548]], device='cuda:0')
[2024-07-24 10:26:04,252][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18005],
        [20805],
        [32156],
        [33650],
        [23902],
        [21522],
        [21600],
        [22690],
        [21654],
        [19856],
        [21899],
        [25242],
        [23131],
        [22398],
        [22363],
        [18289],
        [16808],
        [16640]], device='cuda:0')
[2024-07-24 10:26:04,254][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14334],
        [24878],
        [38230],
        [38470],
        [38465],
        [38091],
        [38173],
        [38326],
        [38386],
        [38310],
        [37913],
        [37472],
        [38422],
        [37724],
        [37409],
        [36041],
        [35734],
        [35811]], device='cuda:0')
[2024-07-24 10:26:04,256][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 6007],
        [ 3558],
        [ 4523],
        [11251],
        [10865],
        [ 9750],
        [10162],
        [13916],
        [16012],
        [15539],
        [18470],
        [20057],
        [16827],
        [24675],
        [25403],
        [23360],
        [21141],
        [20734]], device='cuda:0')
[2024-07-24 10:26:04,257][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14036],
        [14733],
        [39513],
        [34084],
        [35156],
        [33216],
        [35723],
        [33352],
        [30641],
        [28576],
        [30735],
        [28286],
        [31408],
        [27724],
        [28539],
        [26655],
        [24354],
        [25564]], device='cuda:0')
[2024-07-24 10:26:04,259][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34132],
        [34909],
        [41786],
        [43037],
        [45113],
        [45520],
        [44529],
        [44226],
        [44343],
        [43720],
        [44829],
        [45472],
        [43728],
        [42013],
        [43117],
        [41560],
        [42537],
        [43278]], device='cuda:0')
[2024-07-24 10:26:04,261][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10674],
        [10541],
        [ 8075],
        [ 6287],
        [ 5746],
        [ 5153],
        [ 5511],
        [ 5289],
        [ 5210],
        [ 6098],
        [ 5272],
        [ 5610],
        [ 5325],
        [ 5213],
        [ 5294],
        [ 5196],
        [ 5383],
        [ 5182]], device='cuda:0')
[2024-07-24 10:26:04,263][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[28582],
        [28582],
        [ 6131],
        [21933],
        [ 6499],
        [ 4017],
        [21474],
        [ 9487],
        [25514],
        [22128],
        [ 6986],
        [ 9407],
        [14917],
        [ 6735],
        [20734],
        [18498],
        [19500],
        [ 8476]], device='cuda:0')
[2024-07-24 10:26:04,264][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[38216],
        [35742],
        [24018],
        [24280],
        [27514],
        [29544],
        [25000],
        [27715],
        [27266],
        [28798],
        [27512],
        [26832],
        [26317],
        [28265],
        [27865],
        [28503],
        [28751],
        [30170]], device='cuda:0')
[2024-07-24 10:26:04,266][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[16680],
        [19216],
        [17456],
        [20423],
        [19039],
        [23436],
        [24480],
        [22611],
        [21192],
        [24036],
        [21119],
        [19348],
        [22392],
        [24270],
        [25552],
        [25192],
        [25405],
        [25672]], device='cuda:0')
[2024-07-24 10:26:04,268][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284],
        [12284]], device='cuda:0')
[2024-07-24 10:26:04,321][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:04,322][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,323][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,324][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,324][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,325][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,326][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,326][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,327][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,328][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,328][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,329][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,330][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,330][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0157, 0.9843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,331][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7423, 0.2577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,332][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9602, 0.0398], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,333][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8885, 0.1115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,335][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9819, 0.0181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,336][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2448, 0.7552], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,338][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0129, 0.9871], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,340][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2783, 0.7217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,341][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5087, 0.4913], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,343][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2390, 0.7610], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,344][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2464, 0.7536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,346][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1885, 0.8115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,348][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.0055, 0.7066, 0.2879], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,349][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.0576, 0.8881, 0.0543], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,351][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.1665, 0.6203, 0.2133], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,352][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.6015, 0.2146, 0.1839], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,354][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.1856, 0.6486, 0.1658], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,355][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.0308, 0.3917, 0.5775], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,357][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([5.0285e-04, 4.8441e-01, 5.1508e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,358][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.1398, 0.5619, 0.2984], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,359][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.3531, 0.3291, 0.3178], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,360][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.1567, 0.4336, 0.4096], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,360][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.0945, 0.4497, 0.4558], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,362][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0455, 0.3038, 0.6507], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,363][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0054, 0.5241, 0.2185, 0.2520], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,364][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2499, 0.1584, 0.5805, 0.0112], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,366][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5643, 0.1250, 0.2873, 0.0234], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,368][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6286, 0.1206, 0.1600, 0.0908], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,369][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6641, 0.1529, 0.1298, 0.0532], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,371][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0441, 0.1930, 0.6117, 0.1513], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,372][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([1.3498e-04, 6.8616e-02, 9.1542e-01, 1.5827e-02], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,374][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0912, 0.3363, 0.2258, 0.3467], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,375][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2643, 0.2497, 0.2398, 0.2462], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,377][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0881, 0.3073, 0.2931, 0.3116], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,378][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0948, 0.3052, 0.2940, 0.3061], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,380][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0396, 0.1563, 0.4383, 0.3658], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,382][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0026, 0.4979, 0.1902, 0.2226, 0.0868], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,383][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0710, 0.4524, 0.3023, 0.0110, 0.1632], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,385][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.1385, 0.4157, 0.1460, 0.2130, 0.0868], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,386][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.3248, 0.1592, 0.2166, 0.1593, 0.1401], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,388][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.1681, 0.4096, 0.1117, 0.2760, 0.0346], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,390][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0200, 0.2472, 0.4119, 0.1317, 0.1892], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,391][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([3.8858e-04, 2.1046e-01, 5.4550e-01, 1.3514e-01, 1.0851e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,393][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0386, 0.2131, 0.1569, 0.3220, 0.2695], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,394][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.2164, 0.2025, 0.1933, 0.1998, 0.1880], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,396][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0588, 0.2428, 0.2301, 0.2458, 0.2224], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,397][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0608, 0.2158, 0.2156, 0.2137, 0.2941], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,399][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0245, 0.1613, 0.4364, 0.1964, 0.1814], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,400][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0025, 0.4682, 0.1735, 0.2011, 0.0773, 0.0775], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,401][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0534, 0.0491, 0.0832, 0.0211, 0.7414, 0.0518], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,401][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0709, 0.2526, 0.1219, 0.2055, 0.2697, 0.0793], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,402][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.4495, 0.1049, 0.1380, 0.0832, 0.1278, 0.0966], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,403][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0842, 0.2660, 0.0846, 0.2758, 0.1650, 0.1244], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,405][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0140, 0.1174, 0.2925, 0.0879, 0.4115, 0.0767], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,406][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ were] are: tensor([2.8234e-04, 7.2913e-02, 3.6843e-01, 9.0334e-02, 4.5035e-01, 1.7691e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,407][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0352, 0.2083, 0.1167, 0.2855, 0.1691, 0.1852], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,409][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.1817, 0.1689, 0.1624, 0.1669, 0.1565, 0.1635], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,411][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0535, 0.1953, 0.1885, 0.1983, 0.1860, 0.1784], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,412][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0587, 0.1769, 0.1711, 0.1868, 0.2216, 0.1850], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,414][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0274, 0.0902, 0.4963, 0.1433, 0.1249, 0.1179], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,416][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0019, 0.4411, 0.1617, 0.1882, 0.0708, 0.0712, 0.0651],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,417][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0150, 0.0399, 0.0796, 0.0124, 0.7658, 0.0737, 0.0137],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,419][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0059, 0.5176, 0.0305, 0.2587, 0.1504, 0.0159, 0.0209],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,421][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.1741, 0.1287, 0.1335, 0.1112, 0.1333, 0.2096, 0.1095],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,422][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0082, 0.4057, 0.0196, 0.4142, 0.0913, 0.0399, 0.0211],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,424][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0094, 0.0659, 0.3057, 0.0688, 0.3773, 0.0808, 0.0920],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,426][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0006, 0.1406, 0.2065, 0.1441, 0.2534, 0.0810, 0.1738],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,427][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0218, 0.2310, 0.1059, 0.3008, 0.1413, 0.1129, 0.0863],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,429][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.1614, 0.1472, 0.1407, 0.1447, 0.1345, 0.1410, 0.1305],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,431][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0410, 0.1675, 0.1577, 0.1712, 0.1584, 0.1563, 0.1478],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,432][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0389, 0.1567, 0.1492, 0.1525, 0.1987, 0.1513, 0.1527],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,434][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0108, 0.0904, 0.1963, 0.1752, 0.0923, 0.1485, 0.2866],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,436][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0014, 0.4457, 0.1525, 0.1791, 0.0632, 0.0635, 0.0575, 0.0371],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,437][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([8.4367e-02, 1.3113e-01, 1.8959e-01, 5.6634e-03, 3.0955e-01, 6.0264e-02,
        2.1915e-01, 2.8519e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,438][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0879, 0.3470, 0.1406, 0.1325, 0.1594, 0.0645, 0.0221, 0.0459],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,440][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.3101, 0.0810, 0.1192, 0.0659, 0.1073, 0.1470, 0.1087, 0.0608],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,442][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0419, 0.2780, 0.0438, 0.2206, 0.0643, 0.0706, 0.0186, 0.2623],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,442][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0305, 0.1199, 0.2995, 0.1031, 0.1930, 0.0591, 0.1758, 0.0191],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,443][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0004, 0.0837, 0.3100, 0.0559, 0.2640, 0.0298, 0.2390, 0.0173],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,444][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0183, 0.1306, 0.1152, 0.1964, 0.1757, 0.1585, 0.0753, 0.1300],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,446][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1432, 0.1285, 0.1234, 0.1268, 0.1184, 0.1248, 0.1146, 0.1204],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,447][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0295, 0.1505, 0.1408, 0.1535, 0.1377, 0.1326, 0.1310, 0.1244],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,449][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0373, 0.1360, 0.1333, 0.1360, 0.1671, 0.1326, 0.1246, 0.1331],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,451][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0144, 0.0670, 0.2061, 0.1299, 0.1050, 0.0801, 0.2429, 0.1546],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,452][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0016, 0.4138, 0.1473, 0.1706, 0.0623, 0.0621, 0.0553, 0.0367, 0.0502],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,454][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0528, 0.1599, 0.0819, 0.0085, 0.2570, 0.1163, 0.3151, 0.0071, 0.0015],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,456][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1564, 0.1858, 0.1731, 0.1175, 0.1130, 0.0773, 0.0220, 0.0765, 0.0783],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,457][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2313, 0.0759, 0.0986, 0.0662, 0.1029, 0.1453, 0.0982, 0.0675, 0.1141],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,459][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0491, 0.1701, 0.0446, 0.1893, 0.0423, 0.0727, 0.0187, 0.3764, 0.0368],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,461][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0134, 0.1195, 0.2009, 0.1007, 0.1588, 0.0766, 0.2383, 0.0520, 0.0398],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,462][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0004, 0.0163, 0.1136, 0.0229, 0.2887, 0.0124, 0.3734, 0.0966, 0.0756],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,464][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0196, 0.1664, 0.0711, 0.1801, 0.1297, 0.1137, 0.0836, 0.1407, 0.0951],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,466][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1202, 0.1140, 0.1090, 0.1130, 0.1065, 0.1111, 0.1050, 0.1103, 0.1109],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,467][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0289, 0.1311, 0.1237, 0.1340, 0.1225, 0.1170, 0.1164, 0.1111, 0.1153],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,469][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0335, 0.1148, 0.1132, 0.1153, 0.1471, 0.1198, 0.1094, 0.1132, 0.1337],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,471][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0124, 0.0634, 0.1735, 0.1026, 0.1223, 0.0898, 0.2356, 0.0788, 0.1217],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,472][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0019, 0.3697, 0.1390, 0.1608, 0.0620, 0.0628, 0.0559, 0.0379, 0.0509,
        0.0591], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,474][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0195, 0.1658, 0.2273, 0.0243, 0.3443, 0.1390, 0.0506, 0.0061, 0.0038,
        0.0191], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,476][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0082, 0.1535, 0.0260, 0.1364, 0.1298, 0.0203, 0.0797, 0.2217, 0.2050,
        0.0193], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,477][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.1137, 0.0934, 0.1067, 0.0783, 0.0826, 0.1309, 0.0872, 0.0837, 0.1663,
        0.0571], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,479][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0070, 0.1091, 0.0152, 0.1616, 0.0761, 0.0245, 0.0713, 0.4032, 0.1200,
        0.0120], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,481][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0021, 0.0529, 0.2530, 0.0347, 0.1960, 0.0696, 0.1808, 0.0144, 0.0260,
        0.1704], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,482][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0010, 0.0345, 0.0696, 0.0592, 0.0702, 0.0263, 0.1060, 0.1296, 0.3567,
        0.1469], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,483][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0084, 0.1446, 0.0366, 0.1896, 0.0774, 0.0656, 0.0724, 0.2169, 0.0603,
        0.1283], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,484][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.1075, 0.1024, 0.0979, 0.1014, 0.0952, 0.0997, 0.0940, 0.0991, 0.1001,
        0.1027], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,485][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0329, 0.1154, 0.1084, 0.1171, 0.1109, 0.1115, 0.1068, 0.0989, 0.1028,
        0.0954], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,486][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0239, 0.1005, 0.0940, 0.0971, 0.1267, 0.0992, 0.0915, 0.0999, 0.1181,
        0.1492], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,488][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0088, 0.0613, 0.1734, 0.0853, 0.0859, 0.0418, 0.1495, 0.0583, 0.0700,
        0.2658], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,489][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0019, 0.3526, 0.1299, 0.1477, 0.0567, 0.0564, 0.0512, 0.0345, 0.0469,
        0.0551, 0.0672], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,490][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.7386e-01, 4.6126e-02, 1.0611e-01, 2.1245e-03, 2.1200e-01, 1.7077e-01,
        2.1515e-01, 8.9495e-04, 4.4034e-03, 6.8370e-02, 1.8206e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,492][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.2162, 0.1157, 0.1854, 0.0593, 0.0945, 0.0778, 0.0122, 0.0378, 0.0682,
        0.0597, 0.0732], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,494][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.2010, 0.0667, 0.0926, 0.0530, 0.1100, 0.1077, 0.0833, 0.0610, 0.1050,
        0.0543, 0.0654], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,495][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1113, 0.1381, 0.0655, 0.1044, 0.0357, 0.0896, 0.0165, 0.2251, 0.0569,
        0.0260, 0.1310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,497][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0120, 0.0772, 0.2027, 0.0674, 0.1980, 0.0611, 0.0993, 0.0197, 0.0246,
        0.2196, 0.0184], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,498][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([3.1753e-04, 9.2855e-03, 1.4337e-01, 7.5339e-03, 1.1209e-01, 5.4062e-03,
        1.3617e-01, 1.2196e-02, 1.1234e-01, 4.5019e-01, 1.1102e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,500][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0188, 0.1295, 0.0668, 0.1448, 0.1034, 0.0658, 0.0519, 0.1210, 0.0983,
        0.0694, 0.1303], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,502][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1019, 0.0945, 0.0899, 0.0925, 0.0864, 0.0906, 0.0842, 0.0896, 0.0908,
        0.0937, 0.0859], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,503][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0281, 0.1067, 0.1022, 0.1089, 0.1003, 0.0975, 0.0970, 0.0899, 0.0931,
        0.0868, 0.0895], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,505][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0274, 0.0910, 0.0891, 0.0903, 0.1096, 0.0916, 0.0844, 0.0896, 0.1067,
        0.1219, 0.0983], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,507][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0087, 0.0531, 0.1331, 0.1123, 0.0612, 0.0506, 0.1863, 0.0627, 0.0619,
        0.1860, 0.0839], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,509][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0018, 0.3292, 0.1221, 0.1409, 0.0551, 0.0552, 0.0492, 0.0326, 0.0442,
        0.0518, 0.0631, 0.0547], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,510][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0245, 0.2234, 0.1187, 0.0069, 0.0969, 0.1924, 0.1696, 0.0061, 0.0024,
        0.0513, 0.0025, 0.1052], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,512][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0142, 0.3182, 0.0346, 0.1745, 0.0632, 0.0195, 0.0188, 0.0872, 0.1215,
        0.0130, 0.1146, 0.0207], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,514][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0845, 0.0706, 0.0882, 0.0687, 0.0584, 0.1073, 0.0726, 0.0662, 0.1511,
        0.0659, 0.1064, 0.0602], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,515][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0070, 0.1730, 0.0148, 0.1697, 0.0205, 0.0234, 0.0237, 0.2831, 0.0612,
        0.0062, 0.2129, 0.0046], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,517][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0040, 0.0551, 0.0684, 0.0294, 0.0433, 0.0728, 0.1927, 0.0326, 0.0318,
        0.3639, 0.0334, 0.0727], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,519][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([7.0793e-05, 2.0153e-02, 5.9425e-02, 1.2201e-02, 1.5494e-02, 1.2955e-02,
        9.8471e-02, 2.3010e-02, 1.3584e-01, 4.1927e-01, 1.4833e-01, 5.4780e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,520][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0118, 0.0976, 0.0527, 0.1463, 0.0855, 0.1037, 0.0283, 0.1092, 0.0664,
        0.1329, 0.0871, 0.0785], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,522][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0986, 0.0864, 0.0845, 0.0851, 0.0794, 0.0838, 0.0759, 0.0803, 0.0827,
        0.0859, 0.0778, 0.0796], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,524][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0226, 0.1029, 0.0965, 0.1042, 0.0928, 0.0904, 0.0892, 0.0820, 0.0858,
        0.0781, 0.0815, 0.0741], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,525][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0221, 0.0792, 0.0843, 0.0787, 0.1094, 0.0835, 0.0717, 0.0736, 0.0925,
        0.0980, 0.0872, 0.1197], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,526][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0069, 0.0543, 0.1638, 0.0710, 0.0675, 0.0711, 0.1059, 0.0603, 0.0829,
        0.2067, 0.0500, 0.0594], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,527][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0013, 0.3370, 0.1205, 0.1380, 0.0507, 0.0504, 0.0445, 0.0287, 0.0394,
        0.0470, 0.0583, 0.0503, 0.0340], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,528][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0283, 0.0383, 0.1235, 0.0106, 0.2021, 0.0863, 0.0613, 0.0032, 0.0075,
        0.0955, 0.0013, 0.3320, 0.0100], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,529][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0195, 0.4071, 0.0504, 0.1488, 0.0890, 0.0194, 0.0089, 0.0606, 0.0686,
        0.0096, 0.0692, 0.0104, 0.0383], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,531][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.1765, 0.0536, 0.0891, 0.0473, 0.0663, 0.0795, 0.0569, 0.0479, 0.0891,
        0.0474, 0.0737, 0.0652, 0.1073], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,533][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0192, 0.2572, 0.0269, 0.1635, 0.0367, 0.0384, 0.0073, 0.0984, 0.0345,
        0.0073, 0.1409, 0.0037, 0.1657], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,534][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0075, 0.0609, 0.2030, 0.0525, 0.0757, 0.0434, 0.0776, 0.0228, 0.0279,
        0.2279, 0.0230, 0.1167, 0.0610], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,536][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([5.5611e-05, 2.0492e-02, 2.5176e-02, 1.1975e-02, 3.8503e-02, 6.9849e-03,
        2.7010e-02, 2.4525e-02, 2.5350e-01, 3.7190e-01, 1.2522e-01, 8.8429e-02,
        6.2251e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,537][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0268, 0.1214, 0.0503, 0.1599, 0.0812, 0.0453, 0.0342, 0.1109, 0.0805,
        0.0732, 0.0999, 0.0781, 0.0383], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,539][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0928, 0.0801, 0.0777, 0.0784, 0.0731, 0.0773, 0.0699, 0.0742, 0.0769,
        0.0794, 0.0722, 0.0730, 0.0750], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,541][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0173, 0.0973, 0.0913, 0.0987, 0.0868, 0.0835, 0.0851, 0.0771, 0.0806,
        0.0738, 0.0763, 0.0693, 0.0629], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,542][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0226, 0.0718, 0.0704, 0.0751, 0.0907, 0.0761, 0.0662, 0.0710, 0.0890,
        0.0920, 0.0861, 0.0982, 0.0908], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,544][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0087, 0.0470, 0.1877, 0.0885, 0.0669, 0.0549, 0.1429, 0.0634, 0.0688,
        0.1028, 0.0489, 0.0614, 0.0582], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,546][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0013, 0.3306, 0.1146, 0.1316, 0.0486, 0.0482, 0.0432, 0.0280, 0.0376,
        0.0449, 0.0563, 0.0483, 0.0332, 0.0336], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,547][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.4699e-02, 1.4907e-02, 3.2036e-02, 7.7124e-04, 8.8884e-02, 3.7055e-02,
        1.5098e-01, 2.6922e-04, 2.2983e-03, 5.5805e-02, 1.9257e-04, 4.0743e-01,
        1.9453e-01, 1.4081e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,549][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3519, 0.0868, 0.2239, 0.0304, 0.0372, 0.0660, 0.0043, 0.0109, 0.0245,
        0.0469, 0.0315, 0.0085, 0.0483, 0.0288], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,551][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1928, 0.0496, 0.0585, 0.0386, 0.0563, 0.0674, 0.0566, 0.0388, 0.0728,
        0.0385, 0.0575, 0.0527, 0.1259, 0.0942], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,553][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1550, 0.1020, 0.0588, 0.0481, 0.0138, 0.0879, 0.0042, 0.0496, 0.0194,
        0.0169, 0.0499, 0.0030, 0.1963, 0.1951], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,554][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0100, 0.0656, 0.1454, 0.0518, 0.1012, 0.0364, 0.0739, 0.0128, 0.0247,
        0.1402, 0.0134, 0.1186, 0.1958, 0.0102], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,556][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.6765e-05, 6.0649e-03, 1.3643e-01, 4.9666e-03, 5.7726e-02, 5.6220e-03,
        9.9119e-02, 7.6038e-03, 1.6210e-01, 2.2977e-01, 3.9039e-02, 1.4062e-01,
        1.0590e-01, 4.9952e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,557][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0143, 0.0975, 0.0506, 0.1096, 0.0733, 0.0713, 0.0494, 0.0846, 0.0737,
        0.0572, 0.0899, 0.0700, 0.0584, 0.1000], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,559][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0825, 0.0739, 0.0712, 0.0733, 0.0686, 0.0724, 0.0661, 0.0698, 0.0719,
        0.0741, 0.0678, 0.0680, 0.0701, 0.0702], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,561][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0155, 0.0893, 0.0841, 0.0919, 0.0816, 0.0782, 0.0773, 0.0727, 0.0762,
        0.0678, 0.0717, 0.0659, 0.0622, 0.0657], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,563][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0193, 0.0686, 0.0682, 0.0705, 0.0853, 0.0713, 0.0669, 0.0684, 0.0796,
        0.0912, 0.0752, 0.0914, 0.0796, 0.0647], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,565][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0070, 0.0462, 0.1166, 0.0874, 0.0597, 0.0431, 0.1440, 0.0587, 0.0600,
        0.1493, 0.0564, 0.0523, 0.0252, 0.0942], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,566][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0015, 0.2882, 0.1074, 0.1247, 0.0485, 0.0487, 0.0431, 0.0287, 0.0380,
        0.0450, 0.0557, 0.0486, 0.0340, 0.0341, 0.0537], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,567][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([4.8984e-03, 1.0391e-02, 2.4658e-02, 3.9309e-03, 2.5360e-01, 1.0114e-02,
        9.1636e-03, 5.8099e-04, 1.1976e-03, 2.3449e-02, 5.3770e-04, 6.5318e-01,
        3.8583e-03, 2.2238e-04, 2.1335e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,568][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0664, 0.2789, 0.1051, 0.0938, 0.0819, 0.0312, 0.0040, 0.0196, 0.0310,
        0.0226, 0.0496, 0.0123, 0.0365, 0.0807, 0.0865], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,569][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1178, 0.0523, 0.0525, 0.0383, 0.0545, 0.0700, 0.0496, 0.0329, 0.0760,
        0.0307, 0.0610, 0.0532, 0.0962, 0.0962, 0.1186], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,570][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0685, 0.0977, 0.0390, 0.0606, 0.0146, 0.0551, 0.0031, 0.0541, 0.0167,
        0.0108, 0.0752, 0.0030, 0.1133, 0.2595, 0.1288], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,571][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0007, 0.0222, 0.0657, 0.0117, 0.1175, 0.0295, 0.0582, 0.0114, 0.0181,
        0.3186, 0.0220, 0.1753, 0.1282, 0.0069, 0.0139], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,572][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([1.1883e-04, 1.3572e-02, 2.6411e-02, 1.0723e-02, 6.0232e-02, 8.1669e-03,
        3.1449e-02, 2.9061e-02, 9.2859e-02, 3.0090e-01, 7.7525e-02, 1.5202e-01,
        4.6130e-02, 1.1198e-01, 3.8850e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,574][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0137, 0.1033, 0.0464, 0.1221, 0.0564, 0.0608, 0.0452, 0.0908, 0.0682,
        0.0568, 0.1013, 0.0525, 0.0410, 0.1039, 0.0376], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,576][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0736, 0.0685, 0.0656, 0.0679, 0.0642, 0.0673, 0.0626, 0.0658, 0.0669,
        0.0687, 0.0636, 0.0642, 0.0665, 0.0661, 0.0685], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,578][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0209, 0.0788, 0.0749, 0.0799, 0.0743, 0.0722, 0.0719, 0.0682, 0.0703,
        0.0644, 0.0667, 0.0626, 0.0596, 0.0628, 0.0726], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,579][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0186, 0.0636, 0.0637, 0.0631, 0.0805, 0.0630, 0.0575, 0.0636, 0.0741,
        0.0847, 0.0706, 0.0872, 0.0773, 0.0609, 0.0715], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,581][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0072, 0.0373, 0.1207, 0.0787, 0.0603, 0.0424, 0.1504, 0.0493, 0.0596,
        0.1278, 0.0437, 0.0562, 0.0262, 0.0608, 0.0793], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,583][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0009, 0.2910, 0.1046, 0.1232, 0.0450, 0.0445, 0.0391, 0.0254, 0.0344,
        0.0418, 0.0527, 0.0455, 0.0316, 0.0312, 0.0508, 0.0382],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,584][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.0362e-02, 5.3930e-02, 3.5317e-02, 2.5332e-03, 1.3008e-01, 1.9335e-02,
        5.7298e-02, 6.2002e-04, 5.3195e-04, 5.5276e-02, 8.4744e-04, 6.1161e-01,
        1.8288e-02, 8.5050e-04, 2.8618e-03, 2.6167e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,586][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1781, 0.0696, 0.1283, 0.0392, 0.0417, 0.0458, 0.0042, 0.0164, 0.0247,
        0.0302, 0.0414, 0.0153, 0.0526, 0.0974, 0.1170, 0.0981],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,588][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1299, 0.0375, 0.0436, 0.0334, 0.0429, 0.0663, 0.0445, 0.0329, 0.0594,
        0.0356, 0.0474, 0.0431, 0.0955, 0.0871, 0.1393, 0.0616],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,590][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0661, 0.0364, 0.0285, 0.0263, 0.0090, 0.0422, 0.0034, 0.0403, 0.0096,
        0.0091, 0.0351, 0.0025, 0.1267, 0.2739, 0.2111, 0.0799],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,591][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0031, 0.0369, 0.0891, 0.0235, 0.0772, 0.0375, 0.0865, 0.0099, 0.0140,
        0.2517, 0.0183, 0.1033, 0.1357, 0.0052, 0.0833, 0.0246],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,593][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([5.7037e-05, 2.9739e-03, 1.1380e-02, 5.0704e-03, 5.9442e-02, 2.0419e-03,
        3.9327e-02, 1.2998e-02, 2.0494e-02, 3.5831e-01, 4.5715e-02, 1.4865e-01,
        6.7625e-02, 8.2041e-02, 1.3893e-01, 4.9374e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,594][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0146, 0.0838, 0.0399, 0.0970, 0.0565, 0.0718, 0.0484, 0.0718, 0.0553,
        0.0720, 0.0830, 0.0533, 0.0463, 0.0863, 0.0822, 0.0377],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,596][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0680, 0.0643, 0.0609, 0.0633, 0.0599, 0.0627, 0.0588, 0.0614, 0.0624,
        0.0644, 0.0598, 0.0602, 0.0625, 0.0617, 0.0642, 0.0656],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,598][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0220, 0.0728, 0.0692, 0.0736, 0.0689, 0.0670, 0.0655, 0.0632, 0.0648,
        0.0589, 0.0616, 0.0584, 0.0567, 0.0594, 0.0672, 0.0707],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,600][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0171, 0.0589, 0.0599, 0.0581, 0.0754, 0.0602, 0.0566, 0.0600, 0.0684,
        0.0792, 0.0637, 0.0815, 0.0704, 0.0552, 0.0668, 0.0686],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,602][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0075, 0.0357, 0.0912, 0.0619, 0.0664, 0.0416, 0.1175, 0.0582, 0.0647,
        0.1559, 0.0462, 0.0582, 0.0243, 0.0517, 0.0454, 0.0733],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,603][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0012, 0.2688, 0.1004, 0.1181, 0.0449, 0.0449, 0.0387, 0.0254, 0.0343,
        0.0410, 0.0513, 0.0445, 0.0308, 0.0302, 0.0478, 0.0366, 0.0411],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,605][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0175, 0.1043, 0.0540, 0.0180, 0.2082, 0.0362, 0.0783, 0.0031, 0.0051,
        0.0483, 0.0039, 0.2992, 0.0939, 0.0011, 0.0042, 0.0093, 0.0155],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,607][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0441, 0.2135, 0.0533, 0.0727, 0.0455, 0.0189, 0.0022, 0.0165, 0.0325,
        0.0126, 0.0406, 0.0091, 0.0218, 0.0613, 0.0731, 0.2003, 0.0820],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,608][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0576, 0.0439, 0.0535, 0.0385, 0.0443, 0.0667, 0.0417, 0.0336, 0.0713,
        0.0362, 0.0581, 0.0461, 0.0889, 0.0861, 0.1165, 0.0777, 0.0394],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,609][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0522, 0.0710, 0.0226, 0.0307, 0.0117, 0.0374, 0.0032, 0.0454, 0.0131,
        0.0064, 0.0419, 0.0040, 0.1018, 0.1989, 0.1565, 0.1532, 0.0499],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,610][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0005, 0.0147, 0.0508, 0.0109, 0.2011, 0.0262, 0.0677, 0.0072, 0.0109,
        0.1721, 0.0133, 0.1617, 0.1550, 0.0037, 0.0414, 0.0255, 0.0371],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,611][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([9.7742e-05, 9.6736e-03, 3.2401e-02, 1.3289e-02, 4.9334e-02, 8.1392e-03,
        2.2102e-02, 1.9931e-02, 1.6366e-01, 2.4607e-01, 4.2733e-02, 1.2134e-01,
        2.5803e-02, 4.7349e-02, 3.4650e-02, 1.3849e-01, 2.4935e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,613][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0077, 0.0740, 0.0392, 0.1078, 0.0645, 0.0376, 0.0372, 0.0810, 0.0478,
        0.0585, 0.0739, 0.0598, 0.0407, 0.0968, 0.0434, 0.0379, 0.0921],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,615][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0641, 0.0605, 0.0576, 0.0595, 0.0564, 0.0588, 0.0553, 0.0578, 0.0584,
        0.0603, 0.0558, 0.0563, 0.0583, 0.0582, 0.0603, 0.0622, 0.0603],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,616][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0274, 0.0664, 0.0638, 0.0668, 0.0630, 0.0636, 0.0614, 0.0582, 0.0600,
        0.0562, 0.0582, 0.0547, 0.0521, 0.0538, 0.0618, 0.0649, 0.0677],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,618][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0138, 0.0559, 0.0547, 0.0536, 0.0689, 0.0552, 0.0486, 0.0557, 0.0661,
        0.0724, 0.0620, 0.0764, 0.0672, 0.0536, 0.0613, 0.0643, 0.0702],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,620][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0058, 0.0469, 0.1112, 0.0704, 0.0501, 0.0476, 0.0943, 0.0572, 0.0538,
        0.1140, 0.0477, 0.0433, 0.0288, 0.0485, 0.0467, 0.0487, 0.0851],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,622][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0010, 0.2716, 0.0963, 0.1126, 0.0416, 0.0413, 0.0368, 0.0237, 0.0319,
        0.0383, 0.0482, 0.0416, 0.0287, 0.0289, 0.0465, 0.0351, 0.0389, 0.0368],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,623][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.5942e-03, 1.5791e-02, 3.0442e-02, 8.2486e-04, 7.3099e-02, 2.6694e-02,
        1.2904e-01, 2.1099e-04, 2.7191e-03, 4.7252e-02, 1.7002e-04, 3.7023e-01,
        1.6655e-01, 1.1389e-04, 1.0949e-02, 1.4939e-02, 1.0226e-01, 1.2212e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,625][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4185, 0.0399, 0.1809, 0.0133, 0.0173, 0.0468, 0.0017, 0.0037, 0.0114,
        0.0348, 0.0098, 0.0040, 0.0180, 0.0104, 0.0511, 0.0615, 0.0590, 0.0179],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,627][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1357, 0.0348, 0.0414, 0.0273, 0.0408, 0.0495, 0.0417, 0.0281, 0.0522,
        0.0292, 0.0409, 0.0391, 0.0909, 0.0667, 0.1206, 0.0636, 0.0363, 0.0614],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,628][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2417, 0.0365, 0.0467, 0.0152, 0.0052, 0.0758, 0.0016, 0.0175, 0.0072,
        0.0138, 0.0160, 0.0014, 0.0811, 0.0898, 0.1330, 0.0813, 0.0247, 0.1116],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,630][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0022, 0.0389, 0.1039, 0.0273, 0.1072, 0.0285, 0.0635, 0.0054, 0.0164,
        0.1110, 0.0069, 0.1063, 0.1739, 0.0031, 0.0634, 0.0419, 0.0992, 0.0010],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,631][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.7902e-05, 3.6843e-03, 9.2290e-02, 3.6894e-03, 4.7455e-02, 2.9995e-03,
        6.7777e-02, 5.1070e-03, 1.3785e-01, 1.6717e-01, 2.1427e-02, 1.0631e-01,
        6.7683e-02, 3.6881e-03, 5.6055e-02, 6.8998e-02, 1.4138e-01, 6.3925e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,633][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0115, 0.0644, 0.0360, 0.0737, 0.0523, 0.0515, 0.0353, 0.0590, 0.0552,
        0.0451, 0.0638, 0.0501, 0.0405, 0.0692, 0.0518, 0.0422, 0.1203, 0.0782],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,635][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0605, 0.0570, 0.0546, 0.0564, 0.0531, 0.0555, 0.0520, 0.0546, 0.0554,
        0.0571, 0.0527, 0.0529, 0.0550, 0.0546, 0.0568, 0.0587, 0.0572, 0.0559],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,637][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0164, 0.0655, 0.0612, 0.0663, 0.0600, 0.0587, 0.0570, 0.0549, 0.0569,
        0.0509, 0.0540, 0.0501, 0.0488, 0.0508, 0.0599, 0.0635, 0.0656, 0.0594],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,639][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0154, 0.0519, 0.0517, 0.0522, 0.0634, 0.0535, 0.0517, 0.0533, 0.0596,
        0.0697, 0.0564, 0.0674, 0.0620, 0.0493, 0.0598, 0.0596, 0.0664, 0.0568],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,640][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0058, 0.0353, 0.0804, 0.0631, 0.0423, 0.0360, 0.1010, 0.0474, 0.0463,
        0.1059, 0.0437, 0.0368, 0.0194, 0.0718, 0.0446, 0.0451, 0.0914, 0.0838],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:04,699][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:04,700][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,701][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,701][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,702][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,703][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,703][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,704][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,705][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,707][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,708][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,709][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,710][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:04,710][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9753, 0.0247], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,711][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9919e-01, 8.1190e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,712][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9602, 0.0398], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,713][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8067, 0.1933], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,715][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9819, 0.0181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,717][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9697, 0.0303], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,718][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6777, 0.3223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,720][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9867, 0.0133], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,721][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9918, 0.0082], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,722][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.9915e-01, 8.5115e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,724][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,725][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9502, 0.0498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:04,727][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.4222, 0.1855, 0.3924], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,729][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.2074, 0.5884, 0.2042], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,730][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.1665, 0.6203, 0.2133], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,732][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.1373, 0.7275, 0.1353], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,733][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.1856, 0.6486, 0.1658], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,735][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.4324, 0.3309, 0.2367], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,737][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.0222, 0.9267, 0.0511], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,738][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.4454, 0.3582, 0.1964], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,740][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.3273, 0.4243, 0.2484], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,741][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.7840, 0.0560, 0.1599], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,743][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.8073, 0.0524, 0.1404], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,745][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.6225, 0.1234, 0.2541], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:04,746][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6088, 0.0162, 0.3357, 0.0393], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,748][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8409, 0.0014, 0.1562, 0.0016], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,749][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5643, 0.1250, 0.2873, 0.0234], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,751][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2889, 0.4654, 0.1072, 0.1386], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,752][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6641, 0.1529, 0.1298, 0.0532], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,752][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7093, 0.0461, 0.2366, 0.0081], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,753][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0640, 0.5083, 0.1565, 0.2712], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,754][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.7966, 0.0907, 0.0861, 0.0266], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,755][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7833, 0.0250, 0.1869, 0.0048], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,757][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9389, 0.0050, 0.0543, 0.0019], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,758][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9831, 0.0021, 0.0131, 0.0017], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,760][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8424, 0.0313, 0.0751, 0.0512], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:04,762][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.1731, 0.0625, 0.1629, 0.3965, 0.2049], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,763][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.3963, 0.0876, 0.1583, 0.0795, 0.2783], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,765][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.1385, 0.4157, 0.1460, 0.2130, 0.0868], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,766][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.1512, 0.4403, 0.0693, 0.3190, 0.0202], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,768][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.1681, 0.4096, 0.1117, 0.2760, 0.0346], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,769][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.4382, 0.2339, 0.1846, 0.0837, 0.0595], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,771][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0068, 0.4097, 0.0218, 0.5191, 0.0427], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,773][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.5843, 0.1952, 0.0998, 0.1056, 0.0150], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,774][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.4626, 0.1868, 0.1789, 0.1183, 0.0534], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,776][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.8650, 0.0237, 0.1005, 0.0086, 0.0022], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,778][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.8819, 0.0326, 0.0474, 0.0277, 0.0105], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,779][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.6844, 0.0715, 0.1201, 0.0808, 0.0431], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:04,781][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.2698, 0.0803, 0.2237, 0.1519, 0.1424, 0.1319], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,783][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.1464, 0.1743, 0.1544, 0.2016, 0.1766, 0.1468], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,784][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0709, 0.2526, 0.1219, 0.2055, 0.2697, 0.0793], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,786][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0577, 0.3190, 0.0729, 0.3327, 0.1291, 0.0887], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,788][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0842, 0.2660, 0.0846, 0.2758, 0.1650, 0.1244], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,789][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1929, 0.1295, 0.1651, 0.2324, 0.1271, 0.1529], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,791][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0124, 0.3105, 0.0398, 0.3321, 0.2484, 0.0567], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,793][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1700, 0.2929, 0.1075, 0.2069, 0.0997, 0.1229], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,793][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.2224, 0.1731, 0.1749, 0.1803, 0.1143, 0.1351], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,794][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.5472, 0.0491, 0.1678, 0.0349, 0.0418, 0.1592], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,795][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.4926, 0.0825, 0.1246, 0.0737, 0.0365, 0.1901], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,796][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.4382, 0.0752, 0.1528, 0.0923, 0.0407, 0.2008], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:04,797][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0044, 0.0789, 0.0119, 0.3415, 0.1294, 0.0071, 0.4268],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,798][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.1425, 0.0234, 0.0811, 0.0688, 0.1769, 0.0846, 0.4228],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,800][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0059, 0.5176, 0.0305, 0.2587, 0.1504, 0.0159, 0.0209],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,802][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0141, 0.5422, 0.0165, 0.3636, 0.0276, 0.0319, 0.0040],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,803][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0082, 0.4057, 0.0196, 0.4142, 0.0913, 0.0399, 0.0211],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,805][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.1106, 0.2955, 0.1631, 0.0761, 0.2582, 0.0590, 0.0375],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,806][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([1.6810e-04, 3.5057e-01, 4.1859e-03, 4.2816e-01, 1.6163e-01, 8.6030e-03,
        4.6687e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,807][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0867, 0.4416, 0.0369, 0.2762, 0.0492, 0.0613, 0.0481],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,809][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0514, 0.3642, 0.0881, 0.2242, 0.1931, 0.0551, 0.0239],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,811][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.2558, 0.3338, 0.1341, 0.0758, 0.0670, 0.1286, 0.0048],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,813][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.4842, 0.2108, 0.0260, 0.1295, 0.0085, 0.1323, 0.0086],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,814][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.2702, 0.0595, 0.0852, 0.1514, 0.0382, 0.1213, 0.2743],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:04,816][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0075, 0.0364, 0.0173, 0.1438, 0.0618, 0.0085, 0.3513, 0.3735],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,818][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0399, 0.0083, 0.0339, 0.0058, 0.0353, 0.0143, 0.7690, 0.0935],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,819][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0879, 0.3470, 0.1406, 0.1325, 0.1594, 0.0645, 0.0221, 0.0459],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,821][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0559, 0.4711, 0.0420, 0.3134, 0.0260, 0.0601, 0.0052, 0.0264],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,823][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0419, 0.2780, 0.0438, 0.2206, 0.0643, 0.0706, 0.0186, 0.2623],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,824][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0696, 0.2693, 0.1174, 0.0828, 0.1038, 0.0432, 0.2336, 0.0803],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,826][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0030, 0.3734, 0.0172, 0.2944, 0.1365, 0.0388, 0.0983, 0.0383],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,828][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1813, 0.1955, 0.0728, 0.1895, 0.0602, 0.0559, 0.1101, 0.1346],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,829][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2353, 0.2081, 0.1678, 0.1311, 0.0688, 0.1188, 0.0259, 0.0443],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,831][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.4070, 0.1479, 0.1514, 0.0382, 0.0676, 0.1285, 0.0419, 0.0174],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,833][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2769, 0.1924, 0.0568, 0.2196, 0.0284, 0.1189, 0.0357, 0.0712],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,834][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1011, 0.0349, 0.0331, 0.0802, 0.0205, 0.0507, 0.0348, 0.6446],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:04,835][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0111, 0.0296, 0.0164, 0.1644, 0.0458, 0.0104, 0.1278, 0.4949, 0.0995],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,836][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1438, 0.0175, 0.0937, 0.0124, 0.1322, 0.0443, 0.3748, 0.1207, 0.0607],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,837][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1564, 0.1858, 0.1731, 0.1175, 0.1130, 0.0773, 0.0220, 0.0765, 0.0783],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,838][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0576, 0.4202, 0.0404, 0.3098, 0.0329, 0.0572, 0.0072, 0.0382, 0.0366],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,839][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0491, 0.1701, 0.0446, 0.1893, 0.0423, 0.0727, 0.0187, 0.3764, 0.0368],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,841][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1835, 0.1328, 0.1558, 0.0697, 0.1533, 0.0732, 0.1258, 0.0786, 0.0272],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,843][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0056, 0.2393, 0.0161, 0.3172, 0.0622, 0.0487, 0.0638, 0.1562, 0.0909],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,844][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1699, 0.1916, 0.0646, 0.1747, 0.0207, 0.0580, 0.0468, 0.2269, 0.0468],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,846][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2778, 0.1477, 0.1644, 0.1004, 0.0828, 0.1356, 0.0154, 0.0529, 0.0229],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,847][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.4740, 0.1143, 0.1628, 0.0290, 0.0428, 0.1296, 0.0218, 0.0116, 0.0141],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,849][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3715, 0.1130, 0.0443, 0.1760, 0.0112, 0.1386, 0.0200, 0.0632, 0.0622],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,851][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0974, 0.0353, 0.0320, 0.0641, 0.0215, 0.0480, 0.0239, 0.3000, 0.3777],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:04,852][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0462, 0.0686, 0.0632, 0.1140, 0.0925, 0.0444, 0.1599, 0.2180, 0.1405,
        0.0527], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,854][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0242, 0.0570, 0.0304, 0.0804, 0.0875, 0.0364, 0.2289, 0.1984, 0.2116,
        0.0453], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,856][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0082, 0.1535, 0.0260, 0.1364, 0.1298, 0.0203, 0.0797, 0.2217, 0.2050,
        0.0193], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,858][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0129, 0.2052, 0.0249, 0.2641, 0.0837, 0.0330, 0.0665, 0.1434, 0.1453,
        0.0209], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,859][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0070, 0.1091, 0.0152, 0.1616, 0.0761, 0.0245, 0.0713, 0.4032, 0.1200,
        0.0120], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,861][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0733, 0.0907, 0.0799, 0.1078, 0.1038, 0.0715, 0.1316, 0.1382, 0.1306,
        0.0727], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,863][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0010, 0.1969, 0.0069, 0.2072, 0.0906, 0.0104, 0.1109, 0.1947, 0.1770,
        0.0045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,865][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0234, 0.1542, 0.0262, 0.1383, 0.0565, 0.0328, 0.1315, 0.2939, 0.1176,
        0.0256], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,866][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0386, 0.0973, 0.0524, 0.1313, 0.1062, 0.0529, 0.0906, 0.1872, 0.1977,
        0.0459], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,868][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.3455, 0.0604, 0.1505, 0.0366, 0.0515, 0.1361, 0.0465, 0.0359, 0.0348,
        0.1022], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,870][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.3613, 0.1154, 0.0634, 0.0845, 0.0235, 0.1470, 0.0137, 0.0404, 0.0422,
        0.1086], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,872][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.1438, 0.0683, 0.0911, 0.0815, 0.0534, 0.0817, 0.0766, 0.1691, 0.1518,
        0.0827], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:04,873][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0203, 0.0247, 0.0309, 0.0944, 0.0509, 0.0119, 0.1238, 0.3856, 0.1276,
        0.0169, 0.1130], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,875][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0199, 0.0100, 0.0204, 0.0081, 0.0627, 0.0118, 0.3966, 0.1912, 0.1632,
        0.0219, 0.0943], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,877][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2162, 0.1157, 0.1854, 0.0593, 0.0945, 0.0778, 0.0122, 0.0378, 0.0682,
        0.0597, 0.0732], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,878][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1314, 0.3066, 0.0635, 0.2433, 0.0247, 0.0824, 0.0044, 0.0231, 0.0326,
        0.0329, 0.0551], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,880][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1113, 0.1381, 0.0655, 0.1044, 0.0357, 0.0896, 0.0165, 0.2251, 0.0569,
        0.0260, 0.1310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,882][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1018, 0.0802, 0.1081, 0.1244, 0.0827, 0.0684, 0.1416, 0.0922, 0.0643,
        0.0641, 0.0723], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,882][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0071, 0.1186, 0.0247, 0.1541, 0.1174, 0.0447, 0.0597, 0.0920, 0.1986,
        0.0121, 0.1709], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,883][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.3271, 0.1030, 0.0812, 0.1161, 0.0215, 0.0651, 0.0287, 0.1024, 0.0391,
        0.0540, 0.0618], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,884][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.3095, 0.1108, 0.1297, 0.0772, 0.0380, 0.1094, 0.0098, 0.0509, 0.0442,
        0.0562, 0.0644], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,885][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.4364, 0.0857, 0.1461, 0.0317, 0.0508, 0.1268, 0.0233, 0.0112, 0.0151,
        0.0646, 0.0082], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,887][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.2998, 0.1152, 0.0416, 0.1564, 0.0152, 0.1253, 0.0124, 0.0481, 0.0514,
        0.0580, 0.0764], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,888][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0887, 0.0290, 0.0323, 0.0540, 0.0171, 0.0458, 0.0147, 0.2363, 0.1363,
        0.0262, 0.3195], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:04,890][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0056, 0.0058, 0.0099, 0.0534, 0.0283, 0.0082, 0.2222, 0.2952, 0.1128,
        0.0110, 0.1859, 0.0616], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,891][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0008, 0.0204, 0.0020, 0.0184, 0.0255, 0.0035, 0.3868, 0.2026, 0.0619,
        0.0047, 0.2260, 0.0474], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,893][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0142, 0.3182, 0.0346, 0.1745, 0.0632, 0.0195, 0.0188, 0.0872, 0.1215,
        0.0130, 0.1146, 0.0207], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,895][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0210, 0.3810, 0.0211, 0.2878, 0.0178, 0.0327, 0.0061, 0.0429, 0.0553,
        0.0133, 0.1161, 0.0049], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,896][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0070, 0.1730, 0.0148, 0.1697, 0.0205, 0.0234, 0.0237, 0.2831, 0.0612,
        0.0062, 0.2129, 0.0046], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,898][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0189, 0.1979, 0.0283, 0.1421, 0.0531, 0.0414, 0.2442, 0.0680, 0.0348,
        0.0370, 0.1202, 0.0143], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,900][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0004, 0.2411, 0.0036, 0.2132, 0.0251, 0.0079, 0.0397, 0.0488, 0.1865,
        0.0017, 0.2230, 0.0092], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,902][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.1085, 0.1929, 0.0455, 0.1445, 0.0181, 0.0473, 0.0333, 0.1082, 0.0524,
        0.0346, 0.1960, 0.0187], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,903][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0350, 0.1587, 0.0345, 0.0871, 0.0406, 0.0459, 0.0471, 0.2063, 0.1164,
        0.0262, 0.1740, 0.0282], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,905][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.3147, 0.1242, 0.1217, 0.0756, 0.0202, 0.1614, 0.0113, 0.0252, 0.0532,
        0.0671, 0.0205, 0.0049], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,907][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.3448, 0.1513, 0.0420, 0.1269, 0.0476, 0.1222, 0.0021, 0.0331, 0.0285,
        0.0271, 0.0544, 0.0200], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,909][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.1809, 0.0465, 0.0498, 0.0489, 0.0285, 0.0820, 0.0318, 0.1274, 0.1252,
        0.0410, 0.1730, 0.0650], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:04,910][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0010, 0.0101, 0.0035, 0.0494, 0.0140, 0.0015, 0.0856, 0.2835, 0.0984,
        0.0028, 0.1785, 0.1445, 0.1273], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,912][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0230, 0.0109, 0.0284, 0.0093, 0.0172, 0.0109, 0.1776, 0.0710, 0.0746,
        0.0254, 0.1150, 0.1699, 0.2669], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,914][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0195, 0.4071, 0.0504, 0.1488, 0.0890, 0.0194, 0.0089, 0.0606, 0.0686,
        0.0096, 0.0692, 0.0104, 0.0383], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,916][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0367, 0.4486, 0.0379, 0.2385, 0.0196, 0.0465, 0.0035, 0.0205, 0.0364,
        0.0131, 0.0628, 0.0055, 0.0304], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,917][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0192, 0.2572, 0.0269, 0.1635, 0.0367, 0.0384, 0.0073, 0.0984, 0.0345,
        0.0073, 0.1409, 0.0037, 0.1657], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,919][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.2210, 0.1567, 0.2344, 0.0209, 0.0594, 0.0602, 0.0420, 0.0212, 0.0202,
        0.0797, 0.0180, 0.0465, 0.0199], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,921][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0006, 0.2290, 0.0050, 0.1957, 0.0478, 0.0137, 0.0308, 0.0412, 0.1238,
        0.0018, 0.2007, 0.0136, 0.0963], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,923][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0906, 0.3369, 0.0444, 0.1495, 0.0173, 0.0496, 0.0072, 0.0545, 0.0279,
        0.0128, 0.0914, 0.0070, 0.1107], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,924][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.2334, 0.1886, 0.1265, 0.0430, 0.0309, 0.0637, 0.0059, 0.0323, 0.0317,
        0.0378, 0.0616, 0.0377, 0.1068], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,924][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.4298, 0.1316, 0.1038, 0.0357, 0.0479, 0.1364, 0.0161, 0.0116, 0.0156,
        0.0528, 0.0091, 0.0080, 0.0016], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,925][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.3072, 0.1641, 0.0351, 0.1428, 0.0162, 0.1051, 0.0107, 0.0554, 0.0268,
        0.0442, 0.0666, 0.0077, 0.0180], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,926][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0677, 0.0105, 0.0223, 0.0242, 0.0155, 0.0427, 0.0222, 0.1519, 0.1044,
        0.0198, 0.1429, 0.0401, 0.3358], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:04,928][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0172, 0.0068, 0.0201, 0.0356, 0.0129, 0.0084, 0.1114, 0.1098, 0.0933,
        0.0112, 0.1157, 0.1126, 0.1661, 0.1790], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,930][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0240, 0.0042, 0.0229, 0.0031, 0.0154, 0.0113, 0.4198, 0.0599, 0.0971,
        0.0187, 0.0770, 0.0870, 0.1239, 0.0358], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,931][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3519, 0.0868, 0.2239, 0.0304, 0.0372, 0.0660, 0.0043, 0.0109, 0.0245,
        0.0469, 0.0315, 0.0085, 0.0483, 0.0288], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,933][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2037, 0.2815, 0.0847, 0.1318, 0.0162, 0.0884, 0.0020, 0.0122, 0.0188,
        0.0296, 0.0472, 0.0054, 0.0339, 0.0447], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,935][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1550, 0.1020, 0.0588, 0.0481, 0.0138, 0.0879, 0.0042, 0.0496, 0.0194,
        0.0169, 0.0499, 0.0030, 0.1963, 0.1951], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,936][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0987, 0.1018, 0.1093, 0.0386, 0.0558, 0.0498, 0.1172, 0.0469, 0.0743,
        0.0547, 0.0683, 0.0750, 0.0597, 0.0501], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,938][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0102, 0.1175, 0.0238, 0.0691, 0.0571, 0.0518, 0.0284, 0.0323, 0.0545,
        0.0080, 0.1040, 0.0208, 0.2829, 0.1396], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,940][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1099, 0.0733, 0.0269, 0.0487, 0.0041, 0.0258, 0.0075, 0.0312, 0.0184,
        0.0135, 0.0419, 0.0034, 0.2144, 0.3811], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,942][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3429, 0.0548, 0.1193, 0.0233, 0.0121, 0.0934, 0.0046, 0.0136, 0.0270,
        0.0421, 0.0426, 0.0167, 0.1470, 0.0606], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,943][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4226, 0.0806, 0.1473, 0.0260, 0.0488, 0.1298, 0.0180, 0.0102, 0.0153,
        0.0655, 0.0095, 0.0101, 0.0059, 0.0103], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,945][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3063, 0.0897, 0.0396, 0.1207, 0.0081, 0.1158, 0.0109, 0.0362, 0.0367,
        0.0511, 0.0612, 0.0037, 0.0151, 0.1048], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,947][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0621, 0.0229, 0.0183, 0.0367, 0.0101, 0.0301, 0.0087, 0.1171, 0.0815,
        0.0153, 0.1549, 0.0184, 0.0907, 0.3333], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:04,949][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0083, 0.0189, 0.0134, 0.0629, 0.0176, 0.0061, 0.0797, 0.1199, 0.0560,
        0.0087, 0.0849, 0.1128, 0.0827, 0.2098, 0.1182], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,950][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0319, 0.0067, 0.0163, 0.0088, 0.0183, 0.0163, 0.2106, 0.1024, 0.0667,
        0.0206, 0.1023, 0.1207, 0.1014, 0.1284, 0.0485], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,952][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0664, 0.2789, 0.1051, 0.0938, 0.0819, 0.0312, 0.0040, 0.0196, 0.0310,
        0.0226, 0.0496, 0.0123, 0.0365, 0.0807, 0.0865], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,954][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1144, 0.2011, 0.0554, 0.1737, 0.0152, 0.0677, 0.0032, 0.0175, 0.0474,
        0.0210, 0.0545, 0.0055, 0.0542, 0.1251, 0.0441], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,956][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0685, 0.0977, 0.0390, 0.0606, 0.0146, 0.0551, 0.0031, 0.0541, 0.0167,
        0.0108, 0.0752, 0.0030, 0.1133, 0.2595, 0.1288], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,958][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0847, 0.1120, 0.0889, 0.0451, 0.1506, 0.0460, 0.0796, 0.0547, 0.0343,
        0.0505, 0.0354, 0.1064, 0.0401, 0.0562, 0.0155], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,959][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0004, 0.0884, 0.0033, 0.0827, 0.0740, 0.0068, 0.0139, 0.0396, 0.0410,
        0.0012, 0.0695, 0.0161, 0.1452, 0.3022, 0.1158], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,961][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0884, 0.1541, 0.0221, 0.0539, 0.0066, 0.0280, 0.0040, 0.0269, 0.0097,
        0.0105, 0.0316, 0.0039, 0.0534, 0.5005, 0.0064], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,963][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.3014, 0.0820, 0.0981, 0.0394, 0.0227, 0.0811, 0.0030, 0.0283, 0.0188,
        0.0311, 0.0401, 0.0241, 0.0782, 0.1263, 0.0252], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,965][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.4843, 0.0741, 0.1342, 0.0186, 0.0399, 0.1172, 0.0193, 0.0090, 0.0129,
        0.0567, 0.0092, 0.0082, 0.0029, 0.0076, 0.0056], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,966][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.2640, 0.0838, 0.0506, 0.0892, 0.0188, 0.1043, 0.0067, 0.0394, 0.0387,
        0.0520, 0.0530, 0.0143, 0.0127, 0.1433, 0.0292], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,967][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0636, 0.0214, 0.0257, 0.0277, 0.0165, 0.0321, 0.0235, 0.1088, 0.1034,
        0.0185, 0.1523, 0.0283, 0.1021, 0.1908, 0.0853], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:04,968][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0119, 0.0051, 0.0111, 0.0459, 0.0091, 0.0070, 0.0400, 0.1385, 0.0442,
        0.0081, 0.0797, 0.0761, 0.1171, 0.2253, 0.1438, 0.0369],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,969][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0232, 0.0073, 0.0176, 0.0146, 0.0189, 0.0111, 0.2266, 0.0738, 0.0397,
        0.0200, 0.0905, 0.1041, 0.1207, 0.0611, 0.1568, 0.0141],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,970][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1781, 0.0696, 0.1283, 0.0392, 0.0417, 0.0458, 0.0042, 0.0164, 0.0247,
        0.0302, 0.0414, 0.0153, 0.0526, 0.0974, 0.1170, 0.0981],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,972][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1425, 0.1960, 0.0633, 0.1423, 0.0197, 0.0712, 0.0028, 0.0156, 0.0219,
        0.0245, 0.0398, 0.0075, 0.0446, 0.0809, 0.0629, 0.0645],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,974][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0661, 0.0364, 0.0285, 0.0263, 0.0090, 0.0422, 0.0034, 0.0403, 0.0096,
        0.0091, 0.0351, 0.0025, 0.1267, 0.2739, 0.2111, 0.0799],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,976][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0740, 0.1040, 0.0731, 0.0928, 0.0466, 0.0415, 0.0668, 0.0475, 0.0272,
        0.0340, 0.0586, 0.0543, 0.0497, 0.0861, 0.1202, 0.0237],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,977][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0041, 0.0756, 0.0088, 0.0598, 0.0252, 0.0230, 0.0120, 0.0285, 0.0265,
        0.0040, 0.0664, 0.0097, 0.1014, 0.2404, 0.1911, 0.1233],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,979][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2118, 0.0444, 0.0316, 0.0239, 0.0046, 0.0371, 0.0081, 0.0278, 0.0088,
        0.0238, 0.0246, 0.0042, 0.0901, 0.3546, 0.0395, 0.0651],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,981][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1706, 0.0674, 0.0709, 0.0440, 0.0155, 0.0562, 0.0044, 0.0176, 0.0145,
        0.0269, 0.0412, 0.0231, 0.1619, 0.1222, 0.1251, 0.0385],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,983][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5167, 0.0580, 0.1226, 0.0195, 0.0314, 0.1153, 0.0119, 0.0075, 0.0104,
        0.0595, 0.0073, 0.0072, 0.0044, 0.0082, 0.0123, 0.0079],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,985][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4387, 0.0452, 0.0301, 0.0693, 0.0059, 0.1185, 0.0051, 0.0178, 0.0233,
        0.0456, 0.0362, 0.0029, 0.0073, 0.0823, 0.0205, 0.0511],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,986][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0940, 0.0133, 0.0271, 0.0235, 0.0104, 0.0332, 0.0079, 0.1075, 0.0749,
        0.0183, 0.1099, 0.0229, 0.0766, 0.1989, 0.0342, 0.1475],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:04,988][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0093, 0.0094, 0.0121, 0.0293, 0.0130, 0.0053, 0.0699, 0.1478, 0.0396,
        0.0090, 0.0651, 0.1074, 0.1043, 0.2097, 0.1051, 0.0458, 0.0180],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,990][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0072, 0.0033, 0.0044, 0.0089, 0.0143, 0.0050, 0.1228, 0.1496, 0.0610,
        0.0089, 0.1091, 0.1353, 0.0618, 0.1794, 0.0809, 0.0317, 0.0162],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,992][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0441, 0.2135, 0.0533, 0.0727, 0.0455, 0.0189, 0.0022, 0.0165, 0.0325,
        0.0126, 0.0406, 0.0091, 0.0218, 0.0613, 0.0731, 0.2003, 0.0820],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,993][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0604, 0.2472, 0.0412, 0.1705, 0.0192, 0.0474, 0.0032, 0.0181, 0.0267,
        0.0155, 0.0385, 0.0063, 0.0299, 0.0796, 0.0531, 0.1128, 0.0305],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,995][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0522, 0.0710, 0.0226, 0.0307, 0.0117, 0.0374, 0.0032, 0.0454, 0.0131,
        0.0064, 0.0419, 0.0040, 0.1018, 0.1989, 0.1565, 0.1532, 0.0499],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,997][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0782, 0.0325, 0.0375, 0.0265, 0.0607, 0.0369, 0.0634, 0.1010, 0.0500,
        0.0449, 0.0792, 0.1088, 0.0578, 0.1005, 0.0621, 0.0335, 0.0264],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:04,998][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0003, 0.1660, 0.0031, 0.0652, 0.0447, 0.0067, 0.0089, 0.0210, 0.0411,
        0.0008, 0.0625, 0.0080, 0.1026, 0.1507, 0.1365, 0.1369, 0.0450],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,000][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.1583, 0.0550, 0.0237, 0.0198, 0.0095, 0.0362, 0.0044, 0.0265, 0.0100,
        0.0108, 0.0292, 0.0081, 0.0471, 0.4218, 0.0552, 0.0552, 0.0293],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,002][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1279, 0.0415, 0.0510, 0.0312, 0.0299, 0.0437, 0.0035, 0.0369, 0.0275,
        0.0216, 0.0525, 0.0442, 0.1003, 0.1276, 0.0741, 0.0932, 0.0933],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,003][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([6.4536e-01, 1.9264e-02, 1.0105e-01, 1.1084e-02, 1.3607e-02, 1.0248e-01,
        8.5454e-03, 6.5729e-03, 1.2835e-02, 4.4250e-02, 5.4425e-03, 5.7163e-03,
        2.1483e-03, 7.7851e-03, 6.6481e-03, 6.7462e-03, 4.5532e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,005][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([7.9317e-01, 2.4038e-02, 1.8441e-02, 2.1787e-02, 2.5979e-03, 5.7842e-02,
        1.6985e-04, 3.0346e-03, 3.6559e-03, 2.8701e-02, 5.3345e-03, 1.9780e-03,
        1.8940e-03, 2.4115e-02, 2.6802e-03, 9.4913e-03, 1.0675e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,006][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.1537, 0.0154, 0.0386, 0.0211, 0.0087, 0.0394, 0.0319, 0.0911, 0.0611,
        0.0303, 0.0882, 0.0171, 0.0999, 0.1684, 0.0553, 0.0679, 0.0121],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,008][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0396, 0.0027, 0.0266, 0.0160, 0.0107, 0.0116, 0.0562, 0.0665, 0.0609,
        0.0167, 0.0706, 0.1053, 0.1208, 0.1124, 0.1439, 0.0735, 0.0159, 0.0501],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,009][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0234, 0.0031, 0.0196, 0.0026, 0.0140, 0.0096, 0.3282, 0.0552, 0.0723,
        0.0187, 0.0618, 0.0803, 0.0873, 0.0275, 0.1245, 0.0404, 0.0190, 0.0125],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,010][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4185, 0.0399, 0.1809, 0.0133, 0.0173, 0.0468, 0.0017, 0.0037, 0.0114,
        0.0348, 0.0098, 0.0040, 0.0180, 0.0104, 0.0511, 0.0615, 0.0590, 0.0179],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,011][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2741, 0.1796, 0.0843, 0.0830, 0.0112, 0.0783, 0.0011, 0.0083, 0.0139,
        0.0272, 0.0263, 0.0038, 0.0228, 0.0321, 0.0319, 0.0445, 0.0346, 0.0431],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,013][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2417, 0.0365, 0.0467, 0.0152, 0.0052, 0.0758, 0.0016, 0.0175, 0.0072,
        0.0138, 0.0160, 0.0014, 0.0811, 0.0898, 0.1330, 0.0813, 0.0247, 0.1116],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,014][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1852, 0.0611, 0.1211, 0.0294, 0.0340, 0.0596, 0.0718, 0.0288, 0.0409,
        0.0730, 0.0423, 0.0514, 0.0326, 0.0320, 0.0451, 0.0443, 0.0344, 0.0131],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,016][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0161, 0.0530, 0.0216, 0.0266, 0.0178, 0.0546, 0.0134, 0.0163, 0.0293,
        0.0065, 0.0386, 0.0079, 0.1114, 0.0506, 0.1503, 0.1475, 0.1168, 0.1216],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,018][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3151, 0.0306, 0.0333, 0.0218, 0.0018, 0.0372, 0.0027, 0.0129, 0.0077,
        0.0163, 0.0179, 0.0019, 0.0611, 0.1732, 0.0156, 0.0620, 0.0195, 0.1694],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,020][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4235, 0.0260, 0.0993, 0.0111, 0.0065, 0.0724, 0.0018, 0.0062, 0.0108,
        0.0351, 0.0176, 0.0088, 0.0662, 0.0270, 0.0387, 0.0491, 0.0662, 0.0337],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,022][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6041, 0.0351, 0.1047, 0.0128, 0.0182, 0.1127, 0.0077, 0.0054, 0.0086,
        0.0518, 0.0048, 0.0039, 0.0028, 0.0064, 0.0091, 0.0065, 0.0026, 0.0028],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,023][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6372, 0.0309, 0.0235, 0.0400, 0.0017, 0.0953, 0.0018, 0.0088, 0.0107,
        0.0316, 0.0179, 0.0009, 0.0032, 0.0395, 0.0131, 0.0252, 0.0009, 0.0176],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,025][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0970, 0.0196, 0.0199, 0.0254, 0.0064, 0.0320, 0.0059, 0.0810, 0.0568,
        0.0143, 0.1048, 0.0125, 0.0581, 0.2538, 0.0263, 0.0644, 0.0027, 0.1189],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,028][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:05,030][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15854],
        [34521],
        [43834],
        [42350],
        [33125],
        [37532],
        [44803],
        [35213],
        [37848],
        [34930],
        [31358],
        [17109],
        [30479],
        [27121],
        [30718],
        [29620],
        [31942],
        [22109]], device='cuda:0')
[2024-07-24 10:26:05,032][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13076],
        [30532],
        [41565],
        [43171],
        [31636],
        [34407],
        [45215],
        [34823],
        [36691],
        [34464],
        [30416],
        [15554],
        [30474],
        [25828],
        [30768],
        [28910],
        [29765],
        [19912]], device='cuda:0')
[2024-07-24 10:26:05,034][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[26117],
        [31763],
        [32491],
        [31412],
        [31280],
        [30782],
        [30429],
        [30304],
        [29898],
        [29364],
        [28918],
        [28886],
        [28888],
        [28681],
        [28381],
        [28246],
        [28052],
        [27883]], device='cuda:0')
[2024-07-24 10:26:05,036][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22875],
        [23405],
        [21210],
        [ 2012],
        [ 6665],
        [ 5590],
        [ 5446],
        [ 7641],
        [13321],
        [ 5511],
        [11176],
        [11146],
        [ 5916],
        [12306],
        [ 5486],
        [ 6813],
        [ 9796],
        [12117]], device='cuda:0')
[2024-07-24 10:26:05,037][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6044],
        [ 6112],
        [18068],
        [12158],
        [27701],
        [32488],
        [30450],
        [30340],
        [33408],
        [40590],
        [33031],
        [36522],
        [33392],
        [29582],
        [37451],
        [41164],
        [39531],
        [31680]], device='cuda:0')
[2024-07-24 10:26:05,040][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[39323],
        [38732],
        [35649],
        [36678],
        [36253],
        [37704],
        [37621],
        [37500],
        [37515],
        [37501],
        [38151],
        [38092],
        [38533],
        [38654],
        [37918],
        [37785],
        [37719],
        [37761]], device='cuda:0')
[2024-07-24 10:26:05,041][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18415],
        [18650],
        [26055],
        [23513],
        [23378],
        [24631],
        [22607],
        [25140],
        [25754],
        [26461],
        [25215],
        [24278],
        [23916],
        [25586],
        [24908],
        [24766],
        [25594],
        [26077]], device='cuda:0')
[2024-07-24 10:26:05,043][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35552],
        [39839],
        [32082],
        [30846],
        [31604],
        [30550],
        [30048],
        [31346],
        [31831],
        [29152],
        [29410],
        [28998],
        [29414],
        [30734],
        [28844],
        [30133],
        [30061],
        [31239]], device='cuda:0')
[2024-07-24 10:26:05,045][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45611],
        [45449],
        [47000],
        [46956],
        [47578],
        [48993],
        [47463],
        [47095],
        [45269],
        [43821],
        [46123],
        [46188],
        [46510],
        [46845],
        [47208],
        [46970],
        [45692],
        [46608]], device='cuda:0')
[2024-07-24 10:26:05,047][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9096],
        [10149],
        [ 6083],
        [ 7091],
        [ 8489],
        [ 5897],
        [ 7322],
        [ 6164],
        [ 7507],
        [ 8828],
        [ 9791],
        [ 9214],
        [10080],
        [ 9939],
        [ 9456],
        [ 8135],
        [ 8014],
        [ 7323]], device='cuda:0')
[2024-07-24 10:26:05,049][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[47061],
        [46959],
        [46650],
        [46574],
        [46890],
        [46846],
        [46808],
        [46691],
        [46672],
        [46689],
        [46712],
        [46732],
        [46792],
        [46741],
        [46766],
        [46788],
        [46840],
        [46859]], device='cuda:0')
[2024-07-24 10:26:05,051][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[7059],
        [3276],
        [2830],
        [2340],
        [2046],
        [2057],
        [1992],
        [1803],
        [1731],
        [1769],
        [1804],
        [1745],
        [1630],
        [1512],
        [1533],
        [1548],
        [1628],
        [1571]], device='cuda:0')
[2024-07-24 10:26:05,053][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41731],
        [42165],
        [40179],
        [40829],
        [41314],
        [40781],
        [41687],
        [41756],
        [41146],
        [40056],
        [39989],
        [40230],
        [40467],
        [40939],
        [40981],
        [41165],
        [41222],
        [41623]], device='cuda:0')
[2024-07-24 10:26:05,054][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27601],
        [20651],
        [33415],
        [26298],
        [28719],
        [30295],
        [19686],
        [19020],
        [18366],
        [18595],
        [17041],
        [19168],
        [19510],
        [16939],
        [18334],
        [16943],
        [17539],
        [16037]], device='cuda:0')
[2024-07-24 10:26:05,056][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[32421],
        [18196],
        [ 1841],
        [ 3788],
        [ 1474],
        [ 7299],
        [ 4626],
        [ 4889],
        [ 9034],
        [ 6917],
        [ 4052],
        [  640],
        [  932],
        [ 2262],
        [ 5111],
        [ 6692],
        [13457],
        [10121]], device='cuda:0')
[2024-07-24 10:26:05,058][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43086],
        [43781],
        [42670],
        [41684],
        [39441],
        [40414],
        [37962],
        [40612],
        [41034],
        [40793],
        [41768],
        [42480],
        [43174],
        [42948],
        [42922],
        [42704],
        [42778],
        [42585]], device='cuda:0')
[2024-07-24 10:26:05,059][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9877],
        [ 9901],
        [34560],
        [10663],
        [22380],
        [26934],
        [29103],
        [32224],
        [28398],
        [28533],
        [29645],
        [29704],
        [26212],
        [29529],
        [25891],
        [25955],
        [24520],
        [27542]], device='cuda:0')
[2024-07-24 10:26:05,061][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[45418],
        [43822],
        [ 3970],
        [20647],
        [ 5180],
        [ 5724],
        [ 5212],
        [ 5575],
        [ 9740],
        [14493],
        [13397],
        [10352],
        [ 8283],
        [19916],
        [10996],
        [20304],
        [15924],
        [22476]], device='cuda:0')
[2024-07-24 10:26:05,063][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18191],
        [28724],
        [38392],
        [37852],
        [38959],
        [38722],
        [39534],
        [39061],
        [38705],
        [37493],
        [37905],
        [38338],
        [38989],
        [37574],
        [38206],
        [37525],
        [37979],
        [35944]], device='cuda:0')
[2024-07-24 10:26:05,065][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[  274],
        [  311],
        [12058],
        [ 5496],
        [19065],
        [17158],
        [21531],
        [19497],
        [20457],
        [20257],
        [19500],
        [22760],
        [18102],
        [10165],
        [11976],
        [ 8497],
        [ 8711],
        [ 5979]], device='cuda:0')
[2024-07-24 10:26:05,066][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[26281],
        [24936],
        [29235],
        [21094],
        [29781],
        [31934],
        [30915],
        [28938],
        [28181],
        [28332],
        [28718],
        [29896],
        [30116],
        [29713],
        [30623],
        [30169],
        [30526],
        [29613]], device='cuda:0')
[2024-07-24 10:26:05,068][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30644],
        [24725],
        [10062],
        [13271],
        [12181],
        [17951],
        [15344],
        [16631],
        [17904],
        [19991],
        [22707],
        [17403],
        [19171],
        [24390],
        [19553],
        [19603],
        [18563],
        [20711]], device='cuda:0')
[2024-07-24 10:26:05,070][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12154],
        [12193],
        [26477],
        [16116],
        [22776],
        [28652],
        [27161],
        [27899],
        [28033],
        [29051],
        [25823],
        [27159],
        [23782],
        [21296],
        [26285],
        [25271],
        [27484],
        [26278]], device='cuda:0')
[2024-07-24 10:26:05,072][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30757],
        [30489],
        [ 3697],
        [28746],
        [ 4689],
        [ 2422],
        [ 3587],
        [ 2311],
        [ 2531],
        [ 3128],
        [ 2371],
        [ 2665],
        [ 2389],
        [ 2441],
        [ 2063],
        [ 1969],
        [ 3048],
        [ 3752]], device='cuda:0')
[2024-07-24 10:26:05,074][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[3630],
        [3629],
        [3261],
        [3366],
        [3146],
        [4609],
        [9549],
        [7383],
        [6194],
        [5968],
        [5791],
        [7401],
        [6892],
        [5868],
        [5306],
        [4814],
        [3544],
        [3911]], device='cuda:0')
[2024-07-24 10:26:05,076][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[39844],
        [39678],
        [31153],
        [39300],
        [33218],
        [19129],
        [17315],
        [12395],
        [13645],
        [17780],
        [13520],
        [14274],
        [13207],
        [12223],
        [11718],
        [14359],
        [31599],
        [22150]], device='cuda:0')
[2024-07-24 10:26:05,078][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8382],
        [ 6836],
        [ 8408],
        [ 5472],
        [ 7584],
        [13047],
        [ 3715],
        [25716],
        [31684],
        [26999],
        [35549],
        [35192],
        [11553],
        [23606],
        [24325],
        [24535],
        [20047],
        [24220]], device='cuda:0')
[2024-07-24 10:26:05,080][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22911],
        [23077],
        [26449],
        [26638],
        [29559],
        [26782],
        [25378],
        [25660],
        [25479],
        [22252],
        [23586],
        [21945],
        [27296],
        [25366],
        [27641],
        [26554],
        [25693],
        [25675]], device='cuda:0')
[2024-07-24 10:26:05,082][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[14082],
        [17153],
        [12929],
        [13457],
        [10022],
        [ 8627],
        [12347],
        [ 8370],
        [ 5185],
        [ 8566],
        [ 6535],
        [13087],
        [11288],
        [10579],
        [ 8845],
        [ 8312],
        [ 5472],
        [ 6807]], device='cuda:0')
[2024-07-24 10:26:05,083][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914],
        [30914]], device='cuda:0')
[2024-07-24 10:26:05,149][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:05,150][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,150][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,151][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,152][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,153][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,155][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,156][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,157][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,158][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,159][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,160][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,160][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,161][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9988e-01, 1.2009e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,162][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3678, 0.6322], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,163][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6931, 0.3069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,163][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2647, 0.7353], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,164][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8525, 0.1475], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,165][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5831, 0.4169], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,167][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9401, 0.0599], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,169][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4958, 0.5042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,170][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9377, 0.0623], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,172][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0374, 0.9626], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,173][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4386, 0.5614], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,174][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9956e-01, 4.3986e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,176][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.9469, 0.0133, 0.0398], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,178][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.0287, 0.8923, 0.0790], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,179][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.6452, 0.2813, 0.0736], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,181][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.0751, 0.5078, 0.4171], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,182][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.8855, 0.0428, 0.0717], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,184][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.2161, 0.5416, 0.2423], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,186][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.7439, 0.0816, 0.1744], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,187][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.2652, 0.5421, 0.1926], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,189][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.1526, 0.6600, 0.1873], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,190][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.0156, 0.9191, 0.0652], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,192][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.3457, 0.3573, 0.2969], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,194][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.8872, 0.0635, 0.0493], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,195][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8550e-01, 1.3085e-03, 1.3162e-02, 2.5899e-05], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,196][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0127, 0.5034, 0.0640, 0.4199], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,197][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6648, 0.1868, 0.1093, 0.0391], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,197][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0764, 0.3381, 0.2935, 0.2920], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,198][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6093, 0.1142, 0.1625, 0.1140], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,199][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1574, 0.4245, 0.1204, 0.2978], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,200][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8799, 0.0307, 0.0551, 0.0343], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,202][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2684, 0.4509, 0.0951, 0.1856], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,203][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3567, 0.2519, 0.2568, 0.1346], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,205][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0392, 0.7058, 0.0753, 0.1797], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,207][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2554, 0.3103, 0.2131, 0.2211], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,208][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.4944e-01, 1.7881e-03, 4.8624e-02, 1.4500e-04], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,210][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.8754, 0.0190, 0.0874, 0.0059, 0.0124], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,211][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0021, 0.2986, 0.0201, 0.6464, 0.0328], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,213][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.4405, 0.3059, 0.1167, 0.0670, 0.0699], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,214][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0344, 0.3134, 0.2430, 0.2523, 0.1569], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,216][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.6067, 0.0550, 0.0857, 0.0388, 0.2137], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,218][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.2131, 0.3168, 0.1307, 0.2556, 0.0839], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,219][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.6976, 0.0485, 0.1015, 0.0415, 0.1109], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,221][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.1944, 0.4295, 0.0607, 0.2534, 0.0620], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,222][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.1940, 0.3308, 0.1168, 0.3146, 0.0437], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,224][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0307, 0.3760, 0.0551, 0.2527, 0.2855], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,226][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.1712, 0.2649, 0.1615, 0.2154, 0.1871], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,227][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.8194, 0.0945, 0.0629, 0.0187, 0.0045], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,229][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.8998, 0.0122, 0.0266, 0.0031, 0.0195, 0.0388], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,230][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0021, 0.3919, 0.0272, 0.4964, 0.0489, 0.0335], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,232][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.3731, 0.3214, 0.1335, 0.0579, 0.0925, 0.0216], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,234][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0616, 0.2520, 0.2255, 0.2158, 0.1778, 0.0673], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,235][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.7385, 0.0269, 0.0474, 0.0237, 0.1093, 0.0541], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,237][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0724, 0.2430, 0.0906, 0.2976, 0.2026, 0.0938], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,239][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.5640, 0.0750, 0.1275, 0.0778, 0.0365, 0.1191], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,239][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0780, 0.2838, 0.0880, 0.2758, 0.1828, 0.0916], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,240][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0651, 0.2561, 0.0866, 0.3422, 0.1708, 0.0792], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,241][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0054, 0.2343, 0.0239, 0.4944, 0.2110, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,242][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.1728, 0.1955, 0.1496, 0.1717, 0.1471, 0.1633], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,243][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.7890, 0.0363, 0.0644, 0.0174, 0.0108, 0.0821], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,245][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.5529, 0.1057, 0.0680, 0.0196, 0.0148, 0.2240, 0.0151],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,246][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ working] are: tensor([5.3768e-04, 2.2877e-01, 1.7664e-02, 6.6141e-01, 3.9844e-02, 2.8044e-02,
        2.3735e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,248][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.4734, 0.2281, 0.0845, 0.0516, 0.0677, 0.0243, 0.0703],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,249][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0246, 0.2674, 0.2029, 0.2211, 0.1325, 0.0690, 0.0826],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,251][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.3914, 0.0660, 0.0598, 0.0569, 0.1518, 0.1153, 0.1589],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,253][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0280, 0.3514, 0.0447, 0.3138, 0.1791, 0.0432, 0.0399],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,254][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.5026, 0.1195, 0.0965, 0.1305, 0.0541, 0.0515, 0.0453],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,256][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0482, 0.3554, 0.0291, 0.3329, 0.1377, 0.0362, 0.0605],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,257][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0033, 0.2585, 0.0145, 0.4538, 0.2396, 0.0155, 0.0148],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,259][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0144, 0.1104, 0.0368, 0.1003, 0.4143, 0.0239, 0.2999],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,261][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0832, 0.2285, 0.1039, 0.1975, 0.1526, 0.1057, 0.1286],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,262][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.6402, 0.0408, 0.0685, 0.0252, 0.0088, 0.1577, 0.0587],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,264][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([8.8008e-01, 1.4531e-02, 4.5180e-02, 6.4803e-04, 1.3764e-02, 3.7921e-02,
        6.8904e-03, 9.8238e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,265][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0010, 0.2411, 0.0218, 0.5438, 0.0288, 0.0397, 0.0392, 0.0846],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,267][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.3443, 0.2189, 0.0979, 0.0466, 0.0992, 0.0317, 0.0791, 0.0823],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,269][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0264, 0.2360, 0.1980, 0.1931, 0.1304, 0.0607, 0.0821, 0.0733],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,270][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2003, 0.0615, 0.0781, 0.0544, 0.1638, 0.0948, 0.1168, 0.2302],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,272][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0353, 0.4107, 0.0409, 0.2706, 0.1094, 0.0338, 0.0175, 0.0818],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,274][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.3356, 0.1024, 0.0546, 0.1527, 0.0333, 0.0395, 0.0214, 0.2606],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,275][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0654, 0.3230, 0.0373, 0.2844, 0.1106, 0.0414, 0.0643, 0.0737],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,277][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0357, 0.2890, 0.0608, 0.3221, 0.1745, 0.0332, 0.0286, 0.0560],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,279][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0083, 0.1482, 0.0226, 0.0288, 0.2094, 0.0113, 0.5222, 0.0492],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,280][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0859, 0.1677, 0.1061, 0.1677, 0.1412, 0.1112, 0.1295, 0.0908],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,281][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([5.6655e-01, 1.6513e-02, 9.0893e-02, 1.5463e-03, 5.7227e-03, 1.0064e-01,
        2.1803e-01, 1.0578e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,282][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.2024e-01, 6.0293e-03, 2.9976e-02, 1.1125e-03, 7.9060e-03, 2.8618e-02,
        3.4926e-03, 1.7727e-03, 8.4963e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,283][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0012, 0.1545, 0.0181, 0.6122, 0.0178, 0.0393, 0.0184, 0.0825, 0.0558],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,284][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3099, 0.1754, 0.0807, 0.0317, 0.0659, 0.0259, 0.0864, 0.0534, 0.1707],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,285][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0252, 0.2052, 0.1740, 0.1780, 0.1302, 0.0634, 0.0786, 0.0761, 0.0692],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,286][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1889, 0.0456, 0.0646, 0.0454, 0.1451, 0.0967, 0.1098, 0.2083, 0.0956],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,288][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0674, 0.3072, 0.0596, 0.1935, 0.1131, 0.0479, 0.0182, 0.0729, 0.1201],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,289][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3384, 0.0959, 0.0589, 0.0992, 0.0380, 0.0398, 0.0197, 0.1039, 0.2063],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,291][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0711, 0.2999, 0.0366, 0.2416, 0.0948, 0.0416, 0.0532, 0.0904, 0.0709],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,292][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0830, 0.2233, 0.0692, 0.2694, 0.1422, 0.0448, 0.0319, 0.1044, 0.0318],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,294][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0075, 0.1129, 0.0148, 0.0768, 0.1853, 0.0129, 0.4848, 0.0733, 0.0317],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,296][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0850, 0.1572, 0.0980, 0.1410, 0.1256, 0.1022, 0.1156, 0.0831, 0.0923],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,297][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([8.3794e-01, 2.0647e-03, 4.3504e-02, 3.8773e-04, 1.7019e-03, 4.1899e-02,
        7.1415e-02, 2.4327e-04, 8.4883e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,299][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.3244, 0.1655, 0.0809, 0.0469, 0.0190, 0.1398, 0.0325, 0.0573, 0.0749,
        0.0589], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,300][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([2.0225e-04, 1.6585e-01, 1.1153e-02, 4.8118e-01, 3.5168e-02, 1.6288e-02,
        3.3689e-02, 1.3908e-01, 1.1208e-01, 5.3121e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,301][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.3327, 0.2057, 0.0940, 0.0383, 0.0390, 0.0261, 0.0882, 0.0532, 0.1067,
        0.0161], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,303][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0169, 0.2559, 0.1753, 0.1995, 0.0982, 0.0504, 0.0574, 0.0562, 0.0530,
        0.0371], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,305][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.4549, 0.0242, 0.0261, 0.0166, 0.0790, 0.0362, 0.0599, 0.1232, 0.0445,
        0.1353], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,307][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0161, 0.1478, 0.0292, 0.1846, 0.1346, 0.0326, 0.0876, 0.1725, 0.1723,
        0.0225], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,308][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.3516, 0.0711, 0.1033, 0.0780, 0.0488, 0.0905, 0.0216, 0.0727, 0.0892,
        0.0733], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,310][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0316, 0.1306, 0.0377, 0.1673, 0.1274, 0.0414, 0.1212, 0.1726, 0.1401,
        0.0301], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,312][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0075, 0.1465, 0.0194, 0.2458, 0.1035, 0.0201, 0.0764, 0.2230, 0.1460,
        0.0119], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,313][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0029, 0.0997, 0.0126, 0.2279, 0.1476, 0.0175, 0.2116, 0.1328, 0.1355,
        0.0119], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,315][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0979, 0.1383, 0.0940, 0.1217, 0.1038, 0.0966, 0.0989, 0.0782, 0.0865,
        0.0842], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,317][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.2600, 0.1841, 0.0529, 0.0570, 0.0113, 0.0909, 0.1492, 0.0394, 0.0557,
        0.0996], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,318][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([7.5754e-01, 1.7461e-03, 3.8433e-02, 1.6555e-04, 1.5483e-02, 2.7327e-02,
        4.7822e-03, 1.3992e-03, 5.8477e-03, 1.4572e-01, 1.5500e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,320][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0013, 0.1509, 0.0221, 0.4632, 0.0267, 0.0378, 0.0211, 0.0933, 0.0790,
        0.0050, 0.0995], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,322][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3342, 0.1454, 0.1046, 0.0354, 0.0699, 0.0110, 0.1102, 0.0677, 0.0666,
        0.0284, 0.0265], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,323][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0321, 0.1627, 0.1431, 0.1397, 0.1071, 0.0592, 0.0692, 0.0680, 0.0627,
        0.0591, 0.0972], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,324][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1813, 0.0350, 0.0467, 0.0372, 0.1082, 0.0582, 0.0705, 0.1635, 0.0808,
        0.1462, 0.0723], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,325][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0665, 0.2587, 0.0559, 0.1964, 0.0742, 0.0436, 0.0097, 0.0499, 0.1008,
        0.0155, 0.1288], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,326][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2215, 0.0818, 0.0488, 0.1055, 0.0434, 0.0313, 0.0118, 0.0807, 0.0953,
        0.0168, 0.2633], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,327][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1038, 0.2223, 0.0480, 0.1530, 0.1099, 0.0498, 0.0477, 0.0781, 0.0635,
        0.0172, 0.1066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,328][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1438, 0.1625, 0.1155, 0.1610, 0.1344, 0.0673, 0.0151, 0.0464, 0.0305,
        0.0189, 0.1044], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,330][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0029, 0.1109, 0.0092, 0.0664, 0.1404, 0.0077, 0.5011, 0.0693, 0.0488,
        0.0068, 0.0364], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,332][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0402, 0.1224, 0.0750, 0.1297, 0.1241, 0.0821, 0.1216, 0.0791, 0.0876,
        0.0630, 0.0753], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,333][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([6.9910e-01, 9.7790e-04, 4.1882e-02, 2.2567e-04, 3.6755e-03, 4.5719e-02,
        4.0740e-02, 1.2816e-04, 6.0485e-03, 1.6145e-01, 5.7024e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,334][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.4696, 0.0604, 0.0951, 0.0151, 0.0082, 0.0821, 0.0147, 0.0112, 0.0577,
        0.1061, 0.0665, 0.0134], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,336][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([2.6456e-04, 1.1076e-01, 7.1947e-03, 5.2710e-01, 1.8692e-02, 2.3229e-02,
        1.4346e-02, 1.1304e-01, 8.6155e-02, 3.2979e-03, 8.7522e-02, 8.3937e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,337][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.2883, 0.1851, 0.0893, 0.0541, 0.0412, 0.0207, 0.0914, 0.0508, 0.0644,
        0.0164, 0.0371, 0.0612], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,339][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0171, 0.1805, 0.1325, 0.1439, 0.0825, 0.0518, 0.0594, 0.0556, 0.0570,
        0.0466, 0.0979, 0.0752], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,341][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.2157, 0.0220, 0.0351, 0.0160, 0.0918, 0.0435, 0.0929, 0.1168, 0.0293,
        0.1413, 0.0381, 0.1574], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,343][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0155, 0.2077, 0.0275, 0.1902, 0.0875, 0.0208, 0.0263, 0.0945, 0.1105,
        0.0084, 0.1900, 0.0211], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,344][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.1275, 0.0635, 0.0549, 0.0769, 0.1787, 0.0312, 0.0111, 0.0738, 0.0756,
        0.0188, 0.1844, 0.1036], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,346][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0186, 0.2439, 0.0172, 0.2329, 0.0752, 0.0199, 0.0482, 0.1008, 0.0898,
        0.0073, 0.1276, 0.0185], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,348][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0061, 0.3033, 0.0145, 0.3638, 0.0465, 0.0115, 0.0105, 0.0585, 0.0324,
        0.0032, 0.1465, 0.0032], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,349][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([1.8623e-04, 1.5312e-01, 2.0969e-03, 1.3055e-01, 8.6810e-02, 3.0884e-03,
        3.7788e-01, 9.7456e-02, 3.7301e-02, 2.0097e-03, 7.4047e-02, 3.5456e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,351][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0644, 0.1192, 0.0803, 0.1130, 0.1099, 0.0828, 0.0993, 0.0625, 0.0737,
        0.0646, 0.0679, 0.0625], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,352][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.3685, 0.1517, 0.0445, 0.0286, 0.0024, 0.1217, 0.0728, 0.0103, 0.0222,
        0.1565, 0.0165, 0.0043], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,354][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.6143, 0.0164, 0.0556, 0.0058, 0.0196, 0.0522, 0.0054, 0.0142, 0.0212,
        0.1199, 0.0169, 0.0317, 0.0269], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,355][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([4.4633e-04, 1.6984e-01, 1.0617e-02, 4.9834e-01, 1.0503e-02, 2.1521e-02,
        9.6785e-03, 5.2566e-02, 4.1394e-02, 2.2439e-03, 7.9164e-02, 5.6758e-03,
        9.8008e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,357][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2397, 0.1806, 0.0600, 0.0550, 0.0325, 0.0264, 0.0888, 0.0534, 0.0758,
        0.0165, 0.0422, 0.0593, 0.0698], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,359][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0208, 0.1616, 0.1265, 0.1345, 0.0878, 0.0462, 0.0581, 0.0542, 0.0555,
        0.0463, 0.0833, 0.0800, 0.0455], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,361][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1375, 0.0221, 0.0229, 0.0234, 0.0733, 0.0488, 0.0657, 0.1290, 0.0536,
        0.1178, 0.0671, 0.1184, 0.1204], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,362][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0378, 0.3200, 0.0397, 0.1570, 0.0442, 0.0346, 0.0101, 0.0498, 0.0805,
        0.0108, 0.1364, 0.0095, 0.0696], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,364][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.2797, 0.0865, 0.0592, 0.0796, 0.0454, 0.0437, 0.0095, 0.0611, 0.0865,
        0.0188, 0.1757, 0.0309, 0.0235], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,365][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0349, 0.2079, 0.0230, 0.1948, 0.1046, 0.0265, 0.0303, 0.0840, 0.0747,
        0.0085, 0.1213, 0.0131, 0.0763], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,366][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0092, 0.3353, 0.0225, 0.2349, 0.1389, 0.0161, 0.0059, 0.0375, 0.0183,
        0.0027, 0.1306, 0.0047, 0.0434], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,367][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0264, 0.1071, 0.0669, 0.0407, 0.1181, 0.0373, 0.2047, 0.0531, 0.0285,
        0.0408, 0.0342, 0.1436, 0.0985], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,368][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0693, 0.1127, 0.0666, 0.1110, 0.0950, 0.0743, 0.0874, 0.0595, 0.0671,
        0.0539, 0.0729, 0.0520, 0.0783], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,370][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.3774, 0.1050, 0.0709, 0.0446, 0.0122, 0.1863, 0.0402, 0.0159, 0.0382,
        0.0591, 0.0092, 0.0115, 0.0296], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,371][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7033, 0.0060, 0.0386, 0.0009, 0.0109, 0.0252, 0.0073, 0.0008, 0.0045,
        0.1522, 0.0080, 0.0199, 0.0208, 0.0016], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,373][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.1372, 0.0163, 0.4128, 0.0210, 0.0411, 0.0137, 0.0519, 0.0492,
        0.0033, 0.0832, 0.0101, 0.1050, 0.0541], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,375][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2149, 0.0998, 0.0699, 0.0302, 0.0516, 0.0197, 0.0753, 0.0897, 0.0846,
        0.0156, 0.0521, 0.1108, 0.0646, 0.0213], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,376][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0183, 0.1451, 0.1227, 0.1254, 0.0888, 0.0425, 0.0553, 0.0564, 0.0505,
        0.0481, 0.0800, 0.0784, 0.0481, 0.0402], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,378][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0958, 0.0272, 0.0344, 0.0320, 0.0809, 0.0605, 0.0580, 0.1175, 0.0595,
        0.1072, 0.0579, 0.1327, 0.0825, 0.0537], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,380][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0734, 0.2666, 0.0559, 0.1374, 0.0588, 0.0412, 0.0041, 0.0255, 0.0499,
        0.0103, 0.0835, 0.0096, 0.0553, 0.1284], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,382][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1290, 0.0523, 0.0298, 0.0630, 0.0285, 0.0176, 0.0079, 0.0816, 0.0750,
        0.0095, 0.1803, 0.0178, 0.0122, 0.2955], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,384][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0590, 0.2111, 0.0272, 0.1770, 0.0566, 0.0285, 0.0194, 0.0428, 0.0484,
        0.0082, 0.0813, 0.0107, 0.1252, 0.1045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,385][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1350, 0.2021, 0.0998, 0.1289, 0.0895, 0.0390, 0.0064, 0.0242, 0.0158,
        0.0088, 0.0845, 0.0054, 0.0652, 0.0955], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,387][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0044, 0.0679, 0.0088, 0.0225, 0.0717, 0.0066, 0.4261, 0.0507, 0.0374,
        0.0067, 0.0355, 0.1052, 0.1296, 0.0269], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,389][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0769, 0.1064, 0.0696, 0.1004, 0.0818, 0.0726, 0.0829, 0.0564, 0.0580,
        0.0519, 0.0642, 0.0472, 0.0703, 0.0612], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,390][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.7898e-01, 2.9073e-03, 5.3042e-02, 5.0070e-04, 1.6852e-03, 2.8315e-02,
        9.5521e-02, 7.9225e-05, 2.4949e-03, 2.5920e-01, 9.8294e-05, 3.3614e-03,
        7.2996e-02, 8.2333e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,392][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.6648, 0.0152, 0.0233, 0.0020, 0.0036, 0.0475, 0.0122, 0.0018, 0.0068,
        0.0777, 0.0308, 0.0056, 0.0826, 0.0194, 0.0067], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,393][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0012, 0.1040, 0.0167, 0.3664, 0.0207, 0.0389, 0.0112, 0.0416, 0.0387,
        0.0048, 0.0738, 0.0108, 0.1152, 0.0535, 0.1024], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,395][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.2258, 0.1384, 0.0513, 0.0459, 0.0443, 0.0234, 0.0562, 0.0662, 0.0953,
        0.0150, 0.0479, 0.0711, 0.0585, 0.0159, 0.0448], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,397][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0159, 0.1448, 0.1165, 0.1261, 0.0789, 0.0439, 0.0522, 0.0495, 0.0491,
        0.0467, 0.0785, 0.0724, 0.0439, 0.0386, 0.0430], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,399][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1016, 0.0187, 0.0184, 0.0173, 0.0702, 0.0350, 0.0527, 0.1050, 0.0514,
        0.1042, 0.0503, 0.1159, 0.1006, 0.0337, 0.1251], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,401][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0778, 0.1871, 0.0492, 0.1122, 0.0335, 0.0378, 0.0049, 0.0296, 0.0582,
        0.0120, 0.0915, 0.0076, 0.0793, 0.1454, 0.0742], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,402][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.2718, 0.0398, 0.0532, 0.0332, 0.0352, 0.0277, 0.0078, 0.0508, 0.0705,
        0.0165, 0.1504, 0.0250, 0.0168, 0.1623, 0.0389], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,404][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0606, 0.1669, 0.0235, 0.1258, 0.0666, 0.0232, 0.0174, 0.0391, 0.0429,
        0.0077, 0.0797, 0.0110, 0.0863, 0.1416, 0.1076], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,406][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0195, 0.2703, 0.0311, 0.1582, 0.0730, 0.0182, 0.0028, 0.0327, 0.0224,
        0.0030, 0.0838, 0.0030, 0.0408, 0.1921, 0.0489], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,407][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0457, 0.0471, 0.0498, 0.0446, 0.0931, 0.0372, 0.1861, 0.0496, 0.0232,
        0.0359, 0.0286, 0.1937, 0.1068, 0.0437, 0.0150], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,408][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0596, 0.0902, 0.0626, 0.0865, 0.0777, 0.0634, 0.0797, 0.0560, 0.0596,
        0.0535, 0.0644, 0.0500, 0.0701, 0.0643, 0.0623], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,409][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.4493, 0.0651, 0.0647, 0.0114, 0.0035, 0.1325, 0.0420, 0.0032, 0.0222,
        0.0952, 0.0057, 0.0032, 0.0552, 0.0231, 0.0239], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,410][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([8.1020e-01, 5.5705e-03, 1.8528e-02, 7.9084e-04, 3.6555e-03, 1.9412e-02,
        3.4221e-03, 2.1917e-03, 9.0786e-04, 7.6483e-02, 8.8888e-03, 9.2544e-03,
        2.7961e-02, 6.6725e-03, 5.8321e-03, 2.3225e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,411][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0021, 0.0552, 0.0199, 0.3059, 0.0128, 0.0315, 0.0109, 0.0411, 0.0308,
        0.0039, 0.0543, 0.0089, 0.1109, 0.0711, 0.1439, 0.0966],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,413][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2478, 0.1219, 0.0622, 0.0246, 0.0363, 0.0230, 0.0500, 0.0407, 0.1053,
        0.0098, 0.0348, 0.0717, 0.0468, 0.0146, 0.0466, 0.0640],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,415][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0183, 0.1249, 0.1105, 0.1124, 0.0805, 0.0389, 0.0518, 0.0486, 0.0463,
        0.0486, 0.0741, 0.0768, 0.0477, 0.0392, 0.0456, 0.0359],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,416][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1344, 0.0212, 0.0275, 0.0196, 0.0629, 0.0457, 0.0530, 0.0912, 0.0376,
        0.0981, 0.0422, 0.1048, 0.0657, 0.0346, 0.1130, 0.0486],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,418][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0761, 0.1653, 0.0456, 0.0943, 0.0431, 0.0334, 0.0045, 0.0248, 0.0472,
        0.0110, 0.0725, 0.0104, 0.0643, 0.1341, 0.0820, 0.0915],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,420][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2385, 0.0421, 0.0362, 0.0366, 0.0251, 0.0236, 0.0072, 0.0537, 0.0703,
        0.0150, 0.1418, 0.0199, 0.0124, 0.1662, 0.0236, 0.0879],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,422][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0718, 0.1391, 0.0267, 0.1123, 0.0392, 0.0264, 0.0134, 0.0343, 0.0343,
        0.0092, 0.0715, 0.0105, 0.0836, 0.1109, 0.1216, 0.0951],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,423][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0879, 0.1193, 0.0534, 0.0997, 0.0624, 0.0254, 0.0059, 0.0325, 0.0172,
        0.0068, 0.0854, 0.0071, 0.0603, 0.1668, 0.1196, 0.0505],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,425][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0080, 0.0760, 0.0132, 0.1047, 0.0744, 0.0136, 0.2972, 0.0538, 0.0291,
        0.0110, 0.0341, 0.0733, 0.1207, 0.0313, 0.0485, 0.0112],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,427][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0556, 0.0763, 0.0590, 0.0780, 0.0686, 0.0595, 0.0776, 0.0547, 0.0562,
        0.0548, 0.0585, 0.0471, 0.0701, 0.0622, 0.0594, 0.0624],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,428][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([6.4961e-01, 2.8852e-03, 2.2592e-02, 5.6682e-04, 4.9395e-04, 2.4169e-02,
        3.6792e-02, 3.2173e-04, 1.5313e-03, 1.6819e-01, 2.5814e-04, 1.3950e-03,
        5.7341e-02, 2.6740e-03, 3.0854e-02, 3.2955e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,430][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.3644, 0.0632, 0.0896, 0.0104, 0.0158, 0.1125, 0.0111, 0.0108, 0.0263,
        0.0828, 0.0970, 0.0189, 0.0371, 0.0345, 0.0132, 0.0027, 0.0095],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,432][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0003, 0.0747, 0.0093, 0.2998, 0.0118, 0.0138, 0.0063, 0.0412, 0.0257,
        0.0033, 0.0464, 0.0078, 0.0368, 0.0756, 0.1076, 0.1589, 0.0810],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,434][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.1873, 0.1010, 0.0509, 0.0336, 0.0323, 0.0408, 0.0611, 0.0772, 0.0963,
        0.0099, 0.0400, 0.0616, 0.0603, 0.0192, 0.0501, 0.0603, 0.0180],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,435][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0147, 0.1670, 0.1107, 0.1285, 0.0714, 0.0381, 0.0442, 0.0421, 0.0403,
        0.0340, 0.0750, 0.0645, 0.0355, 0.0322, 0.0358, 0.0351, 0.0308],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,437][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.2299, 0.0111, 0.0179, 0.0109, 0.0490, 0.0286, 0.0381, 0.0919, 0.0272,
        0.1007, 0.0283, 0.0915, 0.0566, 0.0202, 0.0837, 0.0395, 0.0748],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,439][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0907, 0.1270, 0.0560, 0.0669, 0.0344, 0.0386, 0.0056, 0.0308, 0.0508,
        0.0133, 0.0715, 0.0106, 0.0604, 0.1074, 0.0680, 0.1003, 0.0677],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,441][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.2079, 0.0235, 0.0335, 0.0191, 0.0209, 0.0220, 0.0116, 0.0648, 0.0649,
        0.0154, 0.1513, 0.0215, 0.0189, 0.1906, 0.0401, 0.0775, 0.0164],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,443][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.1451, 0.1324, 0.0355, 0.0719, 0.0553, 0.0323, 0.0111, 0.0294, 0.0325,
        0.0118, 0.0508, 0.0121, 0.0539, 0.0783, 0.0710, 0.0761, 0.1007],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,444][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0358, 0.1508, 0.0415, 0.1012, 0.0409, 0.0191, 0.0034, 0.0249, 0.0258,
        0.0044, 0.0870, 0.0042, 0.0521, 0.1587, 0.0682, 0.0876, 0.0946],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,446][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0229, 0.0354, 0.0215, 0.0648, 0.0897, 0.0211, 0.1655, 0.0769, 0.0423,
        0.0233, 0.0540, 0.1438, 0.0816, 0.0635, 0.0358, 0.0153, 0.0425],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,448][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0514, 0.0673, 0.0511, 0.0665, 0.0616, 0.0544, 0.0715, 0.0479, 0.0549,
        0.0557, 0.0554, 0.0461, 0.0675, 0.0591, 0.0607, 0.0603, 0.0684],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,449][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.3861, 0.0357, 0.0375, 0.0060, 0.0047, 0.0659, 0.0810, 0.0026, 0.0133,
        0.1554, 0.0042, 0.0063, 0.1344, 0.0119, 0.0358, 0.0049, 0.0143],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,450][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.4947e-01, 2.5881e-03, 2.5067e-02, 3.5462e-04, 6.0484e-03, 1.6446e-02,
        4.4444e-03, 3.8497e-04, 2.1156e-03, 1.2438e-01, 3.7193e-03, 1.2355e-02,
        1.2064e-02, 7.4186e-04, 4.0147e-03, 1.1883e-03, 3.3942e-02, 6.7856e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,451][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.0719, 0.0108, 0.2556, 0.0105, 0.0295, 0.0067, 0.0290, 0.0248,
        0.0018, 0.0431, 0.0041, 0.0559, 0.0370, 0.0952, 0.1212, 0.0538, 0.1479],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,452][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1931, 0.0706, 0.0587, 0.0228, 0.0411, 0.0182, 0.0679, 0.0775, 0.0769,
        0.0103, 0.0422, 0.0889, 0.0545, 0.0178, 0.0529, 0.0616, 0.0286, 0.0165],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,454][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0154, 0.1149, 0.1030, 0.1016, 0.0740, 0.0384, 0.0482, 0.0483, 0.0436,
        0.0438, 0.0682, 0.0655, 0.0430, 0.0370, 0.0422, 0.0364, 0.0369, 0.0394],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,455][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0794, 0.0184, 0.0253, 0.0210, 0.0581, 0.0440, 0.0403, 0.0834, 0.0410,
        0.0835, 0.0395, 0.0992, 0.0556, 0.0363, 0.0987, 0.0492, 0.0826, 0.0446],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,457][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1113, 0.1387, 0.0552, 0.0713, 0.0361, 0.0379, 0.0022, 0.0145, 0.0348,
        0.0101, 0.0520, 0.0070, 0.0426, 0.0838, 0.0483, 0.0714, 0.0718, 0.1110],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,459][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1404, 0.0274, 0.0235, 0.0315, 0.0173, 0.0138, 0.0058, 0.0576, 0.0513,
        0.0084, 0.1434, 0.0123, 0.0098, 0.2402, 0.0236, 0.0605, 0.0051, 0.1282],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,461][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1335, 0.1400, 0.0317, 0.0931, 0.0293, 0.0328, 0.0091, 0.0205, 0.0263,
        0.0091, 0.0445, 0.0076, 0.0691, 0.0516, 0.0843, 0.0692, 0.1090, 0.0392],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,463][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2448, 0.0755, 0.0927, 0.0445, 0.0314, 0.0282, 0.0024, 0.0104, 0.0084,
        0.0082, 0.0358, 0.0034, 0.0322, 0.0401, 0.0883, 0.0373, 0.1594, 0.0569],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,464][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0039, 0.0538, 0.0064, 0.0204, 0.0655, 0.0052, 0.3823, 0.0513, 0.0329,
        0.0057, 0.0327, 0.1009, 0.1174, 0.0228, 0.0389, 0.0167, 0.0246, 0.0186],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,466][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0519, 0.0601, 0.0518, 0.0640, 0.0560, 0.0541, 0.0703, 0.0477, 0.0486,
        0.0471, 0.0524, 0.0406, 0.0614, 0.0543, 0.0534, 0.0576, 0.0600, 0.0687],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,468][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.9106e-01, 1.1310e-03, 3.4047e-02, 2.7199e-04, 1.0550e-03, 1.6351e-02,
        6.9783e-02, 4.5410e-05, 1.2791e-03, 2.5127e-01, 5.0173e-05, 2.3804e-03,
        4.8704e-02, 4.3016e-04, 2.1355e-02, 7.0379e-04, 5.9589e-02, 4.9542e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,535][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:05,536][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,538][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,539][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,541][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,541][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,542][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,543][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,543][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,544][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,545][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,545][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,546][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:05,547][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9920, 0.0080], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,547][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0603, 0.9397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,548][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6174, 0.3826], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,549][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9346, 0.0654], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,550][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9913, 0.0087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,550][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7089, 0.2911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,552][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9401, 0.0599], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,554][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4958, 0.5042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,555][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9377, 0.0623], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,556][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0374, 0.9626], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,557][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1829, 0.8171], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,558][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6697, 0.3303], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:05,558][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.4609, 0.2974, 0.2417], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,559][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.0534, 0.8692, 0.0774], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,561][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.3300, 0.3344, 0.3356], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,562][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.5049, 0.2426, 0.2526], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,564][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.8289, 0.0385, 0.1326], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,565][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.4739, 0.3996, 0.1265], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,567][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.7439, 0.0816, 0.1744], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,568][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.2652, 0.5421, 0.1926], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,570][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.1526, 0.6600, 0.1873], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,572][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.0156, 0.9191, 0.0652], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,573][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.1615, 0.5963, 0.2422], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,575][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.1608, 0.6767, 0.1624], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:05,576][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8718, 0.0277, 0.0877, 0.0128], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,578][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0070, 0.7826, 0.0152, 0.1952], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,580][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3847, 0.2876, 0.2104, 0.1173], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,581][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7813, 0.0583, 0.1220, 0.0384], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,583][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.8438, 0.0664, 0.0751, 0.0148], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,584][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3590, 0.3327, 0.1348, 0.1736], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,586][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8799, 0.0307, 0.0551, 0.0343], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,588][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2684, 0.4509, 0.0951, 0.1856], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,589][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3567, 0.2519, 0.2568, 0.1346], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,591][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0392, 0.7058, 0.0753, 0.1797], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,593][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0663, 0.5595, 0.0890, 0.2853], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,594][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1672, 0.5201, 0.0625, 0.2502], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:05,596][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.7603, 0.0766, 0.0894, 0.0514, 0.0223], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,597][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0040, 0.5579, 0.0115, 0.3936, 0.0330], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,598][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.3863, 0.1971, 0.1929, 0.1400, 0.0837], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,599][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.7501, 0.0410, 0.1112, 0.0476, 0.0500], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,600][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.6834, 0.1678, 0.0898, 0.0416, 0.0174], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,601][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.1923, 0.2947, 0.1192, 0.2652, 0.1286], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,602][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.6976, 0.0485, 0.1015, 0.0415, 0.1109], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,603][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.1944, 0.4295, 0.0607, 0.2534, 0.0620], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,605][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.1940, 0.3308, 0.1168, 0.3146, 0.0437], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,606][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0307, 0.3760, 0.0551, 0.2527, 0.2855], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,608][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0050, 0.5480, 0.0261, 0.1853, 0.2356], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,609][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0449, 0.5340, 0.0332, 0.3342, 0.0537], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:05,611][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.2204, 0.1609, 0.1408, 0.1905, 0.1678, 0.1196], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,613][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0079, 0.4476, 0.0190, 0.3540, 0.1437, 0.0276], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,615][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1434, 0.2225, 0.1579, 0.1646, 0.1703, 0.1412], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,616][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1513, 0.1661, 0.1127, 0.1983, 0.2458, 0.1258], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,618][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.5271, 0.0911, 0.1388, 0.0522, 0.0436, 0.1473], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,620][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.3808, 0.2349, 0.0675, 0.1700, 0.0621, 0.0846], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,621][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.5640, 0.0750, 0.1275, 0.0778, 0.0365, 0.1191], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,623][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0780, 0.2838, 0.0880, 0.2758, 0.1828, 0.0916], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,625][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0651, 0.2561, 0.0866, 0.3422, 0.1708, 0.0792], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,626][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0054, 0.2343, 0.0239, 0.4944, 0.2110, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,628][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0624, 0.3123, 0.0933, 0.2789, 0.1664, 0.0868], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,630][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0603, 0.2580, 0.0651, 0.3319, 0.2069, 0.0778], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:05,631][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0418, 0.1485, 0.0470, 0.3914, 0.2599, 0.0517, 0.0596],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,633][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.0007, 0.4896, 0.0042, 0.3945, 0.0929, 0.0052, 0.0130],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,635][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0909, 0.3000, 0.1083, 0.2319, 0.0915, 0.1374, 0.0400],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,636][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.4042, 0.0871, 0.1017, 0.1141, 0.0772, 0.1280, 0.0877],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,638][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.1567, 0.3888, 0.0771, 0.2014, 0.0705, 0.0968, 0.0088],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,640][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0821, 0.2714, 0.0885, 0.2253, 0.0944, 0.1124, 0.1260],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,640][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.5026, 0.1195, 0.0965, 0.1305, 0.0541, 0.0515, 0.0453],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,641][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0482, 0.3554, 0.0291, 0.3329, 0.1377, 0.0362, 0.0605],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,642][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0033, 0.2585, 0.0145, 0.4538, 0.2396, 0.0155, 0.0148],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,643][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0144, 0.1104, 0.0368, 0.1003, 0.4143, 0.0239, 0.2999],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,644][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0019, 0.6893, 0.0069, 0.2191, 0.0420, 0.0053, 0.0356],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,645][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0039, 0.4930, 0.0104, 0.3705, 0.1064, 0.0129, 0.0029],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:05,647][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2726, 0.1838, 0.0989, 0.1444, 0.1170, 0.0769, 0.0389, 0.0676],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,649][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0026, 0.6203, 0.0074, 0.2656, 0.0213, 0.0082, 0.0085, 0.0662],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,650][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1639, 0.2445, 0.1439, 0.1712, 0.0690, 0.1451, 0.0241, 0.0383],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,652][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.4276, 0.0843, 0.1205, 0.0761, 0.0895, 0.1143, 0.0477, 0.0400],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,653][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0649, 0.4443, 0.0735, 0.2473, 0.0708, 0.0653, 0.0236, 0.0102],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,655][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1207, 0.2200, 0.0827, 0.1669, 0.0940, 0.0925, 0.1170, 0.1061],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,657][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.3356, 0.1024, 0.0546, 0.1527, 0.0333, 0.0395, 0.0214, 0.2606],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,658][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0654, 0.3230, 0.0373, 0.2844, 0.1106, 0.0414, 0.0643, 0.0737],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,660][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0357, 0.2890, 0.0608, 0.3221, 0.1745, 0.0332, 0.0286, 0.0560],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,662][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0083, 0.1482, 0.0226, 0.0288, 0.2094, 0.0113, 0.5222, 0.0492],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,664][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0016, 0.5324, 0.0086, 0.2587, 0.0620, 0.0050, 0.1098, 0.0219],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,665][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0097, 0.4305, 0.0123, 0.3575, 0.0961, 0.0145, 0.0069, 0.0725],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:05,667][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3548, 0.0684, 0.0800, 0.0648, 0.0677, 0.0552, 0.0408, 0.1362, 0.1322],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,669][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0044, 0.5607, 0.0086, 0.2577, 0.0275, 0.0104, 0.0066, 0.0682, 0.0561],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,671][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1800, 0.1961, 0.1438, 0.1389, 0.0626, 0.1377, 0.0255, 0.0362, 0.0793],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,672][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4113, 0.0606, 0.1139, 0.0603, 0.0902, 0.1113, 0.0505, 0.0435, 0.0583],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,674][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2608, 0.2461, 0.1009, 0.1692, 0.0354, 0.1376, 0.0109, 0.0118, 0.0273],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,676][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1287, 0.2171, 0.0727, 0.1493, 0.0730, 0.0753, 0.0936, 0.1206, 0.0697],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,678][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3384, 0.0959, 0.0589, 0.0992, 0.0380, 0.0398, 0.0197, 0.1039, 0.2063],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,679][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0711, 0.2999, 0.0366, 0.2416, 0.0948, 0.0416, 0.0532, 0.0904, 0.0709],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,681][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0830, 0.2233, 0.0692, 0.2694, 0.1422, 0.0448, 0.0319, 0.1044, 0.0318],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,682][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0075, 0.1129, 0.0148, 0.0768, 0.1853, 0.0129, 0.4848, 0.0733, 0.0317],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,683][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0043, 0.4704, 0.0149, 0.2277, 0.0899, 0.0098, 0.1249, 0.0272, 0.0308],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,684][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0276, 0.3228, 0.0234, 0.3525, 0.1037, 0.0215, 0.0046, 0.0994, 0.0445],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:05,684][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0331, 0.0840, 0.0327, 0.1345, 0.0784, 0.0362, 0.1215, 0.2412, 0.2124,
        0.0260], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,686][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.0015, 0.1756, 0.0062, 0.2310, 0.0871, 0.0097, 0.0740, 0.2468, 0.1628,
        0.0052], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,688][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0623, 0.1050, 0.0956, 0.1236, 0.1048, 0.0946, 0.0671, 0.0859, 0.1631,
        0.0980], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,689][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0740, 0.0912, 0.0624, 0.1258, 0.1166, 0.0738, 0.1243, 0.1439, 0.1285,
        0.0597], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,691][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.4268, 0.0779, 0.1259, 0.0386, 0.0402, 0.1299, 0.0189, 0.0181, 0.0333,
        0.0904], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,693][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0762, 0.2154, 0.0507, 0.1700, 0.0611, 0.0810, 0.1080, 0.1240, 0.0849,
        0.0287], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,694][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.3516, 0.0711, 0.1033, 0.0780, 0.0488, 0.0905, 0.0216, 0.0727, 0.0892,
        0.0733], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,696][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0316, 0.1306, 0.0377, 0.1673, 0.1274, 0.0414, 0.1212, 0.1726, 0.1401,
        0.0301], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,698][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0075, 0.1465, 0.0194, 0.2458, 0.1035, 0.0201, 0.0764, 0.2230, 0.1460,
        0.0119], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,700][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0029, 0.0997, 0.0126, 0.2279, 0.1476, 0.0175, 0.2116, 0.1328, 0.1355,
        0.0119], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,701][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0191, 0.2531, 0.0385, 0.2037, 0.1086, 0.0414, 0.1308, 0.0673, 0.1032,
        0.0344], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,703][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0062, 0.1431, 0.0162, 0.2146, 0.1578, 0.0172, 0.0605, 0.2315, 0.1420,
        0.0109], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:05,705][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.3657, 0.0567, 0.0841, 0.0483, 0.0705, 0.0562, 0.0189, 0.0632, 0.0910,
        0.0256, 0.1196], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,707][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0028, 0.4464, 0.0086, 0.2211, 0.0288, 0.0089, 0.0058, 0.0529, 0.0782,
        0.0018, 0.1446], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,708][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1810, 0.1449, 0.1264, 0.1193, 0.0574, 0.1344, 0.0197, 0.0302, 0.0562,
        0.0978, 0.0328], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,710][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.2973, 0.0536, 0.1047, 0.0565, 0.0948, 0.0931, 0.0426, 0.0475, 0.0679,
        0.0576, 0.0844], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,712][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1210, 0.3310, 0.0805, 0.1702, 0.0699, 0.0997, 0.0201, 0.0175, 0.0355,
        0.0297, 0.0249], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,714][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1539, 0.1658, 0.0715, 0.1098, 0.0596, 0.0750, 0.0842, 0.0974, 0.0559,
        0.0311, 0.0957], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,715][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2215, 0.0818, 0.0488, 0.1055, 0.0434, 0.0313, 0.0118, 0.0807, 0.0953,
        0.0168, 0.2633], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,717][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1038, 0.2223, 0.0480, 0.1530, 0.1099, 0.0498, 0.0477, 0.0781, 0.0635,
        0.0172, 0.1066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,719][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1438, 0.1625, 0.1155, 0.1610, 0.1344, 0.0673, 0.0151, 0.0464, 0.0305,
        0.0189, 0.1044], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,721][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0029, 0.1109, 0.0092, 0.0664, 0.1404, 0.0077, 0.5011, 0.0693, 0.0488,
        0.0068, 0.0364], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,722][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0026, 0.4527, 0.0102, 0.2565, 0.0754, 0.0073, 0.1040, 0.0268, 0.0316,
        0.0054, 0.0274], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,724][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0611, 0.2731, 0.0397, 0.2293, 0.0692, 0.0324, 0.0025, 0.0618, 0.0557,
        0.0101, 0.1653], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:05,724][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0470, 0.1406, 0.0337, 0.1065, 0.0921, 0.0218, 0.0446, 0.1219, 0.1570,
        0.0114, 0.1994, 0.0240], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,725][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([2.8887e-04, 2.7045e-01, 2.1817e-03, 3.1966e-01, 2.2331e-02, 3.0221e-03,
        5.8330e-03, 5.7234e-02, 1.2950e-01, 6.1285e-04, 1.8592e-01, 2.9684e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,726][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.1400, 0.1419, 0.1042, 0.1301, 0.0578, 0.1238, 0.0179, 0.0370, 0.0877,
        0.0678, 0.0549, 0.0370], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,727][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.1551, 0.0687, 0.0820, 0.0858, 0.1096, 0.0738, 0.0779, 0.0670, 0.0798,
        0.0546, 0.1153, 0.0304], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,729][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.3286, 0.1854, 0.0991, 0.0749, 0.0490, 0.1168, 0.0085, 0.0109, 0.0262,
        0.0538, 0.0207, 0.0263], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,730][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0534, 0.1469, 0.0524, 0.1347, 0.0630, 0.0568, 0.0962, 0.1043, 0.0741,
        0.0407, 0.1300, 0.0475], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,732][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.1275, 0.0635, 0.0549, 0.0769, 0.1787, 0.0312, 0.0111, 0.0738, 0.0756,
        0.0188, 0.1844, 0.1036], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,734][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0186, 0.2439, 0.0172, 0.2329, 0.0752, 0.0199, 0.0482, 0.1008, 0.0898,
        0.0073, 0.1276, 0.0185], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,735][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0061, 0.3033, 0.0145, 0.3638, 0.0465, 0.0115, 0.0105, 0.0585, 0.0324,
        0.0032, 0.1465, 0.0032], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,736][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([1.8623e-04, 1.5312e-01, 2.0969e-03, 1.3055e-01, 8.6810e-02, 3.0884e-03,
        3.7788e-01, 9.7456e-02, 3.7301e-02, 2.0097e-03, 7.4047e-02, 3.5456e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,738][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0035, 0.3413, 0.0182, 0.1992, 0.1965, 0.0108, 0.1138, 0.0187, 0.0414,
        0.0083, 0.0235, 0.0249], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,740][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0020, 0.3080, 0.0057, 0.2257, 0.0702, 0.0054, 0.0082, 0.0835, 0.0494,
        0.0013, 0.2260, 0.0144], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:05,742][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0424, 0.1570, 0.0439, 0.2125, 0.0535, 0.0318, 0.0102, 0.0822, 0.1229,
        0.0074, 0.1466, 0.0062, 0.0834], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,743][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0006, 0.4738, 0.0030, 0.1855, 0.0156, 0.0030, 0.0038, 0.0431, 0.0690,
        0.0006, 0.1599, 0.0011, 0.0411], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,745][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1812, 0.1182, 0.1147, 0.1143, 0.0399, 0.1454, 0.0207, 0.0358, 0.0677,
        0.0777, 0.0394, 0.0198, 0.0251], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,747][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.2740, 0.0498, 0.0813, 0.0471, 0.0735, 0.0747, 0.0509, 0.0484, 0.0635,
        0.0484, 0.0740, 0.0146, 0.0999], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,749][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.1199, 0.3048, 0.0750, 0.2436, 0.0693, 0.0733, 0.0174, 0.0136, 0.0239,
        0.0254, 0.0135, 0.0089, 0.0114], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,750][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0596, 0.1656, 0.0477, 0.1595, 0.0470, 0.0538, 0.0659, 0.0946, 0.0673,
        0.0350, 0.1178, 0.0307, 0.0557], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,752][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.2797, 0.0865, 0.0592, 0.0796, 0.0454, 0.0437, 0.0095, 0.0611, 0.0865,
        0.0188, 0.1757, 0.0309, 0.0235], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,754][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0349, 0.2079, 0.0230, 0.1948, 0.1046, 0.0265, 0.0303, 0.0840, 0.0747,
        0.0085, 0.1213, 0.0131, 0.0763], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,756][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0092, 0.3353, 0.0225, 0.2349, 0.1389, 0.0161, 0.0059, 0.0375, 0.0183,
        0.0027, 0.1306, 0.0047, 0.0434], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,757][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0264, 0.1071, 0.0669, 0.0407, 0.1181, 0.0373, 0.2047, 0.0531, 0.0285,
        0.0408, 0.0342, 0.1436, 0.0985], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,759][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0023, 0.1880, 0.0074, 0.1994, 0.0723, 0.0070, 0.1090, 0.0340, 0.0613,
        0.0066, 0.0552, 0.0155, 0.2420], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,761][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0062, 0.3567, 0.0101, 0.2345, 0.0307, 0.0100, 0.0019, 0.0389, 0.0435,
        0.0021, 0.2269, 0.0059, 0.0325], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:05,763][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2216, 0.0759, 0.0682, 0.0481, 0.0433, 0.0359, 0.0114, 0.0436, 0.0855,
        0.0118, 0.1029, 0.0086, 0.1406, 0.1026], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,765][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0021, 0.4768, 0.0069, 0.1652, 0.0162, 0.0057, 0.0026, 0.0252, 0.0437,
        0.0009, 0.0793, 0.0017, 0.0539, 0.1198], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,766][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1997, 0.1246, 0.1183, 0.0881, 0.0428, 0.1267, 0.0156, 0.0271, 0.0465,
        0.0876, 0.0285, 0.0335, 0.0274, 0.0336], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,767][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3965, 0.0317, 0.0945, 0.0311, 0.0501, 0.0809, 0.0165, 0.0231, 0.0411,
        0.0412, 0.0494, 0.0151, 0.0862, 0.0426], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,768][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1840, 0.2075, 0.1236, 0.1470, 0.0422, 0.1264, 0.0134, 0.0129, 0.0315,
        0.0489, 0.0172, 0.0147, 0.0184, 0.0121], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,768][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1367, 0.1427, 0.0568, 0.0972, 0.0525, 0.0531, 0.0624, 0.0779, 0.0470,
        0.0340, 0.0722, 0.0351, 0.0739, 0.0586], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,770][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1290, 0.0523, 0.0298, 0.0630, 0.0285, 0.0176, 0.0079, 0.0816, 0.0750,
        0.0095, 0.1803, 0.0178, 0.0122, 0.2955], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,772][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0590, 0.2111, 0.0272, 0.1770, 0.0566, 0.0285, 0.0194, 0.0428, 0.0484,
        0.0082, 0.0813, 0.0107, 0.1252, 0.1045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,774][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1350, 0.2021, 0.0998, 0.1289, 0.0895, 0.0390, 0.0064, 0.0242, 0.0158,
        0.0088, 0.0845, 0.0054, 0.0652, 0.0955], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,775][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0044, 0.0679, 0.0088, 0.0225, 0.0717, 0.0066, 0.4261, 0.0507, 0.0374,
        0.0067, 0.0355, 0.1052, 0.1296, 0.0269], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,777][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0060, 0.2181, 0.0182, 0.2042, 0.0684, 0.0108, 0.1129, 0.0215, 0.0270,
        0.0077, 0.0242, 0.0113, 0.2101, 0.0597], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,779][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0352, 0.2991, 0.0241, 0.1823, 0.0586, 0.0175, 0.0008, 0.0316, 0.0251,
        0.0037, 0.1313, 0.0111, 0.0290, 0.1507], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:05,781][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.1017, 0.0779, 0.0438, 0.0748, 0.0392, 0.0273, 0.0077, 0.0331, 0.0798,
        0.0098, 0.0847, 0.0080, 0.1212, 0.1964, 0.0946], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,782][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0037, 0.3419, 0.0076, 0.1430, 0.0219, 0.0080, 0.0019, 0.0245, 0.0461,
        0.0015, 0.1254, 0.0015, 0.0437, 0.1703, 0.0590], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,784][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1990, 0.1060, 0.1235, 0.0835, 0.0456, 0.1151, 0.0158, 0.0293, 0.0607,
        0.0748, 0.0359, 0.0313, 0.0227, 0.0398, 0.0169], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,786][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.3716, 0.0294, 0.0704, 0.0404, 0.0578, 0.0646, 0.0175, 0.0235, 0.0391,
        0.0344, 0.0529, 0.0142, 0.0974, 0.0464, 0.0403], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,788][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.1576, 0.1952, 0.1202, 0.1430, 0.1404, 0.0912, 0.0109, 0.0057, 0.0131,
        0.0355, 0.0119, 0.0275, 0.0109, 0.0083, 0.0286], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,789][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0703, 0.1625, 0.0322, 0.1224, 0.0343, 0.0482, 0.0511, 0.0862, 0.0507,
        0.0244, 0.1097, 0.0201, 0.0572, 0.0784, 0.0524], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,791][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.2718, 0.0398, 0.0532, 0.0332, 0.0352, 0.0277, 0.0078, 0.0508, 0.0705,
        0.0165, 0.1504, 0.0250, 0.0168, 0.1623, 0.0389], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,793][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0606, 0.1669, 0.0235, 0.1258, 0.0666, 0.0232, 0.0174, 0.0391, 0.0429,
        0.0077, 0.0797, 0.0110, 0.0863, 0.1416, 0.1076], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,795][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0195, 0.2703, 0.0311, 0.1582, 0.0730, 0.0182, 0.0028, 0.0327, 0.0224,
        0.0030, 0.0838, 0.0030, 0.0408, 0.1921, 0.0489], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,797][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0457, 0.0471, 0.0498, 0.0446, 0.0931, 0.0372, 0.1861, 0.0496, 0.0232,
        0.0359, 0.0286, 0.1937, 0.1068, 0.0437, 0.0150], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,798][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0026, 0.2924, 0.0098, 0.1574, 0.0696, 0.0058, 0.0792, 0.0182, 0.0284,
        0.0057, 0.0262, 0.0121, 0.1517, 0.0576, 0.0834], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,800][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0090, 0.1872, 0.0128, 0.1561, 0.0354, 0.0097, 0.0014, 0.0269, 0.0365,
        0.0021, 0.1316, 0.0055, 0.0345, 0.2560, 0.0952], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:05,802][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1535, 0.0272, 0.0402, 0.0257, 0.0290, 0.0232, 0.0096, 0.0378, 0.0507,
        0.0102, 0.0840, 0.0111, 0.1176, 0.1102, 0.1077, 0.1621],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,804][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0027, 0.1896, 0.0056, 0.1030, 0.0141, 0.0043, 0.0032, 0.0303, 0.0476,
        0.0013, 0.1226, 0.0027, 0.0497, 0.2108, 0.1066, 0.1060],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,805][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2151, 0.1046, 0.1171, 0.0656, 0.0389, 0.1049, 0.0144, 0.0208, 0.0460,
        0.0807, 0.0218, 0.0289, 0.0198, 0.0281, 0.0177, 0.0756],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,807][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3682, 0.0202, 0.0825, 0.0228, 0.0466, 0.0637, 0.0184, 0.0168, 0.0261,
        0.0434, 0.0376, 0.0203, 0.0928, 0.0432, 0.0522, 0.0453],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,809][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3480, 0.1192, 0.1108, 0.0803, 0.0280, 0.1288, 0.0074, 0.0081, 0.0213,
        0.0458, 0.0159, 0.0114, 0.0119, 0.0110, 0.0237, 0.0283],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,810][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0944, 0.1363, 0.0531, 0.0832, 0.0504, 0.0433, 0.0609, 0.0833, 0.0445,
        0.0294, 0.0751, 0.0350, 0.0708, 0.0647, 0.0426, 0.0330],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,810][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2385, 0.0421, 0.0362, 0.0366, 0.0251, 0.0236, 0.0072, 0.0537, 0.0703,
        0.0150, 0.1418, 0.0199, 0.0124, 0.1662, 0.0236, 0.0879],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,811][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0718, 0.1391, 0.0267, 0.1123, 0.0392, 0.0264, 0.0134, 0.0343, 0.0343,
        0.0092, 0.0715, 0.0105, 0.0836, 0.1109, 0.1216, 0.0951],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,813][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0879, 0.1193, 0.0534, 0.0997, 0.0624, 0.0254, 0.0059, 0.0325, 0.0172,
        0.0068, 0.0854, 0.0071, 0.0603, 0.1668, 0.1196, 0.0505],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,815][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0080, 0.0760, 0.0132, 0.1047, 0.0744, 0.0136, 0.2972, 0.0538, 0.0291,
        0.0110, 0.0341, 0.0733, 0.1207, 0.0313, 0.0485, 0.0112],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,816][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0084, 0.2282, 0.0194, 0.1288, 0.0637, 0.0115, 0.0955, 0.0227, 0.0270,
        0.0111, 0.0298, 0.0165, 0.1474, 0.0752, 0.0872, 0.0276],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,818][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0271, 0.1453, 0.0198, 0.1242, 0.0352, 0.0139, 0.0012, 0.0302, 0.0194,
        0.0034, 0.0982, 0.0103, 0.0284, 0.2366, 0.1109, 0.0958],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:05,820][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.1466, 0.0354, 0.0410, 0.0416, 0.0199, 0.0270, 0.0060, 0.0323, 0.0671,
        0.0109, 0.0642, 0.0065, 0.0561, 0.1057, 0.0730, 0.2328, 0.0339],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,822][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0053, 0.2152, 0.0069, 0.1046, 0.0162, 0.0095, 0.0022, 0.0247, 0.0385,
        0.0022, 0.1027, 0.0021, 0.0206, 0.1990, 0.0459, 0.1512, 0.0530],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,823][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.2173, 0.0573, 0.1032, 0.0590, 0.0366, 0.1127, 0.0166, 0.0339, 0.0682,
        0.0636, 0.0343, 0.0242, 0.0222, 0.0395, 0.0170, 0.0795, 0.0151],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,825][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.5021, 0.0207, 0.0595, 0.0185, 0.0325, 0.0639, 0.0084, 0.0118, 0.0191,
        0.0419, 0.0355, 0.0135, 0.0406, 0.0251, 0.0275, 0.0346, 0.0448],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,827][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.6402, 0.0361, 0.0896, 0.0164, 0.0140, 0.0946, 0.0027, 0.0025, 0.0077,
        0.0459, 0.0064, 0.0108, 0.0050, 0.0037, 0.0082, 0.0107, 0.0054],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,829][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0739, 0.1150, 0.0334, 0.0996, 0.0403, 0.0438, 0.0652, 0.0882, 0.0504,
        0.0226, 0.0886, 0.0274, 0.0714, 0.0693, 0.0531, 0.0353, 0.0227],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,830][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.2079, 0.0235, 0.0335, 0.0191, 0.0209, 0.0220, 0.0116, 0.0648, 0.0649,
        0.0154, 0.1513, 0.0215, 0.0189, 0.1906, 0.0401, 0.0775, 0.0164],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,832][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.1451, 0.1324, 0.0355, 0.0719, 0.0553, 0.0323, 0.0111, 0.0294, 0.0325,
        0.0118, 0.0508, 0.0121, 0.0539, 0.0783, 0.0710, 0.0761, 0.1007],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,834][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0358, 0.1508, 0.0415, 0.1012, 0.0409, 0.0191, 0.0034, 0.0249, 0.0258,
        0.0044, 0.0870, 0.0042, 0.0521, 0.1587, 0.0682, 0.0876, 0.0946],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,836][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0229, 0.0354, 0.0215, 0.0648, 0.0897, 0.0211, 0.1655, 0.0769, 0.0423,
        0.0233, 0.0540, 0.1438, 0.0816, 0.0635, 0.0358, 0.0153, 0.0425],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,838][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0072, 0.1825, 0.0147, 0.1049, 0.0834, 0.0117, 0.0769, 0.0122, 0.0318,
        0.0130, 0.0333, 0.0177, 0.1690, 0.0565, 0.0968, 0.0270, 0.0614],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,839][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0296, 0.1775, 0.0276, 0.0874, 0.0691, 0.0186, 0.0012, 0.0214, 0.0196,
        0.0038, 0.0771, 0.0141, 0.0154, 0.1573, 0.0854, 0.1244, 0.0708],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:05,841][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3808, 0.0330, 0.0617, 0.0175, 0.0203, 0.0266, 0.0063, 0.0228, 0.0374,
        0.0107, 0.0349, 0.0052, 0.0695, 0.0358, 0.0561, 0.1088, 0.0397, 0.0328],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,843][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0032, 0.3061, 0.0061, 0.1001, 0.0097, 0.0049, 0.0013, 0.0171, 0.0302,
        0.0008, 0.0665, 0.0013, 0.0266, 0.0961, 0.0783, 0.1109, 0.0333, 0.1073],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,845][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2135, 0.1026, 0.1037, 0.0637, 0.0355, 0.0943, 0.0152, 0.0218, 0.0384,
        0.0764, 0.0194, 0.0287, 0.0194, 0.0256, 0.0163, 0.0575, 0.0229, 0.0451],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,846][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5322, 0.0130, 0.0827, 0.0118, 0.0210, 0.0612, 0.0059, 0.0089, 0.0149,
        0.0354, 0.0183, 0.0084, 0.0391, 0.0178, 0.0237, 0.0276, 0.0629, 0.0153],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,848][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.5756, 0.0390, 0.0852, 0.0318, 0.0081, 0.1183, 0.0035, 0.0038, 0.0139,
        0.0477, 0.0073, 0.0069, 0.0078, 0.0050, 0.0128, 0.0184, 0.0103, 0.0046],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,850][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1316, 0.1140, 0.0478, 0.0776, 0.0440, 0.0417, 0.0540, 0.0671, 0.0398,
        0.0312, 0.0596, 0.0311, 0.0605, 0.0483, 0.0448, 0.0333, 0.0287, 0.0450],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,851][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1404, 0.0274, 0.0235, 0.0315, 0.0173, 0.0138, 0.0058, 0.0576, 0.0513,
        0.0084, 0.1434, 0.0123, 0.0098, 0.2402, 0.0236, 0.0605, 0.0051, 0.1282],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,852][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1335, 0.1400, 0.0317, 0.0931, 0.0293, 0.0328, 0.0091, 0.0205, 0.0263,
        0.0091, 0.0445, 0.0076, 0.0691, 0.0516, 0.0843, 0.0692, 0.1090, 0.0392],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,853][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2448, 0.0755, 0.0927, 0.0445, 0.0314, 0.0282, 0.0024, 0.0104, 0.0084,
        0.0082, 0.0358, 0.0034, 0.0322, 0.0401, 0.0883, 0.0373, 0.1594, 0.0569],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,854][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0039, 0.0538, 0.0064, 0.0204, 0.0655, 0.0052, 0.3823, 0.0513, 0.0329,
        0.0057, 0.0327, 0.1009, 0.1174, 0.0228, 0.0389, 0.0167, 0.0246, 0.0186],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,856][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0106, 0.1197, 0.0227, 0.1093, 0.0697, 0.0121, 0.1195, 0.0178, 0.0242,
        0.0108, 0.0217, 0.0139, 0.2014, 0.0540, 0.0875, 0.0258, 0.0468, 0.0325],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,857][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0772, 0.1837, 0.0337, 0.1044, 0.0489, 0.0214, 0.0004, 0.0181, 0.0157,
        0.0040, 0.0752, 0.0120, 0.0161, 0.0919, 0.0630, 0.0786, 0.0488, 0.1068],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:05,861][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:05,863][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15949],
        [21879],
        [23812],
        [25123],
        [ 8601],
        [18747],
        [29137],
        [14601],
        [15172],
        [15945],
        [10347],
        [ 2529],
        [ 8622],
        [ 6975],
        [ 9000],
        [ 6099],
        [ 8323],
        [ 4325]], device='cuda:0')
[2024-07-24 10:26:05,865][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[20917],
        [34714],
        [31242],
        [35690],
        [14014],
        [22806],
        [29254],
        [15765],
        [18916],
        [18102],
        [11074],
        [ 3374],
        [ 8639],
        [ 8776],
        [ 9806],
        [ 8156],
        [ 9217],
        [ 5940]], device='cuda:0')
[2024-07-24 10:26:05,867][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[34724],
        [34744],
        [35783],
        [34914],
        [37108],
        [39608],
        [45358],
        [39290],
        [38172],
        [45438],
        [41496],
        [45139],
        [44041],
        [42455],
        [43363],
        [41218],
        [45004],
        [42993]], device='cuda:0')
[2024-07-24 10:26:05,869][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[46463],
        [47124],
        [46644],
        [47517],
        [47526],
        [47435],
        [47424],
        [47191],
        [47228],
        [46488],
        [46798],
        [46811],
        [47179],
        [47001],
        [46556],
        [45954],
        [45964],
        [46110]], device='cuda:0')
[2024-07-24 10:26:05,871][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16919],
        [16150],
        [17253],
        [17899],
        [18345],
        [18954],
        [18282],
        [18254],
        [18503],
        [18213],
        [18609],
        [18379],
        [18660],
        [19337],
        [18149],
        [19025],
        [18544],
        [18830]], device='cuda:0')
[2024-07-24 10:26:05,873][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2170],
        [3141],
        [4992],
        [5422],
        [6081],
        [6261],
        [6831],
        [6712],
        [6824],
        [6785],
        [7089],
        [7232],
        [7392],
        [7526],
        [7634],
        [7784],
        [7534],
        [7905]], device='cuda:0')
[2024-07-24 10:26:05,874][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[35423],
        [37252],
        [29664],
        [24792],
        [24072],
        [26225],
        [26660],
        [25784],
        [25519],
        [30797],
        [28633],
        [27806],
        [30074],
        [28674],
        [30751],
        [29601],
        [29172],
        [28333]], device='cuda:0')
[2024-07-24 10:26:05,876][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[4576],
        [8478],
        [8928],
        [8242],
        [6988],
        [5989],
        [6663],
        [6487],
        [4484],
        [2686],
        [3671],
        [2785],
        [3593],
        [2587],
        [1519],
        [1265],
        [1180],
        [1098]], device='cuda:0')
[2024-07-24 10:26:05,878][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[7351],
        [5415],
        [2505],
        [4134],
        [1736],
        [2582],
        [3582],
        [8511],
        [6773],
        [5422],
        [6609],
        [3456],
        [5751],
        [8098],
        [7075],
        [7882],
        [9187],
        [9084]], device='cuda:0')
[2024-07-24 10:26:05,880][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[16865],
        [42870],
        [44799],
        [43754],
        [44022],
        [44735],
        [44430],
        [44564],
        [44815],
        [45221],
        [45569],
        [45413],
        [45321],
        [45204],
        [45503],
        [45174],
        [43971],
        [43584]], device='cuda:0')
[2024-07-24 10:26:05,882][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[18650],
        [17170],
        [12395],
        [14657],
        [14515],
        [15738],
        [16053],
        [15706],
        [16127],
        [17161],
        [15756],
        [14442],
        [14089],
        [15247],
        [16872],
        [18594],
        [16810],
        [17607]], device='cuda:0')
[2024-07-24 10:26:05,884][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38945],
        [19393],
        [21582],
        [24711],
        [39567],
        [37527],
        [45663],
        [41754],
        [41192],
        [38880],
        [40282],
        [39204],
        [46391],
        [43640],
        [47401],
        [42507],
        [45976],
        [43853]], device='cuda:0')
[2024-07-24 10:26:05,886][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10371],
        [ 7739],
        [10767],
        [10408],
        [11786],
        [11888],
        [11582],
        [12028],
        [11573],
        [11066],
        [11351],
        [11182],
        [10381],
        [10352],
        [10103],
        [ 9900],
        [ 9245],
        [ 9434]], device='cuda:0')
[2024-07-24 10:26:05,888][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 9413],
        [ 9415],
        [ 9106],
        [ 8923],
        [ 9409],
        [10104],
        [11835],
        [12765],
        [10195],
        [11305],
        [ 8847],
        [11298],
        [11419],
        [ 9385],
        [10071],
        [ 8066],
        [ 9887],
        [10441]], device='cuda:0')
[2024-07-24 10:26:05,890][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22446],
        [10937],
        [ 7135],
        [12297],
        [11576],
        [18931],
        [25664],
        [27084],
        [21709],
        [17152],
        [30699],
        [27322],
        [24153],
        [23427],
        [25963],
        [24390],
        [21956],
        [20998]], device='cuda:0')
[2024-07-24 10:26:05,891][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[34825],
        [34684],
        [35495],
        [34799],
        [35110],
        [29510],
        [26939],
        [29968],
        [25264],
        [23922],
        [25780],
        [25542],
        [27355],
        [24782],
        [22334],
        [17546],
        [17006],
        [18088]], device='cuda:0')
[2024-07-24 10:26:05,893][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25091],
        [44257],
        [44567],
        [45662],
        [46834],
        [46956],
        [47017],
        [46470],
        [46779],
        [47702],
        [47067],
        [47717],
        [47065],
        [46564],
        [46773],
        [47159],
        [47049],
        [47183]], device='cuda:0')
[2024-07-24 10:26:05,895][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 8116],
        [14092],
        [12513],
        [12727],
        [10689],
        [10233],
        [11642],
        [11379],
        [10706],
        [ 8995],
        [ 9756],
        [ 9545],
        [ 9694],
        [ 9143],
        [ 8959],
        [ 8688],
        [ 8713],
        [ 8768]], device='cuda:0')
[2024-07-24 10:26:05,897][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31112],
        [24095],
        [19739],
        [23855],
        [26805],
        [29284],
        [31948],
        [31138],
        [32400],
        [33270],
        [34291],
        [35171],
        [36252],
        [36946],
        [38317],
        [39408],
        [37748],
        [37218]], device='cuda:0')
[2024-07-24 10:26:05,898][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 6098],
        [ 5612],
        [ 2432],
        [ 2362],
        [ 4166],
        [ 4424],
        [15530],
        [16957],
        [13043],
        [ 8718],
        [15414],
        [11358],
        [16006],
        [14346],
        [13983],
        [11017],
        [ 3147],
        [ 4955]], device='cuda:0')
[2024-07-24 10:26:05,900][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9302],
        [ 7703],
        [ 8932],
        [ 9907],
        [12314],
        [10827],
        [13739],
        [13620],
        [13249],
        [14154],
        [13980],
        [15558],
        [14704],
        [14463],
        [14910],
        [15574],
        [15820],
        [15870]], device='cuda:0')
[2024-07-24 10:26:05,902][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12680],
        [ 9292],
        [13925],
        [10907],
        [14676],
        [18795],
        [22178],
        [24157],
        [25453],
        [21956],
        [26719],
        [19132],
        [24568],
        [26234],
        [23778],
        [24935],
        [23044],
        [26032]], device='cuda:0')
[2024-07-24 10:26:05,904][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13276],
        [20056],
        [19804],
        [17115],
        [16958],
        [17262],
        [16813],
        [16357],
        [16221],
        [16874],
        [15545],
        [14871],
        [15974],
        [16302],
        [15805],
        [16134],
        [17170],
        [17141]], device='cuda:0')
[2024-07-24 10:26:05,905][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21490],
        [30291],
        [49168],
        [47994],
        [48695],
        [48180],
        [48259],
        [48365],
        [48303],
        [48336],
        [47835],
        [48799],
        [48667],
        [48291],
        [48797],
        [48520],
        [48571],
        [47500]], device='cuda:0')
[2024-07-24 10:26:05,907][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32953],
        [34668],
        [34315],
        [32689],
        [29110],
        [28463],
        [24601],
        [24995],
        [26081],
        [28934],
        [26219],
        [28149],
        [25466],
        [24313],
        [23985],
        [25962],
        [25368],
        [24770]], device='cuda:0')
[2024-07-24 10:26:05,909][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[22608],
        [34736],
        [35836],
        [34128],
        [35254],
        [34643],
        [34019],
        [33103],
        [32973],
        [31965],
        [32698],
        [33330],
        [33237],
        [33248],
        [33481],
        [33157],
        [34935],
        [34493]], device='cuda:0')
[2024-07-24 10:26:05,911][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9515],
        [24621],
        [29904],
        [30052],
        [30064],
        [30375],
        [30071],
        [29612],
        [29562],
        [31420],
        [30621],
        [30762],
        [30798],
        [31150],
        [31633],
        [32263],
        [32927],
        [32123]], device='cuda:0')
[2024-07-24 10:26:05,913][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26766],
        [18834],
        [ 9095],
        [ 8974],
        [ 6634],
        [ 7280],
        [ 5764],
        [ 5767],
        [ 6147],
        [ 6605],
        [ 5681],
        [ 6475],
        [ 5383],
        [ 5486],
        [ 5581],
        [ 5433],
        [ 6887],
        [ 6269]], device='cuda:0')
[2024-07-24 10:26:05,914][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38100],
        [ 9697],
        [15126],
        [ 9096],
        [11201],
        [15014],
        [18979],
        [15874],
        [15211],
        [21403],
        [15089],
        [10816],
        [16238],
        [14546],
        [15241],
        [13884],
        [15096],
        [14545]], device='cuda:0')
[2024-07-24 10:26:05,916][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333],
        [15333]], device='cuda:0')
[2024-07-24 10:26:06,002][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:06,003][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,005][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,006][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,007][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,008][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,009][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,009][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,010][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,011][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,011][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,012][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,013][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,013][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3762, 0.6238], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,014][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,015][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.1163e-04, 9.9989e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,016][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4623, 0.5377], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,017][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7116, 0.2884], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,018][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0408, 0.9592], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,019][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2018, 0.7982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,019][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,020][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3998, 0.6002], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,021][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4723, 0.5277], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,021][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0431, 0.9569], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,022][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6105, 0.3895], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,023][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.0633, 0.7897, 0.1469], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,024][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([8.7095e-05, 9.6317e-01, 3.6740e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,025][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([7.4472e-06, 9.2140e-01, 7.8589e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,027][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.4984, 0.3040, 0.1975], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,028][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.2187, 0.5838, 0.1975], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,030][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.0049, 0.4580, 0.5371], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,031][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.3506, 0.3906, 0.2588], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,033][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.0170, 0.9281, 0.0549], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,035][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.2270, 0.4600, 0.3130], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,036][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.1518, 0.6737, 0.1745], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,038][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.0084, 0.8871, 0.1045], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,039][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0727, 0.6773, 0.2500], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,041][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0253, 0.6108, 0.0830, 0.2809], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,042][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3271e-04, 6.4313e-01, 5.0266e-02, 3.0637e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,043][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([6.2775e-05, 4.9060e-01, 9.6290e-02, 4.1304e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,044][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5648, 0.2446, 0.1246, 0.0660], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,044][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3926, 0.2697, 0.2123, 0.1254], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,045][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0062, 0.3171, 0.3504, 0.3264], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,046][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0858, 0.3629, 0.2575, 0.2939], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,047][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.8339e-04, 6.7411e-01, 2.7697e-03, 3.2293e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,049][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1724, 0.3259, 0.2517, 0.2500], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,050][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1248, 0.4902, 0.0749, 0.3101], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,052][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0070, 0.4487, 0.0556, 0.4886], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,053][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1476, 0.4266, 0.2804, 0.1455], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,055][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0179, 0.4546, 0.0427, 0.3048, 0.1800], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,056][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([1.2239e-04, 5.9950e-01, 3.7017e-02, 2.7027e-01, 9.3092e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,057][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([2.2333e-05, 3.9714e-01, 6.0727e-02, 3.5514e-01, 1.8697e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,059][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.2605, 0.2628, 0.1205, 0.0750, 0.2812], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,060][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.4415, 0.2844, 0.1012, 0.1483, 0.0246], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,062][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0016, 0.2459, 0.2447, 0.2760, 0.2317], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,064][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0730, 0.2686, 0.2044, 0.2389, 0.2151], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,065][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([2.7115e-04, 6.1565e-01, 2.7834e-03, 2.5395e-01, 1.2735e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,067][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0526, 0.2457, 0.0829, 0.4554, 0.1633], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,068][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.1139, 0.3378, 0.0646, 0.2034, 0.2803], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,070][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0194, 0.2860, 0.0544, 0.1854, 0.4548], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,071][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0097, 0.3753, 0.0600, 0.3154, 0.2396], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,073][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0262, 0.2348, 0.0609, 0.2752, 0.3311, 0.0719], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,074][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ were] are: tensor([4.2494e-06, 7.3786e-01, 1.0869e-02, 2.0477e-01, 4.3441e-02, 3.0524e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,075][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ were] are: tensor([3.0165e-05, 3.5274e-01, 5.4433e-02, 3.0408e-01, 1.5476e-01, 1.3396e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,077][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.2753, 0.1278, 0.1080, 0.0712, 0.1191, 0.2986], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,079][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0933, 0.2365, 0.0791, 0.3435, 0.0650, 0.1827], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,080][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0007, 0.2770, 0.2370, 0.2775, 0.2060, 0.0017], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,082][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0646, 0.2698, 0.2059, 0.2200, 0.1494, 0.0904], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,084][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0056, 0.4541, 0.0244, 0.2688, 0.2161, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,085][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0299, 0.1755, 0.0771, 0.3348, 0.2801, 0.1025], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,086][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0353, 0.1958, 0.0537, 0.3205, 0.3101, 0.0847], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,087][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0012, 0.2054, 0.0147, 0.3567, 0.3888, 0.0331], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,087][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0175, 0.3935, 0.1066, 0.2376, 0.1601, 0.0847], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,088][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ working] are: tensor([7.8302e-05, 1.6162e-01, 3.2992e-03, 3.6674e-01, 4.6166e-01, 4.0569e-03,
        2.5510e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,089][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ working] are: tensor([3.1898e-05, 5.8450e-01, 2.4966e-02, 2.3296e-01, 7.1540e-02, 1.3166e-02,
        7.2836e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,090][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ working] are: tensor([2.3819e-05, 2.8724e-01, 4.9563e-02, 2.5991e-01, 1.4131e-01, 1.3287e-01,
        1.2908e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,092][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.1248, 0.1403, 0.0739, 0.0528, 0.1837, 0.2222, 0.2022],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,094][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.1267, 0.2753, 0.0687, 0.2213, 0.0405, 0.2488, 0.0186],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,095][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0007, 0.2706, 0.1943, 0.2971, 0.1751, 0.0043, 0.0578],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,096][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0337, 0.2177, 0.1151, 0.1925, 0.1798, 0.1093, 0.1518],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,097][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ working] are: tensor([2.7584e-05, 5.4744e-01, 5.9243e-04, 2.4504e-01, 8.6773e-02, 5.9421e-04,
        1.1953e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,099][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0134, 0.1566, 0.0412, 0.3770, 0.2572, 0.0713, 0.0833],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,101][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0036, 0.3567, 0.0090, 0.3005, 0.2928, 0.0147, 0.0226],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,102][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0023, 0.3573, 0.0219, 0.1374, 0.4104, 0.0275, 0.0433],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,104][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0029, 0.4188, 0.0396, 0.2275, 0.1234, 0.0423, 0.1455],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,106][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0008, 0.3096, 0.0081, 0.1793, 0.4861, 0.0050, 0.0020, 0.0091],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,107][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.4542e-05, 6.1458e-01, 1.8626e-02, 2.1873e-01, 6.0382e-02, 6.5734e-03,
        5.2249e-02, 2.8846e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,108][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.2215e-05, 2.6847e-01, 4.6823e-02, 2.2875e-01, 1.2193e-01, 9.8891e-02,
        1.2414e-01, 1.1097e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,110][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2007, 0.1635, 0.0814, 0.0479, 0.1247, 0.2367, 0.0949, 0.0502],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,111][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1067, 0.2998, 0.0919, 0.1944, 0.0287, 0.1668, 0.0061, 0.1056],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,113][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0011, 0.2158, 0.2296, 0.2274, 0.2068, 0.0050, 0.0675, 0.0468],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,115][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0238, 0.2198, 0.1239, 0.1748, 0.1577, 0.0738, 0.1105, 0.1157],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,116][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([7.9881e-05, 3.8073e-01, 1.3943e-03, 1.6948e-01, 1.0391e-01, 1.4451e-03,
        1.7250e-01, 1.7046e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,117][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0122, 0.2410, 0.0368, 0.2411, 0.3564, 0.0336, 0.0483, 0.0306],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,119][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0090, 0.3677, 0.0121, 0.2498, 0.3295, 0.0142, 0.0071, 0.0107],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,121][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0034, 0.2155, 0.0254, 0.0828, 0.3260, 0.0198, 0.1965, 0.1306],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,122][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0059, 0.5010, 0.0506, 0.1808, 0.0817, 0.0407, 0.0966, 0.0427],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,124][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0051, 0.3278, 0.0226, 0.1924, 0.3952, 0.0143, 0.0043, 0.0171, 0.0213],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,125][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.8973e-05, 5.6926e-01, 1.9657e-02, 2.1351e-01, 5.9163e-02, 7.9098e-03,
        5.2007e-02, 3.1496e-02, 4.6974e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,127][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.6066e-05, 1.9859e-01, 4.2297e-02, 1.8016e-01, 9.8990e-02, 9.2182e-02,
        1.1312e-01, 1.1044e-01, 1.6419e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,128][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1778, 0.1522, 0.0745, 0.0516, 0.1253, 0.2269, 0.0997, 0.0485, 0.0434],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,128][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1782, 0.2258, 0.0885, 0.1079, 0.0303, 0.1893, 0.0056, 0.1205, 0.0539],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,129][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0007, 0.2153, 0.2075, 0.2288, 0.1952, 0.0050, 0.0557, 0.0462, 0.0457],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,130][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0300, 0.1923, 0.0992, 0.1584, 0.1373, 0.0773, 0.1034, 0.1050, 0.0972],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,131][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.5210e-04, 4.0154e-01, 1.9229e-03, 2.0294e-01, 1.0136e-01, 2.0761e-03,
        1.3133e-01, 1.1205e-01, 4.6631e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,133][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0386, 0.1648, 0.0659, 0.1894, 0.2725, 0.0513, 0.0369, 0.0681, 0.1126],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,135][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0232, 0.2654, 0.0243, 0.2035, 0.3936, 0.0257, 0.0115, 0.0219, 0.0309],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,136][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0024, 0.1217, 0.0209, 0.1495, 0.2807, 0.0244, 0.2175, 0.1057, 0.0774],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,138][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0075, 0.4646, 0.0560, 0.1668, 0.0873, 0.0491, 0.0833, 0.0442, 0.0413],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,139][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0011, 0.1153, 0.0094, 0.2117, 0.2112, 0.0117, 0.0925, 0.1735, 0.1686,
        0.0050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,141][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([1.1521e-05, 5.8902e-01, 1.5769e-02, 2.0922e-01, 5.0084e-02, 6.0636e-03,
        4.4346e-02, 2.7874e-02, 4.2758e-02, 1.4864e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,142][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([5.9347e-05, 1.7533e-01, 3.5143e-02, 1.7446e-01, 8.6876e-02, 9.6404e-02,
        9.1236e-02, 1.1166e-01, 1.6702e-01, 6.1812e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,143][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.1234, 0.1024, 0.0666, 0.0504, 0.1004, 0.1876, 0.1301, 0.0924, 0.0720,
        0.0747], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,145][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0176, 0.1529, 0.0211, 0.2095, 0.0324, 0.0721, 0.0294, 0.2950, 0.1515,
        0.0185], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,146][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([1.3914e-04, 2.9469e-01, 1.4756e-01, 3.0097e-01, 1.3266e-01, 1.0870e-03,
        4.1617e-02, 3.7488e-02, 3.9395e-02, 4.4015e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,148][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0254, 0.1772, 0.0937, 0.1406, 0.1494, 0.0514, 0.0957, 0.1142, 0.0951,
        0.0573], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,150][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0044, 0.2802, 0.0180, 0.1861, 0.1568, 0.0235, 0.1012, 0.1259, 0.0862,
        0.0175], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,152][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0055, 0.0699, 0.0208, 0.1668, 0.1353, 0.0307, 0.1833, 0.2037, 0.1690,
        0.0148], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,153][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0056, 0.1026, 0.0135, 0.2059, 0.1740, 0.0248, 0.1333, 0.1589, 0.1659,
        0.0154], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,155][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0012, 0.0644, 0.0114, 0.1485, 0.2332, 0.0238, 0.1481, 0.2129, 0.1440,
        0.0125], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,157][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0042, 0.2496, 0.0441, 0.1911, 0.1010, 0.0427, 0.1393, 0.0985, 0.0980,
        0.0314], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,159][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0040, 0.2546, 0.0318, 0.1442, 0.4655, 0.0138, 0.0019, 0.0117, 0.0245,
        0.0013, 0.0467], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,160][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.1496e-05, 4.9443e-01, 2.0684e-02, 2.0020e-01, 5.7670e-02, 9.1533e-03,
        5.2863e-02, 3.3069e-02, 4.8153e-02, 1.8317e-02, 6.5437e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,161][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([3.0806e-05, 1.5111e-01, 3.3336e-02, 1.4362e-01, 8.6701e-02, 7.9447e-02,
        9.2539e-02, 8.5799e-02, 1.5221e-01, 5.8853e-02, 1.1636e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,163][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1845, 0.1208, 0.0808, 0.0413, 0.1154, 0.2083, 0.0823, 0.0475, 0.0398,
        0.0454, 0.0339], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,164][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1882, 0.2295, 0.0751, 0.1120, 0.0168, 0.1952, 0.0035, 0.0812, 0.0532,
        0.0162, 0.0291], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,166][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0006, 0.2225, 0.2208, 0.2282, 0.1566, 0.0037, 0.0397, 0.0404, 0.0462,
        0.0091, 0.0321], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,168][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0183, 0.1485, 0.0974, 0.1308, 0.1161, 0.0691, 0.0842, 0.0911, 0.0855,
        0.0533, 0.1057], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,169][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([8.1140e-05, 3.9658e-01, 1.2776e-03, 1.6575e-01, 8.0473e-02, 1.7772e-03,
        1.2062e-01, 1.2429e-01, 6.0725e-02, 7.3513e-04, 4.7688e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,171][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0319, 0.1209, 0.0656, 0.1207, 0.3469, 0.0482, 0.0202, 0.0511, 0.1060,
        0.0068, 0.0817], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,172][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0290, 0.3441, 0.0255, 0.1722, 0.2744, 0.0256, 0.0056, 0.0117, 0.0233,
        0.0049, 0.0836], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,174][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0008, 0.1128, 0.0109, 0.0942, 0.2740, 0.0136, 0.1944, 0.1370, 0.1020,
        0.0041, 0.0560], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,175][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0070, 0.3582, 0.0563, 0.1522, 0.1001, 0.0468, 0.1032, 0.0585, 0.0559,
        0.0252, 0.0368], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,175][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([2.9313e-04, 4.1164e-01, 5.5600e-03, 1.6858e-01, 2.9120e-01, 3.1168e-03,
        1.7680e-02, 2.0785e-02, 2.4210e-02, 4.1311e-04, 5.5564e-02, 9.6138e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,176][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([1.1988e-05, 5.2379e-01, 1.5497e-02, 1.9598e-01, 5.0006e-02, 6.0987e-03,
        4.6608e-02, 2.7083e-02, 4.0817e-02, 1.4594e-02, 5.9958e-02, 1.9554e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,177][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([6.4696e-06, 1.4879e-01, 2.3694e-02, 1.3338e-01, 7.3027e-02, 7.0360e-02,
        8.3094e-02, 8.2083e-02, 1.4565e-01, 5.2296e-02, 1.2120e-01, 6.6410e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,179][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0396, 0.1275, 0.0524, 0.0548, 0.1894, 0.1155, 0.1364, 0.0747, 0.0523,
        0.0386, 0.0522, 0.0666], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,180][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0780, 0.3013, 0.0406, 0.1469, 0.0192, 0.1311, 0.0059, 0.1381, 0.0723,
        0.0140, 0.0479, 0.0046], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,182][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0006, 0.1766, 0.1689, 0.2019, 0.1477, 0.0059, 0.0612, 0.0432, 0.0477,
        0.0188, 0.0496, 0.0777], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,184][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0232, 0.1116, 0.0838, 0.1016, 0.1058, 0.0562, 0.0806, 0.0923, 0.0834,
        0.0632, 0.1135, 0.0848], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,185][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0005, 0.3644, 0.0054, 0.1828, 0.1263, 0.0062, 0.1044, 0.0881, 0.0514,
        0.0033, 0.0529, 0.0143], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,187][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0013, 0.1315, 0.0110, 0.2442, 0.2081, 0.0096, 0.0745, 0.0550, 0.1431,
        0.0015, 0.1053, 0.0150], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,189][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0036, 0.2376, 0.0104, 0.1353, 0.3978, 0.0076, 0.0139, 0.0251, 0.0434,
        0.0023, 0.1022, 0.0207], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,190][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0004, 0.0897, 0.0064, 0.1226, 0.3882, 0.0098, 0.0728, 0.1162, 0.0800,
        0.0035, 0.0488, 0.0616], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,192][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0019, 0.1791, 0.0226, 0.1632, 0.1035, 0.0339, 0.1598, 0.1038, 0.0909,
        0.0237, 0.0715, 0.0460], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,193][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([1.4791e-04, 2.7676e-01, 8.4048e-03, 1.5724e-01, 4.5622e-01, 4.0710e-03,
        1.1409e-03, 4.7707e-03, 1.6460e-02, 1.7092e-04, 5.0471e-02, 1.1523e-03,
        2.2988e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,195][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([1.6083e-05, 4.8898e-01, 1.6983e-02, 1.8805e-01, 5.0797e-02, 6.9218e-03,
        4.8499e-02, 2.8593e-02, 4.1570e-02, 1.5304e-02, 5.8245e-02, 1.9459e-02,
        3.6581e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,196][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([5.1283e-06, 1.5010e-01, 2.7860e-02, 1.2692e-01, 7.1933e-02, 7.4769e-02,
        6.7462e-02, 7.3498e-02, 1.2492e-01, 4.6701e-02, 1.1087e-01, 6.5116e-02,
        5.9844e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,198][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.2408, 0.0824, 0.0801, 0.0252, 0.0799, 0.1757, 0.0489, 0.0337, 0.0261,
        0.0457, 0.0267, 0.0268, 0.1081], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,199][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0766, 0.2929, 0.0507, 0.1423, 0.0321, 0.1440, 0.0033, 0.1031, 0.0595,
        0.0090, 0.0373, 0.0070, 0.0423], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,201][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0010, 0.1721, 0.1623, 0.1985, 0.1310, 0.0061, 0.0402, 0.0381, 0.0390,
        0.0085, 0.0349, 0.0604, 0.1078], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,203][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0163, 0.1175, 0.0777, 0.1056, 0.0927, 0.0670, 0.0765, 0.0796, 0.0717,
        0.0486, 0.0891, 0.0783, 0.0795], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,204][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([1.6416e-04, 3.6629e-01, 2.0843e-03, 1.7755e-01, 1.2226e-01, 2.3549e-03,
        7.2105e-02, 1.0632e-01, 4.9496e-02, 1.1962e-03, 6.0677e-02, 1.5058e-02,
        2.4446e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,206][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0046, 0.2535, 0.0269, 0.2930, 0.1388, 0.0328, 0.0180, 0.0246, 0.0507,
        0.0025, 0.0802, 0.0058, 0.0686], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,208][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0050, 0.2265, 0.0109, 0.1765, 0.2833, 0.0114, 0.0059, 0.0159, 0.0484,
        0.0022, 0.1562, 0.0142, 0.0438], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,210][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0078, 0.2496, 0.0466, 0.0356, 0.2435, 0.0339, 0.0454, 0.0607, 0.0641,
        0.0164, 0.0427, 0.0409, 0.1129], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,211][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0018, 0.3806, 0.0300, 0.1666, 0.0682, 0.0248, 0.0899, 0.0489, 0.0546,
        0.0149, 0.0456, 0.0391, 0.0351], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,212][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.6203e-03, 3.7945e-01, 2.3382e-02, 1.4286e-01, 3.3659e-01, 7.6056e-03,
        4.8851e-04, 3.2423e-03, 1.1315e-02, 3.2054e-04, 4.4752e-02, 8.4726e-04,
        1.7624e-02, 2.8902e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,214][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.7045e-05, 4.6251e-01, 1.6930e-02, 1.7821e-01, 4.9319e-02, 6.9747e-03,
        4.4908e-02, 2.6843e-02, 3.9275e-02, 1.4514e-02, 5.5082e-02, 1.8341e-02,
        3.4620e-02, 5.2454e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,215][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.3075e-05, 1.3755e-01, 2.5203e-02, 1.1756e-01, 6.2140e-02, 6.1528e-02,
        7.0863e-02, 6.5943e-02, 1.2789e-01, 4.3666e-02, 9.9045e-02, 5.8054e-02,
        6.0919e-02, 6.9617e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,216][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1597, 0.0913, 0.0725, 0.0393, 0.0866, 0.1404, 0.0525, 0.0369, 0.0357,
        0.0334, 0.0354, 0.0407, 0.1357, 0.0399], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,217][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0935, 0.2860, 0.0797, 0.1404, 0.0165, 0.1249, 0.0021, 0.0499, 0.0351,
        0.0081, 0.0279, 0.0037, 0.0256, 0.1066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,218][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0010, 0.1545, 0.1539, 0.1659, 0.1308, 0.0042, 0.0431, 0.0326, 0.0382,
        0.0128, 0.0333, 0.0612, 0.1081, 0.0603], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,218][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0167, 0.1222, 0.0685, 0.1033, 0.0905, 0.0483, 0.0654, 0.0696, 0.0661,
        0.0427, 0.0850, 0.0687, 0.0696, 0.0836], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,220][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0004, 0.3239, 0.0035, 0.1371, 0.0527, 0.0035, 0.1246, 0.1209, 0.0828,
        0.0017, 0.0678, 0.0113, 0.0295, 0.0404], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,222][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0300, 0.1460, 0.0598, 0.1186, 0.2223, 0.0374, 0.0096, 0.0270, 0.0866,
        0.0035, 0.0994, 0.0167, 0.1043, 0.0387], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,224][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0339, 0.3010, 0.0268, 0.1296, 0.2899, 0.0184, 0.0027, 0.0063, 0.0177,
        0.0027, 0.0807, 0.0181, 0.0313, 0.0409], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,225][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0044, 0.0663, 0.0239, 0.0562, 0.1242, 0.0199, 0.1997, 0.1347, 0.0870,
        0.0073, 0.0331, 0.0247, 0.1686, 0.0500], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,227][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0068, 0.3039, 0.0511, 0.1357, 0.0845, 0.0426, 0.0948, 0.0480, 0.0475,
        0.0240, 0.0408, 0.0441, 0.0518, 0.0244], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,228][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([3.0778e-04, 3.0119e-01, 7.9002e-03, 1.6818e-01, 3.1798e-01, 4.2473e-03,
        9.1122e-04, 5.6361e-03, 1.6053e-02, 1.8646e-04, 4.9115e-02, 6.2629e-04,
        2.0372e-02, 9.8254e-02, 9.0395e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,230][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([1.6376e-05, 4.1668e-01, 1.8097e-02, 1.6443e-01, 5.0509e-02, 7.6147e-03,
        4.5183e-02, 2.7297e-02, 3.8744e-02, 1.6155e-02, 5.3956e-02, 1.9368e-02,
        3.4297e-02, 5.2977e-02, 5.4675e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,231][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([2.7221e-05, 1.1317e-01, 2.5050e-02, 1.0175e-01, 6.0115e-02, 5.5698e-02,
        6.0353e-02, 6.8099e-02, 1.0309e-01, 4.3678e-02, 9.3603e-02, 5.8675e-02,
        5.4479e-02, 7.1633e-02, 9.0583e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,233][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1747, 0.0866, 0.0609, 0.0238, 0.0722, 0.1438, 0.0499, 0.0348, 0.0296,
        0.0385, 0.0288, 0.0270, 0.1127, 0.0418, 0.0749], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,235][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.2206, 0.1363, 0.0522, 0.0723, 0.0093, 0.1465, 0.0013, 0.0567, 0.0388,
        0.0104, 0.0215, 0.0029, 0.0292, 0.1590, 0.0428], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,236][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0002, 0.2014, 0.1587, 0.2005, 0.1118, 0.0016, 0.0290, 0.0261, 0.0311,
        0.0044, 0.0242, 0.0455, 0.1053, 0.0537, 0.0064], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,238][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0156, 0.1040, 0.0649, 0.0931, 0.0845, 0.0609, 0.0615, 0.0664, 0.0618,
        0.0386, 0.0761, 0.0653, 0.0617, 0.0830, 0.0625], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,240][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0004, 0.3462, 0.0027, 0.1437, 0.0946, 0.0030, 0.0750, 0.0961, 0.0570,
        0.0017, 0.0540, 0.0156, 0.0245, 0.0544, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,242][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0066, 0.1120, 0.0256, 0.1181, 0.1250, 0.0190, 0.0168, 0.0262, 0.0702,
        0.0022, 0.0743, 0.0084, 0.1699, 0.0908, 0.1348], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,243][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0092, 0.1964, 0.0127, 0.1436, 0.2682, 0.0112, 0.0034, 0.0098, 0.0352,
        0.0018, 0.0975, 0.0166, 0.0544, 0.1116, 0.0283], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,245][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0088, 0.2363, 0.0236, 0.0981, 0.1753, 0.0363, 0.0302, 0.0592, 0.0540,
        0.0099, 0.0459, 0.0468, 0.0994, 0.0319, 0.0443], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,247][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0040, 0.3126, 0.0329, 0.1458, 0.0748, 0.0375, 0.0911, 0.0455, 0.0458,
        0.0188, 0.0392, 0.0404, 0.0510, 0.0293, 0.0314], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,249][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0039, 0.2934, 0.0283, 0.1233, 0.2991, 0.0107, 0.0014, 0.0072, 0.0158,
        0.0007, 0.0507, 0.0021, 0.0372, 0.0817, 0.0214, 0.0230],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,250][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.1645e-05, 4.2264e-01, 1.4891e-02, 1.5996e-01, 4.5296e-02, 5.9469e-03,
        4.0445e-02, 2.4267e-02, 3.5722e-02, 1.3315e-02, 5.1083e-02, 1.7023e-02,
        3.1368e-02, 4.9572e-02, 5.1686e-02, 3.6775e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,251][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([8.3165e-06, 1.0845e-01, 2.1456e-02, 1.0453e-01, 5.0598e-02, 5.6979e-02,
        5.9409e-02, 6.0302e-02, 9.2874e-02, 4.3091e-02, 8.7935e-02, 4.6918e-02,
        5.0803e-02, 6.1000e-02, 9.2922e-02, 6.2730e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,253][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2586, 0.0821, 0.0692, 0.0277, 0.0545, 0.1567, 0.0358, 0.0241, 0.0220,
        0.0335, 0.0234, 0.0259, 0.0911, 0.0298, 0.0448, 0.0207],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,255][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2893, 0.1189, 0.0784, 0.0534, 0.0101, 0.1434, 0.0010, 0.0330, 0.0236,
        0.0090, 0.0145, 0.0032, 0.0171, 0.0967, 0.0266, 0.0820],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,257][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0004, 0.1552, 0.1566, 0.1727, 0.1235, 0.0024, 0.0367, 0.0286, 0.0307,
        0.0112, 0.0295, 0.0560, 0.0968, 0.0594, 0.0115, 0.0286],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,258][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0187, 0.1061, 0.0579, 0.0849, 0.0795, 0.0525, 0.0535, 0.0569, 0.0554,
        0.0410, 0.0726, 0.0643, 0.0595, 0.0766, 0.0653, 0.0554],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,259][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0007, 0.2692, 0.0051, 0.1274, 0.1025, 0.0044, 0.0895, 0.1020, 0.0715,
        0.0031, 0.0636, 0.0207, 0.0213, 0.0597, 0.0324, 0.0272],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,259][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0261, 0.0813, 0.0443, 0.0718, 0.1177, 0.0264, 0.0088, 0.0253, 0.0666,
        0.0039, 0.0903, 0.0200, 0.1515, 0.0638, 0.1227, 0.0796],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,261][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0143, 0.1571, 0.0174, 0.1242, 0.2665, 0.0134, 0.0038, 0.0122, 0.0254,
        0.0027, 0.0990, 0.0270, 0.0541, 0.1102, 0.0369, 0.0357],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,262][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0064, 0.1147, 0.0295, 0.1153, 0.1105, 0.0390, 0.1155, 0.0816, 0.0600,
        0.0155, 0.0324, 0.0169, 0.1281, 0.0384, 0.0523, 0.0440],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,264][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0061, 0.2497, 0.0477, 0.1288, 0.0835, 0.0454, 0.0893, 0.0486, 0.0459,
        0.0228, 0.0428, 0.0425, 0.0607, 0.0244, 0.0333, 0.0286],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,266][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0018, 0.2527, 0.0356, 0.1064, 0.2526, 0.0122, 0.0029, 0.0094, 0.0319,
        0.0012, 0.0400, 0.0021, 0.0380, 0.0964, 0.0307, 0.0486, 0.0376],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,267][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([3.5921e-05, 2.8979e-01, 1.9423e-02, 1.3940e-01, 4.7238e-02, 1.0172e-02,
        4.5728e-02, 3.3106e-02, 4.3536e-02, 1.8712e-02, 5.6737e-02, 2.3984e-02,
        3.8838e-02, 5.6584e-02, 5.7883e-02, 4.2398e-02, 7.6430e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,268][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([1.8415e-05, 9.7221e-02, 1.7397e-02, 9.3877e-02, 4.9100e-02, 4.6211e-02,
        5.3080e-02, 6.0278e-02, 9.5170e-02, 3.8421e-02, 8.2244e-02, 4.6333e-02,
        4.6403e-02, 6.2206e-02, 8.3898e-02, 6.8099e-02, 6.0044e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,270][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.3058, 0.0780, 0.0522, 0.0213, 0.0515, 0.1257, 0.0390, 0.0259, 0.0223,
        0.0322, 0.0239, 0.0240, 0.0677, 0.0292, 0.0495, 0.0173, 0.0343],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,272][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.1715, 0.1878, 0.0347, 0.0506, 0.0088, 0.1015, 0.0016, 0.0515, 0.0330,
        0.0083, 0.0178, 0.0031, 0.0280, 0.1362, 0.0393, 0.1196, 0.0068],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,273][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0003, 0.1821, 0.1431, 0.1723, 0.1095, 0.0017, 0.0309, 0.0259, 0.0271,
        0.0074, 0.0294, 0.0534, 0.0871, 0.0564, 0.0096, 0.0282, 0.0354],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,275][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0189, 0.0755, 0.0525, 0.0692, 0.0824, 0.0446, 0.0503, 0.0580, 0.0509,
        0.0483, 0.0633, 0.0727, 0.0512, 0.0775, 0.0610, 0.0512, 0.0725],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,277][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0013, 0.2448, 0.0065, 0.1205, 0.1225, 0.0062, 0.0593, 0.0964, 0.0611,
        0.0045, 0.0590, 0.0307, 0.0372, 0.0675, 0.0285, 0.0311, 0.0229],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,279][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0491, 0.1182, 0.0690, 0.0827, 0.0538, 0.0573, 0.0130, 0.0114, 0.0682,
        0.0068, 0.0692, 0.0093, 0.0898, 0.0346, 0.0758, 0.1072, 0.0846],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,281][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0224, 0.1487, 0.0244, 0.1060, 0.2616, 0.0208, 0.0081, 0.0132, 0.0332,
        0.0045, 0.0833, 0.0207, 0.0358, 0.0972, 0.0334, 0.0494, 0.0374],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,282][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0314, 0.0344, 0.0390, 0.0595, 0.1350, 0.0594, 0.0347, 0.0426, 0.0460,
        0.0269, 0.0445, 0.0746, 0.1411, 0.0213, 0.0760, 0.0558, 0.0776],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,284][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0032, 0.1781, 0.0275, 0.1191, 0.0795, 0.0301, 0.1006, 0.0641, 0.0601,
        0.0220, 0.0524, 0.0501, 0.0509, 0.0417, 0.0459, 0.0434, 0.0313],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,285][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.1678e-02, 3.8223e-01, 4.8993e-02, 9.7705e-02, 2.9105e-01, 1.2452e-02,
        3.8059e-04, 2.9571e-03, 1.0187e-02, 6.4226e-04, 3.1544e-02, 1.1852e-03,
        1.5347e-02, 2.3460e-02, 8.0521e-03, 1.0854e-02, 3.0683e-02, 2.0599e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,287][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.7857e-05, 3.3042e-01, 1.5216e-02, 1.3825e-01, 4.2119e-02, 6.8109e-03,
        3.8830e-02, 2.4466e-02, 3.4765e-02, 1.3506e-02, 4.7632e-02, 1.7049e-02,
        3.0623e-02, 4.5277e-02, 4.7185e-02, 3.4062e-02, 6.9387e-02, 6.4384e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,288][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.6397e-05, 9.1435e-02, 2.0695e-02, 8.0984e-02, 4.5701e-02, 4.5338e-02,
        5.1524e-02, 4.9561e-02, 8.6644e-02, 3.4108e-02, 7.1044e-02, 4.2962e-02,
        4.6635e-02, 5.1860e-02, 8.4866e-02, 6.1482e-02, 5.8636e-02, 7.6498e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,290][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2234, 0.0790, 0.0651, 0.0295, 0.0606, 0.1205, 0.0342, 0.0255, 0.0262,
        0.0287, 0.0265, 0.0330, 0.0890, 0.0282, 0.0461, 0.0208, 0.0434, 0.0204],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,292][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1342, 0.2008, 0.0806, 0.0792, 0.0105, 0.1038, 0.0013, 0.0314, 0.0213,
        0.0073, 0.0160, 0.0029, 0.0163, 0.0659, 0.0315, 0.0816, 0.0106, 0.1047],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,294][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0005, 0.1335, 0.1399, 0.1289, 0.1221, 0.0022, 0.0377, 0.0232, 0.0302,
        0.0145, 0.0272, 0.0580, 0.0938, 0.0517, 0.0107, 0.0306, 0.0518, 0.0434],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,295][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0146, 0.0834, 0.0566, 0.0732, 0.0668, 0.0444, 0.0511, 0.0511, 0.0492,
        0.0414, 0.0601, 0.0540, 0.0535, 0.0649, 0.0583, 0.0454, 0.0648, 0.0671],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,297][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0008, 0.2065, 0.0049, 0.0954, 0.0574, 0.0046, 0.1356, 0.1089, 0.0854,
        0.0027, 0.0731, 0.0163, 0.0313, 0.0407, 0.0368, 0.0408, 0.0251, 0.0336],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,299][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0780, 0.0827, 0.0770, 0.0566, 0.1331, 0.0396, 0.0054, 0.0187, 0.0596,
        0.0050, 0.0726, 0.0185, 0.0650, 0.0237, 0.0620, 0.0464, 0.1386, 0.0172],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,300][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0622, 0.2053, 0.0336, 0.0869, 0.3038, 0.0200, 0.0021, 0.0052, 0.0147,
        0.0035, 0.0633, 0.0286, 0.0265, 0.0344, 0.0125, 0.0189, 0.0496, 0.0288],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,301][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0135, 0.0413, 0.0310, 0.0425, 0.0968, 0.0276, 0.1666, 0.1234, 0.0742,
        0.0118, 0.0281, 0.0210, 0.1233, 0.0427, 0.0728, 0.0532, 0.0151, 0.0152],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,302][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0069, 0.2273, 0.0478, 0.1138, 0.0783, 0.0416, 0.0917, 0.0468, 0.0454,
        0.0239, 0.0404, 0.0418, 0.0514, 0.0238, 0.0331, 0.0349, 0.0256, 0.0256],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,391][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:06,392][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,393][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,394][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,395][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,395][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,396][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,397][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,397][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,398][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,399][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,400][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,400][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,401][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3762, 0.6238], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,402][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9677, 0.0323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,402][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,404][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4704, 0.5296], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,405][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1360, 0.8640], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,407][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4139, 0.5861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,408][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9081, 0.0919], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,410][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,411][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3998, 0.6002], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,413][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4723, 0.5277], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,415][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0431, 0.9569], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,416][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3711, 0.6289], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,418][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.0633, 0.7897, 0.1469], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,419][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.3773, 0.1956, 0.4272], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,420][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([5.9359e-04, 9.9203e-01, 7.3725e-03], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,422][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.2682, 0.5085, 0.2232], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,424][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.0756, 0.7818, 0.1426], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,425][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.3642, 0.3991, 0.2367], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,427][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.4872, 0.1693, 0.3434], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,429][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.0090, 0.9537, 0.0373], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,430][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.2270, 0.4600, 0.3130], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,432][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.1518, 0.6737, 0.1745], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,434][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.0084, 0.8871, 0.1045], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,435][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.1065, 0.7001, 0.1933], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,436][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0253, 0.6108, 0.0830, 0.2809], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,438][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6358, 0.0949, 0.2300, 0.0393], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,439][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([6.2991e-04, 6.8052e-01, 4.5512e-03, 3.1429e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,441][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3358, 0.3982, 0.1386, 0.1273], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,441][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0687, 0.5269, 0.1079, 0.2964], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,442][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1311, 0.3716, 0.0757, 0.4215], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,443][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5595, 0.0918, 0.2076, 0.1411], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,443][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([2.1333e-04, 7.7052e-01, 3.2668e-03, 2.2600e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,445][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1724, 0.3259, 0.2517, 0.2500], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,446][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1248, 0.4902, 0.0749, 0.3101], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,448][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0070, 0.4487, 0.0556, 0.4886], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,450][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0963, 0.4367, 0.0869, 0.3801], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,451][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0179, 0.4546, 0.0427, 0.3048, 0.1800], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,453][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.7772, 0.0354, 0.1676, 0.0148, 0.0051], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,455][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0006, 0.4667, 0.0039, 0.2568, 0.2720], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,456][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0970, 0.3263, 0.0854, 0.1106, 0.3806], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,458][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0269, 0.5490, 0.0317, 0.3325, 0.0599], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,459][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0097, 0.3272, 0.0190, 0.3140, 0.3300], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,461][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.4030, 0.0842, 0.1917, 0.1043, 0.2168], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,462][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([2.0160e-04, 6.4841e-01, 2.0857e-03, 1.8909e-01, 1.6022e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,464][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0526, 0.2457, 0.0829, 0.4554, 0.1633], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,466][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.1139, 0.3378, 0.0646, 0.2034, 0.2803], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,467][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0194, 0.2860, 0.0544, 0.1854, 0.4548], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,469][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0321, 0.2065, 0.0516, 0.4506, 0.2591], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,471][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0262, 0.2348, 0.0609, 0.2752, 0.3311, 0.0719], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,472][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.1263, 0.1747, 0.1847, 0.1622, 0.1464, 0.2057], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,473][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([2.5815e-04, 4.1680e-01, 3.5300e-03, 3.6387e-01, 2.0377e-01, 1.1780e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,475][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0700, 0.2601, 0.0776, 0.2315, 0.2511, 0.1097], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,477][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0198, 0.3004, 0.0386, 0.4480, 0.1361, 0.0571], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,478][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1618, 0.1848, 0.1193, 0.2013, 0.2241, 0.1087], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,480][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.2137, 0.1353, 0.1653, 0.1451, 0.1867, 0.1540], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,482][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0026, 0.4758, 0.0161, 0.2322, 0.2532, 0.0201], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,483][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0299, 0.1755, 0.0771, 0.3348, 0.2801, 0.1025], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,484][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0353, 0.1958, 0.0537, 0.3205, 0.3101, 0.0847], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,484][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0012, 0.2054, 0.0147, 0.3567, 0.3888, 0.0331], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,485][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0246, 0.2466, 0.0508, 0.4092, 0.1974, 0.0714], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,486][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([7.8302e-05, 1.6162e-01, 3.2992e-03, 3.6674e-01, 4.6166e-01, 4.0569e-03,
        2.5510e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,488][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.2752, 0.1744, 0.2082, 0.0563, 0.0661, 0.2015, 0.0183],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,489][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([2.4270e-04, 3.8444e-01, 1.5780e-03, 1.9356e-01, 1.3994e-01, 1.9017e-03,
        2.7834e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,490][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0123, 0.3638, 0.0261, 0.1277, 0.3493, 0.0291, 0.0917],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,492][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0038, 0.4007, 0.0124, 0.4141, 0.1253, 0.0170, 0.0268],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,494][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0020, 0.2729, 0.0098, 0.4059, 0.2713, 0.0077, 0.0306],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,495][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.1458, 0.1289, 0.1227, 0.1988, 0.2912, 0.0859, 0.0267],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,496][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([1.5761e-05, 5.7932e-01, 4.0528e-04, 1.7467e-01, 1.1139e-01, 3.4470e-04,
        1.3385e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,498][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0134, 0.1566, 0.0412, 0.3770, 0.2572, 0.0713, 0.0833],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,500][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0036, 0.3567, 0.0090, 0.3005, 0.2928, 0.0147, 0.0226],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,501][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0023, 0.3573, 0.0219, 0.1374, 0.4104, 0.0275, 0.0433],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,503][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0043, 0.2348, 0.0118, 0.5042, 0.1772, 0.0157, 0.0521],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,505][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0008, 0.3096, 0.0081, 0.1793, 0.4861, 0.0050, 0.0020, 0.0091],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,507][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2595, 0.2271, 0.1809, 0.0733, 0.0429, 0.1521, 0.0171, 0.0470],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,508][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.1431e-04, 1.2802e-01, 7.1568e-04, 5.4086e-02, 1.1772e-01, 7.9934e-04,
        2.3030e-01, 4.6824e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,510][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0284, 0.4247, 0.0355, 0.1090, 0.2981, 0.0351, 0.0448, 0.0244],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,511][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0038, 0.4488, 0.0155, 0.3930, 0.0857, 0.0124, 0.0097, 0.0310],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,513][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0015, 0.1494, 0.0071, 0.3398, 0.3808, 0.0074, 0.0274, 0.0867],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,515][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1594, 0.1119, 0.1517, 0.2043, 0.2064, 0.1069, 0.0293, 0.0300],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,516][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([6.0106e-05, 3.6003e-01, 1.2958e-03, 1.1371e-01, 1.4755e-01, 1.0379e-03,
        2.0934e-01, 1.6699e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,518][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0122, 0.2410, 0.0368, 0.2411, 0.3564, 0.0336, 0.0483, 0.0306],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,519][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0090, 0.3677, 0.0121, 0.2498, 0.3295, 0.0142, 0.0071, 0.0107],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,521][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0034, 0.2155, 0.0254, 0.0828, 0.3260, 0.0198, 0.1965, 0.1306],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,523][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0053, 0.2781, 0.0163, 0.4679, 0.1044, 0.0179, 0.0493, 0.0608],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,524][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0051, 0.3278, 0.0226, 0.1924, 0.3952, 0.0143, 0.0043, 0.0171, 0.0213],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,525][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2714, 0.1450, 0.1894, 0.0672, 0.0445, 0.1778, 0.0196, 0.0445, 0.0406],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,526][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.4553e-04, 1.3410e-01, 8.4526e-04, 9.7531e-02, 6.5094e-02, 1.2681e-03,
        2.2360e-01, 3.2838e-01, 1.4904e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,527][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0602, 0.3083, 0.0567, 0.1062, 0.2785, 0.0526, 0.0471, 0.0291, 0.0613],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,528][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0136, 0.4016, 0.0310, 0.2508, 0.1603, 0.0256, 0.0178, 0.0470, 0.0524],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,529][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0057, 0.1441, 0.0133, 0.2914, 0.3275, 0.0119, 0.0217, 0.1074, 0.0769],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,531][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1935, 0.0908, 0.1343, 0.1529, 0.1828, 0.0999, 0.0349, 0.0339, 0.0770],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,532][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.0176e-04, 4.1288e-01, 1.5227e-03, 1.4976e-01, 1.3883e-01, 1.3462e-03,
        1.5418e-01, 9.6373e-02, 4.5009e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,534][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0386, 0.1648, 0.0659, 0.1894, 0.2725, 0.0513, 0.0369, 0.0681, 0.1126],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,535][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0232, 0.2654, 0.0243, 0.2035, 0.3936, 0.0257, 0.0115, 0.0219, 0.0309],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,537][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0024, 0.1217, 0.0209, 0.1495, 0.2807, 0.0244, 0.2175, 0.1057, 0.0774],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,539][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0102, 0.2721, 0.0231, 0.4165, 0.1317, 0.0293, 0.0351, 0.0445, 0.0376],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,541][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0011, 0.1153, 0.0094, 0.2117, 0.2112, 0.0117, 0.0925, 0.1735, 0.1686,
        0.0050], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,542][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([0.1038, 0.0932, 0.1282, 0.1022, 0.0747, 0.1631, 0.0716, 0.0647, 0.0888,
        0.1097], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,543][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([2.5557e-04, 1.8273e-01, 2.3191e-03, 1.7044e-01, 1.1267e-01, 7.5425e-03,
        7.4185e-02, 2.7006e-01, 1.7646e-01, 3.3302e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,545][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0158, 0.1530, 0.0274, 0.1340, 0.1610, 0.0412, 0.1415, 0.1481, 0.1586,
        0.0194], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,547][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0030, 0.1750, 0.0109, 0.2475, 0.0982, 0.0172, 0.0823, 0.2069, 0.1502,
        0.0089], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,549][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0842, 0.1476, 0.0747, 0.1466, 0.1374, 0.0777, 0.0651, 0.1203, 0.0807,
        0.0657], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,550][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.1222, 0.0668, 0.1096, 0.0895, 0.1295, 0.1012, 0.0823, 0.0888, 0.1184,
        0.0917], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,552][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0020, 0.2981, 0.0116, 0.1638, 0.1860, 0.0149, 0.1033, 0.1222, 0.0871,
        0.0110], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,554][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0055, 0.0699, 0.0208, 0.1668, 0.1353, 0.0307, 0.1833, 0.2037, 0.1690,
        0.0148], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,556][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0056, 0.1026, 0.0135, 0.2059, 0.1740, 0.0248, 0.1333, 0.1589, 0.1659,
        0.0154], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,557][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0012, 0.0644, 0.0114, 0.1485, 0.2332, 0.0238, 0.1481, 0.2129, 0.1440,
        0.0125], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,559][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0082, 0.1477, 0.0241, 0.2887, 0.1196, 0.0339, 0.0888, 0.1450, 0.1180,
        0.0259], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:06,561][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0040, 0.2546, 0.0318, 0.1442, 0.4655, 0.0138, 0.0019, 0.0117, 0.0245,
        0.0013, 0.0467], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,562][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2052, 0.1118, 0.1619, 0.0516, 0.0407, 0.1664, 0.0155, 0.0486, 0.0448,
        0.0806, 0.0730], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,564][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([9.9563e-05, 8.9629e-02, 6.6408e-04, 7.3601e-02, 6.7509e-02, 1.3575e-03,
        1.5082e-01, 3.5565e-01, 1.7185e-01, 6.5498e-04, 8.8162e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,565][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0795, 0.2479, 0.0717, 0.0808, 0.2395, 0.0611, 0.0299, 0.0262, 0.0539,
        0.0080, 0.1014], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,567][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0158, 0.4635, 0.0327, 0.2482, 0.0864, 0.0274, 0.0066, 0.0249, 0.0485,
        0.0062, 0.0396], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,568][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0016, 0.0955, 0.0063, 0.1836, 0.3869, 0.0057, 0.0156, 0.0799, 0.0649,
        0.0022, 0.1578], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,569][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1141, 0.0855, 0.1136, 0.1224, 0.1921, 0.0787, 0.0261, 0.0352, 0.0739,
        0.0390, 0.1196], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,569][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.1547e-05, 4.2220e-01, 8.2199e-04, 1.1280e-01, 1.0210e-01, 1.0012e-03,
        1.3489e-01, 1.1741e-01, 6.5711e-02, 4.4775e-04, 4.2574e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,570][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0319, 0.1209, 0.0656, 0.1207, 0.3469, 0.0482, 0.0202, 0.0511, 0.1060,
        0.0068, 0.0817], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,572][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0290, 0.3441, 0.0255, 0.1722, 0.2744, 0.0256, 0.0056, 0.0117, 0.0233,
        0.0049, 0.0836], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,574][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0008, 0.1128, 0.0109, 0.0942, 0.2740, 0.0136, 0.1944, 0.1370, 0.1020,
        0.0041, 0.0560], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,575][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0099, 0.2081, 0.0217, 0.3511, 0.1564, 0.0303, 0.0442, 0.0548, 0.0616,
        0.0226, 0.0394], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:06,576][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([2.9313e-04, 4.1164e-01, 5.5600e-03, 1.6858e-01, 2.9120e-01, 3.1168e-03,
        1.7680e-02, 2.0785e-02, 2.4210e-02, 4.1311e-04, 5.5564e-02, 9.6138e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,578][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.2074, 0.0724, 0.1741, 0.0459, 0.0315, 0.2035, 0.0124, 0.0309, 0.0374,
        0.1073, 0.0596, 0.0174], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,579][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([3.4649e-05, 5.6070e-02, 7.2986e-04, 7.3032e-02, 8.1559e-02, 1.4134e-03,
        1.6027e-01, 3.6101e-01, 1.3127e-01, 1.0424e-03, 7.0718e-02, 6.2851e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,581][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0051, 0.1976, 0.0202, 0.0929, 0.4180, 0.0144, 0.0512, 0.0318, 0.0448,
        0.0027, 0.0984, 0.0229], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,583][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0013, 0.4512, 0.0061, 0.2670, 0.0708, 0.0060, 0.0148, 0.0523, 0.0514,
        0.0016, 0.0755, 0.0020], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,584][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0016, 0.1558, 0.0068, 0.1624, 0.2995, 0.0054, 0.0309, 0.0971, 0.0486,
        0.0024, 0.1520, 0.0374], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,586][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.1126, 0.0562, 0.1174, 0.0860, 0.2295, 0.0849, 0.0304, 0.0260, 0.0422,
        0.0486, 0.0801, 0.0862], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,587][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([1.6875e-04, 4.2058e-01, 2.8787e-03, 1.5329e-01, 1.5660e-01, 2.8435e-03,
        1.0771e-01, 6.5312e-02, 3.9839e-02, 1.6108e-03, 4.0005e-02, 9.1696e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,589][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0013, 0.1315, 0.0110, 0.2442, 0.2081, 0.0096, 0.0745, 0.0550, 0.1431,
        0.0015, 0.1053, 0.0150], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,591][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0036, 0.2376, 0.0104, 0.1353, 0.3978, 0.0076, 0.0139, 0.0251, 0.0434,
        0.0023, 0.1022, 0.0207], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,593][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0004, 0.0897, 0.0064, 0.1226, 0.3882, 0.0098, 0.0728, 0.1162, 0.0800,
        0.0035, 0.0488, 0.0616], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,594][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0056, 0.1033, 0.0192, 0.3752, 0.1571, 0.0294, 0.0299, 0.0696, 0.0807,
        0.0225, 0.0539, 0.0537], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:06,595][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([1.4791e-04, 2.7676e-01, 8.4048e-03, 1.5724e-01, 4.5622e-01, 4.0710e-03,
        1.1409e-03, 4.7707e-03, 1.6460e-02, 1.7092e-04, 5.0471e-02, 1.1523e-03,
        2.2988e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,597][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.3261, 0.1043, 0.1589, 0.0356, 0.0240, 0.1242, 0.0123, 0.0235, 0.0407,
        0.0785, 0.0399, 0.0141, 0.0179], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,599][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0002, 0.1087, 0.0014, 0.0539, 0.0530, 0.0020, 0.1052, 0.1857, 0.1744,
        0.0014, 0.0911, 0.0498, 0.1732], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,601][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0140, 0.2612, 0.0256, 0.0817, 0.2236, 0.0220, 0.0190, 0.0195, 0.0393,
        0.0031, 0.0952, 0.0095, 0.1863], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,603][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0020, 0.3857, 0.0104, 0.2612, 0.1523, 0.0090, 0.0063, 0.0265, 0.0416,
        0.0014, 0.0497, 0.0021, 0.0516], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,604][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0036, 0.1686, 0.0111, 0.2401, 0.2439, 0.0072, 0.0122, 0.0614, 0.0575,
        0.0033, 0.1135, 0.0263, 0.0514], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,606][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1114, 0.0685, 0.1238, 0.1112, 0.1499, 0.0771, 0.0247, 0.0300, 0.0793,
        0.0463, 0.0941, 0.0499, 0.0337], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,608][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([4.5432e-05, 3.8092e-01, 9.0720e-04, 1.2767e-01, 1.7683e-01, 8.5375e-04,
        7.1043e-02, 1.0233e-01, 4.6960e-02, 4.5100e-04, 5.5553e-02, 1.5117e-02,
        2.1319e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,609][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0046, 0.2535, 0.0269, 0.2930, 0.1388, 0.0328, 0.0180, 0.0246, 0.0507,
        0.0025, 0.0802, 0.0058, 0.0686], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,610][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0050, 0.2265, 0.0109, 0.1765, 0.2833, 0.0114, 0.0059, 0.0159, 0.0484,
        0.0022, 0.1562, 0.0142, 0.0438], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,610][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0078, 0.2496, 0.0466, 0.0356, 0.2435, 0.0339, 0.0454, 0.0607, 0.0641,
        0.0164, 0.0427, 0.0409, 0.1129], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,612][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0053, 0.0943, 0.0159, 0.2666, 0.1384, 0.0237, 0.0779, 0.1157, 0.0911,
        0.0181, 0.0706, 0.0696, 0.0129], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:06,613][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.6203e-03, 3.7945e-01, 2.3382e-02, 1.4286e-01, 3.3659e-01, 7.6056e-03,
        4.8851e-04, 3.2423e-03, 1.1315e-02, 3.2054e-04, 4.4752e-02, 8.4726e-04,
        1.7624e-02, 2.8902e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,614][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3064, 0.0456, 0.1656, 0.0305, 0.0164, 0.1468, 0.0123, 0.0321, 0.0355,
        0.0823, 0.0476, 0.0124, 0.0303, 0.0364], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,616][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0003, 0.0295, 0.0009, 0.0274, 0.0244, 0.0011, 0.1585, 0.1562, 0.1090,
        0.0009, 0.0423, 0.0314, 0.1338, 0.2841], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,618][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0448, 0.1600, 0.0434, 0.0495, 0.1861, 0.0269, 0.0120, 0.0125, 0.0305,
        0.0027, 0.0722, 0.0147, 0.2877, 0.0570], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,619][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0076, 0.4540, 0.0237, 0.2417, 0.0618, 0.0150, 0.0020, 0.0163, 0.0349,
        0.0024, 0.0408, 0.0014, 0.0416, 0.0568], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,621][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0032, 0.0939, 0.0094, 0.1743, 0.2624, 0.0079, 0.0147, 0.0849, 0.0591,
        0.0025, 0.1556, 0.0374, 0.0402, 0.0545], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,623][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2148, 0.0573, 0.1539, 0.0751, 0.1591, 0.0895, 0.0148, 0.0153, 0.0394,
        0.0466, 0.0547, 0.0410, 0.0218, 0.0165], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,624][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.3056e-04, 3.1222e-01, 2.5482e-03, 9.2103e-02, 5.4769e-02, 2.0926e-03,
        1.6896e-01, 1.1922e-01, 1.0721e-01, 1.1433e-03, 7.0633e-02, 1.0570e-02,
        3.0224e-02, 2.8069e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,626][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0300, 0.1460, 0.0598, 0.1186, 0.2223, 0.0374, 0.0096, 0.0270, 0.0866,
        0.0035, 0.0994, 0.0167, 0.1043, 0.0387], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,628][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0339, 0.3010, 0.0268, 0.1296, 0.2899, 0.0184, 0.0027, 0.0063, 0.0177,
        0.0027, 0.0807, 0.0181, 0.0313, 0.0409], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,629][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0044, 0.0663, 0.0239, 0.0562, 0.1242, 0.0199, 0.1997, 0.1347, 0.0870,
        0.0073, 0.0331, 0.0247, 0.1686, 0.0500], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,631][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0204, 0.1176, 0.0339, 0.2482, 0.1488, 0.0358, 0.0648, 0.0478, 0.0886,
        0.0316, 0.0382, 0.0499, 0.0117, 0.0627], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:06,632][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([3.0778e-04, 3.0119e-01, 7.9002e-03, 1.6818e-01, 3.1798e-01, 4.2473e-03,
        9.1122e-04, 5.6361e-03, 1.6053e-02, 1.8646e-04, 4.9115e-02, 6.2629e-04,
        2.0372e-02, 9.8254e-02, 9.0395e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,634][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.3683, 0.0270, 0.1570, 0.0215, 0.0275, 0.1458, 0.0079, 0.0160, 0.0163,
        0.0888, 0.0317, 0.0161, 0.0179, 0.0369, 0.0214], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,635][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([1.7696e-04, 5.8590e-02, 5.7855e-04, 3.2553e-02, 3.4315e-02, 8.1646e-04,
        9.9094e-02, 1.8233e-01, 1.2602e-01, 7.5938e-04, 5.9114e-02, 5.2687e-02,
        5.2304e-02, 2.6140e-01, 3.9256e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,637][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0165, 0.1968, 0.0241, 0.0471, 0.1559, 0.0195, 0.0104, 0.0128, 0.0359,
        0.0022, 0.0814, 0.0070, 0.1633, 0.0942, 0.1329], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,639][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0052, 0.2914, 0.0132, 0.2281, 0.0758, 0.0105, 0.0048, 0.0255, 0.0485,
        0.0023, 0.0432, 0.0016, 0.0876, 0.0892, 0.0731], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,641][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0067, 0.1522, 0.0168, 0.1639, 0.2248, 0.0102, 0.0150, 0.0550, 0.0447,
        0.0062, 0.1265, 0.0423, 0.0550, 0.0482, 0.0326], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,643][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1024, 0.0573, 0.1220, 0.0928, 0.2515, 0.0586, 0.0257, 0.0208, 0.0517,
        0.0359, 0.0577, 0.0525, 0.0279, 0.0216, 0.0214], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,644][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([3.0344e-04, 3.9405e-01, 1.8546e-03, 1.0932e-01, 1.1155e-01, 1.7193e-03,
        7.8343e-02, 8.0934e-02, 6.2573e-02, 1.1373e-03, 4.7221e-02, 1.4296e-02,
        2.0181e-02, 3.9023e-02, 3.7490e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,646][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0066, 0.1120, 0.0256, 0.1181, 0.1250, 0.0190, 0.0168, 0.0262, 0.0702,
        0.0022, 0.0743, 0.0084, 0.1699, 0.0908, 0.1348], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,647][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0092, 0.1964, 0.0127, 0.1436, 0.2682, 0.0112, 0.0034, 0.0098, 0.0352,
        0.0018, 0.0975, 0.0166, 0.0544, 0.1116, 0.0283], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,649][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0088, 0.2363, 0.0236, 0.0981, 0.1753, 0.0363, 0.0302, 0.0592, 0.0540,
        0.0099, 0.0459, 0.0468, 0.0994, 0.0319, 0.0443], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,650][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0105, 0.0776, 0.0243, 0.2793, 0.1614, 0.0256, 0.0524, 0.0643, 0.0895,
        0.0251, 0.0427, 0.0539, 0.0098, 0.0688, 0.0149], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:06,651][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0039, 0.2934, 0.0283, 0.1233, 0.2991, 0.0107, 0.0014, 0.0072, 0.0158,
        0.0007, 0.0507, 0.0021, 0.0372, 0.0817, 0.0214, 0.0230],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,652][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3013, 0.0369, 0.1535, 0.0325, 0.0181, 0.1377, 0.0080, 0.0212, 0.0323,
        0.0755, 0.0442, 0.0142, 0.0194, 0.0534, 0.0251, 0.0266],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,653][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.9821e-04, 3.9164e-02, 9.3917e-04, 6.3628e-02, 3.4946e-02, 1.6238e-03,
        1.0304e-01, 1.6568e-01, 8.2022e-02, 1.2241e-03, 5.1620e-02, 3.4282e-02,
        8.5590e-02, 2.5237e-01, 5.6075e-02, 2.7596e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,655][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0460, 0.1624, 0.0402, 0.0487, 0.1361, 0.0298, 0.0118, 0.0115, 0.0272,
        0.0040, 0.0666, 0.0139, 0.1976, 0.0600, 0.0943, 0.0498],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,657][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0118, 0.2399, 0.0253, 0.1651, 0.0915, 0.0166, 0.0046, 0.0238, 0.0458,
        0.0039, 0.0482, 0.0044, 0.0831, 0.1010, 0.0815, 0.0536],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,659][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0095, 0.0785, 0.0166, 0.1377, 0.1924, 0.0135, 0.0151, 0.0646, 0.0493,
        0.0053, 0.1557, 0.0402, 0.0488, 0.0533, 0.0320, 0.0875],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,660][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2003, 0.0451, 0.1314, 0.0698, 0.1327, 0.0794, 0.0161, 0.0221, 0.0485,
        0.0423, 0.0730, 0.0503, 0.0239, 0.0224, 0.0163, 0.0263],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,662][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0006, 0.2869, 0.0047, 0.0930, 0.1200, 0.0030, 0.1032, 0.0934, 0.0850,
        0.0025, 0.0636, 0.0206, 0.0161, 0.0462, 0.0388, 0.0225],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,664][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0261, 0.0813, 0.0443, 0.0718, 0.1177, 0.0264, 0.0088, 0.0253, 0.0666,
        0.0039, 0.0903, 0.0200, 0.1515, 0.0638, 0.1227, 0.0796],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,666][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0143, 0.1571, 0.0174, 0.1242, 0.2665, 0.0134, 0.0038, 0.0122, 0.0254,
        0.0027, 0.0990, 0.0270, 0.0541, 0.1102, 0.0369, 0.0357],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,667][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0064, 0.1147, 0.0295, 0.1153, 0.1105, 0.0390, 0.1155, 0.0816, 0.0600,
        0.0155, 0.0324, 0.0169, 0.1281, 0.0384, 0.0523, 0.0440],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,669][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0141, 0.1286, 0.0285, 0.3399, 0.1129, 0.0287, 0.0407, 0.0512, 0.0689,
        0.0252, 0.0448, 0.0368, 0.0069, 0.0431, 0.0092, 0.0205],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:06,671][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0018, 0.2527, 0.0356, 0.1064, 0.2526, 0.0122, 0.0029, 0.0094, 0.0319,
        0.0012, 0.0400, 0.0021, 0.0380, 0.0964, 0.0307, 0.0486, 0.0376],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,673][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.5821, 0.0086, 0.0935, 0.0068, 0.0059, 0.0997, 0.0014, 0.0068, 0.0104,
        0.0706, 0.0131, 0.0083, 0.0074, 0.0169, 0.0099, 0.0114, 0.0472],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,675][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0003, 0.0609, 0.0010, 0.0517, 0.0318, 0.0015, 0.0893, 0.1705, 0.1305,
        0.0021, 0.0449, 0.0530, 0.0498, 0.1729, 0.0421, 0.0517, 0.0460],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,677][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0564, 0.1779, 0.0411, 0.0505, 0.1166, 0.0341, 0.0106, 0.0143, 0.0361,
        0.0055, 0.0668, 0.0100, 0.0929, 0.0636, 0.0808, 0.0510, 0.0918],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,678][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0079, 0.4468, 0.0163, 0.1572, 0.0619, 0.0125, 0.0046, 0.0151, 0.0299,
        0.0025, 0.0310, 0.0019, 0.0448, 0.0575, 0.0400, 0.0383, 0.0317],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,680][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0846, 0.1360, 0.0588, 0.1096, 0.1400, 0.0446, 0.0116, 0.0390, 0.0287,
        0.0209, 0.0773, 0.0366, 0.0270, 0.0208, 0.0211, 0.0687, 0.0748],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,682][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.3027, 0.0196, 0.1196, 0.0277, 0.0998, 0.0645, 0.0193, 0.0193, 0.0515,
        0.0529, 0.0537, 0.0690, 0.0228, 0.0171, 0.0167, 0.0318, 0.0119],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,684][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0009, 0.2715, 0.0046, 0.1000, 0.1607, 0.0037, 0.0577, 0.0935, 0.0682,
        0.0030, 0.0530, 0.0315, 0.0348, 0.0491, 0.0265, 0.0233, 0.0179],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,686][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0491, 0.1182, 0.0690, 0.0827, 0.0538, 0.0573, 0.0130, 0.0114, 0.0682,
        0.0068, 0.0692, 0.0093, 0.0898, 0.0346, 0.0758, 0.1072, 0.0846],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,687][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0224, 0.1487, 0.0244, 0.1060, 0.2616, 0.0208, 0.0081, 0.0132, 0.0332,
        0.0045, 0.0833, 0.0207, 0.0358, 0.0972, 0.0334, 0.0494, 0.0374],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,689][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0314, 0.0344, 0.0390, 0.0595, 0.1350, 0.0594, 0.0347, 0.0426, 0.0460,
        0.0269, 0.0445, 0.0746, 0.1411, 0.0213, 0.0760, 0.0558, 0.0776],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,691][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0186, 0.0966, 0.0314, 0.3336, 0.1141, 0.0377, 0.0363, 0.0631, 0.0647,
        0.0358, 0.0341, 0.0467, 0.0033, 0.0365, 0.0071, 0.0247, 0.0158],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:06,692][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.1678e-02, 3.8223e-01, 4.8993e-02, 9.7705e-02, 2.9105e-01, 1.2452e-02,
        3.8059e-04, 2.9571e-03, 1.0187e-02, 6.4226e-04, 3.1544e-02, 1.1852e-03,
        1.5347e-02, 2.3460e-02, 8.0521e-03, 1.0854e-02, 3.0683e-02, 2.0599e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,693][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6002, 0.0083, 0.1118, 0.0070, 0.0034, 0.1004, 0.0022, 0.0066, 0.0094,
        0.0589, 0.0133, 0.0047, 0.0087, 0.0088, 0.0074, 0.0081, 0.0336, 0.0073],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,694][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0005, 0.0156, 0.0010, 0.0203, 0.0252, 0.0013, 0.1588, 0.1198, 0.0670,
        0.0012, 0.0315, 0.0327, 0.1292, 0.1873, 0.0772, 0.0230, 0.0065, 0.1020],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,695][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0882, 0.1229, 0.0487, 0.0312, 0.1392, 0.0288, 0.0067, 0.0074, 0.0207,
        0.0032, 0.0499, 0.0153, 0.1832, 0.0349, 0.0762, 0.0299, 0.0892, 0.0244],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,697][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0132, 0.3737, 0.0293, 0.1595, 0.0472, 0.0159, 0.0016, 0.0134, 0.0268,
        0.0031, 0.0284, 0.0015, 0.0357, 0.0415, 0.0492, 0.0355, 0.0561, 0.0681],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,698][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0148, 0.0674, 0.0162, 0.1318, 0.1989, 0.0139, 0.0106, 0.0679, 0.0454,
        0.0043, 0.1318, 0.0424, 0.0325, 0.0393, 0.0167, 0.0780, 0.0530, 0.0352],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,700][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3203, 0.0320, 0.1402, 0.0447, 0.1252, 0.0739, 0.0120, 0.0138, 0.0357,
        0.0415, 0.0447, 0.0440, 0.0163, 0.0127, 0.0117, 0.0171, 0.0096, 0.0047],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,702][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0010, 0.1808, 0.0052, 0.0633, 0.0596, 0.0040, 0.1840, 0.0987, 0.1068,
        0.0027, 0.0764, 0.0166, 0.0307, 0.0268, 0.0500, 0.0475, 0.0281, 0.0177],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,704][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0780, 0.0827, 0.0770, 0.0566, 0.1331, 0.0396, 0.0054, 0.0187, 0.0596,
        0.0050, 0.0726, 0.0185, 0.0650, 0.0237, 0.0620, 0.0464, 0.1386, 0.0172],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,705][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0622, 0.2053, 0.0336, 0.0869, 0.3038, 0.0200, 0.0021, 0.0052, 0.0147,
        0.0035, 0.0633, 0.0286, 0.0265, 0.0344, 0.0125, 0.0189, 0.0496, 0.0288],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,707][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0135, 0.0413, 0.0310, 0.0425, 0.0968, 0.0276, 0.1666, 0.1234, 0.0742,
        0.0118, 0.0281, 0.0210, 0.1233, 0.0427, 0.0728, 0.0532, 0.0151, 0.0152],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,709][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0370, 0.0771, 0.0449, 0.1854, 0.1237, 0.0449, 0.0746, 0.0466, 0.0803,
        0.0448, 0.0372, 0.0460, 0.0108, 0.0507, 0.0128, 0.0235, 0.0161, 0.0438],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:06,712][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:06,714][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8720],
        [ 7555],
        [17295],
        [ 8883],
        [ 3825],
        [ 3415],
        [13050],
        [ 3374],
        [ 3669],
        [ 5684],
        [ 2311],
        [ 1015],
        [ 2871],
        [ 2409],
        [ 3970],
        [ 3028],
        [ 3035],
        [ 2028]], device='cuda:0')
[2024-07-24 10:26:06,716][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8415],
        [11096],
        [22652],
        [13752],
        [ 6899],
        [ 6669],
        [18670],
        [ 5727],
        [ 6698],
        [ 9759],
        [ 4283],
        [ 2255],
        [ 4761],
        [ 4080],
        [ 6600],
        [ 5226],
        [ 4794],
        [ 3189]], device='cuda:0')
[2024-07-24 10:26:06,718][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[46674],
        [20958],
        [14972],
        [12592],
        [12320],
        [13448],
        [12275],
        [12829],
        [12567],
        [ 8731],
        [12942],
        [11696],
        [12498],
        [12403],
        [11884],
        [12301],
        [12829],
        [13277]], device='cuda:0')
[2024-07-24 10:26:06,720][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18954],
        [21879],
        [23262],
        [24345],
        [26127],
        [23850],
        [26093],
        [25793],
        [26512],
        [26208],
        [27969],
        [27733],
        [28323],
        [28803],
        [29436],
        [29202],
        [31611],
        [30722]], device='cuda:0')
[2024-07-24 10:26:06,721][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8459],
        [ 8434],
        [19499],
        [24122],
        [20917],
        [19000],
        [16606],
        [16667],
        [14049],
        [10817],
        [ 9544],
        [ 8751],
        [ 9129],
        [ 8809],
        [ 8445],
        [ 8688],
        [ 8020],
        [ 8498]], device='cuda:0')
[2024-07-24 10:26:06,723][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6319],
        [11119],
        [ 9095],
        [ 9586],
        [12395],
        [13564],
        [16675],
        [15395],
        [16037],
        [17946],
        [16659],
        [17586],
        [16578],
        [17458],
        [17789],
        [16767],
        [16629],
        [17314]], device='cuda:0')
[2024-07-24 10:26:06,725][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[16727],
        [23482],
        [29066],
        [28601],
        [27663],
        [29334],
        [29759],
        [29638],
        [30417],
        [30602],
        [30413],
        [30418],
        [31185],
        [31965],
        [33599],
        [33742],
        [34202],
        [34082]], device='cuda:0')
[2024-07-24 10:26:06,727][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43582],
        [36152],
        [12945],
        [22426],
        [20576],
        [21515],
        [24304],
        [21428],
        [22786],
        [27838],
        [23047],
        [22395],
        [22612],
        [22270],
        [23480],
        [22285],
        [22447],
        [20671]], device='cuda:0')
[2024-07-24 10:26:06,729][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[846],
        [151],
        [187],
        [149],
        [153],
        [155],
        [145],
        [157],
        [178],
        [202],
        [208],
        [239],
        [226],
        [236],
        [241],
        [243],
        [254],
        [257]], device='cuda:0')
[2024-07-24 10:26:06,731][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25216],
        [12430],
        [12608],
        [10530],
        [10790],
        [10754],
        [10706],
        [12580],
        [11867],
        [12179],
        [12682],
        [12440],
        [12850],
        [13701],
        [13753],
        [14197],
        [14357],
        [14839]], device='cuda:0')
[2024-07-24 10:26:06,733][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[34225],
        [41640],
        [44437],
        [41973],
        [40947],
        [42932],
        [42171],
        [43554],
        [43870],
        [41672],
        [44376],
        [42648],
        [40876],
        [42776],
        [40722],
        [41215],
        [40819],
        [41828]], device='cuda:0')
[2024-07-24 10:26:06,735][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[3775],
        [2042],
        [1578],
        [1634],
        [ 725],
        [ 713],
        [ 901],
        [ 818],
        [ 627],
        [ 464],
        [ 622],
        [ 460],
        [ 429],
        [ 491],
        [ 352],
        [ 311],
        [ 326],
        [ 406]], device='cuda:0')
[2024-07-24 10:26:06,737][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[44158],
        [39618],
        [42747],
        [34332],
        [33498],
        [29778],
        [33621],
        [31818],
        [31939],
        [28808],
        [30530],
        [28220],
        [32408],
        [27928],
        [29388],
        [28364],
        [23458],
        [26429]], device='cuda:0')
[2024-07-24 10:26:06,738][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31825],
        [45530],
        [47895],
        [47261],
        [46445],
        [46542],
        [46223],
        [46236],
        [46298],
        [45651],
        [46255],
        [46123],
        [46271],
        [46563],
        [46290],
        [46432],
        [46426],
        [46653]], device='cuda:0')
[2024-07-24 10:26:06,740][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19116],
        [40009],
        [43241],
        [42088],
        [44369],
        [44363],
        [46601],
        [46030],
        [43054],
        [41652],
        [39811],
        [39699],
        [44983],
        [43565],
        [43277],
        [41176],
        [44379],
        [41902]], device='cuda:0')
[2024-07-24 10:26:06,741][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20283],
        [13646],
        [14849],
        [14435],
        [19553],
        [24751],
        [27309],
        [28760],
        [26927],
        [28441],
        [29780],
        [25527],
        [29685],
        [26931],
        [28096],
        [28186],
        [27638],
        [25993]], device='cuda:0')
[2024-07-24 10:26:06,743][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11883],
        [10561],
        [ 1638],
        [ 2356],
        [ 3468],
        [ 1752],
        [ 1622],
        [ 2376],
        [ 1625],
        [ 1847],
        [ 1322],
        [  979],
        [ 1319],
        [ 1002],
        [  755],
        [  812],
        [ 1269],
        [ 1374]], device='cuda:0')
[2024-07-24 10:26:06,745][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[1296],
        [2476],
        [2472],
        [2975],
        [4573],
        [4292],
        [4586],
        [6890],
        [6499],
        [5513],
        [7828],
        [7628],
        [5850],
        [5494],
        [6126],
        [6502],
        [7095],
        [5956]], device='cuda:0')
[2024-07-24 10:26:06,747][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11943],
        [12423],
        [12876],
        [15084],
        [19593],
        [21671],
        [21254],
        [21041],
        [22333],
        [28777],
        [23798],
        [24937],
        [25722],
        [27898],
        [26453],
        [26747],
        [27687],
        [27907]], device='cuda:0')
[2024-07-24 10:26:06,748][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[40143],
        [28867],
        [29701],
        [29559],
        [28727],
        [28538],
        [28325],
        [28563],
        [28919],
        [27993],
        [28517],
        [27869],
        [27960],
        [28486],
        [28642],
        [28527],
        [28786],
        [28668]], device='cuda:0')
[2024-07-24 10:26:06,750][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[7038],
        [ 886],
        [ 587],
        [2510],
        [2477],
        [1568],
        [2833],
        [3035],
        [3237],
        [2713],
        [3221],
        [3040],
        [2849],
        [3184],
        [2811],
        [3173],
        [2309],
        [3150]], device='cuda:0')
[2024-07-24 10:26:06,752][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 1292],
        [ 1791],
        [13337],
        [10671],
        [17467],
        [23908],
        [27356],
        [28715],
        [29119],
        [33766],
        [31055],
        [29646],
        [32036],
        [27878],
        [30730],
        [28999],
        [26168],
        [24437]], device='cuda:0')
[2024-07-24 10:26:06,754][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8741],
        [26279],
        [26075],
        [27985],
        [27975],
        [28032],
        [29849],
        [32493],
        [31740],
        [32274],
        [32557],
        [31267],
        [31737],
        [34059],
        [32368],
        [33373],
        [32739],
        [34086]], device='cuda:0')
[2024-07-24 10:26:06,756][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[35054],
        [32529],
        [33403],
        [33388],
        [29842],
        [27302],
        [24763],
        [24288],
        [22372],
        [16298],
        [21454],
        [20404],
        [23167],
        [19139],
        [14933],
        [14442],
        [16208],
        [17290]], device='cuda:0')
[2024-07-24 10:26:06,758][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31800],
        [42987],
        [41997],
        [41600],
        [40393],
        [38411],
        [40375],
        [40536],
        [38915],
        [36181],
        [39541],
        [37864],
        [37488],
        [38772],
        [36802],
        [35853],
        [35617],
        [37393]], device='cuda:0')
[2024-07-24 10:26:06,760][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15998],
        [34283],
        [33213],
        [37162],
        [23923],
        [27485],
        [23069],
        [16553],
        [15801],
        [16703],
        [15792],
        [18162],
        [20229],
        [15252],
        [21807],
        [19247],
        [22009],
        [16535]], device='cuda:0')
[2024-07-24 10:26:06,762][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[40716],
        [35441],
        [36200],
        [36489],
        [35738],
        [36187],
        [34732],
        [34073],
        [34082],
        [28231],
        [33013],
        [32427],
        [29358],
        [30322],
        [29950],
        [31745],
        [31206],
        [28336]], device='cuda:0')
[2024-07-24 10:26:06,764][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[33426],
        [31601],
        [31798],
        [27997],
        [29165],
        [29078],
        [28271],
        [26488],
        [28616],
        [29345],
        [27202],
        [30740],
        [28389],
        [29964],
        [31933],
        [31009],
        [30108],
        [30506]], device='cuda:0')
[2024-07-24 10:26:06,765][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[30367],
        [13159],
        [ 6807],
        [10136],
        [ 4025],
        [ 3381],
        [ 2631],
        [ 5654],
        [ 6652],
        [ 6583],
        [ 9390],
        [ 5615],
        [ 6266],
        [ 8178],
        [ 5196],
        [ 8670],
        [ 5542],
        [12063]], device='cuda:0')
[2024-07-24 10:26:06,767][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379],
        [17379]], device='cuda:0')
[2024-07-24 10:26:06,859][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:06,860][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,860][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,861][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,862][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,862][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,863][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,864][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,865][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,865][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,866][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,867][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,867][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:06,868][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6234, 0.3766], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,869][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.3521e-04, 9.9906e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,869][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6763, 0.3237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,871][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2833, 0.7167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,872][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0086, 0.9914], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,874][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9961, 0.0039], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,876][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1753, 0.8247], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,877][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0416, 0.9584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,879][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0163, 0.9837], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,880][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3515, 0.6485], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,882][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1026, 0.8974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,884][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0416, 0.9584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:06,885][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.5343, 0.3018, 0.1639], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,886][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.0011, 0.9230, 0.0760], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,887][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.4502, 0.3205, 0.2293], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,887][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.1282, 0.4935, 0.3783], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,888][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.0152, 0.8510, 0.1338], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,889][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.9499, 0.0318, 0.0183], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,890][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.0509, 0.3880, 0.5611], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,892][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.0371, 0.7381, 0.2248], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,893][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.0787, 0.7009, 0.2205], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,895][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.2044, 0.5446, 0.2510], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,897][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.1050, 0.6899, 0.2051], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,898][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.1344, 0.6115, 0.2541], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:06,900][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2158, 0.1226, 0.0328, 0.6288], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,901][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.7596e-04, 2.9453e-01, 2.6788e-02, 6.7820e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,903][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3353, 0.1935, 0.2727, 0.1985], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,904][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0786, 0.1867, 0.2232, 0.5115], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,906][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0015, 0.3737, 0.0244, 0.6004], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,907][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9623, 0.0134, 0.0160, 0.0083], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,909][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0399, 0.2378, 0.4349, 0.2874], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,911][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0039, 0.5113, 0.1869, 0.2979], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,912][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0260, 0.5393, 0.1059, 0.3288], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,914][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2217, 0.3700, 0.1310, 0.2773], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,916][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0308, 0.4293, 0.0401, 0.4999], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,917][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0228, 0.2954, 0.0939, 0.5879], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:06,919][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.2271, 0.1617, 0.0337, 0.4836, 0.0939], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,920][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0031, 0.1953, 0.0309, 0.3778, 0.3929], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,922][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.2252, 0.1527, 0.1241, 0.1559, 0.3421], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,924][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0651, 0.1405, 0.1058, 0.1864, 0.5022], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,925][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0011, 0.2649, 0.0166, 0.6434, 0.0740], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,927][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.9659, 0.0124, 0.0088, 0.0080, 0.0049], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,928][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0149, 0.1856, 0.2995, 0.2358, 0.2642], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,929][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0101, 0.3652, 0.1335, 0.2912, 0.1999], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,930][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0257, 0.3997, 0.1011, 0.2998, 0.1737], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,931][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0497, 0.3479, 0.0561, 0.2025, 0.3437], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,931][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0203, 0.3168, 0.0346, 0.3191, 0.3092], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,933][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0212, 0.1881, 0.0469, 0.4646, 0.2792], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:06,934][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.2370, 0.1027, 0.0569, 0.4488, 0.1052, 0.0495], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,936][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0009, 0.1217, 0.0158, 0.2153, 0.1999, 0.4463], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,938][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.2584, 0.1553, 0.1042, 0.1270, 0.2656, 0.0895], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,939][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0378, 0.1871, 0.1093, 0.2350, 0.3758, 0.0550], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,941][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0016, 0.0979, 0.0141, 0.5860, 0.2759, 0.0246], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,943][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.8267, 0.0191, 0.0279, 0.0188, 0.0143, 0.0931], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,944][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0136, 0.1375, 0.1967, 0.1656, 0.1800, 0.3066], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,946][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0050, 0.3933, 0.0957, 0.2577, 0.1732, 0.0751], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,948][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0132, 0.4194, 0.1178, 0.1972, 0.1347, 0.1177], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,949][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0694, 0.2485, 0.0857, 0.2655, 0.2389, 0.0920], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,951][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0307, 0.2662, 0.0599, 0.3370, 0.2352, 0.0709], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,952][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0185, 0.1731, 0.0481, 0.4238, 0.2868, 0.0496], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:06,954][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0955, 0.1806, 0.0267, 0.4599, 0.1792, 0.0225, 0.0357],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,956][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0016, 0.0586, 0.0140, 0.1057, 0.1051, 0.2281, 0.4869],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,957][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.1375, 0.2009, 0.0960, 0.2456, 0.1709, 0.0617, 0.0874],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,959][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0024, 0.1861, 0.0224, 0.2133, 0.4172, 0.0069, 0.1517],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,960][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ working] are: tensor([2.9361e-04, 8.1451e-02, 4.9467e-03, 6.7039e-01, 2.1811e-01, 1.9669e-02,
        5.1427e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,962][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.5272, 0.0716, 0.0261, 0.0593, 0.0347, 0.2427, 0.0384],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,964][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0091, 0.1097, 0.1510, 0.1355, 0.1435, 0.2575, 0.1937],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,965][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0049, 0.2861, 0.0957, 0.2213, 0.1539, 0.0965, 0.1415],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,967][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0052, 0.4130, 0.0536, 0.2629, 0.1238, 0.1135, 0.0280],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,969][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0263, 0.3482, 0.0353, 0.2832, 0.2341, 0.0376, 0.0353],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,971][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0019, 0.2963, 0.0098, 0.3535, 0.2554, 0.0113, 0.0718],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,971][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ working] are: tensor([3.2636e-04, 1.2808e-01, 4.0540e-03, 4.9633e-01, 3.4770e-01, 3.2191e-03,
        2.0293e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:06,972][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0676, 0.1018, 0.0138, 0.4718, 0.0723, 0.0097, 0.0096, 0.2535],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,973][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([3.2355e-04, 3.0307e-02, 6.3090e-03, 6.5525e-02, 8.4475e-02, 1.0485e-01,
        3.6592e-01, 3.4229e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,974][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0990, 0.1016, 0.1625, 0.1715, 0.2692, 0.0548, 0.1218, 0.0196],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,975][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0036, 0.1225, 0.0274, 0.1325, 0.4809, 0.0058, 0.1847, 0.0426],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,977][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0015, 0.1625, 0.0124, 0.3645, 0.4070, 0.0230, 0.0038, 0.0252],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,979][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.5932, 0.0595, 0.0404, 0.0474, 0.0259, 0.1739, 0.0178, 0.0419],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,980][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0072, 0.0938, 0.1157, 0.1056, 0.1239, 0.2224, 0.1633, 0.1681],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,982][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0015, 0.2994, 0.0954, 0.1865, 0.1395, 0.0716, 0.1346, 0.0717],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,983][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0047, 0.4189, 0.0586, 0.2299, 0.1254, 0.1207, 0.0201, 0.0216],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,985][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0644, 0.3321, 0.0553, 0.2503, 0.2008, 0.0592, 0.0198, 0.0181],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,987][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0041, 0.2946, 0.0133, 0.3144, 0.2576, 0.0118, 0.0497, 0.0545],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,988][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([3.9188e-04, 1.2078e-01, 5.8772e-03, 3.5362e-01, 4.8082e-01, 2.7883e-03,
        1.8587e-02, 1.7130e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:06,990][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([7.1920e-03, 6.4458e-03, 1.1793e-03, 2.8693e-02, 4.0892e-03, 7.1436e-04,
        5.9980e-04, 1.4650e-02, 9.3644e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,991][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.2981e-04, 1.8660e-02, 3.2374e-03, 4.5496e-02, 6.1878e-02, 8.0431e-02,
        2.6102e-01, 2.5246e-01, 2.7668e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,992][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0888, 0.0931, 0.1150, 0.1539, 0.3001, 0.0436, 0.1364, 0.0193, 0.0498],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,994][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0100, 0.0967, 0.0675, 0.0787, 0.5198, 0.0095, 0.1108, 0.0358, 0.0712],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,996][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0019, 0.0950, 0.0182, 0.3544, 0.4355, 0.0195, 0.0035, 0.0626, 0.0093],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,998][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7652, 0.0264, 0.0237, 0.0204, 0.0119, 0.1050, 0.0084, 0.0227, 0.0164],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:06,999][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0052, 0.0797, 0.1111, 0.0904, 0.0993, 0.1803, 0.1394, 0.1623, 0.1322],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,001][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0011, 0.2759, 0.0839, 0.1629, 0.1257, 0.0631, 0.1298, 0.0718, 0.0856],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,003][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0063, 0.4060, 0.0596, 0.2273, 0.1263, 0.1085, 0.0207, 0.0222, 0.0231],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,004][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0699, 0.2923, 0.0604, 0.1931, 0.2698, 0.0542, 0.0153, 0.0118, 0.0332],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,006][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0075, 0.2478, 0.0195, 0.2704, 0.2205, 0.0131, 0.0502, 0.0489, 0.1222],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,008][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0008, 0.2005, 0.0096, 0.3471, 0.3559, 0.0040, 0.0128, 0.0122, 0.0570],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,009][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0196, 0.0158, 0.0063, 0.0645, 0.0147, 0.0060, 0.0042, 0.0528, 0.8117,
        0.0045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,011][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([0.0005, 0.0178, 0.0033, 0.0427, 0.0360, 0.1008, 0.1772, 0.2417, 0.3174,
        0.0626], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,013][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.1073, 0.1378, 0.0895, 0.0978, 0.1682, 0.0842, 0.1122, 0.0189, 0.0842,
        0.0999], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,014][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0101, 0.1224, 0.0338, 0.1769, 0.1928, 0.0272, 0.1637, 0.1239, 0.1272,
        0.0222], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,015][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0003, 0.0597, 0.0043, 0.2810, 0.1588, 0.0121, 0.0500, 0.2094, 0.2215,
        0.0029], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,016][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.3396, 0.0646, 0.0210, 0.0555, 0.0303, 0.2561, 0.0385, 0.1007, 0.0663,
        0.0275], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,016][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0029, 0.0747, 0.0806, 0.0819, 0.0787, 0.1781, 0.1165, 0.1545, 0.1284,
        0.1037], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,018][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0005, 0.2592, 0.0623, 0.1701, 0.1016, 0.0636, 0.1210, 0.0774, 0.0959,
        0.0484], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,020][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0026, 0.5223, 0.0506, 0.1995, 0.0871, 0.0900, 0.0114, 0.0132, 0.0141,
        0.0091], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,021][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([0.0338, 0.1907, 0.0524, 0.1897, 0.1745, 0.0587, 0.0854, 0.0783, 0.1043,
        0.0321], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,023][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0102, 0.1563, 0.0302, 0.2259, 0.1599, 0.0369, 0.0852, 0.1191, 0.1592,
        0.0172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,025][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0073, 0.1056, 0.0194, 0.2587, 0.1537, 0.0282, 0.0976, 0.1080, 0.2069,
        0.0146], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,026][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([8.8351e-03, 9.1841e-03, 2.1440e-03, 3.7087e-02, 6.3563e-03, 1.2237e-03,
        1.1906e-03, 1.9419e-02, 8.9725e-01, 5.2355e-04, 1.6791e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,028][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0026, 0.0323, 0.0142, 0.0370, 0.0409, 0.1310, 0.1155, 0.1171, 0.1708,
        0.1349, 0.2037], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,029][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0788, 0.0575, 0.1105, 0.0958, 0.1866, 0.0388, 0.1404, 0.0187, 0.0542,
        0.1402, 0.0785], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,031][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0034, 0.0684, 0.0353, 0.0883, 0.4290, 0.0059, 0.1077, 0.0464, 0.0864,
        0.0030, 0.1264], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,033][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0010, 0.2524, 0.0077, 0.3147, 0.2872, 0.0209, 0.0015, 0.0444, 0.0348,
        0.0013, 0.0341], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,034][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.7820, 0.0203, 0.0189, 0.0157, 0.0094, 0.0978, 0.0066, 0.0169, 0.0138,
        0.0070, 0.0115], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,036][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0049, 0.0607, 0.0820, 0.0666, 0.0804, 0.1383, 0.1056, 0.1185, 0.1183,
        0.1042, 0.1205], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,038][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0005, 0.2286, 0.0785, 0.1322, 0.1113, 0.0510, 0.1083, 0.0598, 0.0846,
        0.0388, 0.1065], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,040][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0049, 0.3915, 0.0546, 0.2117, 0.1220, 0.1109, 0.0181, 0.0194, 0.0204,
        0.0122, 0.0343], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,041][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0398, 0.2534, 0.0559, 0.1716, 0.2952, 0.0413, 0.0144, 0.0116, 0.0336,
        0.0094, 0.0737], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,043][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0034, 0.2117, 0.0122, 0.2617, 0.2104, 0.0085, 0.0305, 0.0378, 0.0800,
        0.0010, 0.1430], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,045][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0011, 0.1188, 0.0142, 0.2452, 0.4823, 0.0045, 0.0144, 0.0090, 0.0544,
        0.0007, 0.0554], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,046][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0138, 0.0141, 0.0025, 0.0447, 0.0094, 0.0022, 0.0015, 0.0229, 0.8641,
        0.0014, 0.0181, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,048][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0012, 0.0178, 0.0055, 0.0309, 0.0324, 0.0658, 0.1177, 0.1355, 0.1808,
        0.0647, 0.2300, 0.1177], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,050][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0824, 0.0744, 0.0677, 0.0681, 0.1732, 0.0411, 0.0862, 0.0090, 0.0604,
        0.1046, 0.0392, 0.1938], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,052][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0036, 0.0799, 0.0193, 0.1265, 0.3502, 0.0063, 0.1099, 0.0538, 0.0788,
        0.0029, 0.1085, 0.0602], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,053][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([1.9824e-04, 2.1600e-01, 6.6187e-03, 4.3311e-01, 7.5789e-02, 9.1730e-03,
        1.3877e-02, 1.0326e-01, 8.4175e-02, 8.1813e-04, 4.6448e-02, 1.0535e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,055][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.7109, 0.0372, 0.0131, 0.0201, 0.0102, 0.1240, 0.0114, 0.0240, 0.0164,
        0.0099, 0.0171, 0.0057], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,056][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0027, 0.0532, 0.0700, 0.0677, 0.0676, 0.1259, 0.0854, 0.1294, 0.0993,
        0.0862, 0.1337, 0.0788], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,056][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0040, 0.1686, 0.0561, 0.1401, 0.0777, 0.0518, 0.0890, 0.0642, 0.0859,
        0.0495, 0.1380, 0.0751], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,057][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0035, 0.3742, 0.0515, 0.2175, 0.1131, 0.1146, 0.0181, 0.0182, 0.0196,
        0.0130, 0.0336, 0.0231], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,058][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0153, 0.2689, 0.0315, 0.1394, 0.3348, 0.0240, 0.0231, 0.0110, 0.0352,
        0.0082, 0.0724, 0.0362], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,060][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0019, 0.1481, 0.0090, 0.2197, 0.2842, 0.0078, 0.0405, 0.0389, 0.0834,
        0.0012, 0.1344, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,061][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0021, 0.1282, 0.0109, 0.3302, 0.3294, 0.0066, 0.0285, 0.0179, 0.0584,
        0.0016, 0.0648, 0.0215], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,063][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([4.8803e-03, 1.1559e-02, 1.2420e-03, 3.5079e-02, 8.0080e-03, 1.0150e-03,
        5.4972e-04, 1.9960e-02, 8.6498e-01, 3.4841e-04, 1.9853e-02, 5.0623e-03,
        2.7461e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,064][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0005, 0.0122, 0.0029, 0.0245, 0.0246, 0.0433, 0.1059, 0.1197, 0.1417,
        0.0413, 0.2235, 0.0936, 0.1663], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,066][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0883, 0.0767, 0.0804, 0.1153, 0.1829, 0.0573, 0.0872, 0.0121, 0.0361,
        0.0509, 0.0392, 0.1404, 0.0332], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,068][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0073, 0.1027, 0.0325, 0.0647, 0.4206, 0.0067, 0.0792, 0.0312, 0.0662,
        0.0037, 0.0704, 0.0510, 0.0639], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,069][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([3.8033e-04, 1.1463e-01, 2.8332e-03, 6.8351e-01, 5.8080e-02, 7.7515e-03,
        1.6840e-03, 4.0598e-02, 4.6448e-02, 5.4664e-04, 3.5192e-02, 5.7372e-03,
        2.6144e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,071][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.6792, 0.0384, 0.0217, 0.0222, 0.0138, 0.1299, 0.0077, 0.0242, 0.0184,
        0.0072, 0.0190, 0.0063, 0.0122], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,072][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0031, 0.0541, 0.0626, 0.0620, 0.0666, 0.1205, 0.0818, 0.1099, 0.0897,
        0.0909, 0.1146, 0.0727, 0.0713], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,074][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0033, 0.1725, 0.0592, 0.1266, 0.0784, 0.0453, 0.0683, 0.0568, 0.0823,
        0.0389, 0.1167, 0.0681, 0.0836], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,076][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0019, 0.3995, 0.0442, 0.2098, 0.0965, 0.1125, 0.0124, 0.0152, 0.0167,
        0.0108, 0.0277, 0.0165, 0.0364], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,078][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0469, 0.2017, 0.0537, 0.1769, 0.2715, 0.0360, 0.0180, 0.0154, 0.0475,
        0.0105, 0.0765, 0.0233, 0.0221], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,080][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0023, 0.1797, 0.0110, 0.1902, 0.2361, 0.0078, 0.0250, 0.0304, 0.0913,
        0.0012, 0.1695, 0.0132, 0.0424], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,081][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0020, 0.1482, 0.0113, 0.2483, 0.3641, 0.0049, 0.0085, 0.0107, 0.0496,
        0.0009, 0.0825, 0.0134, 0.0557], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,083][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.6444e-03, 6.8456e-03, 9.0130e-04, 2.8931e-02, 4.1295e-03, 6.2571e-04,
        5.1832e-04, 1.1987e-02, 8.7236e-01, 2.5214e-04, 1.3885e-02, 2.7834e-03,
        2.9660e-02, 2.1480e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,084][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.6405e-05, 7.5368e-03, 1.8481e-03, 1.6600e-02, 2.3814e-02, 3.6576e-02,
        9.7649e-02, 8.5419e-02, 1.0475e-01, 4.1622e-02, 2.6146e-01, 1.0133e-01,
        1.4649e-01, 7.4817e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,086][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0359, 0.0443, 0.0721, 0.0922, 0.2171, 0.0263, 0.1076, 0.0113, 0.0398,
        0.0663, 0.0474, 0.2010, 0.0191, 0.0195], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,087][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0034, 0.0391, 0.0206, 0.0365, 0.3698, 0.0035, 0.0938, 0.0396, 0.0570,
        0.0020, 0.0777, 0.0741, 0.1318, 0.0511], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,089][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.9188e-04, 7.8919e-02, 2.7211e-03, 1.1788e-01, 6.6296e-01, 4.4983e-03,
        1.5842e-03, 2.6512e-02, 3.3738e-02, 2.4019e-04, 1.7023e-02, 3.8449e-02,
        1.1785e-02, 3.5028e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,090][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6957, 0.0359, 0.0304, 0.0248, 0.0138, 0.1151, 0.0058, 0.0192, 0.0139,
        0.0063, 0.0152, 0.0063, 0.0082, 0.0094], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,092][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0020, 0.0413, 0.0603, 0.0519, 0.0668, 0.1112, 0.0879, 0.0913, 0.0814,
        0.0941, 0.0930, 0.0754, 0.0743, 0.0690], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,094][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0010, 0.1854, 0.0515, 0.1033, 0.0792, 0.0380, 0.0747, 0.0440, 0.0651,
        0.0315, 0.0909, 0.0678, 0.0950, 0.0726], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,096][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0020, 0.3478, 0.0460, 0.2158, 0.1086, 0.1141, 0.0136, 0.0155, 0.0171,
        0.0095, 0.0275, 0.0176, 0.0384, 0.0263], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,097][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0557, 0.2223, 0.0621, 0.1664, 0.2329, 0.0465, 0.0107, 0.0091, 0.0369,
        0.0111, 0.0810, 0.0242, 0.0210, 0.0203], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,098][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0032, 0.1662, 0.0109, 0.2056, 0.2190, 0.0068, 0.0277, 0.0325, 0.0841,
        0.0008, 0.1564, 0.0159, 0.0341, 0.0368], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,099][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0008, 0.1089, 0.0123, 0.2210, 0.4246, 0.0041, 0.0136, 0.0089, 0.0533,
        0.0006, 0.0533, 0.0152, 0.0552, 0.0284], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,100][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([8.1546e-03, 1.3103e-02, 1.7718e-03, 3.1760e-02, 7.5514e-03, 1.0629e-03,
        5.9888e-04, 1.4823e-02, 8.4206e-01, 4.2144e-04, 1.7187e-02, 3.8388e-03,
        3.4130e-02, 2.0363e-02, 3.1749e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,101][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0003, 0.0111, 0.0026, 0.0212, 0.0211, 0.0416, 0.0835, 0.0819, 0.1072,
        0.0400, 0.1897, 0.0768, 0.1309, 0.0792, 0.1129], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,103][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0828, 0.0694, 0.0450, 0.0772, 0.1431, 0.0361, 0.0863, 0.0056, 0.0184,
        0.0608, 0.0617, 0.1391, 0.0296, 0.0142, 0.1308], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,105][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0070, 0.0492, 0.0263, 0.0549, 0.4182, 0.0055, 0.0380, 0.0167, 0.0293,
        0.0025, 0.0629, 0.0673, 0.0764, 0.0384, 0.1074], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,107][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0017, 0.1683, 0.0078, 0.4819, 0.1042, 0.0162, 0.0013, 0.0382, 0.0514,
        0.0016, 0.0594, 0.0110, 0.0054, 0.0474, 0.0042], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,108][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.6496, 0.0302, 0.0235, 0.0211, 0.0145, 0.1340, 0.0076, 0.0231, 0.0187,
        0.0064, 0.0174, 0.0064, 0.0138, 0.0142, 0.0195], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,110][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0021, 0.0488, 0.0568, 0.0579, 0.0582, 0.0989, 0.0763, 0.0909, 0.0761,
        0.0743, 0.1021, 0.0653, 0.0677, 0.0661, 0.0585], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,112][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0011, 0.1655, 0.0436, 0.1063, 0.0684, 0.0330, 0.0627, 0.0475, 0.0651,
        0.0270, 0.1025, 0.0571, 0.0773, 0.0798, 0.0631], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,114][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0019, 0.4024, 0.0560, 0.1862, 0.0897, 0.1168, 0.0099, 0.0115, 0.0125,
        0.0091, 0.0208, 0.0129, 0.0272, 0.0197, 0.0235], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,115][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0558, 0.2365, 0.0596, 0.1686, 0.2573, 0.0361, 0.0094, 0.0068, 0.0283,
        0.0092, 0.0645, 0.0187, 0.0135, 0.0128, 0.0228], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,117][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0019, 0.1684, 0.0099, 0.1958, 0.2204, 0.0059, 0.0146, 0.0236, 0.0714,
        0.0007, 0.1490, 0.0122, 0.0228, 0.0371, 0.0664], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,119][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0010, 0.1261, 0.0079, 0.2385, 0.3999, 0.0032, 0.0083, 0.0080, 0.0368,
        0.0004, 0.0602, 0.0125, 0.0461, 0.0260, 0.0251], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,120][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([8.9559e-03, 6.4032e-03, 1.0560e-03, 2.3088e-02, 2.5811e-03, 6.2178e-04,
        3.2558e-04, 9.5804e-03, 6.5732e-01, 2.7053e-04, 9.2906e-03, 1.7333e-03,
        1.6284e-02, 1.5784e-02, 1.2757e-03, 2.4543e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,121][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.0408e-04, 6.9312e-03, 1.7900e-03, 1.6930e-02, 2.0664e-02, 3.1902e-02,
        7.9330e-02, 7.5618e-02, 8.7132e-02, 3.2028e-02, 2.0364e-01, 8.5225e-02,
        1.2354e-01, 6.0785e-02, 9.1271e-02, 8.3115e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,123][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1000, 0.0629, 0.0578, 0.0582, 0.1592, 0.0223, 0.0681, 0.0080, 0.0217,
        0.0971, 0.0545, 0.1856, 0.0249, 0.0117, 0.0515, 0.0164],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,125][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0116, 0.0491, 0.0500, 0.0378, 0.3725, 0.0075, 0.0534, 0.0200, 0.0438,
        0.0045, 0.0600, 0.0728, 0.0582, 0.0384, 0.0922, 0.0281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,127][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0010, 0.1709, 0.0132, 0.4719, 0.1522, 0.0234, 0.0056, 0.0226, 0.0261,
        0.0021, 0.0212, 0.0130, 0.0180, 0.0230, 0.0219, 0.0139],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,128][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7467, 0.0224, 0.0246, 0.0163, 0.0093, 0.1014, 0.0041, 0.0142, 0.0105,
        0.0042, 0.0105, 0.0042, 0.0065, 0.0070, 0.0100, 0.0080],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,130][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0023, 0.0414, 0.0518, 0.0506, 0.0489, 0.0965, 0.0703, 0.0915, 0.0695,
        0.0737, 0.0932, 0.0559, 0.0608, 0.0711, 0.0581, 0.0645],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,132][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0017, 0.1720, 0.0469, 0.1000, 0.0673, 0.0327, 0.0633, 0.0403, 0.0508,
        0.0257, 0.0778, 0.0565, 0.0762, 0.0683, 0.0654, 0.0549],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,134][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0028, 0.3841, 0.0504, 0.1817, 0.0913, 0.1038, 0.0103, 0.0121, 0.0130,
        0.0089, 0.0227, 0.0150, 0.0305, 0.0211, 0.0242, 0.0282],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,135][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1102, 0.1766, 0.0856, 0.1255, 0.2259, 0.0570, 0.0100, 0.0085, 0.0296,
        0.0130, 0.0577, 0.0238, 0.0153, 0.0146, 0.0249, 0.0216],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,137][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0044, 0.1589, 0.0136, 0.1915, 0.1809, 0.0079, 0.0175, 0.0271, 0.0799,
        0.0011, 0.1382, 0.0142, 0.0238, 0.0348, 0.0464, 0.0598],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,139][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0019, 0.1392, 0.0147, 0.2402, 0.2866, 0.0056, 0.0093, 0.0085, 0.0569,
        0.0009, 0.0686, 0.0118, 0.0522, 0.0363, 0.0238, 0.0436],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,140][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([2.0574e-02, 1.2159e-02, 3.0731e-03, 2.7985e-02, 8.7423e-03, 1.9333e-03,
        6.3473e-04, 1.3930e-02, 5.9662e-01, 9.1603e-04, 1.3854e-02, 6.1844e-03,
        2.0448e-02, 1.3424e-02, 1.7510e-03, 2.5761e-01, 1.5705e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,141][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0003, 0.0064, 0.0015, 0.0168, 0.0140, 0.0407, 0.0678, 0.0775, 0.1006,
        0.0273, 0.1465, 0.0645, 0.1303, 0.0730, 0.0969, 0.0982, 0.0378],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,142][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.1058, 0.0798, 0.0568, 0.0605, 0.1003, 0.0441, 0.0625, 0.0065, 0.0263,
        0.0683, 0.0497, 0.0994, 0.0473, 0.0183, 0.0572, 0.0155, 0.1017],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,143][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0309, 0.0749, 0.0514, 0.0758, 0.2664, 0.0134, 0.0543, 0.0245, 0.0383,
        0.0089, 0.0552, 0.0611, 0.0255, 0.0463, 0.0921, 0.0361, 0.0449],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,144][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0036, 0.1520, 0.0113, 0.2081, 0.3658, 0.0175, 0.0022, 0.0208, 0.0597,
        0.0010, 0.0159, 0.0291, 0.0045, 0.0135, 0.0119, 0.0763, 0.0070],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,146][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.6388, 0.0345, 0.0191, 0.0203, 0.0117, 0.1199, 0.0091, 0.0265, 0.0189,
        0.0081, 0.0164, 0.0070, 0.0137, 0.0123, 0.0221, 0.0174, 0.0042],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,148][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0024, 0.0363, 0.0456, 0.0445, 0.0437, 0.0860, 0.0645, 0.0928, 0.0683,
        0.0704, 0.0931, 0.0524, 0.0491, 0.0614, 0.0515, 0.0705, 0.0675],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,149][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0006, 0.1376, 0.0402, 0.0920, 0.0651, 0.0315, 0.0585, 0.0387, 0.0509,
        0.0281, 0.0852, 0.0599, 0.0734, 0.0707, 0.0594, 0.0612, 0.0470],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,151][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0024, 0.4359, 0.0490, 0.1688, 0.0719, 0.0914, 0.0083, 0.0090, 0.0095,
        0.0075, 0.0175, 0.0114, 0.0229, 0.0172, 0.0177, 0.0214, 0.0383],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,152][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.2111, 0.1402, 0.1060, 0.0546, 0.1083, 0.0545, 0.0116, 0.0116, 0.0379,
        0.0250, 0.0481, 0.0252, 0.0164, 0.0144, 0.0297, 0.0224, 0.0830],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,154][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0069, 0.1209, 0.0159, 0.1502, 0.1364, 0.0116, 0.0231, 0.0349, 0.0928,
        0.0021, 0.1249, 0.0149, 0.0212, 0.0436, 0.0646, 0.0690, 0.0671],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,156][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0245, 0.0914, 0.0354, 0.1879, 0.1611, 0.0209, 0.0132, 0.0155, 0.0713,
        0.0047, 0.0830, 0.0187, 0.0793, 0.0773, 0.0323, 0.0595, 0.0238],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,157][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.8341e-03, 4.4087e-03, 8.4637e-04, 1.8085e-02, 2.7962e-03, 5.0402e-04,
        3.2474e-04, 8.1417e-03, 7.2161e-01, 2.2302e-04, 8.6756e-03, 2.0714e-03,
        1.8684e-02, 1.5586e-02, 1.2236e-03, 1.7930e-01, 6.4863e-05, 9.6265e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,159][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8512e-05, 3.8748e-03, 8.4886e-04, 1.0530e-02, 1.5174e-02, 2.4298e-02,
        6.7812e-02, 5.9567e-02, 7.3324e-02, 2.4304e-02, 2.0933e-01, 7.5810e-02,
        1.1137e-01, 5.1904e-02, 7.8657e-02, 8.4688e-02, 3.5667e-02, 7.2813e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,161][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0707, 0.0325, 0.0647, 0.0512, 0.1398, 0.0180, 0.0893, 0.0058, 0.0195,
        0.0682, 0.0329, 0.1731, 0.0186, 0.0102, 0.0466, 0.0150, 0.1342, 0.0093],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,162][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0085, 0.0377, 0.0292, 0.0300, 0.2667, 0.0044, 0.0745, 0.0327, 0.0498,
        0.0028, 0.0724, 0.0658, 0.0858, 0.0405, 0.0978, 0.0320, 0.0413, 0.0281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,164][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.4918e-04, 9.3186e-02, 2.8776e-03, 1.0926e-01, 6.1137e-01, 4.4292e-03,
        1.4623e-03, 2.6612e-02, 3.0215e-02, 1.8693e-04, 1.6935e-02, 3.9287e-02,
        1.2469e-02, 4.8609e-03, 7.4598e-03, 2.5580e-02, 8.1186e-03, 5.4388e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,165][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6729, 0.0365, 0.0345, 0.0259, 0.0137, 0.1022, 0.0056, 0.0190, 0.0137,
        0.0055, 0.0142, 0.0064, 0.0076, 0.0091, 0.0115, 0.0107, 0.0034, 0.0076],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,167][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0012, 0.0326, 0.0463, 0.0416, 0.0537, 0.0910, 0.0677, 0.0713, 0.0640,
        0.0717, 0.0750, 0.0590, 0.0542, 0.0530, 0.0454, 0.0595, 0.0659, 0.0470],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,169][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0006, 0.1557, 0.0444, 0.0829, 0.0668, 0.0295, 0.0611, 0.0331, 0.0478,
        0.0240, 0.0664, 0.0560, 0.0730, 0.0551, 0.0549, 0.0527, 0.0473, 0.0486],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,171][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0018, 0.3158, 0.0434, 0.1784, 0.0936, 0.0955, 0.0105, 0.0114, 0.0126,
        0.0078, 0.0218, 0.0150, 0.0309, 0.0207, 0.0246, 0.0294, 0.0488, 0.0379],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,173][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1720, 0.1656, 0.0919, 0.0907, 0.1614, 0.0571, 0.0092, 0.0064, 0.0259,
        0.0165, 0.0527, 0.0193, 0.0142, 0.0116, 0.0216, 0.0173, 0.0556, 0.0109],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,175][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0063, 0.1415, 0.0140, 0.1605, 0.1771, 0.0080, 0.0204, 0.0264, 0.0727,
        0.0009, 0.1377, 0.0173, 0.0238, 0.0285, 0.0375, 0.0513, 0.0440, 0.0321],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,176][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0024, 0.1216, 0.0187, 0.1722, 0.3411, 0.0060, 0.0109, 0.0086, 0.0592,
        0.0009, 0.0563, 0.0144, 0.0414, 0.0277, 0.0258, 0.0362, 0.0292, 0.0275],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,265][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:07,266][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,267][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,268][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,268][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,269][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,270][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,270][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,271][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,272][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,272][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,273][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,274][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,274][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6234, 0.3766], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,275][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.5740e-04, 9.9974e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,276][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8324, 0.1676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,277][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2833, 0.7167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,279][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0251, 0.9749], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,281][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8685, 0.1315], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,282][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0054, 0.9946], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,284][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7581, 0.2419], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,285][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2644, 0.7356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,287][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3515, 0.6485], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,287][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1026, 0.8974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,288][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0416, 0.9584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,289][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.5343, 0.3018, 0.1639], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,289][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([1.9657e-04, 9.8092e-01, 1.8886e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,291][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.4712, 0.2446, 0.2841], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,293][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.1282, 0.4935, 0.3783], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,294][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.0513, 0.7897, 0.1590], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,296][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.3554, 0.3979, 0.2468], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,297][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.0267, 0.8813, 0.0920], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,299][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.1430, 0.6660, 0.1911], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,301][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.5103, 0.2019, 0.2878], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,302][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.2044, 0.5446, 0.2510], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,304][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.1050, 0.6899, 0.2051], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,305][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.1344, 0.6115, 0.2541], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,307][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2158, 0.1226, 0.0328, 0.6288], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,308][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4270e-06, 4.1500e-01, 1.0040e-03, 5.8399e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,310][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6244, 0.1687, 0.1475, 0.0595], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,311][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0786, 0.1867, 0.2232, 0.5115], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,313][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0054, 0.5515, 0.0171, 0.4260], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,314][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5102, 0.2199, 0.1341, 0.1358], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,315][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([6.3565e-05, 3.8838e-01, 2.8206e-03, 6.0874e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,317][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2033, 0.5319, 0.1042, 0.1606], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,319][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1114, 0.4497, 0.1634, 0.2755], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,320][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2217, 0.3700, 0.1310, 0.2773], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,322][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0308, 0.4293, 0.0401, 0.4999], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,324][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0228, 0.2954, 0.0939, 0.5879], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,325][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.2271, 0.1617, 0.0337, 0.4836, 0.0939], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,326][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([5.5345e-05, 5.0801e-01, 2.0823e-03, 3.0531e-01, 1.8453e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,328][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.4227, 0.1855, 0.1134, 0.0866, 0.1918], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,329][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0651, 0.1405, 0.1058, 0.1864, 0.5022], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,330][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0111, 0.5765, 0.0323, 0.2200, 0.1601], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,331][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.4487, 0.2651, 0.0916, 0.1537, 0.0410], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,331][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0007, 0.2878, 0.0042, 0.4554, 0.2520], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,332][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0448, 0.6606, 0.0652, 0.1774, 0.0520], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,334][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.1862, 0.2952, 0.1163, 0.1739, 0.2285], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,335][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0497, 0.3479, 0.0561, 0.2025, 0.3437], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,337][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0203, 0.3168, 0.0346, 0.3191, 0.3092], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,339][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0212, 0.1881, 0.0469, 0.4646, 0.2792], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,340][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.2370, 0.1027, 0.0569, 0.4488, 0.1052, 0.0495], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,341][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([6.6158e-05, 3.2730e-01, 3.7916e-03, 3.7483e-01, 2.8802e-01, 5.9854e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,343][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.2179, 0.1966, 0.1455, 0.1257, 0.1701, 0.1441], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,345][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0378, 0.1871, 0.1093, 0.2350, 0.3758, 0.0550], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,346][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0098, 0.2314, 0.0301, 0.4298, 0.2537, 0.0452], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,348][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1349, 0.1775, 0.1215, 0.2574, 0.1919, 0.1169], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,350][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0046, 0.3923, 0.0267, 0.2972, 0.2557, 0.0235], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,351][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0914, 0.2376, 0.1098, 0.2472, 0.1853, 0.1288], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,353][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0966, 0.1832, 0.1150, 0.2200, 0.3225, 0.0628], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,354][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0694, 0.2485, 0.0857, 0.2655, 0.2389, 0.0920], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,356][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0307, 0.2662, 0.0599, 0.3370, 0.2352, 0.0709], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,358][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0185, 0.1731, 0.0481, 0.4238, 0.2868, 0.0496], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,359][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0955, 0.1806, 0.0267, 0.4599, 0.1792, 0.0225, 0.0357],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,361][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([1.0276e-05, 2.5476e-01, 8.3816e-04, 4.8555e-01, 1.4212e-01, 8.6476e-04,
        1.1586e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,362][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.3881, 0.2019, 0.0786, 0.0585, 0.0739, 0.1237, 0.0753],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,364][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0024, 0.1861, 0.0224, 0.2133, 0.4172, 0.0069, 0.1517],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,365][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0005, 0.2716, 0.0050, 0.4173, 0.2927, 0.0070, 0.0061],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,367][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0120, 0.2868, 0.0239, 0.4761, 0.1639, 0.0252, 0.0122],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,368][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([3.7580e-04, 1.6685e-01, 2.3676e-03, 4.4834e-01, 1.5283e-01, 2.4347e-03,
        2.2679e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,370][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0007, 0.3211, 0.0091, 0.5149, 0.1358, 0.0164, 0.0021],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,371][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0028, 0.1863, 0.0152, 0.4288, 0.3438, 0.0062, 0.0169],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,372][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0263, 0.3482, 0.0353, 0.2832, 0.2341, 0.0376, 0.0353],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,373][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0019, 0.2963, 0.0098, 0.3535, 0.2554, 0.0113, 0.0718],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,374][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([3.2636e-04, 1.2808e-01, 4.0540e-03, 4.9633e-01, 3.4770e-01, 3.2191e-03,
        2.0293e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,374][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0676, 0.1018, 0.0138, 0.4718, 0.0723, 0.0097, 0.0096, 0.2535],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,376][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([2.1681e-05, 1.6675e-01, 8.2870e-04, 3.0937e-01, 2.3980e-01, 1.0693e-03,
        1.6195e-01, 1.2021e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,377][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2154, 0.2211, 0.0774, 0.1180, 0.1463, 0.1238, 0.0750, 0.0232],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,379][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0036, 0.1225, 0.0274, 0.1325, 0.4809, 0.0058, 0.1847, 0.0426],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,381][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0007, 0.4782, 0.0042, 0.3448, 0.1634, 0.0038, 0.0015, 0.0033],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,382][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0388, 0.3419, 0.0370, 0.3896, 0.1604, 0.0196, 0.0070, 0.0057],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,383][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.8300e-04, 1.4893e-01, 1.9481e-03, 3.1125e-01, 1.6034e-01, 2.8583e-03,
        2.1928e-01, 1.5522e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,384][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.4186e-02, 5.7785e-01, 2.8382e-02, 2.8655e-01, 7.6211e-02, 1.5172e-02,
        1.0761e-03, 5.7497e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,386][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0007, 0.1789, 0.0057, 0.2902, 0.5086, 0.0021, 0.0078, 0.0061],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,388][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0644, 0.3321, 0.0553, 0.2503, 0.2008, 0.0592, 0.0198, 0.0181],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,389][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0041, 0.2946, 0.0133, 0.3144, 0.2576, 0.0118, 0.0497, 0.0545],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,391][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([3.9188e-04, 1.2078e-01, 5.8772e-03, 3.5362e-01, 4.8082e-01, 2.7883e-03,
        1.8587e-02, 1.7130e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,392][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([7.1920e-03, 6.4458e-03, 1.1793e-03, 2.8693e-02, 4.0892e-03, 7.1436e-04,
        5.9980e-04, 1.4650e-02, 9.3644e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,393][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([8.7572e-06, 1.8600e-01, 6.5972e-04, 3.9968e-01, 2.1175e-01, 7.4919e-04,
        6.0732e-02, 6.7797e-02, 7.2629e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,394][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3319, 0.1692, 0.0796, 0.0898, 0.1028, 0.1210, 0.0600, 0.0196, 0.0260],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,396][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0100, 0.0967, 0.0675, 0.0787, 0.5198, 0.0095, 0.1108, 0.0358, 0.0712],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,398][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0024, 0.4707, 0.0080, 0.3389, 0.1599, 0.0058, 0.0019, 0.0034, 0.0090],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,399][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1521, 0.3014, 0.0761, 0.2696, 0.1404, 0.0365, 0.0064, 0.0059, 0.0117],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,401][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0010, 0.1722, 0.0036, 0.3073, 0.1429, 0.0041, 0.1911, 0.0941, 0.0836],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,402][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([7.1740e-02, 5.1193e-01, 8.6257e-02, 2.0341e-01, 8.6521e-02, 3.3732e-02,
        8.3346e-04, 3.6622e-04, 5.2077e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,404][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0056, 0.2341, 0.0176, 0.2251, 0.4873, 0.0048, 0.0075, 0.0049, 0.0131],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,406][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0699, 0.2923, 0.0604, 0.1931, 0.2698, 0.0542, 0.0153, 0.0118, 0.0332],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,407][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0075, 0.2478, 0.0195, 0.2704, 0.2205, 0.0131, 0.0502, 0.0489, 0.1222],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,409][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0008, 0.2005, 0.0096, 0.3471, 0.3559, 0.0040, 0.0128, 0.0122, 0.0570],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,411][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0196, 0.0158, 0.0063, 0.0645, 0.0147, 0.0060, 0.0042, 0.0528, 0.8117,
        0.0045], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,412][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([4.2263e-05, 1.5612e-01, 2.3509e-03, 1.8998e-01, 1.7108e-01, 4.1455e-03,
        1.0403e-01, 1.9257e-01, 1.7709e-01, 2.5981e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,413][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.1460, 0.1608, 0.0921, 0.0877, 0.1184, 0.1036, 0.0975, 0.0555, 0.0455,
        0.0928], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,414][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0101, 0.1224, 0.0338, 0.1769, 0.1928, 0.0272, 0.1637, 0.1239, 0.1272,
        0.0222], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,415][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0008, 0.1211, 0.0061, 0.3433, 0.2442, 0.0123, 0.0864, 0.0741, 0.1082,
        0.0035], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,416][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0135, 0.1586, 0.0301, 0.2722, 0.1772, 0.0383, 0.0878, 0.1050, 0.1021,
        0.0152], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,417][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([0.0041, 0.2751, 0.0209, 0.2320, 0.1731, 0.0206, 0.0779, 0.0838, 0.0996,
        0.0128], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,418][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0009, 0.1397, 0.0088, 0.3399, 0.2097, 0.0132, 0.0548, 0.0617, 0.1682,
        0.0031], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,420][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0658, 0.1462, 0.0798, 0.2034, 0.1959, 0.0572, 0.0713, 0.0613, 0.0916,
        0.0275], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,422][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([0.0338, 0.1907, 0.0524, 0.1897, 0.1745, 0.0587, 0.0854, 0.0783, 0.1043,
        0.0321], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,423][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([0.0102, 0.1563, 0.0302, 0.2259, 0.1599, 0.0369, 0.0852, 0.1191, 0.1592,
        0.0172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,425][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0073, 0.1056, 0.0194, 0.2587, 0.1537, 0.0282, 0.0976, 0.1080, 0.2069,
        0.0146], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,426][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([8.8351e-03, 9.1841e-03, 2.1440e-03, 3.7087e-02, 6.3563e-03, 1.2237e-03,
        1.1906e-03, 1.9419e-02, 8.9725e-01, 5.2355e-04, 1.6791e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,428][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.0485e-06, 1.0093e-01, 3.3837e-04, 2.6261e-01, 1.4432e-01, 4.6304e-04,
        8.5603e-02, 1.2428e-01, 1.0889e-01, 1.8278e-04, 1.7238e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,429][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2672, 0.1413, 0.0615, 0.0874, 0.1072, 0.0989, 0.0680, 0.0189, 0.0227,
        0.0689, 0.0580], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,431][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0034, 0.0684, 0.0353, 0.0883, 0.4290, 0.0059, 0.1077, 0.0464, 0.0864,
        0.0030, 0.1264], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,432][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([3.1424e-03, 5.9337e-01, 8.7126e-03, 2.4131e-01, 1.0821e-01, 7.2266e-03,
        8.8466e-04, 2.2881e-03, 6.1038e-03, 3.4044e-04, 2.8421e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,434][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1117, 0.3177, 0.0727, 0.2566, 0.1549, 0.0321, 0.0044, 0.0032, 0.0098,
        0.0045, 0.0323], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,435][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.0342e-04, 1.2436e-01, 1.9053e-03, 2.2279e-01, 1.9045e-01, 2.0652e-03,
        1.7621e-01, 1.0021e-01, 8.9858e-02, 8.6892e-04, 9.1174e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,436][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([7.2050e-02, 5.1663e-01, 8.5139e-02, 1.7261e-01, 1.0349e-01, 3.3357e-02,
        4.8284e-04, 2.0700e-04, 5.4451e-03, 1.0264e-03, 9.5630e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,438][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0057, 0.1713, 0.0233, 0.1660, 0.5830, 0.0057, 0.0057, 0.0039, 0.0119,
        0.0006, 0.0230], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,440][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0398, 0.2534, 0.0559, 0.1716, 0.2952, 0.0413, 0.0144, 0.0116, 0.0336,
        0.0094, 0.0737], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,441][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0034, 0.2117, 0.0122, 0.2617, 0.2104, 0.0085, 0.0305, 0.0378, 0.0800,
        0.0010, 0.1430], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,443][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0011, 0.1188, 0.0142, 0.2452, 0.4823, 0.0045, 0.0144, 0.0090, 0.0544,
        0.0007, 0.0554], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,445][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0138, 0.0141, 0.0025, 0.0447, 0.0094, 0.0022, 0.0015, 0.0229, 0.8641,
        0.0014, 0.0181, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,446][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([2.3443e-05, 2.0011e-01, 1.1414e-03, 2.2260e-01, 1.2219e-01, 1.6064e-03,
        4.5531e-02, 9.4659e-02, 1.3802e-01, 8.4378e-04, 1.3028e-01, 4.3007e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,448][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.2077, 0.1687, 0.0468, 0.0814, 0.1119, 0.0718, 0.0879, 0.0165, 0.0164,
        0.0630, 0.0435, 0.0843], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,450][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0036, 0.0799, 0.0193, 0.1265, 0.3502, 0.0063, 0.1099, 0.0538, 0.0788,
        0.0029, 0.1085, 0.0602], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,451][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([1.3015e-04, 4.7377e-01, 2.0304e-03, 2.1754e-01, 1.9553e-01, 2.0956e-03,
        7.6715e-03, 9.7046e-03, 1.9907e-02, 1.3961e-04, 6.6416e-02, 5.0540e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,452][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0100, 0.4202, 0.0138, 0.3179, 0.1285, 0.0105, 0.0135, 0.0058, 0.0137,
        0.0016, 0.0620, 0.0023], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,454][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0006, 0.1477, 0.0038, 0.2422, 0.1427, 0.0048, 0.1258, 0.0798, 0.1016,
        0.0019, 0.1028, 0.0464], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,456][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([5.0361e-04, 5.9303e-01, 5.1926e-03, 2.5065e-01, 1.0157e-01, 3.8142e-03,
        2.2681e-03, 1.1520e-03, 1.4911e-02, 1.6564e-04, 2.6560e-02, 1.8237e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,457][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0282, 0.2077, 0.0525, 0.2310, 0.3728, 0.0149, 0.0064, 0.0053, 0.0186,
        0.0025, 0.0309, 0.0292], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,459][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0153, 0.2689, 0.0315, 0.1394, 0.3348, 0.0240, 0.0231, 0.0110, 0.0352,
        0.0082, 0.0724, 0.0362], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,461][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0019, 0.1481, 0.0090, 0.2197, 0.2842, 0.0078, 0.0405, 0.0389, 0.0834,
        0.0012, 0.1344, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,462][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0021, 0.1282, 0.0109, 0.3302, 0.3294, 0.0066, 0.0285, 0.0179, 0.0584,
        0.0016, 0.0648, 0.0215], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,462][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([4.8803e-03, 1.1559e-02, 1.2420e-03, 3.5079e-02, 8.0080e-03, 1.0150e-03,
        5.4972e-04, 1.9960e-02, 8.6498e-01, 3.4841e-04, 1.9853e-02, 5.0623e-03,
        2.7461e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,463][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([4.5430e-06, 1.3913e-01, 4.7029e-04, 1.9287e-01, 8.0764e-02, 4.2277e-04,
        9.8376e-02, 7.1884e-02, 1.0167e-01, 2.5048e-04, 1.5112e-01, 1.7957e-02,
        1.4508e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,465][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.3236, 0.1608, 0.0772, 0.0790, 0.0680, 0.0880, 0.0426, 0.0114, 0.0191,
        0.0598, 0.0320, 0.0332, 0.0052], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,466][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0073, 0.1027, 0.0325, 0.0647, 0.4206, 0.0067, 0.0792, 0.0312, 0.0662,
        0.0037, 0.0704, 0.0510, 0.0639], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,467][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([3.8448e-04, 4.0535e-01, 3.6678e-03, 4.0214e-01, 1.2421e-01, 3.3393e-03,
        9.9254e-04, 1.7635e-03, 9.4409e-03, 8.3101e-05, 4.1499e-02, 6.4024e-04,
        6.4909e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,469][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0081, 0.3869, 0.0223, 0.3286, 0.1659, 0.0112, 0.0023, 0.0035, 0.0112,
        0.0008, 0.0527, 0.0011, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,471][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0003, 0.1157, 0.0019, 0.2442, 0.2408, 0.0020, 0.1167, 0.0748, 0.0949,
        0.0011, 0.0690, 0.0170, 0.0216], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,472][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([1.8015e-04, 5.7100e-01, 4.5376e-03, 2.4637e-01, 1.4738e-01, 2.6842e-03,
        2.3245e-04, 2.8244e-04, 8.5124e-03, 3.3237e-05, 1.5712e-02, 6.4019e-05,
        3.0172e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,473][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0190, 0.1795, 0.0408, 0.2049, 0.4588, 0.0105, 0.0038, 0.0048, 0.0171,
        0.0012, 0.0241, 0.0152, 0.0204], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,475][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0469, 0.2017, 0.0537, 0.1769, 0.2715, 0.0360, 0.0180, 0.0154, 0.0475,
        0.0105, 0.0765, 0.0233, 0.0221], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,477][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0023, 0.1797, 0.0110, 0.1902, 0.2361, 0.0078, 0.0250, 0.0304, 0.0913,
        0.0012, 0.1695, 0.0132, 0.0424], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,479][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0020, 0.1482, 0.0113, 0.2483, 0.3641, 0.0049, 0.0085, 0.0107, 0.0496,
        0.0009, 0.0825, 0.0134, 0.0557], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,480][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.6444e-03, 6.8456e-03, 9.0130e-04, 2.8931e-02, 4.1295e-03, 6.2571e-04,
        5.1832e-04, 1.1987e-02, 8.7236e-01, 2.5214e-04, 1.3885e-02, 2.7834e-03,
        2.9660e-02, 2.1480e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,481][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.3467e-05, 6.8343e-02, 1.4166e-03, 1.8771e-01, 7.6743e-02, 1.4387e-03,
        8.7602e-02, 8.8094e-02, 9.7579e-02, 7.6171e-04, 1.5345e-01, 2.3558e-02,
        1.4029e-01, 7.2973e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,483][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3040, 0.0800, 0.0739, 0.0604, 0.0943, 0.0981, 0.0616, 0.0169, 0.0242,
        0.0651, 0.0324, 0.0738, 0.0067, 0.0086], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,485][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0034, 0.0391, 0.0206, 0.0365, 0.3698, 0.0035, 0.0938, 0.0396, 0.0570,
        0.0020, 0.0777, 0.0741, 0.1318, 0.0511], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,486][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.5886e-04, 5.6220e-01, 2.2895e-03, 3.0046e-01, 8.0274e-02, 2.1489e-03,
        3.2896e-04, 1.9369e-03, 6.8807e-03, 6.3180e-05, 3.7102e-02, 1.0155e-03,
        3.2845e-03, 1.5548e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,488][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0365, 0.3214, 0.0409, 0.3058, 0.1978, 0.0160, 0.0022, 0.0029, 0.0080,
        0.0019, 0.0557, 0.0028, 0.0066, 0.0015], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,490][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0008, 0.0530, 0.0031, 0.1715, 0.1115, 0.0037, 0.1930, 0.1428, 0.1119,
        0.0021, 0.0649, 0.0356, 0.0424, 0.0638], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,491][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.9658e-02, 6.0932e-01, 3.4397e-02, 2.2252e-01, 7.4928e-02, 1.3743e-02,
        1.1005e-04, 2.3461e-04, 4.9420e-03, 2.3109e-04, 1.6531e-02, 1.0807e-04,
        2.1946e-03, 1.0894e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,492][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.6699e-03, 1.5150e-01, 2.0214e-02, 1.6465e-01, 5.6430e-01, 5.5750e-03,
        5.5381e-03, 4.3159e-03, 1.6557e-02, 5.2453e-04, 2.3798e-02, 1.5793e-02,
        1.8012e-02, 4.5598e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,494][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0557, 0.2223, 0.0621, 0.1664, 0.2329, 0.0465, 0.0107, 0.0091, 0.0369,
        0.0111, 0.0810, 0.0242, 0.0210, 0.0203], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,496][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0032, 0.1662, 0.0109, 0.2056, 0.2190, 0.0068, 0.0277, 0.0325, 0.0841,
        0.0008, 0.1564, 0.0159, 0.0341, 0.0368], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,497][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0008, 0.1089, 0.0123, 0.2210, 0.4246, 0.0041, 0.0136, 0.0089, 0.0533,
        0.0006, 0.0533, 0.0152, 0.0552, 0.0284], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,498][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([8.1546e-03, 1.3103e-02, 1.7718e-03, 3.1760e-02, 7.5514e-03, 1.0629e-03,
        5.9888e-04, 1.4823e-02, 8.4206e-01, 4.2144e-04, 1.7187e-02, 3.8388e-03,
        3.4130e-02, 2.0363e-02, 3.1749e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,500][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.1090e-04, 1.4708e-01, 1.7215e-03, 3.2446e-01, 5.0661e-02, 1.1328e-03,
        5.3979e-02, 6.9851e-02, 7.4337e-02, 1.1021e-03, 8.5963e-02, 1.5875e-02,
        8.3344e-02, 5.6887e-02, 3.3491e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,502][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.3275, 0.1089, 0.0863, 0.0735, 0.1199, 0.0819, 0.0336, 0.0097, 0.0123,
        0.0538, 0.0202, 0.0533, 0.0035, 0.0056, 0.0100], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,503][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0070, 0.0492, 0.0263, 0.0549, 0.4182, 0.0055, 0.0380, 0.0167, 0.0293,
        0.0025, 0.0629, 0.0673, 0.0764, 0.0384, 0.1074], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,504][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([4.5288e-04, 4.5559e-01, 4.2076e-03, 3.1652e-01, 1.4852e-01, 3.2694e-03,
        7.1364e-04, 1.8562e-03, 1.0708e-02, 9.7925e-05, 4.3806e-02, 8.9391e-04,
        8.0503e-03, 2.5177e-03, 2.7992e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,505][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0118, 0.3091, 0.0277, 0.3133, 0.2431, 0.0150, 0.0027, 0.0028, 0.0109,
        0.0009, 0.0439, 0.0016, 0.0094, 0.0024, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,506][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0040, 0.0978, 0.0052, 0.2130, 0.1524, 0.0044, 0.1349, 0.0976, 0.1001,
        0.0029, 0.0525, 0.0297, 0.0245, 0.0352, 0.0458], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,507][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([3.8048e-04, 5.0743e-01, 6.5801e-03, 2.8665e-01, 1.5850e-01, 2.9517e-03,
        1.9555e-04, 3.1488e-04, 8.3576e-03, 4.2371e-05, 2.1925e-02, 6.8352e-05,
        3.4488e-03, 2.3592e-03, 7.9245e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,508][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0320, 0.1438, 0.0579, 0.1709, 0.4851, 0.0116, 0.0050, 0.0029, 0.0110,
        0.0016, 0.0201, 0.0142, 0.0191, 0.0039, 0.0210], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,510][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0558, 0.2365, 0.0596, 0.1686, 0.2573, 0.0361, 0.0094, 0.0068, 0.0283,
        0.0092, 0.0645, 0.0187, 0.0135, 0.0128, 0.0228], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,512][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0019, 0.1684, 0.0099, 0.1958, 0.2204, 0.0059, 0.0146, 0.0236, 0.0714,
        0.0007, 0.1490, 0.0122, 0.0228, 0.0371, 0.0664], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,513][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0010, 0.1261, 0.0079, 0.2385, 0.3999, 0.0032, 0.0083, 0.0080, 0.0368,
        0.0004, 0.0602, 0.0125, 0.0461, 0.0260, 0.0251], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,515][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.9559e-03, 6.4032e-03, 1.0560e-03, 2.3088e-02, 2.5811e-03, 6.2178e-04,
        3.2558e-04, 9.5804e-03, 6.5732e-01, 2.7053e-04, 9.2906e-03, 1.7333e-03,
        1.6284e-02, 1.5784e-02, 1.2757e-03, 2.4543e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,516][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.4982e-05, 1.5952e-01, 1.4983e-03, 3.6520e-01, 7.6234e-02, 1.0006e-03,
        5.6177e-02, 5.2490e-02, 7.2634e-02, 8.6665e-04, 8.9603e-02, 1.7206e-02,
        4.5012e-02, 3.5426e-02, 1.6017e-02, 1.1074e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,518][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2609, 0.1154, 0.0715, 0.0872, 0.0985, 0.0914, 0.0417, 0.0137, 0.0228,
        0.0615, 0.0390, 0.0544, 0.0052, 0.0098, 0.0102, 0.0166],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,520][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0116, 0.0491, 0.0500, 0.0378, 0.3725, 0.0075, 0.0534, 0.0200, 0.0438,
        0.0045, 0.0600, 0.0728, 0.0582, 0.0384, 0.0922, 0.0281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,521][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.4536e-04, 5.0288e-01, 5.3024e-03, 2.7854e-01, 1.3661e-01, 3.5148e-03,
        7.2629e-04, 1.7914e-03, 7.4878e-03, 1.4160e-04, 4.6175e-02, 1.6192e-03,
        5.9420e-03, 2.7557e-03, 2.4960e-03, 3.0717e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,523][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0362, 0.2882, 0.0423, 0.3107, 0.1984, 0.0177, 0.0031, 0.0039, 0.0104,
        0.0019, 0.0625, 0.0033, 0.0083, 0.0023, 0.0081, 0.0027],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,524][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0020, 0.0983, 0.0051, 0.1706, 0.1454, 0.0046, 0.1203, 0.0985, 0.0829,
        0.0026, 0.0686, 0.0327, 0.0207, 0.0539, 0.0370, 0.0567],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,526][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.1799e-02, 5.4225e-01, 4.4827e-02, 2.3487e-01, 1.1281e-01, 1.2344e-02,
        3.1842e-04, 3.6562e-04, 8.1232e-03, 2.7430e-04, 2.1322e-02, 1.7536e-04,
        5.0838e-03, 2.2478e-03, 1.0265e-03, 2.1690e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,527][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0293, 0.1665, 0.0545, 0.1636, 0.4578, 0.0116, 0.0049, 0.0037, 0.0136,
        0.0015, 0.0267, 0.0178, 0.0137, 0.0041, 0.0139, 0.0170],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,529][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1102, 0.1766, 0.0856, 0.1255, 0.2259, 0.0570, 0.0100, 0.0085, 0.0296,
        0.0130, 0.0577, 0.0238, 0.0153, 0.0146, 0.0249, 0.0216],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,531][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0044, 0.1589, 0.0136, 0.1915, 0.1809, 0.0079, 0.0175, 0.0271, 0.0799,
        0.0011, 0.1382, 0.0142, 0.0238, 0.0348, 0.0464, 0.0598],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,533][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0019, 0.1392, 0.0147, 0.2402, 0.2866, 0.0056, 0.0093, 0.0085, 0.0569,
        0.0009, 0.0686, 0.0118, 0.0522, 0.0363, 0.0238, 0.0436],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,534][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([2.0574e-02, 1.2159e-02, 3.0731e-03, 2.7985e-02, 8.7423e-03, 1.9333e-03,
        6.3473e-04, 1.3930e-02, 5.9662e-01, 9.1603e-04, 1.3854e-02, 6.1844e-03,
        2.0448e-02, 1.3424e-02, 1.7510e-03, 2.5761e-01, 1.5705e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,536][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0005, 0.1840, 0.0030, 0.3185, 0.0634, 0.0026, 0.0377, 0.0438, 0.0912,
        0.0025, 0.0576, 0.0399, 0.0537, 0.0360, 0.0186, 0.0151, 0.0320],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,538][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.4170, 0.0952, 0.0709, 0.0373, 0.0606, 0.0779, 0.0327, 0.0105, 0.0114,
        0.0708, 0.0270, 0.0426, 0.0029, 0.0074, 0.0116, 0.0113, 0.0126],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,540][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0309, 0.0749, 0.0514, 0.0758, 0.2664, 0.0134, 0.0543, 0.0245, 0.0383,
        0.0089, 0.0552, 0.0611, 0.0255, 0.0463, 0.0921, 0.0361, 0.0449],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,541][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([1.6042e-03, 5.2882e-01, 7.8956e-03, 1.9051e-01, 2.0156e-01, 7.0989e-03,
        1.5102e-03, 2.5643e-03, 1.0319e-02, 2.5178e-04, 2.9097e-02, 2.5918e-03,
        3.8381e-03, 1.8222e-03, 2.3406e-03, 4.5586e-03, 3.6149e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,543][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0194, 0.3716, 0.0408, 0.3063, 0.1679, 0.0174, 0.0045, 0.0046, 0.0100,
        0.0014, 0.0270, 0.0018, 0.0039, 0.0030, 0.0040, 0.0030, 0.0135],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,544][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0067, 0.2138, 0.0100, 0.1547, 0.1586, 0.0107, 0.0674, 0.0541, 0.0748,
        0.0054, 0.0596, 0.0462, 0.0159, 0.0366, 0.0238, 0.0331, 0.0285],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,546][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([2.7831e-03, 5.1464e-01, 3.2349e-02, 1.5931e-01, 2.0055e-01, 1.1463e-02,
        1.5101e-03, 8.6720e-04, 2.2247e-02, 2.6838e-04, 2.1463e-02, 2.8858e-04,
        7.4166e-03, 3.0803e-03, 2.3131e-03, 5.3900e-03, 1.4059e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,547][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.2822, 0.2283, 0.1035, 0.1167, 0.1311, 0.0285, 0.0036, 0.0029, 0.0096,
        0.0041, 0.0170, 0.0141, 0.0137, 0.0034, 0.0081, 0.0109, 0.0224],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,548][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.2111, 0.1402, 0.1060, 0.0546, 0.1083, 0.0545, 0.0116, 0.0116, 0.0379,
        0.0250, 0.0481, 0.0252, 0.0164, 0.0144, 0.0297, 0.0224, 0.0830],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,548][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0069, 0.1209, 0.0159, 0.1502, 0.1364, 0.0116, 0.0231, 0.0349, 0.0928,
        0.0021, 0.1249, 0.0149, 0.0212, 0.0436, 0.0646, 0.0690, 0.0671],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,550][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0245, 0.0914, 0.0354, 0.1879, 0.1611, 0.0209, 0.0132, 0.0155, 0.0713,
        0.0047, 0.0830, 0.0187, 0.0793, 0.0773, 0.0323, 0.0595, 0.0238],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,552][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.8341e-03, 4.4087e-03, 8.4637e-04, 1.8085e-02, 2.7962e-03, 5.0402e-04,
        3.2474e-04, 8.1417e-03, 7.2161e-01, 2.2302e-04, 8.6756e-03, 2.0714e-03,
        1.8684e-02, 1.5586e-02, 1.2236e-03, 1.7930e-01, 6.4863e-05, 9.6265e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,553][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.4358e-04, 6.7676e-02, 2.6128e-03, 2.0418e-01, 7.1367e-02, 2.3857e-03,
        8.4936e-02, 6.7022e-02, 8.4954e-02, 1.4615e-03, 1.0790e-01, 2.1436e-02,
        8.9794e-02, 5.9692e-02, 4.4678e-02, 2.7566e-02, 1.9438e-02, 4.2748e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,555][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4584, 0.0495, 0.0565, 0.0347, 0.0617, 0.0828, 0.0407, 0.0107, 0.0164,
        0.0609, 0.0215, 0.0580, 0.0039, 0.0055, 0.0070, 0.0106, 0.0160, 0.0053],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,556][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0085, 0.0377, 0.0292, 0.0300, 0.2667, 0.0044, 0.0745, 0.0327, 0.0498,
        0.0028, 0.0724, 0.0658, 0.0858, 0.0405, 0.0978, 0.0320, 0.0413, 0.0281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,558][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.5280e-04, 5.7472e-01, 2.9320e-03, 2.7174e-01, 8.9640e-02, 2.5065e-03,
        3.7911e-04, 1.9987e-03, 6.2740e-03, 7.8724e-05, 3.5545e-02, 1.6673e-03,
        2.7215e-03, 1.6659e-03, 1.2356e-03, 2.1404e-03, 1.9708e-03, 2.0323e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,560][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0700, 0.2947, 0.0552, 0.2537, 0.1825, 0.0181, 0.0023, 0.0032, 0.0076,
        0.0025, 0.0444, 0.0035, 0.0050, 0.0013, 0.0048, 0.0021, 0.0476, 0.0013],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,561][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0018, 0.0420, 0.0040, 0.1293, 0.0713, 0.0053, 0.1739, 0.1013, 0.0840,
        0.0027, 0.0575, 0.0337, 0.0289, 0.0483, 0.0426, 0.0674, 0.0465, 0.0594],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,563][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.6443e-02, 5.9969e-01, 6.5197e-02, 1.5694e-01, 6.1656e-02, 1.8568e-02,
        9.9728e-05, 1.8852e-04, 3.9354e-03, 3.8383e-04, 1.2767e-02, 1.3078e-04,
        1.8691e-03, 7.8542e-04, 3.0044e-04, 8.3065e-04, 9.5818e-03, 6.3033e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,565][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0327, 0.1336, 0.0579, 0.1102, 0.4919, 0.0114, 0.0057, 0.0041, 0.0173,
        0.0013, 0.0218, 0.0205, 0.0150, 0.0039, 0.0123, 0.0196, 0.0348, 0.0059],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,566][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1720, 0.1656, 0.0919, 0.0907, 0.1614, 0.0571, 0.0092, 0.0064, 0.0259,
        0.0165, 0.0527, 0.0193, 0.0142, 0.0116, 0.0216, 0.0173, 0.0556, 0.0109],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,568][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0063, 0.1415, 0.0140, 0.1605, 0.1771, 0.0080, 0.0204, 0.0264, 0.0727,
        0.0009, 0.1377, 0.0173, 0.0238, 0.0285, 0.0375, 0.0513, 0.0440, 0.0321],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,570][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0024, 0.1216, 0.0187, 0.1722, 0.3411, 0.0060, 0.0109, 0.0086, 0.0592,
        0.0009, 0.0563, 0.0144, 0.0414, 0.0277, 0.0258, 0.0362, 0.0292, 0.0275],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:07,574][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:07,576][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7825],
        [3459],
        [2149],
        [2425],
        [ 942],
        [ 833],
        [5082],
        [ 612],
        [ 600],
        [1052],
        [ 314],
        [ 100],
        [ 538],
        [ 476],
        [ 793],
        [ 440],
        [ 279],
        [ 335]], device='cuda:0')
[2024-07-24 10:26:07,578][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[8736],
        [6076],
        [4338],
        [3918],
        [1533],
        [1327],
        [7136],
        [ 998],
        [1116],
        [2050],
        [ 528],
        [ 223],
        [ 913],
        [ 796],
        [1482],
        [ 876],
        [ 758],
        [ 658]], device='cuda:0')
[2024-07-24 10:26:07,579][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5855],
        [36513],
        [31722],
        [39445],
        [39161],
        [37323],
        [39941],
        [39024],
        [34173],
        [34611],
        [34429],
        [34577],
        [34525],
        [34516],
        [34734],
        [35821],
        [36011],
        [35454]], device='cuda:0')
[2024-07-24 10:26:07,581][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[10285],
        [ 5917],
        [ 6376],
        [ 4114],
        [ 5302],
        [ 4366],
        [ 4096],
        [ 3410],
        [ 2623],
        [ 2358],
        [ 2620],
        [ 2710],
        [ 2615],
        [ 2547],
        [ 2434],
        [ 2409],
        [ 2331],
        [ 2342]], device='cuda:0')
[2024-07-24 10:26:07,583][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[845],
        [921],
        [224],
        [206],
        [241],
        [273],
        [414],
        [219],
        [268],
        [335],
        [304],
        [279],
        [291],
        [277],
        [353],
        [286],
        [202],
        [146]], device='cuda:0')
[2024-07-24 10:26:07,585][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1218],
        [ 8007],
        [14357],
        [22809],
        [16023],
        [16716],
        [17584],
        [17919],
        [17386],
        [21059],
        [18646],
        [18063],
        [18124],
        [20577],
        [20363],
        [20461],
        [21661],
        [23312]], device='cuda:0')
[2024-07-24 10:26:07,587][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9786],
        [14970],
        [15222],
        [15729],
        [16234],
        [17282],
        [16696],
        [17560],
        [17585],
        [11155],
        [16359],
        [13898],
        [15507],
        [19348],
        [15513],
        [15404],
        [16639],
        [18964]], device='cuda:0')
[2024-07-24 10:26:07,589][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[2560],
        [2493],
        [1893],
        [2085],
        [2104],
        [1202],
        [ 856],
        [ 820],
        [ 941],
        [ 828],
        [ 999],
        [ 852],
        [ 827],
        [ 839],
        [ 825],
        [ 892],
        [ 795],
        [ 817]], device='cuda:0')
[2024-07-24 10:26:07,590][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28799],
        [22603],
        [13443],
        [14522],
        [12422],
        [15205],
        [16465],
        [18018],
        [16373],
        [17109],
        [16628],
        [15697],
        [15759],
        [15497],
        [15572],
        [15300],
        [15785],
        [15527]], device='cuda:0')
[2024-07-24 10:26:07,592][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[30791],
        [24771],
        [29135],
        [28071],
        [28537],
        [27887],
        [29270],
        [28690],
        [27913],
        [28236],
        [27629],
        [27265],
        [27874],
        [27677],
        [26609],
        [26423],
        [26200],
        [26209]], device='cuda:0')
[2024-07-24 10:26:07,594][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2784],
        [1081],
        [1787],
        [2151],
        [2564],
        [2392],
        [2274],
        [2243],
        [2282],
        [1953],
        [2273],
        [2271],
        [2172],
        [2302],
        [2147],
        [2157],
        [2085],
        [2331]], device='cuda:0')
[2024-07-24 10:26:07,596][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43786],
        [48456],
        [47863],
        [47214],
        [48601],
        [48219],
        [48353],
        [48325],
        [48517],
        [48331],
        [48562],
        [48803],
        [48545],
        [48513],
        [48554],
        [48540],
        [48711],
        [48667]], device='cuda:0')
[2024-07-24 10:26:07,598][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31484],
        [ 7607],
        [ 4077],
        [ 9550],
        [ 4476],
        [ 4933],
        [ 5403],
        [ 5126],
        [ 4996],
        [ 5209],
        [ 4539],
        [ 3687],
        [ 3732],
        [ 3748],
        [ 3216],
        [ 3298],
        [ 2672],
        [ 2877]], device='cuda:0')
[2024-07-24 10:26:07,599][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41893],
        [33042],
        [44999],
        [43089],
        [47892],
        [48125],
        [48089],
        [48879],
        [48182],
        [46487],
        [49068],
        [48380],
        [48578],
        [48926],
        [48658],
        [48110],
        [47408],
        [48461]], device='cuda:0')
[2024-07-24 10:26:07,601][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17569],
        [17226],
        [15786],
        [16870],
        [17626],
        [17881],
        [18029],
        [18615],
        [18376],
        [17726],
        [18620],
        [16376],
        [17722],
        [18500],
        [18322],
        [18241],
        [18722],
        [18686]], device='cuda:0')
[2024-07-24 10:26:07,603][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14424],
        [ 5698],
        [ 6317],
        [ 9944],
        [ 9132],
        [ 8683],
        [ 9342],
        [ 9170],
        [ 1702],
        [ 1857],
        [ 1725],
        [ 1763],
        [ 1729],
        [ 1692],
        [ 1717],
        [ 1211],
        [ 1196],
        [ 1306]], device='cuda:0')
[2024-07-24 10:26:07,605][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 4580],
        [ 5890],
        [ 5822],
        [21012],
        [12667],
        [14633],
        [18488],
        [13976],
        [16612],
        [13166],
        [16462],
        [14707],
        [14985],
        [16533],
        [18293],
        [18401],
        [16556],
        [16919]], device='cuda:0')
[2024-07-24 10:26:07,607][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18169],
        [31461],
        [39652],
        [38714],
        [42460],
        [43507],
        [40963],
        [42950],
        [41652],
        [42345],
        [42294],
        [43559],
        [42344],
        [42841],
        [42760],
        [43030],
        [41327],
        [40390]], device='cuda:0')
[2024-07-24 10:26:07,608][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24417],
        [21892],
        [23435],
        [24195],
        [13357],
        [15497],
        [15259],
        [14107],
        [13200],
        [17294],
        [14031],
        [14165],
        [13741],
        [14338],
        [14459],
        [14768],
        [15916],
        [16289]], device='cuda:0')
[2024-07-24 10:26:07,610][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 1482],
        [43046],
        [43644],
        [46625],
        [45971],
        [47358],
        [47153],
        [46586],
        [46621],
        [46978],
        [46108],
        [46492],
        [47050],
        [46370],
        [46801],
        [46594],
        [46318],
        [46334]], device='cuda:0')
[2024-07-24 10:26:07,612][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[46976],
        [49212],
        [47376],
        [48639],
        [48127],
        [46333],
        [45099],
        [45190],
        [46084],
        [45497],
        [45734],
        [44591],
        [44833],
        [45229],
        [45205],
        [45293],
        [45048],
        [45681]], device='cuda:0')
[2024-07-24 10:26:07,614][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10553],
        [17768],
        [17686],
        [19796],
        [15948],
        [15538],
        [15112],
        [14223],
        [15710],
        [16601],
        [14447],
        [15495],
        [13939],
        [13824],
        [14481],
        [14773],
        [15433],
        [14147]], device='cuda:0')
[2024-07-24 10:26:07,616][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1073],
        [10606],
        [40518],
        [42094],
        [43267],
        [41591],
        [44636],
        [43966],
        [42957],
        [43868],
        [42627],
        [43767],
        [43303],
        [43656],
        [43510],
        [43478],
        [42310],
        [43065]], device='cuda:0')
[2024-07-24 10:26:07,618][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36648],
        [19896],
        [18645],
        [19388],
        [20113],
        [21260],
        [22110],
        [22979],
        [22256],
        [17758],
        [23041],
        [21205],
        [21847],
        [22765],
        [21941],
        [21178],
        [18088],
        [20691]], device='cuda:0')
[2024-07-24 10:26:07,620][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14012],
        [29337],
        [25146],
        [23144],
        [23530],
        [21176],
        [22659],
        [22214],
        [21519],
        [17246],
        [20248],
        [20453],
        [18625],
        [18852],
        [19466],
        [17624],
        [16451],
        [17490]], device='cuda:0')
[2024-07-24 10:26:07,622][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44140],
        [ 4558],
        [ 5171],
        [ 6737],
        [ 5581],
        [ 5642],
        [ 6306],
        [ 6127],
        [ 6680],
        [ 8243],
        [ 7289],
        [ 7294],
        [ 7037],
        [ 7225],
        [ 7427],
        [ 8041],
        [ 9597],
        [ 8770]], device='cuda:0')
[2024-07-24 10:26:07,624][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22902],
        [28824],
        [29490],
        [28759],
        [24645],
        [24268],
        [23224],
        [19695],
        [22631],
        [25309],
        [19464],
        [23070],
        [21897],
        [19792],
        [20505],
        [23530],
        [25838],
        [21567]], device='cuda:0')
[2024-07-24 10:26:07,625][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28705],
        [18209],
        [15002],
        [ 7893],
        [10812],
        [11539],
        [10856],
        [11504],
        [10825],
        [12415],
        [11651],
        [11492],
        [12381],
        [11667],
        [11271],
        [11505],
        [12827],
        [12099]], device='cuda:0')
[2024-07-24 10:26:07,627][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27517],
        [20751],
        [20289],
        [19418],
        [20345],
        [21372],
        [19785],
        [20746],
        [22188],
        [20896],
        [22029],
        [22826],
        [23553],
        [22611],
        [21852],
        [21377],
        [20415],
        [22114]], device='cuda:0')
[2024-07-24 10:26:07,629][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217],
        [30217]], device='cuda:0')
[2024-07-24 10:26:07,722][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:07,723][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,723][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,724][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,725][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,726][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,726][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,727][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,728][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,729][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,729][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,730][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,731][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:07,732][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6807, 0.3193], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,732][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([7.2404e-04, 9.9928e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,734][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1365, 0.8635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,735][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9418, 0.0582], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,737][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8814, 0.1186], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,738][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3092, 0.6908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,739][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3435, 0.6565], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,739][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8963, 0.1037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,740][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0412, 0.9588], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,741][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([3.0513e-04, 9.9969e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,742][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0396, 0.9604], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,744][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0084, 0.9916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:07,746][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.4798, 0.0610, 0.4592], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,747][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([5.2790e-04, 8.7431e-01, 1.2516e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,748][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.0473, 0.4670, 0.4857], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,750][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.6150, 0.1724, 0.2127], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,751][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.7123, 0.0671, 0.2207], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,753][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.3566, 0.2577, 0.3857], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,754][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.2012, 0.5842, 0.2146], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,756][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.3746, 0.3419, 0.2835], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,758][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.2618, 0.5134, 0.2248], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,759][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([2.5688e-06, 9.9342e-01, 6.5774e-03], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,760][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.0381, 0.7657, 0.1963], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,762][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0013, 0.9884, 0.0103], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:07,764][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2528, 0.1168, 0.5689, 0.0615], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,765][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([7.3104e-06, 1.6165e-01, 1.3968e-02, 8.2438e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,766][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0223, 0.3242, 0.3252, 0.3284], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,768][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2337, 0.2782, 0.4189, 0.0692], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,770][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5814, 0.0947, 0.2109, 0.1131], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,771][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1399, 0.3119, 0.3030, 0.2452], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,773][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0459, 0.4890, 0.1586, 0.3065], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,774][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6026, 0.1343, 0.1643, 0.0987], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,776][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0350, 0.5525, 0.1072, 0.3053], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,777][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.5490e-05, 6.0463e-01, 7.2658e-03, 3.8807e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,779][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0038, 0.4500, 0.1012, 0.4450], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,780][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0009, 0.6092, 0.0091, 0.3808], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:07,782][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.1937, 0.0590, 0.5225, 0.0411, 0.1838], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,783][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([2.1045e-05, 8.1413e-02, 1.6576e-02, 2.2138e-01, 6.8061e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,783][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0099, 0.2526, 0.2628, 0.2626, 0.2120], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,784][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.3749, 0.2290, 0.2884, 0.0676, 0.0401], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,785][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.7544, 0.0352, 0.1097, 0.0259, 0.0748], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,786][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.1772, 0.2489, 0.2255, 0.1988, 0.1496], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,788][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0403, 0.4101, 0.1364, 0.2231, 0.1900], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,789][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.3568, 0.2959, 0.1051, 0.2032, 0.0389], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,791][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.2161, 0.2458, 0.1615, 0.1352, 0.2414], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,792][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([1.4489e-04, 5.0432e-01, 1.4456e-02, 3.1254e-01, 1.6854e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,794][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0225, 0.5753, 0.1222, 0.2383, 0.0417], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,795][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0034, 0.5117, 0.0252, 0.3586, 0.1012], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:07,797][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.2129, 0.1304, 0.3609, 0.0913, 0.0816, 0.1228], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,798][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ were] are: tensor([7.3802e-05, 1.3065e-01, 1.3830e-02, 2.5168e-01, 5.9578e-01, 7.9910e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,800][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0121, 0.1973, 0.2014, 0.2024, 0.1675, 0.2193], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,801][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.3097, 0.1535, 0.2345, 0.0950, 0.0706, 0.1368], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,803][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.6163, 0.0522, 0.1642, 0.0429, 0.0428, 0.0816], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,805][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.1705, 0.1970, 0.2447, 0.1542, 0.0834, 0.1503], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,806][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0375, 0.3741, 0.1236, 0.1922, 0.1453, 0.1272], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,808][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1283, 0.1718, 0.1459, 0.2197, 0.1700, 0.1644], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,810][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0532, 0.1826, 0.1710, 0.2067, 0.2778, 0.1087], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,811][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ were] are: tensor([3.0598e-05, 6.0410e-01, 1.0629e-02, 2.1129e-01, 1.2988e-01, 4.4076e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,812][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0066, 0.2509, 0.0628, 0.5121, 0.1329, 0.0348], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,814][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0016, 0.5097, 0.0134, 0.3094, 0.1212, 0.0447], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:07,816][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0334, 0.1863, 0.2312, 0.1049, 0.0763, 0.1459, 0.2220],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,817][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ working] are: tensor([9.1830e-07, 4.5024e-02, 2.2237e-03, 3.0729e-01, 5.2998e-01, 5.2865e-04,
        1.1496e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,819][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0062, 0.1678, 0.1726, 0.1757, 0.1393, 0.1887, 0.1497],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,820][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0125, 0.3092, 0.1109, 0.3436, 0.1142, 0.1045, 0.0052],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,822][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.4972, 0.0809, 0.0878, 0.0740, 0.0375, 0.0632, 0.1595],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,823][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0579, 0.2020, 0.1556, 0.1745, 0.1153, 0.1357, 0.1589],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,825][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0240, 0.2690, 0.1085, 0.1784, 0.1571, 0.1121, 0.1508],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,827][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0145, 0.2483, 0.0277, 0.4827, 0.1604, 0.0334, 0.0330],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,828][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0123, 0.2204, 0.0562, 0.2357, 0.1911, 0.0404, 0.2439],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,829][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ working] are: tensor([1.1143e-04, 3.7244e-01, 1.1169e-02, 2.3999e-01, 1.4542e-01, 8.0723e-02,
        1.5015e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,829][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ working] are: tensor([2.9601e-04, 2.1987e-01, 1.6288e-02, 6.8240e-01, 7.1415e-02, 7.7515e-03,
        1.9807e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,830][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0011, 0.3000, 0.0130, 0.3206, 0.0763, 0.0487, 0.2403],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:07,832][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0554, 0.1145, 0.2932, 0.0764, 0.1491, 0.0930, 0.1830, 0.0354],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,833][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.2263e-07, 4.1353e-02, 2.4756e-03, 1.8617e-01, 4.9853e-01, 5.3003e-04,
        9.8194e-02, 1.7275e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,835][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0044, 0.1527, 0.1558, 0.1554, 0.1208, 0.1712, 0.1283, 0.1114],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,836][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0346, 0.4269, 0.1482, 0.2552, 0.0777, 0.0537, 0.0024, 0.0012],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,838][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.2991, 0.1255, 0.0899, 0.1586, 0.0369, 0.0711, 0.0990, 0.1200],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,839][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0648, 0.1962, 0.1685, 0.1673, 0.1015, 0.1098, 0.1127, 0.0791],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,841][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0042, 0.3859, 0.0803, 0.1869, 0.1231, 0.0539, 0.1034, 0.0623],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,843][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0479, 0.2321, 0.0570, 0.3739, 0.1681, 0.0528, 0.0242, 0.0440],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,844][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0642, 0.1674, 0.1072, 0.1164, 0.1925, 0.0695, 0.1858, 0.0970],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,845][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.9524e-04, 3.2692e-01, 1.1712e-02, 1.9889e-01, 1.2743e-01, 6.6092e-02,
        1.2274e-01, 1.4603e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,847][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([3.2630e-04, 3.3737e-01, 2.2021e-02, 5.7222e-01, 6.2389e-02, 4.2112e-03,
        6.9472e-04, 7.6610e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,848][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0007, 0.2033, 0.0106, 0.1826, 0.0535, 0.0359, 0.1540, 0.3593],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:07,850][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1842, 0.1028, 0.3465, 0.0618, 0.0645, 0.1130, 0.0824, 0.0216, 0.0233],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,851][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.0429e-06, 5.2740e-02, 4.4067e-03, 1.8027e-01, 4.1475e-01, 7.6634e-04,
        7.5930e-02, 1.0990e-01, 1.6124e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,853][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0046, 0.1358, 0.1392, 0.1369, 0.1086, 0.1503, 0.1146, 0.1000, 0.1101],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,855][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2744, 0.2741, 0.2554, 0.0879, 0.0329, 0.0723, 0.0006, 0.0003, 0.0019],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,856][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3167, 0.0515, 0.1462, 0.0683, 0.0424, 0.0878, 0.1427, 0.1074, 0.0369],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,858][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0955, 0.1535, 0.1781, 0.1325, 0.0879, 0.1165, 0.0915, 0.0593, 0.0852],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,860][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0073, 0.2847, 0.0794, 0.1570, 0.1259, 0.0673, 0.1009, 0.0724, 0.1051],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,861][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1044, 0.2066, 0.0799, 0.3137, 0.1227, 0.0667, 0.0192, 0.0441, 0.0428],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,863][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0832, 0.2102, 0.1211, 0.1116, 0.1333, 0.0706, 0.1592, 0.0618, 0.0489],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,864][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.4492e-04, 2.8085e-01, 1.1629e-02, 1.6999e-01, 1.0555e-01, 6.1025e-02,
        9.7740e-02, 1.1192e-01, 1.6115e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,865][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.6574e-03, 4.4291e-01, 6.5509e-02, 4.2254e-01, 5.1089e-02, 8.6091e-03,
        4.0998e-04, 5.4859e-04, 5.7298e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,867][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0005, 0.2186, 0.0064, 0.2002, 0.0480, 0.0230, 0.0990, 0.2254, 0.1790],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:07,869][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0223, 0.1104, 0.2656, 0.0977, 0.1288, 0.0649, 0.0811, 0.0621, 0.0638,
        0.1032], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,870][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([4.1816e-05, 7.5450e-02, 9.4988e-03, 1.6242e-01, 2.4332e-01, 4.7493e-03,
        1.4549e-01, 1.6917e-01, 1.8667e-01, 3.1900e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,872][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0068, 0.1187, 0.1167, 0.1227, 0.0973, 0.1333, 0.1035, 0.0930, 0.1024,
        0.1057], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,873][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0105, 0.2663, 0.0604, 0.2805, 0.1462, 0.0581, 0.0366, 0.0318, 0.1036,
        0.0060], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,874][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.6908, 0.0218, 0.0414, 0.0132, 0.0304, 0.0256, 0.0258, 0.0191, 0.0197,
        0.1121], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,874][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.1480, 0.1446, 0.1467, 0.1027, 0.0705, 0.0848, 0.0836, 0.0406, 0.0635,
        0.1148], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,875][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0139, 0.3176, 0.0938, 0.1426, 0.1037, 0.0666, 0.0698, 0.0606, 0.0792,
        0.0521], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,877][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.0214, 0.1280, 0.0471, 0.2017, 0.1354, 0.0637, 0.1310, 0.1357, 0.0978,
        0.0382], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,878][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0120, 0.1381, 0.0584, 0.1336, 0.1192, 0.0437, 0.1577, 0.1534, 0.1355,
        0.0484], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,880][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([9.9944e-05, 3.0075e-01, 1.2047e-02, 1.5253e-01, 1.3245e-01, 4.1588e-02,
        9.3579e-02, 1.0039e-01, 1.4704e-01, 1.9520e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,881][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([1.7530e-04, 1.5813e-01, 9.5438e-03, 4.8817e-01, 1.7155e-01, 7.6315e-03,
        2.3694e-02, 2.8036e-02, 1.1205e-01, 1.0197e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,882][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([0.0007, 0.2666, 0.0083, 0.1776, 0.0527, 0.0306, 0.0979, 0.2000, 0.1574,
        0.0082], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:07,884][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0351, 0.1095, 0.3523, 0.0717, 0.0982, 0.0961, 0.0897, 0.0202, 0.0380,
        0.0518, 0.0374], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,885][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([6.6657e-07, 3.0427e-02, 2.8255e-03, 1.5098e-01, 4.1417e-01, 5.3258e-04,
        5.9969e-02, 9.2550e-02, 1.0348e-01, 1.2439e-04, 1.4494e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,887][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0060, 0.1077, 0.1077, 0.1089, 0.0884, 0.1162, 0.0928, 0.0830, 0.0904,
        0.0982, 0.1006], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,888][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.4456e-01, 2.9177e-01, 3.2847e-01, 1.0062e-01, 5.0259e-02, 7.3421e-02,
        6.4481e-04, 2.4643e-04, 2.7555e-03, 1.4142e-03, 5.8416e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,890][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1991, 0.0590, 0.0866, 0.0768, 0.0337, 0.0454, 0.0819, 0.0950, 0.0603,
        0.1536, 0.1086], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,892][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0367, 0.1363, 0.1386, 0.1265, 0.0738, 0.0956, 0.0691, 0.0454, 0.0736,
        0.0779, 0.1266], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,893][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0680, 0.1507, 0.0733, 0.0985, 0.0930, 0.1094, 0.0738, 0.0605, 0.0791,
        0.0644, 0.1294], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,895][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0817, 0.1502, 0.0700, 0.2359, 0.1525, 0.0561, 0.0175, 0.0420, 0.0415,
        0.0154, 0.1373], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,897][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0065, 0.2159, 0.0497, 0.1328, 0.1113, 0.0256, 0.1345, 0.0794, 0.0669,
        0.0292, 0.1480], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,898][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([5.5735e-05, 2.3633e-01, 8.0634e-03, 1.4983e-01, 9.2078e-02, 4.4719e-02,
        8.5781e-02, 9.7969e-02, 1.3733e-01, 1.7458e-02, 1.3039e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,899][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([5.2924e-03, 4.0797e-01, 1.0517e-01, 3.7685e-01, 6.0080e-02, 1.2247e-02,
        3.0566e-04, 3.4719e-04, 6.3955e-03, 2.7546e-04, 2.5065e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,901][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0004, 0.1402, 0.0045, 0.1484, 0.0397, 0.0187, 0.0806, 0.1827, 0.1586,
        0.0059, 0.2204], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:07,903][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0274, 0.0356, 0.2729, 0.0304, 0.1680, 0.0515, 0.1004, 0.0254, 0.0243,
        0.0914, 0.0442, 0.1286], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,904][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([5.0136e-06, 6.4125e-02, 7.7755e-03, 2.1988e-01, 3.5677e-01, 1.1972e-03,
        4.1684e-02, 6.6327e-02, 1.0403e-01, 4.2877e-04, 1.0287e-01, 3.4910e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,906][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0031, 0.0994, 0.1014, 0.1040, 0.0808, 0.1139, 0.0846, 0.0735, 0.0816,
        0.0866, 0.0936, 0.0775], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,907][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([3.3389e-03, 5.3189e-01, 4.7299e-02, 2.5329e-01, 1.0155e-01, 2.2405e-02,
        4.7660e-03, 1.4430e-03, 7.8393e-03, 6.4325e-04, 2.5062e-02, 4.6951e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,909][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.5326, 0.0213, 0.0590, 0.0142, 0.0414, 0.0248, 0.0238, 0.0379, 0.0192,
        0.1229, 0.0443, 0.0588], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,911][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0479, 0.1182, 0.0960, 0.0963, 0.0672, 0.0864, 0.0823, 0.0489, 0.0680,
        0.0918, 0.1426, 0.0544], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,912][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0189, 0.1728, 0.0664, 0.0925, 0.0892, 0.0682, 0.0668, 0.0506, 0.0693,
        0.0431, 0.1914, 0.0707], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,914][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0311, 0.1993, 0.0346, 0.2516, 0.1045, 0.0394, 0.0297, 0.0447, 0.0524,
        0.0104, 0.1868, 0.0156], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,916][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0724, 0.0858, 0.0836, 0.0619, 0.1168, 0.0471, 0.1346, 0.0827, 0.0620,
        0.0886, 0.0847, 0.0798], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,917][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([8.2278e-05, 1.9513e-01, 8.8097e-03, 1.3788e-01, 8.7068e-02, 4.7243e-02,
        8.1942e-02, 8.3706e-02, 1.1759e-01, 1.8253e-02, 1.1556e-01, 1.0673e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,918][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([2.0579e-04, 4.7178e-01, 1.0272e-02, 3.7978e-01, 6.2931e-02, 2.8745e-03,
        1.5975e-03, 1.2286e-03, 1.3551e-02, 1.0122e-04, 5.5356e-02, 3.2536e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,919][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0007, 0.1646, 0.0073, 0.1392, 0.0427, 0.0217, 0.0905, 0.1386, 0.1173,
        0.0113, 0.1982, 0.0679], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:07,920][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0499, 0.0746, 0.3234, 0.0618, 0.0764, 0.0541, 0.0618, 0.0161, 0.0273,
        0.0445, 0.0462, 0.0412, 0.1225], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,921][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([1.9588e-06, 3.1825e-02, 4.9088e-03, 1.7594e-01, 2.1593e-01, 7.3560e-04,
        7.0305e-02, 9.9836e-02, 1.6648e-01, 2.7585e-04, 1.3689e-01, 2.7254e-02,
        6.9613e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,922][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0012, 0.0967, 0.0980, 0.1007, 0.0750, 0.1088, 0.0768, 0.0627, 0.0712,
        0.0764, 0.0851, 0.0678, 0.0794], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,923][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([3.6237e-03, 4.0646e-01, 1.4312e-01, 2.5186e-01, 1.2247e-01, 3.6948e-02,
        9.5509e-04, 5.9195e-04, 9.6543e-03, 2.3756e-04, 2.2999e-02, 1.4486e-04,
        9.2675e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,925][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.1763, 0.0221, 0.0319, 0.0146, 0.0100, 0.0183, 0.0213, 0.0373, 0.0325,
        0.0573, 0.0341, 0.0171, 0.5271], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,927][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0458, 0.1321, 0.1274, 0.1174, 0.0388, 0.0833, 0.0542, 0.0361, 0.0557,
        0.0942, 0.1112, 0.0260, 0.0778], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,929][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0023, 0.1812, 0.0422, 0.0954, 0.0770, 0.0302, 0.0640, 0.0470, 0.0562,
        0.0311, 0.2731, 0.0748, 0.0256], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,930][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0449, 0.1671, 0.0582, 0.2887, 0.1508, 0.0490, 0.0116, 0.0228, 0.0264,
        0.0110, 0.1083, 0.0149, 0.0463], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,932][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0046, 0.0851, 0.0453, 0.0922, 0.1008, 0.0210, 0.1330, 0.0735, 0.1047,
        0.0266, 0.0692, 0.0586, 0.1855], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,933][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([4.7882e-05, 1.8624e-01, 6.3045e-03, 1.1596e-01, 7.0316e-02, 3.6684e-02,
        7.3594e-02, 8.0923e-02, 1.1812e-01, 1.6875e-02, 1.0904e-01, 9.0459e-02,
        9.5446e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,935][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([9.2316e-05, 3.2847e-01, 2.0183e-02, 5.0199e-01, 9.2891e-02, 2.9356e-03,
        2.3691e-04, 2.9301e-04, 9.6105e-03, 2.4063e-05, 4.1915e-02, 6.7924e-05,
        1.2958e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,936][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0010, 0.1019, 0.0078, 0.0914, 0.0297, 0.0237, 0.1010, 0.1436, 0.1160,
        0.0101, 0.1644, 0.0471, 0.1624], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:07,938][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0242, 0.0756, 0.2199, 0.0670, 0.0944, 0.0741, 0.1113, 0.0229, 0.0447,
        0.0387, 0.0382, 0.0614, 0.0913, 0.0360], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,939][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.9332e-06, 3.3468e-02, 5.3400e-03, 1.1157e-01, 2.2666e-01, 9.9863e-04,
        6.6248e-02, 7.9560e-02, 1.1149e-01, 3.6753e-04, 1.1036e-01, 3.0843e-02,
        7.0219e-02, 1.5287e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,941][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0027, 0.0867, 0.0881, 0.0890, 0.0684, 0.0954, 0.0719, 0.0627, 0.0694,
        0.0734, 0.0788, 0.0646, 0.0782, 0.0707], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,942][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.7003e-02, 3.7907e-01, 1.5876e-01, 2.7728e-01, 8.6004e-02, 4.7845e-02,
        8.1926e-04, 6.7930e-04, 6.8032e-03, 6.6044e-04, 2.3167e-02, 2.9168e-04,
        1.1457e-03, 4.8082e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,944][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1061, 0.0375, 0.0369, 0.0599, 0.0130, 0.0278, 0.0402, 0.0663, 0.0432,
        0.1007, 0.0641, 0.0154, 0.2895, 0.0995], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,946][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0396, 0.1198, 0.1121, 0.0955, 0.0580, 0.0720, 0.0595, 0.0396, 0.0611,
        0.0674, 0.1003, 0.0460, 0.0661, 0.0629], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,948][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0033, 0.1927, 0.0461, 0.0950, 0.0751, 0.0308, 0.0744, 0.0380, 0.0487,
        0.0277, 0.2529, 0.0625, 0.0240, 0.0289], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,949][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1161, 0.1338, 0.0686, 0.1904, 0.1191, 0.0513, 0.0071, 0.0211, 0.0275,
        0.0112, 0.1099, 0.0123, 0.0407, 0.0907], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,951][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0113, 0.1083, 0.0712, 0.1081, 0.1031, 0.0299, 0.1078, 0.0459, 0.0621,
        0.0322, 0.0793, 0.0637, 0.1249, 0.0522], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,952][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.8890e-05, 1.7067e-01, 6.4253e-03, 1.1492e-01, 6.3570e-02, 3.3530e-02,
        7.1012e-02, 7.3410e-02, 1.0841e-01, 1.6112e-02, 9.8954e-02, 7.7168e-02,
        8.4788e-02, 8.0990e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,954][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.1405e-04, 4.2138e-01, 2.2327e-02, 4.6765e-01, 4.3137e-02, 2.8808e-03,
        1.3236e-04, 2.9217e-04, 5.9213e-03, 4.6038e-05, 3.4488e-02, 1.1214e-04,
        9.9764e-04, 4.2092e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,955][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0008, 0.0972, 0.0058, 0.1035, 0.0306, 0.0206, 0.0646, 0.1312, 0.0983,
        0.0077, 0.1673, 0.0449, 0.0946, 0.1328], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:07,957][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0273, 0.0761, 0.3357, 0.0505, 0.0528, 0.0682, 0.0654, 0.0166, 0.0226,
        0.0316, 0.0309, 0.0294, 0.1234, 0.0194, 0.0500], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,958][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([9.7023e-06, 4.1387e-02, 1.0386e-02, 1.4918e-01, 2.2509e-01, 1.1474e-03,
        4.3051e-02, 6.2000e-02, 1.0870e-01, 4.4595e-04, 1.0396e-01, 2.7704e-02,
        6.2774e-02, 1.0269e-01, 6.1473e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,960][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0051, 0.0769, 0.0771, 0.0795, 0.0640, 0.0845, 0.0665, 0.0606, 0.0657,
        0.0689, 0.0726, 0.0624, 0.0737, 0.0679, 0.0744], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,962][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([8.7007e-04, 3.5210e-01, 7.3725e-02, 3.6509e-01, 1.2603e-01, 2.2818e-02,
        8.2843e-04, 7.9281e-04, 1.3438e-02, 1.2007e-04, 3.9578e-02, 1.5763e-04,
        3.1383e-03, 9.7267e-04, 3.3969e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,962][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1644, 0.0282, 0.0486, 0.0216, 0.0117, 0.0253, 0.0274, 0.0352, 0.0360,
        0.0507, 0.0457, 0.0163, 0.3370, 0.0842, 0.0676], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,963][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0542, 0.0986, 0.1043, 0.0894, 0.0432, 0.0710, 0.0550, 0.0335, 0.0557,
        0.0740, 0.1033, 0.0290, 0.0632, 0.0464, 0.0792], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,964][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0064, 0.1833, 0.0449, 0.0814, 0.0701, 0.0381, 0.0587, 0.0416, 0.0584,
        0.0342, 0.2185, 0.0706, 0.0234, 0.0358, 0.0346], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,966][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.1019, 0.1254, 0.0729, 0.1983, 0.0752, 0.0563, 0.0073, 0.0196, 0.0269,
        0.0125, 0.0972, 0.0082, 0.0360, 0.0787, 0.0835], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,968][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0074, 0.0751, 0.0412, 0.0688, 0.0803, 0.0217, 0.1434, 0.0522, 0.0994,
        0.0261, 0.0713, 0.0483, 0.1352, 0.0454, 0.0841], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,969][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([4.6049e-05, 1.5030e-01, 5.9093e-03, 1.0250e-01, 5.9888e-02, 3.3745e-02,
        6.0918e-02, 6.8307e-02, 9.5219e-02, 1.4291e-02, 9.0307e-02, 7.2719e-02,
        7.8326e-02, 7.6990e-02, 9.0533e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,970][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([6.0344e-05, 3.2910e-01, 1.3551e-02, 5.3433e-01, 6.3604e-02, 2.3730e-03,
        2.2402e-04, 3.3303e-04, 8.3148e-03, 2.0701e-05, 4.2404e-02, 5.6508e-05,
        4.5813e-03, 6.3312e-04, 4.1727e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,972][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0010, 0.0703, 0.0085, 0.0838, 0.0247, 0.0244, 0.0689, 0.1149, 0.0896,
        0.0124, 0.1334, 0.0350, 0.1108, 0.1060, 0.1163], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:07,973][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1196, 0.0642, 0.2995, 0.0522, 0.0436, 0.0904, 0.0604, 0.0167, 0.0205,
        0.0297, 0.0338, 0.0254, 0.0687, 0.0218, 0.0291, 0.0242],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,975][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.6815e-06, 3.6462e-02, 6.5548e-03, 1.1333e-01, 1.5361e-01, 1.1043e-03,
        5.9131e-02, 6.6816e-02, 1.1170e-01, 4.3775e-04, 1.1495e-01, 1.8712e-02,
        5.6635e-02, 1.4965e-01, 3.7857e-02, 7.3045e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,977][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0055, 0.0711, 0.0712, 0.0732, 0.0595, 0.0785, 0.0617, 0.0562, 0.0611,
        0.0646, 0.0672, 0.0577, 0.0679, 0.0623, 0.0687, 0.0737],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,978][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.0177e-02, 3.7942e-01, 1.5817e-01, 2.6880e-01, 1.0675e-01, 3.5968e-02,
        5.6223e-04, 4.8646e-04, 7.3866e-03, 2.6494e-04, 2.9565e-02, 2.3810e-04,
        9.3848e-04, 5.1354e-04, 1.3130e-04, 6.1878e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,980][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2915, 0.0279, 0.0910, 0.0244, 0.0149, 0.0379, 0.0545, 0.0353, 0.0227,
        0.0956, 0.0294, 0.0156, 0.1469, 0.0340, 0.0693, 0.0091],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,982][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0828, 0.0937, 0.1222, 0.0764, 0.0486, 0.0681, 0.0479, 0.0331, 0.0473,
        0.0539, 0.0836, 0.0369, 0.0542, 0.0513, 0.0551, 0.0450],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,983][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0021, 0.2584, 0.0482, 0.0987, 0.0683, 0.0262, 0.0461, 0.0293, 0.0441,
        0.0230, 0.2255, 0.0541, 0.0160, 0.0205, 0.0219, 0.0176],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,985][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1288, 0.1154, 0.0717, 0.1697, 0.0732, 0.0468, 0.0068, 0.0163, 0.0218,
        0.0140, 0.0856, 0.0104, 0.0309, 0.0817, 0.0656, 0.0613],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,987][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0521, 0.1075, 0.0806, 0.0670, 0.0679, 0.0393, 0.0984, 0.0329, 0.0393,
        0.0508, 0.0780, 0.0534, 0.1245, 0.0365, 0.0425, 0.0294],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,988][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.2247e-05, 1.4979e-01, 5.0711e-03, 9.2862e-02, 5.3341e-02, 2.7551e-02,
        5.5570e-02, 6.0671e-02, 9.0360e-02, 1.1374e-02, 8.0522e-02, 6.1427e-02,
        6.8657e-02, 6.6124e-02, 7.3597e-02, 1.0306e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,989][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.8722e-04, 3.0980e-01, 2.9124e-02, 5.1967e-01, 6.5475e-02, 3.1519e-03,
        1.9105e-04, 3.8902e-04, 8.6823e-03, 4.0884e-05, 5.9177e-02, 1.4488e-04,
        2.4059e-03, 6.2035e-04, 2.3416e-04, 7.1095e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,991][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0007, 0.0843, 0.0067, 0.1000, 0.0318, 0.0176, 0.0552, 0.1102, 0.0807,
        0.0079, 0.1297, 0.0357, 0.0785, 0.0989, 0.0750, 0.0870],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:07,993][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0267, 0.0188, 0.3600, 0.0251, 0.0573, 0.0311, 0.0400, 0.0142, 0.0166,
        0.0379, 0.0230, 0.0357, 0.0280, 0.0173, 0.0180, 0.0216, 0.2289],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,994][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([3.9258e-05, 6.8595e-02, 1.4500e-02, 1.0963e-01, 9.0863e-02, 2.3156e-03,
        5.3761e-02, 6.2651e-02, 1.1949e-01, 1.4423e-03, 9.5025e-02, 2.2422e-02,
        4.3564e-02, 9.5372e-02, 3.7538e-02, 8.1979e-02, 1.0081e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,996][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0070, 0.0666, 0.0664, 0.0682, 0.0568, 0.0709, 0.0586, 0.0538, 0.0583,
        0.0605, 0.0626, 0.0550, 0.0619, 0.0586, 0.0639, 0.0676, 0.0632],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,997][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([9.3306e-03, 4.0075e-01, 1.9936e-01, 1.4353e-01, 1.3764e-01, 4.6342e-02,
        2.8051e-03, 1.6476e-03, 1.7669e-02, 4.8707e-04, 2.6125e-02, 3.8207e-04,
        2.9035e-03, 1.2143e-03, 5.0651e-04, 2.3722e-03, 6.9349e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:07,999][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.3914, 0.0347, 0.0687, 0.0270, 0.0147, 0.0180, 0.0185, 0.0356, 0.0325,
        0.0476, 0.0416, 0.0174, 0.0996, 0.0475, 0.0639, 0.0188, 0.0226],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,001][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0960, 0.0859, 0.1078, 0.0662, 0.0486, 0.0556, 0.0470, 0.0268, 0.0405,
        0.0736, 0.0892, 0.0327, 0.0466, 0.0351, 0.0604, 0.0310, 0.0570],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,003][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0018, 0.2249, 0.0461, 0.0884, 0.0694, 0.0257, 0.0395, 0.0323, 0.0471,
        0.0237, 0.2490, 0.0622, 0.0151, 0.0194, 0.0242, 0.0185, 0.0128],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,005][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.1836, 0.0995, 0.0686, 0.1437, 0.0558, 0.0552, 0.0058, 0.0149, 0.0254,
        0.0126, 0.0589, 0.0084, 0.0270, 0.0489, 0.0419, 0.0551, 0.0947],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,006][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0086, 0.0793, 0.0829, 0.0713, 0.0822, 0.0272, 0.0807, 0.0715, 0.0698,
        0.0452, 0.0612, 0.0687, 0.0950, 0.0386, 0.0347, 0.0289, 0.0542],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,007][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([4.8760e-05, 1.2192e-01, 4.0643e-03, 8.5956e-02, 5.0137e-02, 1.9216e-02,
        5.6359e-02, 6.0826e-02, 8.2930e-02, 9.1562e-03, 7.3179e-02, 6.3083e-02,
        6.4344e-02, 5.9682e-02, 7.1366e-02, 9.9393e-02, 7.8342e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,008][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([4.0906e-04, 4.2495e-01, 4.4797e-02, 3.5179e-01, 1.0218e-01, 6.0951e-03,
        7.2208e-04, 7.0591e-04, 1.6296e-02, 7.9034e-05, 4.0337e-02, 2.3783e-04,
        3.1881e-03, 7.1559e-04, 3.8392e-04, 1.4278e-03, 5.6829e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,009][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0013, 0.0837, 0.0068, 0.0741, 0.0236, 0.0216, 0.0586, 0.0924, 0.0772,
        0.0107, 0.1220, 0.0354, 0.0816, 0.0759, 0.0865, 0.0889, 0.0596],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,010][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0575, 0.0444, 0.2339, 0.0409, 0.0737, 0.0726, 0.0823, 0.0140, 0.0271,
        0.0361, 0.0239, 0.0503, 0.0693, 0.0210, 0.0245, 0.0261, 0.0759, 0.0265],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,011][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.0971e-06, 3.1745e-02, 8.9360e-03, 7.5463e-02, 2.1177e-01, 1.2772e-03,
        4.8809e-02, 5.6576e-02, 7.3103e-02, 5.1830e-04, 7.3464e-02, 2.8157e-02,
        5.4804e-02, 1.1126e-01, 3.4909e-02, 4.2045e-02, 6.3576e-02, 8.3576e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,013][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0047, 0.0635, 0.0634, 0.0649, 0.0522, 0.0681, 0.0545, 0.0497, 0.0539,
        0.0567, 0.0587, 0.0504, 0.0602, 0.0552, 0.0609, 0.0649, 0.0599, 0.0582],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,014][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.2213e-02, 3.5713e-01, 2.0233e-01, 2.2261e-01, 9.4920e-02, 4.6408e-02,
        8.7881e-04, 7.0039e-04, 6.8858e-03, 6.9290e-04, 2.4046e-02, 4.1856e-04,
        1.0077e-03, 4.6981e-04, 1.5139e-04, 6.1544e-04, 7.8294e-03, 6.9532e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,016][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1169, 0.0315, 0.0351, 0.0506, 0.0108, 0.0230, 0.0335, 0.0551, 0.0398,
        0.0751, 0.0510, 0.0120, 0.2179, 0.0774, 0.0879, 0.0210, 0.0187, 0.0426],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,018][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0431, 0.0915, 0.0912, 0.0704, 0.0440, 0.0531, 0.0483, 0.0321, 0.0480,
        0.0543, 0.0779, 0.0362, 0.0523, 0.0517, 0.0500, 0.0433, 0.0518, 0.0607],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,020][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0054, 0.1596, 0.0478, 0.0865, 0.0699, 0.0347, 0.0604, 0.0369, 0.0490,
        0.0299, 0.1917, 0.0546, 0.0203, 0.0291, 0.0276, 0.0263, 0.0225, 0.0479],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,022][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1970, 0.0786, 0.0679, 0.1060, 0.0683, 0.0454, 0.0044, 0.0110, 0.0160,
        0.0114, 0.0648, 0.0084, 0.0249, 0.0515, 0.0396, 0.0461, 0.0986, 0.0603],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,023][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0158, 0.1047, 0.0688, 0.0910, 0.0807, 0.0305, 0.0808, 0.0384, 0.0503,
        0.0298, 0.0628, 0.0522, 0.0989, 0.0403, 0.0422, 0.0346, 0.0312, 0.0470],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,025][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.0470e-05, 1.2778e-01, 3.6321e-03, 8.2508e-02, 4.5460e-02, 2.1067e-02,
        5.0175e-02, 5.3351e-02, 7.8913e-02, 8.8040e-03, 7.0868e-02, 5.5418e-02,
        5.9839e-02, 5.7803e-02, 6.6086e-02, 8.6788e-02, 7.0460e-02, 6.1029e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,026][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.2151e-04, 4.0526e-01, 3.3120e-02, 4.5557e-01, 5.2355e-02, 3.1561e-03,
        1.5115e-04, 3.5025e-04, 6.3978e-03, 5.6660e-05, 3.4740e-02, 1.8230e-04,
        1.0286e-03, 4.4582e-04, 1.3553e-04, 4.4229e-04, 5.5104e-03, 7.7632e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,028][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0008, 0.0789, 0.0054, 0.0780, 0.0244, 0.0170, 0.0453, 0.0890, 0.0643,
        0.0057, 0.1129, 0.0364, 0.0627, 0.0870, 0.0589, 0.0712, 0.0463, 0.1158],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,129][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:08,130][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,131][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,133][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,134][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,135][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,136][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,136][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,137][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,138][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,138][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,139][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,140][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,140][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2083, 0.7917], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,141][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([7.2404e-04, 9.9928e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,142][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2196, 0.7804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,142][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9398, 0.0602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,144][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,145][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2005, 0.7995], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,147][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.6795e-05, 9.9997e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,148][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3467, 0.6533], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,150][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0805, 0.9195], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,151][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([5.2741e-06, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,152][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0396, 0.9604], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,153][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,154][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.2459, 0.3741, 0.3800], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,155][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([5.2790e-04, 8.7431e-01, 1.2516e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,156][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.3675, 0.1523, 0.4802], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,156][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.7153, 0.1133, 0.1714], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,157][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.0048, 0.7286, 0.2666], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,159][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.2200, 0.3899, 0.3901], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,160][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([1.1709e-04, 9.2509e-01, 7.4791e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,161][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.3315, 0.3690, 0.2995], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,163][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.2044, 0.3914, 0.4042], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,164][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([1.5108e-05, 9.4637e-01, 5.3614e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,166][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.0381, 0.7657, 0.1963], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,167][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([6.4882e-04, 9.9240e-01, 6.9462e-03], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,168][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0403, 0.2170, 0.1281, 0.6145], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,170][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([7.3104e-06, 1.6165e-01, 1.3968e-02, 8.2438e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,171][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1293, 0.1495, 0.4867, 0.2346], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,173][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3459, 0.2650, 0.3368, 0.0523], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,174][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0008, 0.4298, 0.1169, 0.4524], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,176][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0517, 0.4287, 0.1702, 0.3493], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,177][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.6274e-06, 1.0667e-01, 4.0687e-03, 8.8926e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,179][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1098, 0.3667, 0.1766, 0.3469], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,180][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0204, 0.2607, 0.4962, 0.2226], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,181][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.2113e-07, 8.2776e-02, 9.8602e-04, 9.1624e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,183][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0038, 0.4500, 0.1012, 0.4450], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,184][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.2372e-04, 6.2675e-01, 1.2970e-03, 3.7183e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,186][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0605, 0.2384, 0.0833, 0.3839, 0.2340], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,187][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([2.1045e-05, 8.1413e-02, 1.6576e-02, 2.2138e-01, 6.8061e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,189][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0953, 0.2436, 0.3384, 0.1882, 0.1345], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,190][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.5192, 0.1950, 0.2337, 0.0402, 0.0119], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,192][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0010, 0.3575, 0.0914, 0.2522, 0.2979], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,194][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0392, 0.1855, 0.1403, 0.2599, 0.3751], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,195][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([4.2478e-06, 1.3841e-01, 7.4984e-03, 6.9991e-01, 1.5418e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,196][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.2114, 0.4505, 0.1513, 0.1610, 0.0258], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,197][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0350, 0.2341, 0.2464, 0.1241, 0.3604], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,197][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([4.1734e-06, 1.0617e-01, 5.1023e-03, 7.7001e-01, 1.1872e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,198][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0225, 0.5753, 0.1222, 0.2383, 0.0417], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,199][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0013, 0.5325, 0.0107, 0.4012, 0.0543], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,200][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0230, 0.1523, 0.0738, 0.2804, 0.4232, 0.0474], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,201][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([7.3802e-05, 1.3065e-01, 1.3830e-02, 2.5168e-01, 5.9578e-01, 7.9910e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,203][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0827, 0.1548, 0.2691, 0.1820, 0.2443, 0.0672], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,205][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.3185, 0.1960, 0.2194, 0.1140, 0.0542, 0.0979], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,206][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0029, 0.2795, 0.1043, 0.2799, 0.2935, 0.0399], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,208][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0662, 0.1936, 0.1793, 0.1784, 0.2732, 0.1094], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,209][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([1.2255e-05, 1.1276e-01, 9.4416e-03, 4.9436e-01, 3.7465e-01, 8.7750e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,211][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1026, 0.2079, 0.1623, 0.2481, 0.1415, 0.1376], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,212][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0230, 0.2247, 0.1717, 0.1791, 0.3452, 0.0562], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,213][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([6.6434e-07, 8.7629e-02, 2.5811e-03, 5.1324e-01, 3.9306e-01, 3.4896e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,215][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0066, 0.2509, 0.0628, 0.5121, 0.1329, 0.0348], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,217][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0006, 0.5217, 0.0068, 0.3374, 0.1181, 0.0154], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,218][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0051, 0.1355, 0.0353, 0.4066, 0.3522, 0.0150, 0.0503],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,219][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([9.1830e-07, 4.5024e-02, 2.2237e-03, 3.0729e-01, 5.2998e-01, 5.2865e-04,
        1.1496e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,221][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0062, 0.1873, 0.1569, 0.3615, 0.2471, 0.0183, 0.0227],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,223][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0169, 0.3763, 0.1064, 0.3784, 0.0691, 0.0517, 0.0010],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,225][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0009, 0.2731, 0.0836, 0.1639, 0.3064, 0.0196, 0.1525],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,226][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0102, 0.1219, 0.0873, 0.2033, 0.2719, 0.0414, 0.2640],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,228][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([4.0841e-07, 1.1163e-01, 2.4470e-03, 6.3898e-01, 2.2890e-01, 1.5013e-03,
        1.6546e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,229][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0263, 0.3084, 0.0663, 0.4419, 0.0863, 0.0540, 0.0168],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,231][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0023, 0.1254, 0.1134, 0.1340, 0.5524, 0.0168, 0.0556],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,232][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([4.7671e-07, 8.8670e-02, 1.7131e-03, 6.6006e-01, 1.7720e-01, 1.6857e-03,
        7.0672e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,233][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([2.9601e-04, 2.1987e-01, 1.6288e-02, 6.8240e-01, 7.1415e-02, 7.7515e-03,
        1.9807e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,234][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([1.6170e-04, 3.7886e-01, 3.5674e-03, 4.6680e-01, 3.6311e-02, 6.6621e-03,
        1.0764e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,236][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0022, 0.1173, 0.0316, 0.4423, 0.3076, 0.0099, 0.0389, 0.0502],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,237][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.2263e-07, 4.1353e-02, 2.4756e-03, 1.8617e-01, 4.9853e-01, 5.3003e-04,
        9.8194e-02, 1.7275e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,238][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0077, 0.1557, 0.1622, 0.3742, 0.2442, 0.0180, 0.0286, 0.0092],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,239][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([4.5497e-02, 5.1052e-01, 1.2866e-01, 2.4691e-01, 4.5391e-02, 2.2278e-02,
        4.3941e-04, 3.0390e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,240][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0007, 0.1690, 0.0631, 0.1709, 0.2575, 0.0140, 0.1762, 0.1486],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,240][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0087, 0.1486, 0.0674, 0.2283, 0.2173, 0.0322, 0.1728, 0.1246],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,241][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([2.7589e-07, 5.8684e-02, 1.7339e-03, 4.9700e-01, 2.5710e-01, 9.3638e-04,
        2.7267e-02, 1.5728e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,243][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0142, 0.2971, 0.0556, 0.4736, 0.0932, 0.0289, 0.0147, 0.0226],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,244][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([5.5301e-04, 8.9681e-02, 5.2205e-02, 1.1975e-01, 6.2024e-01, 7.6928e-03,
        7.3933e-02, 3.5946e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,245][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.8694e-06, 1.2618e-01, 2.7048e-03, 5.4424e-01, 1.8495e-01, 2.1599e-03,
        6.1973e-02, 7.7784e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,246][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([3.2630e-04, 3.3737e-01, 2.2021e-02, 5.7222e-01, 6.2389e-02, 4.2112e-03,
        6.9472e-04, 7.6610e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,247][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.9384e-04, 3.2922e-01, 3.8333e-03, 3.1630e-01, 3.8744e-02, 6.9674e-03,
        1.1540e-01, 1.8935e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,249][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0101, 0.1322, 0.0578, 0.3370, 0.3067, 0.0127, 0.0358, 0.0290, 0.0788],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,250][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.0429e-06, 5.2740e-02, 4.4067e-03, 1.8027e-01, 4.1475e-01, 7.6634e-04,
        7.5930e-02, 1.0990e-01, 1.6124e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,252][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0149, 0.1374, 0.2695, 0.2474, 0.2504, 0.0162, 0.0209, 0.0059, 0.0373],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,253][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.5732e-01, 3.0768e-01, 2.1654e-01, 7.3471e-02, 1.4421e-02, 2.9764e-02,
        9.1875e-05, 7.1385e-05, 6.3640e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,255][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0010, 0.1288, 0.1080, 0.0917, 0.2699, 0.0150, 0.1146, 0.1186, 0.1524],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,256][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0206, 0.1534, 0.0845, 0.1746, 0.1772, 0.0322, 0.1460, 0.0695, 0.1419],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,257][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([5.0949e-07, 5.6166e-02, 2.5615e-03, 3.5848e-01, 2.2336e-01, 1.1115e-03,
        1.7897e-02, 8.2983e-02, 2.5744e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,259][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0361, 0.3460, 0.0855, 0.3852, 0.0602, 0.0288, 0.0073, 0.0118, 0.0390],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,261][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0018, 0.0969, 0.0922, 0.0853, 0.5898, 0.0089, 0.0522, 0.0255, 0.0472],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,262][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([7.3065e-07, 9.2960e-02, 2.3995e-03, 4.8297e-01, 1.7646e-01, 1.5438e-03,
        4.9715e-02, 4.8375e-02, 1.4558e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,263][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.6574e-03, 4.4291e-01, 6.5509e-02, 4.2254e-01, 5.1089e-02, 8.6091e-03,
        4.0998e-04, 5.4859e-04, 5.7298e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,265][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.7141e-04, 3.6870e-01, 2.8541e-03, 3.0991e-01, 3.9669e-02, 5.1721e-03,
        5.7117e-02, 1.1075e-01, 1.0555e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,266][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0217, 0.1138, 0.0641, 0.1598, 0.2841, 0.0406, 0.0845, 0.1064, 0.1071,
        0.0179], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,267][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([4.1816e-05, 7.5450e-02, 9.4988e-03, 1.6242e-01, 2.4332e-01, 4.7493e-03,
        1.4549e-01, 1.6917e-01, 1.8667e-01, 3.1900e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,269][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([0.0609, 0.1757, 0.2283, 0.1573, 0.1591, 0.0700, 0.0495, 0.0217, 0.0508,
        0.0268], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,271][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0150, 0.2903, 0.0618, 0.3064, 0.1349, 0.0445, 0.0249, 0.0268, 0.0904,
        0.0051], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,272][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0013, 0.1487, 0.0475, 0.1358, 0.1411, 0.0196, 0.0790, 0.1381, 0.2747,
        0.0143], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,274][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([0.0319, 0.1052, 0.0860, 0.0921, 0.1441, 0.0593, 0.1922, 0.1041, 0.1366,
        0.0485], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,275][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([4.9792e-06, 5.0963e-02, 4.4181e-03, 1.9649e-01, 2.2662e-01, 4.2523e-03,
        4.7780e-02, 2.0499e-01, 2.6339e-01, 1.0856e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,277][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0236, 0.1898, 0.0703, 0.2461, 0.1027, 0.0761, 0.0763, 0.0678, 0.1200,
        0.0274], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,279][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0198, 0.2349, 0.1091, 0.1137, 0.2090, 0.0389, 0.0958, 0.0516, 0.0898,
        0.0373], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,280][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([7.5563e-07, 3.3485e-02, 1.8003e-03, 2.2339e-01, 2.2943e-01, 2.1873e-03,
        1.4611e-01, 1.4231e-01, 2.2048e-01, 8.0194e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,281][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([1.7530e-04, 1.5813e-01, 9.5438e-03, 4.8817e-01, 1.7155e-01, 7.6315e-03,
        2.3694e-02, 2.8036e-02, 1.1205e-01, 1.0197e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,282][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([2.0316e-04, 3.0649e-01, 4.2262e-03, 2.4791e-01, 6.2418e-02, 8.2941e-03,
        1.1387e-01, 1.3211e-01, 1.2016e-01, 4.3190e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,282][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0053, 0.1033, 0.0415, 0.2319, 0.3760, 0.0098, 0.0202, 0.0219, 0.0630,
        0.0016, 0.1256], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,283][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([6.6657e-07, 3.0427e-02, 2.8255e-03, 1.5098e-01, 4.1417e-01, 5.3258e-04,
        5.9969e-02, 9.2550e-02, 1.0348e-01, 1.2439e-04, 1.4494e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,285][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0172, 0.0720, 0.3355, 0.1396, 0.3379, 0.0182, 0.0222, 0.0038, 0.0244,
        0.0052, 0.0239], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,286][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([2.0742e-01, 3.5024e-01, 2.9306e-01, 8.9470e-02, 2.4617e-02, 3.0592e-02,
        9.1906e-05, 5.0683e-05, 9.3794e-04, 4.9799e-04, 3.0216e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,287][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.3213e-04, 7.4616e-02, 3.0750e-02, 6.9028e-02, 1.7322e-01, 3.8113e-03,
        5.6653e-02, 7.0068e-02, 1.8748e-01, 1.8993e-03, 3.3234e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,289][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0132, 0.1306, 0.0800, 0.1727, 0.1826, 0.0319, 0.1138, 0.0523, 0.1172,
        0.0116, 0.0940], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,290][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.9258e-07, 2.6067e-02, 1.2824e-03, 2.3868e-01, 1.9741e-01, 5.4802e-04,
        1.3370e-02, 7.1576e-02, 2.1791e-01, 5.6974e-05, 2.3311e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,292][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0376, 0.2117, 0.1059, 0.3283, 0.0944, 0.0365, 0.0076, 0.0126, 0.0472,
        0.0032, 0.1149], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,293][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0010, 0.0719, 0.0774, 0.0751, 0.5409, 0.0061, 0.0670, 0.0250, 0.0530,
        0.0038, 0.0789], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,295][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.7264e-07, 5.4793e-02, 1.3553e-03, 4.0868e-01, 1.8255e-01, 7.4181e-04,
        5.0974e-02, 4.5711e-02, 1.0637e-01, 8.0255e-05, 1.4875e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,296][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([5.2924e-03, 4.0797e-01, 1.0517e-01, 3.7685e-01, 6.0080e-02, 1.2247e-02,
        3.0566e-04, 3.4719e-04, 6.3955e-03, 2.7546e-04, 2.5065e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,297][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.1624e-04, 2.5972e-01, 2.0369e-03, 2.5668e-01, 4.7068e-02, 3.9121e-03,
        5.6884e-02, 9.4496e-02, 1.0052e-01, 1.5302e-03, 1.7705e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,299][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0058, 0.0832, 0.0434, 0.2263, 0.3644, 0.0113, 0.0279, 0.0328, 0.0551,
        0.0030, 0.1107, 0.0362], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,300][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([5.0136e-06, 6.4125e-02, 7.7755e-03, 2.1988e-01, 3.5677e-01, 1.1972e-03,
        4.1684e-02, 6.6327e-02, 1.0403e-01, 4.2877e-04, 1.0287e-01, 3.4910e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,302][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0089, 0.1080, 0.2246, 0.1822, 0.2843, 0.0215, 0.0281, 0.0084, 0.0508,
        0.0055, 0.0517, 0.0259], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,303][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([3.7802e-03, 6.1242e-01, 3.6706e-02, 2.4307e-01, 7.3554e-02, 8.7479e-03,
        1.2119e-03, 4.3260e-04, 3.2061e-03, 2.0354e-04, 1.6537e-02, 1.2309e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,304][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([9.0161e-05, 6.4204e-02, 2.0489e-02, 9.6808e-02, 1.8827e-01, 2.4209e-03,
        5.2536e-02, 6.5913e-02, 1.9404e-01, 1.6121e-03, 2.6576e-01, 4.7855e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,306][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0032, 0.0667, 0.0284, 0.1309, 0.1764, 0.0145, 0.1126, 0.0747, 0.1714,
        0.0078, 0.1442, 0.0692], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,307][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([9.7690e-07, 4.7490e-02, 3.4654e-03, 3.3496e-01, 1.1700e-01, 1.3444e-03,
        8.9864e-03, 5.5014e-02, 1.9703e-01, 1.2932e-04, 1.9796e-01, 3.6616e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,309][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0250, 0.3123, 0.0711, 0.2787, 0.0852, 0.0371, 0.0097, 0.0103, 0.0382,
        0.0040, 0.1250, 0.0035], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,311][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0029, 0.1384, 0.0866, 0.0911, 0.3933, 0.0126, 0.0407, 0.0226, 0.0521,
        0.0085, 0.0721, 0.0791], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,312][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([1.3427e-06, 4.7662e-02, 3.0673e-03, 4.6162e-01, 1.6085e-01, 1.7600e-03,
        6.7697e-02, 2.8046e-02, 7.2228e-02, 2.3058e-04, 1.2891e-01, 2.7938e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,313][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([2.0579e-04, 4.7178e-01, 1.0272e-02, 3.7978e-01, 6.2931e-02, 2.8745e-03,
        1.5975e-03, 1.2286e-03, 1.3551e-02, 1.0122e-04, 5.5356e-02, 3.2536e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,315][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0005, 0.2582, 0.0071, 0.2360, 0.0560, 0.0099, 0.0716, 0.0755, 0.0783,
        0.0061, 0.1514, 0.0494], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,317][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0052, 0.0939, 0.0453, 0.1570, 0.4013, 0.0118, 0.0236, 0.0279, 0.0699,
        0.0020, 0.0874, 0.0314, 0.0432], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,318][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([1.9588e-06, 3.1825e-02, 4.9088e-03, 1.7594e-01, 2.1593e-01, 7.3560e-04,
        7.0305e-02, 9.9836e-02, 1.6648e-01, 2.7585e-04, 1.3689e-01, 2.7254e-02,
        6.9613e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,320][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0226, 0.1521, 0.2880, 0.2177, 0.1815, 0.0173, 0.0245, 0.0047, 0.0288,
        0.0045, 0.0250, 0.0118, 0.0214], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,321][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([3.5317e-03, 5.0917e-01, 1.0137e-01, 2.6604e-01, 8.6062e-02, 1.2068e-02,
        1.8000e-04, 1.6278e-04, 4.2574e-03, 6.2890e-05, 1.6897e-02, 3.3592e-05,
        1.6795e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,322][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0008, 0.0977, 0.0494, 0.0550, 0.1313, 0.0072, 0.0368, 0.0608, 0.2804,
        0.0053, 0.1978, 0.0604, 0.0171], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,323][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0139, 0.1117, 0.0968, 0.1536, 0.1463, 0.0301, 0.0997, 0.0481, 0.1241,
        0.0141, 0.0719, 0.0314, 0.0584], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,324][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([1.0886e-06, 4.2503e-02, 3.4226e-03, 2.5488e-01, 1.7268e-01, 1.1892e-03,
        1.6311e-02, 7.5276e-02, 1.9265e-01, 1.6950e-04, 1.8796e-01, 3.3600e-02,
        1.9348e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,325][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0329, 0.2226, 0.1049, 0.3457, 0.0837, 0.0388, 0.0038, 0.0065, 0.0357,
        0.0027, 0.1145, 0.0015, 0.0066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,326][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0055, 0.1021, 0.1958, 0.0837, 0.4116, 0.0133, 0.0189, 0.0162, 0.0245,
        0.0092, 0.0536, 0.0388, 0.0268], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,327][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([2.8272e-07, 5.5385e-02, 1.6178e-03, 4.0882e-01, 1.1265e-01, 8.1876e-04,
        5.5331e-02, 3.9684e-02, 1.2410e-01, 1.2152e-04, 1.5875e-01, 1.5453e-02,
        2.7262e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,329][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([9.2316e-05, 3.2847e-01, 2.0183e-02, 5.0199e-01, 9.2891e-02, 2.9356e-03,
        2.3691e-04, 2.9301e-04, 9.6105e-03, 2.4063e-05, 4.1915e-02, 6.7924e-05,
        1.2958e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,330][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([1.6085e-04, 2.5266e-01, 4.0369e-03, 2.0894e-01, 2.8331e-02, 5.5281e-03,
        9.8146e-02, 6.8518e-02, 6.8472e-02, 2.7350e-03, 1.2731e-01, 1.7981e-02,
        1.1718e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,332][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0034, 0.0919, 0.0409, 0.1968, 0.3432, 0.0090, 0.0279, 0.0222, 0.0674,
        0.0019, 0.1198, 0.0260, 0.0288, 0.0208], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,333][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.9332e-06, 3.3468e-02, 5.3400e-03, 1.1157e-01, 2.2666e-01, 9.9863e-04,
        6.6248e-02, 7.9560e-02, 1.1149e-01, 3.6753e-04, 1.1036e-01, 3.0843e-02,
        7.0219e-02, 1.5287e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,334][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0081, 0.0749, 0.2340, 0.1755, 0.2909, 0.0155, 0.0375, 0.0069, 0.0442,
        0.0053, 0.0358, 0.0198, 0.0455, 0.0060], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,336][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.4604e-02, 4.7754e-01, 1.0911e-01, 3.0387e-01, 5.8852e-02, 1.5254e-02,
        1.5727e-04, 1.9183e-04, 2.9816e-03, 1.7258e-04, 1.6871e-02, 7.3819e-05,
        2.1968e-04, 1.0448e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,337][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0004, 0.0695, 0.0261, 0.0533, 0.1346, 0.0042, 0.0498, 0.0506, 0.1360,
        0.0028, 0.2417, 0.0540, 0.0238, 0.1531], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,339][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0093, 0.1355, 0.0558, 0.1601, 0.1167, 0.0231, 0.0769, 0.0544, 0.1193,
        0.0100, 0.1017, 0.0352, 0.0579, 0.0442], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,340][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1435e-06, 3.1253e-02, 2.4078e-03, 1.8564e-01, 1.6444e-01, 8.2802e-04,
        2.4934e-02, 5.9258e-02, 1.8561e-01, 1.4005e-04, 2.2174e-01, 4.1597e-02,
        2.3814e-02, 5.8337e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,342][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0191, 0.1945, 0.0613, 0.3946, 0.0865, 0.0305, 0.0057, 0.0110, 0.0422,
        0.0024, 0.1313, 0.0026, 0.0103, 0.0081], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,344][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0022, 0.0831, 0.1085, 0.0822, 0.3964, 0.0108, 0.0525, 0.0230, 0.0443,
        0.0078, 0.0725, 0.0446, 0.0401, 0.0320], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,345][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.4518e-06, 7.8153e-02, 2.9807e-03, 4.0196e-01, 1.0588e-01, 1.5762e-03,
        7.6703e-02, 3.2616e-02, 9.2859e-02, 2.8245e-04, 1.4476e-01, 1.2589e-02,
        2.9563e-02, 2.0071e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,346][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.1405e-04, 4.2138e-01, 2.2327e-02, 4.6765e-01, 4.3137e-02, 2.8808e-03,
        1.3236e-04, 2.9217e-04, 5.9213e-03, 4.6038e-05, 3.4488e-02, 1.1214e-04,
        9.9764e-04, 4.2092e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,348][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0006, 0.2112, 0.0049, 0.1880, 0.0374, 0.0085, 0.0570, 0.0834, 0.0735,
        0.0039, 0.1660, 0.0309, 0.0519, 0.0828], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,350][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0048, 0.0781, 0.0500, 0.1877, 0.3957, 0.0094, 0.0154, 0.0162, 0.0601,
        0.0013, 0.0961, 0.0192, 0.0200, 0.0130, 0.0330], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,351][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([9.7023e-06, 4.1387e-02, 1.0386e-02, 1.4918e-01, 2.2509e-01, 1.1474e-03,
        4.3051e-02, 6.2000e-02, 1.0870e-01, 4.4595e-04, 1.0396e-01, 2.7704e-02,
        6.2774e-02, 1.0269e-01, 6.1473e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,353][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0242, 0.0525, 0.4083, 0.1183, 0.2736, 0.0172, 0.0176, 0.0022, 0.0182,
        0.0036, 0.0186, 0.0108, 0.0163, 0.0016, 0.0170], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,354][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([7.0636e-04, 4.2256e-01, 4.5290e-02, 3.9230e-01, 9.3456e-02, 6.2682e-03,
        1.6270e-04, 2.4246e-04, 6.1987e-03, 2.7448e-05, 3.1762e-02, 3.9918e-05,
        6.8671e-04, 2.4556e-04, 5.4980e-05], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,356][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0011, 0.0573, 0.0509, 0.0723, 0.1262, 0.0059, 0.0311, 0.0549, 0.1426,
        0.0036, 0.2072, 0.0467, 0.0120, 0.1208, 0.0674], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,358][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0100, 0.0836, 0.0875, 0.1226, 0.1190, 0.0233, 0.0805, 0.0483, 0.1394,
        0.0106, 0.0812, 0.0252, 0.0587, 0.0303, 0.0798], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,359][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([7.8116e-07, 3.2437e-02, 2.6483e-03, 2.8179e-01, 1.9628e-01, 8.8715e-04,
        1.0370e-02, 5.4029e-02, 1.6201e-01, 1.0059e-04, 1.7318e-01, 2.9963e-02,
        1.1743e-02, 3.0396e-02, 1.4171e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,361][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0160, 0.1892, 0.0683, 0.4232, 0.0542, 0.0300, 0.0043, 0.0077, 0.0411,
        0.0017, 0.1432, 0.0010, 0.0088, 0.0059, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,363][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0013, 0.1015, 0.0804, 0.1137, 0.2812, 0.0054, 0.0351, 0.0202, 0.0514,
        0.0038, 0.0981, 0.0289, 0.0294, 0.0387, 0.1108], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,364][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.0449e-06, 6.3355e-02, 2.9960e-03, 4.4176e-01, 1.2712e-01, 1.5373e-03,
        4.6198e-02, 3.3028e-02, 8.2062e-02, 1.9270e-04, 1.3477e-01, 1.1579e-02,
        1.9872e-02, 1.7283e-02, 1.8250e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,365][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([6.0344e-05, 3.2910e-01, 1.3551e-02, 5.3433e-01, 6.3604e-02, 2.3730e-03,
        2.2402e-04, 3.3303e-04, 8.3148e-03, 2.0701e-05, 4.2404e-02, 5.6508e-05,
        4.5813e-03, 6.3312e-04, 4.1727e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,366][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0007, 0.2281, 0.0081, 0.2452, 0.0323, 0.0110, 0.0539, 0.0694, 0.0649,
        0.0063, 0.1181, 0.0179, 0.0533, 0.0451, 0.0457], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,367][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0141, 0.0751, 0.0798, 0.1443, 0.3616, 0.0138, 0.0182, 0.0149, 0.0596,
        0.0028, 0.0994, 0.0260, 0.0227, 0.0162, 0.0246, 0.0270],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,368][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([5.6815e-06, 3.6462e-02, 6.5548e-03, 1.1333e-01, 1.5361e-01, 1.1043e-03,
        5.9131e-02, 6.6816e-02, 1.1170e-01, 4.3775e-04, 1.1495e-01, 1.8712e-02,
        5.6635e-02, 1.4965e-01, 3.7857e-02, 7.3045e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,369][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0334, 0.0490, 0.4791, 0.1019, 0.1848, 0.0202, 0.0183, 0.0032, 0.0237,
        0.0056, 0.0195, 0.0111, 0.0214, 0.0027, 0.0136, 0.0124],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,371][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.0354e-02, 4.7647e-01, 1.1056e-01, 2.8823e-01, 7.3916e-02, 1.1643e-02,
        1.1991e-04, 1.6347e-04, 3.6079e-03, 8.2160e-05, 2.4249e-02, 7.5575e-05,
        2.0168e-04, 1.4017e-04, 2.3477e-05, 1.6548e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,372][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0013, 0.0381, 0.0629, 0.0313, 0.0988, 0.0056, 0.0312, 0.0444, 0.1196,
        0.0048, 0.1752, 0.0520, 0.0152, 0.1350, 0.0800, 0.1047],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,374][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0176, 0.0989, 0.0902, 0.1272, 0.1121, 0.0256, 0.0707, 0.0485, 0.1214,
        0.0109, 0.0683, 0.0292, 0.0492, 0.0304, 0.0410, 0.0587],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,375][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.0248e-06, 3.1615e-02, 4.0937e-03, 2.0078e-01, 1.4783e-01, 1.1257e-03,
        1.3746e-02, 5.2398e-02, 2.2198e-01, 1.6093e-04, 1.6449e-01, 2.3161e-02,
        1.4897e-02, 3.0264e-02, 1.1890e-02, 8.1560e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,377][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0395, 0.2105, 0.0933, 0.3837, 0.0580, 0.0295, 0.0035, 0.0064, 0.0316,
        0.0022, 0.1153, 0.0014, 0.0064, 0.0056, 0.0031, 0.0102],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,379][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0036, 0.0782, 0.1681, 0.0642, 0.3881, 0.0091, 0.0251, 0.0136, 0.0254,
        0.0058, 0.0543, 0.0370, 0.0259, 0.0256, 0.0606, 0.0154],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,380][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([5.8616e-07, 9.5133e-02, 4.1959e-03, 4.3134e-01, 1.1444e-01, 1.8247e-03,
        5.3108e-02, 2.7218e-02, 8.8698e-02, 2.9186e-04, 1.1119e-01, 7.5577e-03,
        1.9619e-02, 1.4042e-02, 1.0424e-02, 2.0915e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,381][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.8722e-04, 3.0980e-01, 2.9124e-02, 5.1967e-01, 6.5475e-02, 3.1519e-03,
        1.9105e-04, 3.8902e-04, 8.6823e-03, 4.0884e-05, 5.9177e-02, 1.4488e-04,
        2.4059e-03, 6.2035e-04, 2.3416e-04, 7.1095e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,383][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0006, 0.2061, 0.0062, 0.2257, 0.0485, 0.0083, 0.0472, 0.0827, 0.0651,
        0.0043, 0.1181, 0.0232, 0.0390, 0.0648, 0.0294, 0.0309],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,385][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0483, 0.1207, 0.0927, 0.1775, 0.1740, 0.0207, 0.0235, 0.0240, 0.0631,
        0.0046, 0.0813, 0.0199, 0.0231, 0.0152, 0.0208, 0.0254, 0.0651],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,386][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([3.9258e-05, 6.8595e-02, 1.4500e-02, 1.0963e-01, 9.0863e-02, 2.3156e-03,
        5.3761e-02, 6.2651e-02, 1.1949e-01, 1.4423e-03, 9.5025e-02, 2.2422e-02,
        4.3564e-02, 9.5372e-02, 3.7538e-02, 8.1979e-02, 1.0081e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,388][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.2536, 0.0595, 0.5147, 0.0312, 0.0428, 0.0304, 0.0056, 0.0010, 0.0061,
        0.0078, 0.0052, 0.0048, 0.0045, 0.0007, 0.0034, 0.0027, 0.0261],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,389][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([1.7009e-02, 4.9596e-01, 2.0223e-01, 1.3620e-01, 9.1318e-02, 2.3459e-02,
        6.5000e-04, 5.7245e-04, 8.7026e-03, 2.3689e-04, 1.9165e-02, 1.2390e-04,
        6.4890e-04, 3.3939e-04, 9.5516e-05, 6.6624e-04, 2.6315e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,391][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0014, 0.0440, 0.0467, 0.0382, 0.0483, 0.0057, 0.0258, 0.0485, 0.1350,
        0.0054, 0.1313, 0.0369, 0.0099, 0.1088, 0.0705, 0.1075, 0.1360],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,393][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0333, 0.0348, 0.0965, 0.0397, 0.0679, 0.0278, 0.0711, 0.0320, 0.0717,
        0.0176, 0.0343, 0.0200, 0.0277, 0.0177, 0.0253, 0.0280, 0.3546],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,394][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([8.7198e-06, 3.8892e-02, 7.7994e-03, 2.1395e-01, 8.2975e-02, 3.4063e-03,
        1.4258e-02, 7.4018e-02, 1.9201e-01, 6.2549e-04, 1.8783e-01, 2.4070e-02,
        1.5544e-02, 1.7481e-02, 1.4276e-02, 7.5929e-02, 3.6926e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,396][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.2190, 0.1565, 0.1928, 0.1748, 0.0497, 0.0679, 0.0036, 0.0051, 0.0230,
        0.0055, 0.0579, 0.0015, 0.0036, 0.0027, 0.0016, 0.0057, 0.0291],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,398][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0064, 0.0768, 0.1255, 0.0552, 0.1757, 0.0116, 0.0527, 0.0155, 0.0336,
        0.0080, 0.0636, 0.0332, 0.0329, 0.0255, 0.0628, 0.0249, 0.1961],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,399][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([6.2330e-06, 6.1050e-02, 6.5828e-03, 3.6664e-01, 9.7975e-02, 2.8209e-03,
        7.7354e-02, 4.4872e-02, 8.8938e-02, 5.4900e-04, 9.4028e-02, 1.4438e-02,
        2.1531e-02, 1.1493e-02, 1.3434e-02, 2.9836e-02, 6.8448e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,401][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([4.0906e-04, 4.2495e-01, 4.4797e-02, 3.5179e-01, 1.0218e-01, 6.0951e-03,
        7.2208e-04, 7.0591e-04, 1.6296e-02, 7.9034e-05, 4.0337e-02, 2.3783e-04,
        3.1881e-03, 7.1559e-04, 3.8392e-04, 1.4278e-03, 5.6829e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,402][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0005, 0.2409, 0.0056, 0.1955, 0.0360, 0.0076, 0.0584, 0.0552, 0.0640,
        0.0052, 0.1275, 0.0220, 0.0420, 0.0283, 0.0428, 0.0333, 0.0354],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,404][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0216, 0.0770, 0.0847, 0.1282, 0.3125, 0.0166, 0.0213, 0.0153, 0.0433,
        0.0036, 0.0781, 0.0258, 0.0212, 0.0129, 0.0208, 0.0227, 0.0753, 0.0189],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,406][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.0971e-06, 3.1745e-02, 8.9360e-03, 7.5463e-02, 2.1177e-01, 1.2772e-03,
        4.8809e-02, 5.6576e-02, 7.3103e-02, 5.1830e-04, 7.3464e-02, 2.8157e-02,
        5.4804e-02, 1.1126e-01, 3.4909e-02, 4.2045e-02, 6.3576e-02, 8.3576e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,407][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0391, 0.0520, 0.3960, 0.1006, 0.1614, 0.0208, 0.0237, 0.0036, 0.0260,
        0.0076, 0.0177, 0.0110, 0.0248, 0.0027, 0.0149, 0.0136, 0.0808, 0.0036],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,408][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.7574e-02, 4.6423e-01, 1.6341e-01, 2.3001e-01, 6.3895e-02, 1.6668e-02,
        1.6842e-04, 2.0236e-04, 2.9872e-03, 2.1720e-04, 1.7055e-02, 1.2005e-04,
        1.8122e-04, 1.0210e-04, 2.1687e-05, 1.3522e-04, 2.8287e-03, 1.9078e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,409][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0006, 0.0358, 0.0259, 0.0283, 0.0771, 0.0034, 0.0288, 0.0342, 0.0705,
        0.0022, 0.1601, 0.0343, 0.0125, 0.1039, 0.0711, 0.1019, 0.0980, 0.1114],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,410][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0128, 0.0746, 0.0478, 0.0707, 0.0750, 0.0167, 0.0439, 0.0320, 0.0689,
        0.0082, 0.0539, 0.0243, 0.0355, 0.0264, 0.0286, 0.0434, 0.2922, 0.0450],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,412][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.4008e-06, 2.8207e-02, 4.3499e-03, 1.3790e-01, 1.5134e-01, 1.3203e-03,
        1.9513e-02, 4.1824e-02, 1.3504e-01, 2.1403e-04, 1.6668e-01, 3.6545e-02,
        1.9990e-02, 4.1607e-02, 2.0637e-02, 7.2122e-02, 5.4867e-02, 6.7836e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,414][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0555, 0.2022, 0.0963, 0.2984, 0.0704, 0.0374, 0.0044, 0.0079, 0.0312,
        0.0031, 0.1120, 0.0025, 0.0076, 0.0052, 0.0035, 0.0108, 0.0425, 0.0091],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,415][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0058, 0.0679, 0.1440, 0.0504, 0.2834, 0.0126, 0.0345, 0.0125, 0.0265,
        0.0089, 0.0448, 0.0356, 0.0309, 0.0191, 0.0461, 0.0158, 0.1354, 0.0259],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,417][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.2860e-06, 9.7863e-02, 5.4067e-03, 3.5297e-01, 9.9656e-02, 2.6172e-03,
        6.2779e-02, 2.7313e-02, 7.5818e-02, 4.2708e-04, 1.1106e-01, 1.0434e-02,
        2.0034e-02, 1.6975e-02, 1.6098e-02, 1.5961e-02, 6.3012e-02, 2.1573e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,418][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.2151e-04, 4.0526e-01, 3.3120e-02, 4.5557e-01, 5.2355e-02, 3.1561e-03,
        1.5115e-04, 3.5025e-04, 6.3978e-03, 5.6660e-05, 3.4740e-02, 1.8230e-04,
        1.0286e-03, 4.4582e-04, 1.3553e-04, 4.4229e-04, 5.5104e-03, 7.7632e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,420][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0010, 0.2091, 0.0061, 0.1725, 0.0369, 0.0101, 0.0468, 0.0678, 0.0550,
        0.0042, 0.1269, 0.0303, 0.0356, 0.0592, 0.0266, 0.0269, 0.0330, 0.0517],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,423][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:08,425][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[18350],
        [ 1507],
        [  769],
        [  375],
        [  176],
        [  263],
        [  209],
        [  115],
        [  141],
        [  288],
        [  101],
        [  286],
        [  260],
        [  207],
        [  266],
        [  221],
        [  157],
        [  168]], device='cuda:0')
[2024-07-24 10:26:08,427][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5317],
        [3054],
        [1433],
        [ 919],
        [ 429],
        [ 530],
        [ 531],
        [ 251],
        [ 318],
        [ 686],
        [ 235],
        [ 720],
        [ 632],
        [ 480],
        [ 759],
        [ 587],
        [ 462],
        [ 446]], device='cuda:0')
[2024-07-24 10:26:08,429][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[34092],
        [24466],
        [ 4171],
        [ 4028],
        [ 7163],
        [11949],
        [22654],
        [20968],
        [15013],
        [21881],
        [16833],
        [24339],
        [17957],
        [25037],
        [17010],
        [18115],
        [14688],
        [22910]], device='cuda:0')
[2024-07-24 10:26:08,431][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 4386],
        [40191],
        [39773],
        [40417],
        [33598],
        [34677],
        [31506],
        [30748],
        [32521],
        [30802],
        [32103],
        [33533],
        [31816],
        [32140],
        [31638],
        [31849],
        [28953],
        [29458]], device='cuda:0')
[2024-07-24 10:26:08,433][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8119],
        [12306],
        [26777],
        [21848],
        [23873],
        [18179],
        [16272],
        [15255],
        [15046],
        [12468],
        [12097],
        [13809],
        [12610],
        [12053],
        [12035],
        [11540],
        [11467],
        [10914]], device='cuda:0')
[2024-07-24 10:26:08,435][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25399],
        [23724],
        [18799],
        [15042],
        [15926],
        [15481],
        [11796],
        [11897],
        [14563],
        [10916],
        [13953],
        [11275],
        [11800],
        [11677],
        [11198],
        [11738],
        [12423],
        [12128]], device='cuda:0')
[2024-07-24 10:26:08,437][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[12663],
        [14749],
        [25869],
        [25958],
        [21481],
        [25232],
        [25277],
        [22353],
        [24739],
        [18522],
        [21064],
        [19472],
        [21726],
        [21185],
        [21759],
        [22528],
        [21060],
        [21411]], device='cuda:0')
[2024-07-24 10:26:08,439][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[13889],
        [ 3834],
        [ 9699],
        [ 6601],
        [ 6021],
        [ 5241],
        [ 3662],
        [ 4294],
        [ 4096],
        [ 4008],
        [ 3465],
        [ 3234],
        [ 3065],
        [ 3027],
        [ 2923],
        [ 3074],
        [ 3202],
        [ 2915]], device='cuda:0')
[2024-07-24 10:26:08,440][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26145],
        [ 6388],
        [15776],
        [ 9078],
        [12813],
        [12707],
        [12589],
        [ 9410],
        [10009],
        [10398],
        [10839],
        [ 9907],
        [ 8044],
        [ 7976],
        [ 8436],
        [ 8073],
        [ 8301],
        [ 9210]], device='cuda:0')
[2024-07-24 10:26:08,442][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1017],
        [ 1175],
        [ 7705],
        [ 3863],
        [ 9627],
        [14425],
        [16009],
        [15110],
        [12820],
        [11509],
        [11366],
        [10434],
        [12615],
        [ 9967],
        [ 8085],
        [ 7488],
        [ 6869],
        [ 6645]], device='cuda:0')
[2024-07-24 10:26:08,444][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16566],
        [ 1787],
        [  404],
        [ 1270],
        [  295],
        [  384],
        [  599],
        [  447],
        [  526],
        [ 1137],
        [ 1381],
        [  973],
        [ 1424],
        [ 1345],
        [ 1855],
        [ 1440],
        [ 1414],
        [ 1831]], device='cuda:0')
[2024-07-24 10:26:08,446][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 3358],
        [ 2509],
        [ 2742],
        [ 5193],
        [ 6101],
        [ 5641],
        [ 8728],
        [ 9764],
        [13190],
        [11759],
        [15168],
        [16584],
        [13410],
        [13569],
        [13387],
        [15685],
        [15180],
        [15178]], device='cuda:0')
[2024-07-24 10:26:08,448][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22966],
        [23733],
        [23523],
        [18623],
        [20553],
        [17067],
        [16065],
        [17185],
        [18672],
        [17478],
        [18977],
        [19319],
        [17725],
        [18472],
        [17604],
        [17691],
        [19232],
        [18476]], device='cuda:0')
[2024-07-24 10:26:08,450][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22880],
        [19338],
        [19417],
        [17677],
        [18098],
        [18027],
        [17568],
        [16632],
        [16140],
        [16591],
        [15394],
        [16029],
        [15178],
        [14564],
        [14026],
        [14246],
        [14159],
        [14118]], device='cuda:0')
[2024-07-24 10:26:08,451][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[39983],
        [24795],
        [27244],
        [23027],
        [15781],
        [29317],
        [18845],
        [20202],
        [22168],
        [28992],
        [16871],
        [14256],
        [21149],
        [19840],
        [22319],
        [18915],
        [21002],
        [15150]], device='cuda:0')
[2024-07-24 10:26:08,453][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 5515],
        [ 6729],
        [ 4682],
        [10926],
        [ 5542],
        [ 3659],
        [ 4825],
        [ 5466],
        [ 5108],
        [ 4788],
        [ 4582],
        [ 4436],
        [ 4076],
        [ 4629],
        [ 4438],
        [ 4310],
        [ 5032],
        [ 4004]], device='cuda:0')
[2024-07-24 10:26:08,455][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[42856],
        [19920],
        [18862],
        [20608],
        [36195],
        [34222],
        [32645],
        [30801],
        [26036],
        [19925],
        [25618],
        [25123],
        [18245],
        [17155],
        [17499],
        [15052],
        [14782],
        [16682]], device='cuda:0')
[2024-07-24 10:26:08,456][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[16916],
        [ 4441],
        [ 7512],
        [ 9252],
        [ 8859],
        [ 9672],
        [10660],
        [10917],
        [10962],
        [12744],
        [ 9938],
        [11993],
        [10880],
        [11563],
        [ 9455],
        [ 9913],
        [10228],
        [12141]], device='cuda:0')
[2024-07-24 10:26:08,458][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 5737],
        [ 8374],
        [13741],
        [27797],
        [23629],
        [29603],
        [35201],
        [34830],
        [30201],
        [31955],
        [32773],
        [32379],
        [33149],
        [34206],
        [33507],
        [33682],
        [32502],
        [34230]], device='cuda:0')
[2024-07-24 10:26:08,460][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 7292],
        [28876],
        [24933],
        [22484],
        [18575],
        [17246],
        [14481],
        [10195],
        [ 8662],
        [ 8369],
        [ 6392],
        [ 6840],
        [ 6745],
        [ 4421],
        [ 4521],
        [ 3761],
        [ 4251],
        [ 3622]], device='cuda:0')
[2024-07-24 10:26:08,462][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[16509],
        [15459],
        [27894],
        [28359],
        [26569],
        [25247],
        [28911],
        [29169],
        [27909],
        [29238],
        [26161],
        [25445],
        [27761],
        [26630],
        [26950],
        [26369],
        [20412],
        [20002]], device='cuda:0')
[2024-07-24 10:26:08,463][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25434],
        [33831],
        [33147],
        [38825],
        [38370],
        [37199],
        [38213],
        [38200],
        [39976],
        [40495],
        [38667],
        [38606],
        [38738],
        [38811],
        [38170],
        [38944],
        [39207],
        [39903]], device='cuda:0')
[2024-07-24 10:26:08,465][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8111],
        [ 7537],
        [ 4600],
        [ 7960],
        [ 7232],
        [ 9181],
        [11002],
        [11449],
        [10325],
        [16227],
        [12622],
        [12492],
        [12270],
        [14023],
        [13670],
        [12623],
        [10747],
        [14997]], device='cuda:0')
[2024-07-24 10:26:08,467][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4678],
        [17516],
        [ 9043],
        [10179],
        [17949],
        [19233],
        [23575],
        [25325],
        [23088],
        [15367],
        [21178],
        [17865],
        [17642],
        [18435],
        [20775],
        [20542],
        [16130],
        [17892]], device='cuda:0')
[2024-07-24 10:26:08,469][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12850],
        [12550],
        [12290],
        [ 2283],
        [ 1872],
        [ 1959],
        [ 1637],
        [ 2004],
        [ 1417],
        [ 1791],
        [ 1382],
        [ 1415],
        [ 1524],
        [ 1841],
        [ 1727],
        [ 1843],
        [ 1953],
        [ 2325]], device='cuda:0')
[2024-07-24 10:26:08,471][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7873],
        [22756],
        [23131],
        [29218],
        [27092],
        [30583],
        [31194],
        [30555],
        [29601],
        [34772],
        [30183],
        [31175],
        [31731],
        [30898],
        [31873],
        [32279],
        [31229],
        [31071]], device='cuda:0')
[2024-07-24 10:26:08,473][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1376],
        [3080],
        [3091],
        [4945],
        [5386],
        [5205],
        [5925],
        [5296],
        [5453],
        [5452],
        [5810],
        [5797],
        [5734],
        [6199],
        [6242],
        [6372],
        [6228],
        [6504]], device='cuda:0')
[2024-07-24 10:26:08,475][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[47022],
        [43825],
        [42768],
        [33899],
        [34592],
        [34632],
        [29609],
        [31077],
        [35056],
        [34069],
        [36469],
        [35465],
        [36753],
        [36922],
        [37374],
        [37671],
        [40054],
        [38686]], device='cuda:0')
[2024-07-24 10:26:08,477][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17619],
        [22197],
        [23285],
        [25218],
        [33068],
        [19536],
        [29326],
        [29374],
        [27228],
        [20357],
        [32156],
        [35057],
        [28536],
        [28204],
        [23840],
        [29134],
        [26623],
        [31731]], device='cuda:0')
[2024-07-24 10:26:08,479][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214],
        [17214]], device='cuda:0')
[2024-07-24 10:26:08,594][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:08,595][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,597][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,598][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,598][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,599][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,600][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,601][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,601][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,602][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,603][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,603][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,604][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:08,605][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([1.7854e-04, 9.9982e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,605][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.6258e-04, 9.9964e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,606][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0181, 0.9819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,607][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,608][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0183, 0.9817], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,609][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6736, 0.3264], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,610][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0716, 0.9284], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,610][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3969, 0.6031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,611][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0055, 0.9945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,612][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0298, 0.9702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,613][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0401, 0.9599], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,613][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0026, 0.9974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:08,614][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.0075, 0.2203, 0.7722], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,615][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([6.0932e-04, 9.0917e-01, 9.0220e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,616][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.0190, 0.5222, 0.4588], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,618][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.0035, 0.8282, 0.1682], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,619][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.0137, 0.8541, 0.1322], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,621][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([0.2239, 0.6196, 0.1565], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,623][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.0627, 0.7619, 0.1755], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,624][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.7049, 0.1198, 0.1754], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,626][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([0.0024, 0.8168, 0.1808], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,627][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([0.0168, 0.4411, 0.5420], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,629][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.0271, 0.0174, 0.9555], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,631][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0019, 0.4737, 0.5245], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:08,632][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([1.1560e-04, 1.6637e-01, 3.2333e-01, 5.1018e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,633][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.8931e-04, 3.6912e-01, 2.9020e-02, 6.0137e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,634][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0059, 0.3722, 0.2866, 0.3352], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,636][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0010, 0.5149, 0.0694, 0.4148], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,637][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0068, 0.3799, 0.0290, 0.5843], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,639][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1581, 0.4212, 0.1316, 0.2891], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,641][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1518, 0.5143, 0.1065, 0.2274], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,642][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4480, 0.1466, 0.2205, 0.1849], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,643][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([6.8058e-04, 2.0752e-01, 3.6749e-02, 7.5505e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,645][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0023, 0.1505, 0.7301, 0.1172], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,646][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0033, 0.0410, 0.8573, 0.0984], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,647][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.2482e-04, 1.1994e-01, 1.0032e-01, 7.7952e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:08,647][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0007, 0.1359, 0.3266, 0.2272, 0.3097], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,648][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0010, 0.3418, 0.0253, 0.3648, 0.2670], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,649][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0022, 0.2941, 0.2282, 0.2708, 0.2047], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,650][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0026, 0.4157, 0.0511, 0.3141, 0.2164], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,652][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0091, 0.3839, 0.0349, 0.4730, 0.0991], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,654][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0545, 0.2828, 0.0985, 0.2748, 0.2894], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,655][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.5960, 0.2210, 0.1022, 0.0671, 0.0137], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,657][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.5353, 0.1444, 0.1004, 0.1334, 0.0866], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,658][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0030, 0.2362, 0.1998, 0.3126, 0.2483], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,660][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([0.0109, 0.2782, 0.5998, 0.0949, 0.0162], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,662][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0148, 0.0136, 0.8966, 0.0429, 0.0320], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,663][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([4.6309e-04, 9.4483e-02, 9.0299e-02, 3.1291e-01, 5.0185e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:08,664][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ were] are: tensor([2.2889e-04, 6.5021e-02, 1.4311e-01, 1.4558e-01, 6.2100e-01, 2.5054e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,665][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ were] are: tensor([1.0982e-04, 1.8105e-01, 1.4414e-02, 4.3819e-01, 3.4994e-01, 1.6302e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,667][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0062, 0.2213, 0.1868, 0.2023, 0.1735, 0.2099], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,668][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0011, 0.2405, 0.1202, 0.1866, 0.1662, 0.2854], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,670][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0133, 0.3140, 0.0301, 0.4796, 0.1017, 0.0613], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,672][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.1257, 0.1458, 0.0357, 0.0954, 0.1159, 0.4815], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,673][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0282, 0.3857, 0.0951, 0.2848, 0.1051, 0.1011], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,675][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.5482, 0.0712, 0.1126, 0.0666, 0.0193, 0.1821], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,677][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0020, 0.2053, 0.0514, 0.4710, 0.1899, 0.0803], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,678][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0021, 0.2208, 0.3878, 0.2900, 0.0447, 0.0546], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,680][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0053, 0.0069, 0.7617, 0.0192, 0.0122, 0.1946], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,681][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ were] are: tensor([8.3155e-05, 8.4868e-02, 3.1666e-02, 2.8654e-01, 5.7951e-01, 1.7324e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:08,682][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ working] are: tensor([1.8127e-05, 1.5047e-01, 7.6629e-02, 3.6497e-01, 3.1207e-01, 1.6359e-02,
        7.9480e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,684][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0006, 0.3345, 0.0160, 0.3974, 0.2093, 0.0120, 0.0301],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,685][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0009, 0.1907, 0.1507, 0.1830, 0.1412, 0.1766, 0.1568],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,687][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0006, 0.2534, 0.0287, 0.2111, 0.1502, 0.1345, 0.2215],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,688][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0094, 0.2953, 0.0219, 0.4213, 0.0766, 0.0430, 0.1324],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,689][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0067, 0.1156, 0.0330, 0.1194, 0.1162, 0.4651, 0.1440],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,690][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.1999, 0.4731, 0.0582, 0.1760, 0.0147, 0.0754, 0.0028],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,691][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0777, 0.1675, 0.1198, 0.1925, 0.0758, 0.2680, 0.0987],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,691][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0016, 0.1085, 0.0953, 0.3055, 0.1768, 0.1035, 0.2088],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,693][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ working] are: tensor([7.3355e-05, 3.4134e-01, 8.6995e-02, 5.2159e-01, 2.5615e-02, 2.1285e-02,
        3.1036e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,694][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0057, 0.0134, 0.5788, 0.0395, 0.0263, 0.3189, 0.0174],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,695][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ working] are: tensor([1.7662e-05, 6.3250e-02, 1.2620e-02, 3.6021e-01, 3.7225e-01, 1.1796e-02,
        1.7986e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:08,696][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([6.7840e-06, 7.4813e-02, 8.2276e-02, 2.6365e-01, 3.8410e-01, 1.1145e-02,
        7.8682e-02, 1.0533e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,698][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0006, 0.2747, 0.0182, 0.2941, 0.2739, 0.0127, 0.0423, 0.0835],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,699][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0010, 0.1713, 0.1340, 0.1567, 0.1196, 0.1543, 0.1361, 0.1271],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,701][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0003, 0.2010, 0.0307, 0.1646, 0.1149, 0.1396, 0.1662, 0.1827],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,703][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0057, 0.2400, 0.0184, 0.3509, 0.0572, 0.0320, 0.0992, 0.1966],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,704][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0235, 0.1381, 0.0553, 0.0975, 0.0853, 0.4397, 0.0869, 0.0740],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,706][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1607, 0.4724, 0.0760, 0.1742, 0.0214, 0.0790, 0.0030, 0.0134],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,708][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1175, 0.1189, 0.1325, 0.1579, 0.0544, 0.2794, 0.0597, 0.0797],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,710][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0017, 0.1324, 0.0756, 0.2857, 0.1219, 0.0913, 0.1219, 0.1696],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,711][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.1372e-04, 4.3552e-01, 2.3149e-01, 3.0818e-01, 1.4646e-02, 9.0104e-03,
        8.1508e-04, 2.2027e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,712][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0052, 0.0155, 0.5774, 0.0443, 0.0324, 0.2754, 0.0212, 0.0288],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,714][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0003, 0.0393, 0.0470, 0.1595, 0.2909, 0.0234, 0.1600, 0.2795],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:08,715][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.0553e-05, 6.5401e-02, 1.3227e-01, 1.4806e-01, 3.3679e-01, 7.7350e-03,
        4.2021e-02, 3.8767e-02, 2.2895e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,716][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.5144e-04, 2.0267e-01, 1.4863e-02, 2.6911e-01, 2.4069e-01, 8.2813e-03,
        3.6343e-02, 6.7468e-02, 1.6033e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,718][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0011, 0.1520, 0.1189, 0.1422, 0.1077, 0.1357, 0.1211, 0.1125, 0.1088],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,720][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0002, 0.1617, 0.0279, 0.1402, 0.0957, 0.1120, 0.1396, 0.1456, 0.1771],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,721][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0040, 0.2101, 0.0147, 0.3115, 0.0493, 0.0269, 0.0869, 0.1714, 0.1252],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,723][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0303, 0.1126, 0.0390, 0.0855, 0.0845, 0.4077, 0.0968, 0.0714, 0.0722],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,725][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0628, 0.4836, 0.0639, 0.2529, 0.0233, 0.0556, 0.0047, 0.0158, 0.0374],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,726][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1915, 0.1124, 0.1103, 0.1381, 0.0472, 0.2686, 0.0475, 0.0474, 0.0370],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,728][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0016, 0.1023, 0.0754, 0.2041, 0.1249, 0.0768, 0.0862, 0.1041, 0.2246],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,729][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.5195e-03, 2.0068e-01, 6.3754e-01, 1.3650e-01, 9.1814e-03, 1.2343e-02,
        4.1170e-04, 6.5901e-05, 1.7497e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,731][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0066, 0.0161, 0.5807, 0.0401, 0.0291, 0.2467, 0.0185, 0.0226, 0.0396],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,731][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.9176e-04, 3.2689e-02, 3.1517e-02, 1.2892e-01, 1.7179e-01, 1.3144e-02,
        8.8049e-02, 1.4496e-01, 3.8873e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:08,732][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([1.5467e-04, 4.4170e-02, 9.6848e-02, 8.5996e-02, 4.2497e-01, 2.2388e-02,
        6.7358e-02, 6.9865e-02, 1.7922e-01, 9.0251e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,733][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([7.1667e-05, 9.5596e-02, 9.0648e-03, 2.2825e-01, 2.2396e-01, 9.0739e-03,
        7.5005e-02, 1.4996e-01, 2.0291e-01, 6.1082e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,734][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([0.0027, 0.1269, 0.1004, 0.1185, 0.0984, 0.1198, 0.1133, 0.1050, 0.0992,
        0.1158], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,735][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0017, 0.1653, 0.0447, 0.1270, 0.0905, 0.1638, 0.1079, 0.1083, 0.1246,
        0.0662], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,737][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([0.0050, 0.1364, 0.0167, 0.2787, 0.0587, 0.0436, 0.0907, 0.2101, 0.1508,
        0.0093], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,739][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([0.0152, 0.0986, 0.0144, 0.0459, 0.0400, 0.6658, 0.0452, 0.0266, 0.0290,
        0.0194], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,740][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([0.0330, 0.3465, 0.0677, 0.2207, 0.0658, 0.0778, 0.0213, 0.0577, 0.0814,
        0.0281], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,742][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([0.3387, 0.0720, 0.0843, 0.0749, 0.0340, 0.2136, 0.0335, 0.0386, 0.0233,
        0.0871], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,744][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.0006, 0.0950, 0.0388, 0.2164, 0.1101, 0.0360, 0.1218, 0.1523, 0.2078,
        0.0214], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,745][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([4.1007e-06, 3.3256e-01, 2.6083e-02, 5.1090e-01, 4.1676e-02, 7.1807e-03,
        7.3783e-03, 3.7461e-03, 7.0325e-02, 1.4705e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,747][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([0.0144, 0.0032, 0.6897, 0.0115, 0.0093, 0.2175, 0.0054, 0.0063, 0.0123,
        0.0305], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,748][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([6.0545e-07, 7.7914e-03, 1.2727e-03, 4.3029e-02, 1.4642e-01, 9.1088e-04,
        5.0416e-02, 1.8751e-01, 5.6240e-01, 2.5377e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:08,749][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([5.5498e-06, 2.4271e-02, 9.0947e-02, 1.0299e-01, 3.7384e-01, 5.2360e-03,
        3.7255e-02, 3.5954e-02, 1.8134e-01, 1.1862e-03, 1.4698e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,750][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.9359e-04, 1.6431e-01, 1.2695e-02, 2.0963e-01, 2.1339e-01, 7.4471e-03,
        3.3110e-02, 5.8419e-02, 1.0743e-01, 2.7007e-03, 1.9067e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,752][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0007, 0.1218, 0.0997, 0.1144, 0.0895, 0.1113, 0.0981, 0.0891, 0.0864,
        0.0971, 0.0921], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,754][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0002, 0.1417, 0.0216, 0.1093, 0.0818, 0.0714, 0.1245, 0.1258, 0.1461,
        0.0588, 0.1188], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,755][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0029, 0.1702, 0.0165, 0.2408, 0.0445, 0.0264, 0.0761, 0.1437, 0.0997,
        0.0080, 0.1714], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,757][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0108, 0.1050, 0.0386, 0.0859, 0.0714, 0.3429, 0.0840, 0.0682, 0.0750,
        0.0530, 0.0651], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,759][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0727, 0.4152, 0.0808, 0.2001, 0.0318, 0.0614, 0.0057, 0.0162, 0.0302,
        0.0106, 0.0751], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,761][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0628, 0.1039, 0.1137, 0.1530, 0.0437, 0.2692, 0.0477, 0.0486, 0.0456,
        0.0495, 0.0624], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,762][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0012, 0.0654, 0.0458, 0.1689, 0.1123, 0.0514, 0.0788, 0.1147, 0.2059,
        0.0148, 0.1408], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,763][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([8.7443e-04, 1.1172e-01, 7.9701e-01, 6.8104e-02, 9.0981e-03, 9.6575e-03,
        1.4445e-04, 2.4544e-05, 9.8874e-04, 3.0812e-05, 2.3485e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,765][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0019, 0.0132, 0.5508, 0.0377, 0.0253, 0.2195, 0.0163, 0.0207, 0.0379,
        0.0624, 0.0143], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,766][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([4.4267e-05, 9.8785e-03, 2.3499e-02, 6.0127e-02, 1.9884e-01, 7.5299e-03,
        1.0353e-01, 1.1916e-01, 2.6394e-01, 2.3279e-03, 2.1113e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:08,768][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([2.8405e-05, 4.6594e-02, 9.7144e-02, 1.2119e-01, 3.0080e-01, 1.1300e-02,
        2.9552e-02, 3.2262e-02, 1.5297e-01, 2.0334e-03, 1.5880e-01, 4.7333e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,769][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([2.0459e-04, 1.4384e-01, 1.2617e-02, 1.7882e-01, 2.2080e-01, 7.6237e-03,
        2.7731e-02, 5.2172e-02, 9.7241e-02, 2.7574e-03, 1.8302e-01, 7.3179e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,771][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0005, 0.1103, 0.0876, 0.1046, 0.0770, 0.1003, 0.0905, 0.0837, 0.0800,
        0.0916, 0.0832, 0.0907], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,772][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0002, 0.1422, 0.0162, 0.1101, 0.0715, 0.0811, 0.1047, 0.1126, 0.1343,
        0.0468, 0.1119, 0.0685], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,774][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0031, 0.1454, 0.0195, 0.2010, 0.0428, 0.0279, 0.0770, 0.1385, 0.0981,
        0.0124, 0.1620, 0.0724], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,776][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([0.0113, 0.0905, 0.0285, 0.0618, 0.0581, 0.3988, 0.0847, 0.0525, 0.0560,
        0.0679, 0.0556, 0.0344], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,777][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.2268, 0.3072, 0.1047, 0.1288, 0.0297, 0.0830, 0.0028, 0.0114, 0.0199,
        0.0143, 0.0552, 0.0163], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,778][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0485, 0.1091, 0.0475, 0.1411, 0.0832, 0.1542, 0.0704, 0.0744, 0.0508,
        0.0453, 0.0993, 0.0763], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,779][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([0.0005, 0.0685, 0.0518, 0.1152, 0.1277, 0.0359, 0.0789, 0.0998, 0.1928,
        0.0148, 0.1411, 0.0729], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,780][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([2.1091e-05, 6.3148e-01, 1.2043e-01, 1.9208e-01, 2.2325e-02, 6.3672e-03,
        1.6377e-03, 2.6264e-04, 6.4137e-03, 4.6644e-05, 1.8890e-02, 5.5513e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,781][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0030, 0.0091, 0.4791, 0.0284, 0.0208, 0.3138, 0.0132, 0.0180, 0.0347,
        0.0564, 0.0122, 0.0113], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,782][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([9.0491e-06, 1.4523e-02, 7.8527e-03, 8.4952e-02, 1.6880e-01, 4.1450e-03,
        3.9945e-02, 1.4231e-01, 2.8491e-01, 8.7443e-04, 1.7159e-01, 8.0098e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:08,784][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([3.1058e-05, 4.5078e-02, 1.1000e-01, 8.7952e-02, 2.5984e-01, 8.9148e-03,
        3.2399e-02, 3.3829e-02, 1.6840e-01, 2.3263e-03, 1.4544e-01, 3.4291e-02,
        7.1494e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,785][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0008, 0.1502, 0.0201, 0.1640, 0.2203, 0.0091, 0.0288, 0.0514, 0.0954,
        0.0055, 0.1515, 0.0558, 0.0471], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,787][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0006, 0.0978, 0.0817, 0.0917, 0.0749, 0.0861, 0.0812, 0.0739, 0.0704,
        0.0817, 0.0720, 0.0845, 0.1035], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,788][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0002, 0.1076, 0.0182, 0.0904, 0.0679, 0.0728, 0.1098, 0.1035, 0.1218,
        0.0665, 0.0949, 0.0610, 0.0853], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,789][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0069, 0.1549, 0.0130, 0.2037, 0.0336, 0.0206, 0.0645, 0.1292, 0.0954,
        0.0102, 0.1327, 0.0561, 0.0792], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,790][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0218, 0.1067, 0.0390, 0.0535, 0.0534, 0.4599, 0.0410, 0.0344, 0.0355,
        0.0402, 0.0362, 0.0210, 0.0573], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,791][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.2673, 0.3811, 0.0710, 0.1146, 0.0132, 0.0571, 0.0031, 0.0085, 0.0176,
        0.0166, 0.0380, 0.0070, 0.0049], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,793][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.2573, 0.1187, 0.0730, 0.0900, 0.0326, 0.1676, 0.0371, 0.0354, 0.0310,
        0.0333, 0.0508, 0.0264, 0.0467], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,794][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0014, 0.0531, 0.0629, 0.1460, 0.0746, 0.0445, 0.0911, 0.1167, 0.1616,
        0.0213, 0.1259, 0.0396, 0.0613], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,796][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([6.9968e-06, 2.6009e-01, 3.7856e-01, 2.8898e-01, 1.8423e-02, 8.5527e-03,
        4.2586e-04, 1.1692e-04, 9.6162e-03, 8.7922e-06, 3.4899e-02, 1.0417e-05,
        3.0917e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,797][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0044, 0.0060, 0.5791, 0.0214, 0.0145, 0.2553, 0.0089, 0.0123, 0.0244,
        0.0516, 0.0071, 0.0071, 0.0080], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,799][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([1.5449e-05, 1.5651e-02, 1.1213e-02, 5.6671e-02, 1.2164e-01, 3.8023e-03,
        4.4421e-02, 1.1012e-01, 3.6635e-01, 1.1586e-03, 1.6570e-01, 7.6692e-02,
        2.6563e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:08,800][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.0750e-05, 2.7637e-02, 7.6794e-02, 7.1378e-02, 2.6354e-01, 6.2220e-03,
        4.7491e-02, 3.5880e-02, 1.6786e-01, 2.0438e-03, 1.5176e-01, 3.3610e-02,
        7.4489e-02, 4.1278e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,802][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0006, 0.1627, 0.0176, 0.1424, 0.1781, 0.0089, 0.0402, 0.0457, 0.0935,
        0.0042, 0.1664, 0.0511, 0.0570, 0.0316], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,803][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0006, 0.0953, 0.0785, 0.0866, 0.0664, 0.0824, 0.0743, 0.0694, 0.0669,
        0.0735, 0.0693, 0.0765, 0.0934, 0.0668], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,805][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0001, 0.1017, 0.0180, 0.0844, 0.0624, 0.0619, 0.0995, 0.0933, 0.1108,
        0.0516, 0.0887, 0.0573, 0.0810, 0.0893], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,807][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0037, 0.1289, 0.0126, 0.1778, 0.0321, 0.0168, 0.0560, 0.1120, 0.0786,
        0.0064, 0.1261, 0.0512, 0.0707, 0.1272], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,808][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0237, 0.1127, 0.0418, 0.0645, 0.0537, 0.3337, 0.0451, 0.0429, 0.0447,
        0.0386, 0.0462, 0.0297, 0.0759, 0.0469], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,810][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0952, 0.4216, 0.0663, 0.1841, 0.0181, 0.0518, 0.0057, 0.0139, 0.0268,
        0.0113, 0.0731, 0.0095, 0.0075, 0.0150], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,812][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0381, 0.1108, 0.0750, 0.1320, 0.0442, 0.1834, 0.0503, 0.0578, 0.0452,
        0.0436, 0.0781, 0.0340, 0.0447, 0.0627], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,814][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0016, 0.0513, 0.0432, 0.1263, 0.0825, 0.0432, 0.0732, 0.1036, 0.1370,
        0.0206, 0.0931, 0.0481, 0.0605, 0.1157], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,815][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.4023e-05, 3.4484e-01, 2.9538e-01, 3.1370e-01, 1.2272e-02, 8.4070e-03,
        1.7212e-04, 8.9624e-05, 4.1295e-03, 2.3021e-05, 2.0639e-02, 2.2318e-05,
        2.2063e-04, 6.8848e-05], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,817][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0016, 0.0145, 0.4928, 0.0387, 0.0271, 0.2113, 0.0182, 0.0226, 0.0431,
        0.0640, 0.0163, 0.0158, 0.0165, 0.0173], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,818][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.5060e-05, 1.0310e-02, 1.9520e-02, 4.0310e-02, 1.3078e-01, 6.9117e-03,
        7.0110e-02, 1.1465e-01, 2.2324e-01, 3.0018e-03, 1.5534e-01, 1.1530e-01,
        3.9716e-02, 7.0751e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:08,819][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([1.1333e-05, 3.4979e-02, 1.2788e-01, 1.0804e-01, 2.7589e-01, 7.8426e-03,
        2.4390e-02, 2.1701e-02, 1.1021e-01, 1.4747e-03, 1.5396e-01, 2.1267e-02,
        5.5046e-02, 2.9542e-02, 2.7774e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,821][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0022, 0.2016, 0.0252, 0.1800, 0.1618, 0.0136, 0.0207, 0.0408, 0.0902,
        0.0067, 0.1366, 0.0385, 0.0382, 0.0246, 0.0191], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,823][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0011, 0.0836, 0.0714, 0.0800, 0.0637, 0.0759, 0.0679, 0.0649, 0.0626,
        0.0699, 0.0648, 0.0727, 0.0845, 0.0629, 0.0741], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,824][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0003, 0.0920, 0.0186, 0.0769, 0.0600, 0.0627, 0.0869, 0.0831, 0.0968,
        0.0548, 0.0797, 0.0540, 0.0724, 0.0786, 0.0833], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,825][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0040, 0.1197, 0.0124, 0.1669, 0.0292, 0.0168, 0.0502, 0.1040, 0.0760,
        0.0062, 0.1152, 0.0457, 0.0629, 0.1209, 0.0700], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,826][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0430, 0.0964, 0.0362, 0.0562, 0.0525, 0.3244, 0.0448, 0.0381, 0.0384,
        0.0282, 0.0437, 0.0237, 0.0714, 0.0399, 0.0632], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,827][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.3827, 0.3104, 0.0663, 0.0916, 0.0098, 0.0549, 0.0019, 0.0062, 0.0141,
        0.0131, 0.0308, 0.0049, 0.0032, 0.0063, 0.0037], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,829][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0889, 0.1212, 0.0870, 0.1055, 0.0339, 0.1820, 0.0447, 0.0388, 0.0333,
        0.0436, 0.0565, 0.0266, 0.0467, 0.0477, 0.0436], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,831][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0009, 0.0291, 0.0759, 0.1037, 0.0910, 0.0456, 0.0870, 0.0915, 0.1423,
        0.0253, 0.0901, 0.0422, 0.0706, 0.0815, 0.0232], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,832][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([3.5536e-07, 3.2898e-01, 9.4992e-02, 5.1151e-01, 1.1875e-02, 3.3907e-03,
        1.6590e-04, 6.8301e-05, 6.9004e-03, 2.3766e-06, 4.1539e-02, 6.6221e-06,
        4.7049e-04, 9.2005e-05, 9.0135e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,834][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0067, 0.0094, 0.4975, 0.0278, 0.0207, 0.2559, 0.0133, 0.0171, 0.0322,
        0.0632, 0.0108, 0.0109, 0.0123, 0.0117, 0.0104], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,835][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.2705e-05, 4.4354e-03, 9.9925e-03, 3.2675e-02, 9.4695e-02, 4.0867e-03,
        4.6110e-02, 1.0482e-01, 2.9335e-01, 1.2158e-03, 1.7193e-01, 8.3802e-02,
        3.8249e-02, 5.4243e-02, 6.0368e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:08,836][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.2680e-05, 2.3877e-02, 1.8220e-01, 5.8501e-02, 3.3164e-01, 7.2668e-03,
        2.3564e-02, 1.8651e-02, 9.5494e-02, 1.5569e-03, 8.4943e-02, 1.9361e-02,
        4.6232e-02, 2.6013e-02, 1.7007e-02, 6.3683e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,838][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0006, 0.1947, 0.0179, 0.1710, 0.1406, 0.0099, 0.0245, 0.0390, 0.0829,
        0.0042, 0.1316, 0.0328, 0.0372, 0.0271, 0.0185, 0.0676],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,840][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0012, 0.0760, 0.0668, 0.0720, 0.0571, 0.0708, 0.0628, 0.0609, 0.0581,
        0.0655, 0.0605, 0.0671, 0.0810, 0.0581, 0.0684, 0.0737],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,841][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0001, 0.0851, 0.0205, 0.0691, 0.0521, 0.0588, 0.0801, 0.0722, 0.0914,
        0.0511, 0.0727, 0.0460, 0.0635, 0.0717, 0.0688, 0.0965],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,843][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0018, 0.1085, 0.0114, 0.1608, 0.0284, 0.0149, 0.0443, 0.0906, 0.0629,
        0.0041, 0.1045, 0.0387, 0.0535, 0.1110, 0.0649, 0.0998],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,845][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0769, 0.0983, 0.0378, 0.0539, 0.0459, 0.2548, 0.0427, 0.0371, 0.0360,
        0.0282, 0.0439, 0.0257, 0.0745, 0.0407, 0.0642, 0.0396],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,847][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1565, 0.3963, 0.0754, 0.1441, 0.0150, 0.0559, 0.0034, 0.0101, 0.0231,
        0.0137, 0.0499, 0.0065, 0.0059, 0.0101, 0.0067, 0.0273],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,849][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1938, 0.0796, 0.1150, 0.0942, 0.0301, 0.2017, 0.0271, 0.0291, 0.0206,
        0.0345, 0.0427, 0.0263, 0.0251, 0.0381, 0.0192, 0.0228],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,850][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0007, 0.0524, 0.0572, 0.1774, 0.0569, 0.0436, 0.0500, 0.0684, 0.1438,
        0.0154, 0.0918, 0.0268, 0.0452, 0.0838, 0.0109, 0.0757],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,851][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.1699e-05, 2.7290e-01, 3.5191e-01, 3.4218e-01, 7.0504e-03, 6.2126e-03,
        1.0748e-04, 3.7049e-05, 2.8744e-03, 6.0048e-06, 1.6546e-02, 4.3892e-06,
        1.0514e-04, 3.4205e-05, 3.1164e-06, 2.0841e-05], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,853][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0047, 0.0111, 0.5329, 0.0329, 0.0239, 0.1946, 0.0141, 0.0184, 0.0326,
        0.0536, 0.0135, 0.0137, 0.0124, 0.0133, 0.0102, 0.0179],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,855][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.4831e-05, 3.1899e-03, 2.5191e-02, 2.1612e-02, 1.4392e-01, 6.0767e-03,
        4.8988e-02, 5.8622e-02, 1.5237e-01, 1.9744e-03, 1.1767e-01, 1.1636e-01,
        3.7480e-02, 4.1633e-02, 6.2227e-02, 1.6265e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:08,856][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0005, 0.0318, 0.2613, 0.0848, 0.1038, 0.0245, 0.0190, 0.0256, 0.0890,
        0.0045, 0.1095, 0.0157, 0.0284, 0.0202, 0.0150, 0.0512, 0.1152],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,858][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0043, 0.1999, 0.0238, 0.1604, 0.0947, 0.0175, 0.0178, 0.0405, 0.0882,
        0.0090, 0.1348, 0.0424, 0.0290, 0.0191, 0.0150, 0.0669, 0.0368],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,860][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0014, 0.0715, 0.0603, 0.0677, 0.0539, 0.0641, 0.0596, 0.0568, 0.0538,
        0.0607, 0.0569, 0.0626, 0.0733, 0.0546, 0.0643, 0.0702, 0.0684],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,862][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0009, 0.0824, 0.0121, 0.0693, 0.0470, 0.0510, 0.0730, 0.0748, 0.0835,
        0.0397, 0.0736, 0.0483, 0.0573, 0.0695, 0.0673, 0.0896, 0.0607],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,864][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0029, 0.0960, 0.0103, 0.1405, 0.0273, 0.0191, 0.0445, 0.0996, 0.0685,
        0.0061, 0.1075, 0.0380, 0.0555, 0.1085, 0.0615, 0.0932, 0.0210],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,865][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.1066, 0.0854, 0.0344, 0.0478, 0.0462, 0.2469, 0.0446, 0.0351, 0.0345,
        0.0251, 0.0427, 0.0231, 0.0658, 0.0350, 0.0541, 0.0325, 0.0403],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,866][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.6671, 0.1571, 0.0398, 0.0422, 0.0034, 0.0378, 0.0009, 0.0035, 0.0064,
        0.0094, 0.0148, 0.0025, 0.0013, 0.0023, 0.0014, 0.0077, 0.0024],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,867][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.2661, 0.0688, 0.0782, 0.0674, 0.0268, 0.1895, 0.0254, 0.0308, 0.0212,
        0.0466, 0.0328, 0.0251, 0.0189, 0.0344, 0.0202, 0.0231, 0.0246],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,868][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0021, 0.0524, 0.0975, 0.1054, 0.0922, 0.0501, 0.0741, 0.0661, 0.1002,
        0.0259, 0.0847, 0.0464, 0.0282, 0.0448, 0.0077, 0.0455, 0.0767],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,869][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([9.6008e-06, 4.8325e-01, 2.8207e-01, 1.8759e-01, 1.5330e-02, 4.7078e-03,
        4.5270e-04, 9.8132e-05, 7.4908e-03, 9.7471e-06, 1.7755e-02, 1.6181e-05,
        1.8159e-04, 1.1092e-04, 5.8050e-06, 4.3320e-05, 8.7070e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,871][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0169, 0.0076, 0.5190, 0.0274, 0.0217, 0.2263, 0.0120, 0.0159, 0.0281,
        0.0466, 0.0104, 0.0124, 0.0100, 0.0109, 0.0084, 0.0142, 0.0122],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,872][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([5.3113e-05, 2.3124e-03, 7.8983e-03, 1.6635e-02, 1.0248e-01, 3.6712e-03,
        2.9060e-02, 9.3418e-02, 2.1871e-01, 8.6586e-04, 9.4994e-02, 9.9476e-02,
        1.2372e-02, 3.2650e-02, 3.5306e-02, 1.5174e-01, 9.8363e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:08,874][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([4.6969e-05, 2.3670e-02, 1.3354e-01, 5.3303e-02, 1.9478e-01, 8.1024e-03,
        2.9962e-02, 1.9820e-02, 8.6026e-02, 2.2805e-03, 8.8561e-02, 2.0617e-02,
        3.9048e-02, 2.2631e-02, 1.7064e-02, 5.5121e-02, 1.6087e-01, 4.4562e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,875][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.1720, 0.0194, 0.1340, 0.1408, 0.0103, 0.0283, 0.0359, 0.0726,
        0.0046, 0.1314, 0.0378, 0.0415, 0.0249, 0.0186, 0.0543, 0.0455, 0.0270],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,877][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0008, 0.0704, 0.0600, 0.0647, 0.0504, 0.0634, 0.0551, 0.0528, 0.0510,
        0.0561, 0.0526, 0.0573, 0.0683, 0.0504, 0.0611, 0.0660, 0.0645, 0.0549],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,878][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0002, 0.0740, 0.0141, 0.0618, 0.0459, 0.0460, 0.0722, 0.0672, 0.0789,
        0.0366, 0.0639, 0.0423, 0.0581, 0.0651, 0.0627, 0.0835, 0.0589, 0.0687],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,880][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0018, 0.0940, 0.0098, 0.1399, 0.0266, 0.0144, 0.0395, 0.0817, 0.0564,
        0.0037, 0.0947, 0.0372, 0.0520, 0.0975, 0.0524, 0.0860, 0.0186, 0.0937],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,882][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0357, 0.0944, 0.0386, 0.0544, 0.0450, 0.2438, 0.0397, 0.0360, 0.0382,
        0.0304, 0.0405, 0.0264, 0.0634, 0.0378, 0.0556, 0.0406, 0.0466, 0.0329],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,884][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1621, 0.3616, 0.0682, 0.1489, 0.0141, 0.0542, 0.0044, 0.0115, 0.0221,
        0.0122, 0.0562, 0.0079, 0.0064, 0.0116, 0.0068, 0.0258, 0.0078, 0.0181],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,886][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0553, 0.0945, 0.0741, 0.1088, 0.0353, 0.1718, 0.0408, 0.0451, 0.0340,
        0.0390, 0.0600, 0.0286, 0.0350, 0.0494, 0.0287, 0.0308, 0.0281, 0.0407],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,887][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0018, 0.0440, 0.0468, 0.1085, 0.0592, 0.0398, 0.0557, 0.0675, 0.0842,
        0.0168, 0.0626, 0.0343, 0.0350, 0.0764, 0.0137, 0.0643, 0.0789, 0.1107],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,889][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.9857e-05, 3.2835e-01, 3.3278e-01, 3.0414e-01, 8.6714e-03, 5.7402e-03,
        1.4101e-04, 5.8327e-05, 2.9920e-03, 1.7245e-05, 1.5282e-02, 1.7369e-05,
        1.1182e-04, 4.6400e-05, 5.4958e-06, 3.2509e-05, 1.5368e-03, 4.8336e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,890][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0020, 0.0138, 0.4860, 0.0380, 0.0251, 0.1780, 0.0171, 0.0210, 0.0386,
        0.0551, 0.0148, 0.0143, 0.0142, 0.0158, 0.0122, 0.0217, 0.0171, 0.0152],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:08,892][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0002, 0.0046, 0.0326, 0.0204, 0.0975, 0.0076, 0.0561, 0.0637, 0.1174,
        0.0032, 0.0834, 0.1000, 0.0276, 0.0412, 0.0376, 0.0814, 0.1809, 0.0446],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,011][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:09,012][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,013][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,015][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,016][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,017][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,017][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,018][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,019][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,019][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,020][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,021][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,021][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,022][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.7854e-04, 9.9982e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,023][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.4892e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,024][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.4583e-05, 9.9994e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,025][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0167, 0.9833], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,027][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1313, 0.8687], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,029][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0198, 0.9802], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,030][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.9586e-05, 9.9998e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,031][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0320, 0.9680], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,033][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0055, 0.9945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,034][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0298, 0.9702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,036][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,038][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0026, 0.9974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,039][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.0075, 0.2203, 0.7722], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,040][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([3.1029e-06, 9.1030e-01, 8.9695e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,041][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([5.9869e-04, 8.1430e-01, 1.8510e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,043][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.0172, 0.2341, 0.7488], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,044][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.4610, 0.2734, 0.2656], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,045][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([0.0370, 0.3164, 0.6467], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,046][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([0.0018, 0.5520, 0.4462], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,047][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.2062, 0.2267, 0.5671], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,047][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([0.0024, 0.8168, 0.1808], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,049][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([0.0168, 0.4411, 0.5420], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,050][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.0012, 0.0013, 0.9975], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,052][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.0019, 0.4737, 0.5245], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,053][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.1560e-04, 1.6637e-01, 3.2333e-01, 5.1018e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,054][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.4468e-08, 1.5424e-01, 5.4663e-03, 8.4030e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,055][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.0293e-06, 1.2107e-01, 1.8344e-02, 8.6058e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,057][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0007, 0.0804, 0.5918, 0.3272], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,058][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0433, 0.3354, 0.1576, 0.4637], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,060][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0012, 0.1641, 0.7739, 0.0609], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,061][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.6808e-05, 2.4469e-01, 1.0173e-01, 6.5356e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,062][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0282, 0.2503, 0.1605, 0.5610], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,064][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([6.8058e-04, 2.0752e-01, 3.6749e-02, 7.5505e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,065][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0023, 0.1505, 0.7301, 0.1172], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,066][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([2.2135e-04, 4.8064e-04, 9.9440e-01, 4.8969e-03], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,067][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.2482e-04, 1.1994e-01, 1.0032e-01, 7.7952e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,069][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0007, 0.1359, 0.3266, 0.2272, 0.3097], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,070][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([9.1321e-07, 3.5756e-01, 2.7706e-02, 4.6607e-01, 1.4866e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,071][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([4.5798e-05, 1.8706e-01, 4.3048e-02, 5.4808e-01, 2.2177e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,073][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0029, 0.0787, 0.3989, 0.1671, 0.3524], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,074][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.2099, 0.3004, 0.1973, 0.2739, 0.0185], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,076][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([0.0061, 0.2819, 0.6222, 0.0686, 0.0211], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,078][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([0.0009, 0.2185, 0.3494, 0.2678, 0.1634], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,079][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.1081, 0.1805, 0.3520, 0.2765, 0.0828], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,081][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0030, 0.2362, 0.1998, 0.3126, 0.2483], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,082][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([0.0109, 0.2782, 0.5998, 0.0949, 0.0162], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,084][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([2.2434e-03, 3.8898e-04, 9.0264e-01, 1.9441e-03, 9.2788e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,085][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([4.6309e-04, 9.4483e-02, 9.0299e-02, 3.1291e-01, 5.0185e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,086][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([2.2889e-04, 6.5021e-02, 1.4311e-01, 1.4558e-01, 6.2100e-01, 2.5054e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,087][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([1.8677e-07, 2.1859e-01, 7.1119e-03, 5.3672e-01, 2.3401e-01, 3.5712e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,087][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([7.9048e-05, 1.4081e-01, 2.2138e-02, 5.3377e-01, 2.8420e-01, 1.8996e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,088][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0061, 0.0675, 0.3065, 0.1631, 0.3212, 0.1355], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,089][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.1590, 0.2200, 0.2215, 0.2451, 0.0505, 0.1039], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,091][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0050, 0.1493, 0.5616, 0.1689, 0.0547, 0.0604], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,092][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([1.3224e-04, 2.6937e-01, 1.0061e-01, 3.6828e-01, 2.2060e-01, 4.1003e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,093][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1477, 0.1211, 0.3874, 0.1612, 0.0572, 0.1254], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,095][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0020, 0.2053, 0.0514, 0.4710, 0.1899, 0.0803], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,096][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0021, 0.2208, 0.3878, 0.2900, 0.0447, 0.0546], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,097][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([3.7282e-04, 9.5959e-04, 5.4281e-01, 4.8964e-03, 4.4552e-01, 5.4457e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,098][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([8.3155e-05, 8.4868e-02, 3.1666e-02, 2.8654e-01, 5.7951e-01, 1.7324e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,099][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([1.8127e-05, 1.5047e-01, 7.6629e-02, 3.6497e-01, 3.1207e-01, 1.6359e-02,
        7.9480e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,101][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([7.4120e-08, 2.3290e-01, 9.2920e-03, 6.1754e-01, 1.3137e-01, 2.3379e-03,
        6.5570e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,102][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([1.1545e-05, 9.7614e-02, 1.9720e-02, 5.2330e-01, 2.6217e-01, 1.0963e-02,
        8.6224e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,103][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([2.2765e-04, 4.2932e-02, 1.6318e-01, 1.8863e-01, 4.0669e-01, 8.7635e-02,
        1.1070e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,105][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0205, 0.3501, 0.0544, 0.4995, 0.0150, 0.0566, 0.0040],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,106][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0005, 0.3094, 0.2734, 0.3132, 0.0514, 0.0474, 0.0048],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,108][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([1.9681e-05, 2.8778e-01, 6.9501e-02, 4.9635e-01, 1.0145e-01, 2.6699e-02,
        1.8195e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,109][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0062, 0.1127, 0.1549, 0.4144, 0.0914, 0.0962, 0.1242],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,111][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0016, 0.1085, 0.0953, 0.3055, 0.1768, 0.1035, 0.2088],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,112][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([7.3355e-05, 3.4134e-01, 8.6995e-02, 5.2159e-01, 2.5615e-02, 2.1285e-02,
        3.1036e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,113][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([3.3656e-04, 7.6373e-04, 6.8923e-01, 3.9071e-03, 2.7954e-01, 6.0119e-03,
        2.0208e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,114][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([1.7662e-05, 6.3250e-02, 1.2620e-02, 3.6021e-01, 3.7225e-01, 1.1796e-02,
        1.7986e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,115][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([6.7840e-06, 7.4813e-02, 8.2276e-02, 2.6365e-01, 3.8410e-01, 1.1145e-02,
        7.8682e-02, 1.0533e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,117][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.3169e-08, 2.6704e-01, 1.1363e-02, 5.3038e-01, 1.5590e-01, 2.4656e-03,
        1.0325e-02, 2.2530e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,118][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([6.8898e-06, 7.6954e-02, 1.8225e-02, 4.2425e-01, 2.4375e-01, 8.3931e-03,
        7.8155e-02, 1.5027e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,119][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([7.7699e-05, 4.0485e-02, 1.4335e-01, 1.9235e-01, 3.8474e-01, 6.7033e-02,
        9.0026e-02, 8.1938e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,121][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0121, 0.2856, 0.0573, 0.5481, 0.0210, 0.0542, 0.0075, 0.0143],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,122][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([2.4569e-04, 3.4214e-01, 4.3054e-01, 1.7218e-01, 2.9656e-02, 2.3342e-02,
        1.3657e-03, 5.3330e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,123][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([8.6573e-06, 2.2131e-01, 6.4711e-02, 5.2490e-01, 9.9513e-02, 1.9773e-02,
        1.8068e-02, 5.1713e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,125][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0049, 0.1025, 0.1948, 0.3504, 0.0661, 0.1005, 0.0831, 0.0977],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,127][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0017, 0.1324, 0.0756, 0.2857, 0.1219, 0.0913, 0.1219, 0.1696],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,128][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.1372e-04, 4.3552e-01, 2.3149e-01, 3.0818e-01, 1.4646e-02, 9.0104e-03,
        8.1508e-04, 2.2027e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,129][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([3.4114e-04, 3.6132e-04, 7.7005e-01, 2.2710e-03, 2.0124e-01, 4.3688e-03,
        1.7336e-02, 4.0250e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,129][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0003, 0.0393, 0.0470, 0.1595, 0.2909, 0.0234, 0.1600, 0.2795],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,130][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.0553e-05, 6.5401e-02, 1.3227e-01, 1.4806e-01, 3.3679e-01, 7.7350e-03,
        4.2021e-02, 3.8767e-02, 2.2895e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,131][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([7.1101e-08, 2.4415e-01, 1.7809e-02, 4.5274e-01, 1.2992e-01, 1.7879e-03,
        6.2967e-03, 1.1779e-02, 1.3552e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,132][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.1051e-05, 5.4318e-02, 2.5478e-02, 3.3187e-01, 2.6511e-01, 7.7269e-03,
        5.6688e-02, 8.7339e-02, 1.7146e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,133][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.2640e-04, 2.6933e-02, 2.0821e-01, 1.5511e-01, 3.0825e-01, 6.4271e-02,
        7.6477e-02, 5.0418e-02, 1.1020e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,135][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0270, 0.2472, 0.1374, 0.4862, 0.0191, 0.0569, 0.0045, 0.0074, 0.0141],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,136][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.3516e-03, 1.3391e-01, 7.7109e-01, 5.7595e-02, 1.3250e-02, 1.9020e-02,
        4.8803e-04, 1.4855e-04, 3.1501e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,137][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([7.2366e-06, 1.8015e-01, 7.4916e-02, 4.7043e-01, 6.3240e-02, 1.1500e-02,
        1.8617e-02, 2.6865e-02, 1.5427e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,138][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0112, 0.1257, 0.2112, 0.3366, 0.0364, 0.0990, 0.0354, 0.0503, 0.0942],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,140][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0016, 0.1023, 0.0754, 0.2041, 0.1249, 0.0768, 0.0862, 0.1041, 0.2246],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,141][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.5195e-03, 2.0068e-01, 6.3754e-01, 1.3650e-01, 9.1814e-03, 1.2343e-02,
        4.1170e-04, 6.5901e-05, 1.7497e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,142][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.8394e-04, 7.0875e-05, 8.7229e-01, 4.4315e-04, 1.1600e-01, 1.5501e-03,
        5.5707e-03, 7.3520e-04, 3.0584e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,143][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.9176e-04, 3.2689e-02, 3.1517e-02, 1.2892e-01, 1.7179e-01, 1.3144e-02,
        8.8049e-02, 1.4496e-01, 3.8873e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,144][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([1.5467e-04, 4.4170e-02, 9.6848e-02, 8.5996e-02, 4.2497e-01, 2.2388e-02,
        6.7358e-02, 6.9865e-02, 1.7922e-01, 9.0251e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,145][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([1.3380e-07, 9.9466e-02, 7.6653e-03, 3.1698e-01, 2.4987e-01, 2.5408e-03,
        2.1170e-02, 4.9533e-02, 2.5215e-01, 6.3627e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,147][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([1.6181e-05, 5.6138e-02, 9.6558e-03, 2.8905e-01, 1.9008e-01, 7.3904e-03,
        8.4100e-02, 1.6275e-01, 1.9681e-01, 4.0168e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,148][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0016, 0.0500, 0.1808, 0.1288, 0.2450, 0.0969, 0.1186, 0.0680, 0.0936,
        0.0166], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,150][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([0.0346, 0.2329, 0.1166, 0.3942, 0.0407, 0.0935, 0.0142, 0.0231, 0.0392,
        0.0110], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,151][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([1.6138e-04, 3.3121e-01, 1.1022e-01, 3.5866e-01, 8.1858e-02, 3.6784e-02,
        1.3991e-02, 7.4200e-03, 5.8892e-02, 8.1430e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,153][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([6.8698e-05, 1.2539e-01, 7.3221e-02, 1.9157e-01, 2.0854e-01, 2.5353e-02,
        4.9795e-02, 8.2914e-02, 2.3745e-01, 5.6905e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,154][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([0.0313, 0.0901, 0.2589, 0.1773, 0.0658, 0.1108, 0.0531, 0.0650, 0.0848,
        0.0628], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,156][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([0.0006, 0.0950, 0.0388, 0.2164, 0.1101, 0.0360, 0.1218, 0.1523, 0.2078,
        0.0214], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,157][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([4.1007e-06, 3.3256e-01, 2.6083e-02, 5.1090e-01, 4.1676e-02, 7.1807e-03,
        7.3783e-03, 3.7461e-03, 7.0325e-02, 1.4705e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,158][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([2.8973e-04, 4.9893e-04, 5.1572e-01, 2.7849e-03, 4.0614e-01, 4.8485e-03,
        3.4475e-02, 7.2985e-03, 1.7672e-02, 1.0273e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,159][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([6.0545e-07, 7.7914e-03, 1.2727e-03, 4.3029e-02, 1.4642e-01, 9.1088e-04,
        5.0416e-02, 1.8751e-01, 5.6240e-01, 2.5377e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,160][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([5.5498e-06, 2.4271e-02, 9.0947e-02, 1.0299e-01, 3.7384e-01, 5.2360e-03,
        3.7255e-02, 3.5954e-02, 1.8134e-01, 1.1862e-03, 1.4698e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,161][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.2493e-08, 1.1452e-01, 1.0223e-02, 4.5724e-01, 1.6856e-01, 1.3526e-03,
        8.2629e-03, 1.5156e-02, 1.1670e-01, 1.0686e-04, 1.0788e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,163][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([4.2463e-06, 4.0267e-02, 1.0832e-02, 2.2602e-01, 2.1336e-01, 3.9408e-03,
        5.3285e-02, 7.7707e-02, 1.5504e-01, 1.3970e-03, 2.1815e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,164][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.8041e-05, 1.8696e-02, 1.9266e-01, 8.9639e-02, 3.6855e-01, 4.5042e-02,
        9.1893e-02, 4.0449e-02, 7.7559e-02, 3.2200e-03, 7.2191e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,166][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0333, 0.2308, 0.1644, 0.4233, 0.0238, 0.0642, 0.0070, 0.0092, 0.0142,
        0.0037, 0.0259], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,167][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.3571e-04, 1.0249e-01, 8.2222e-01, 3.8728e-02, 1.0565e-02, 1.5911e-02,
        2.8447e-04, 8.2106e-05, 1.9596e-03, 9.1759e-05, 6.7325e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,168][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([7.3972e-06, 1.2163e-01, 7.9561e-02, 3.4894e-01, 9.1101e-02, 1.1042e-02,
        2.2986e-02, 3.1156e-02, 1.3882e-01, 8.2438e-04, 1.5393e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,170][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0085, 0.0956, 0.1843, 0.2710, 0.0454, 0.0782, 0.0430, 0.0430, 0.0857,
        0.0152, 0.1300], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,171][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0012, 0.0654, 0.0458, 0.1689, 0.1123, 0.0514, 0.0788, 0.1147, 0.2059,
        0.0148, 0.1408], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,172][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([8.7443e-04, 1.1172e-01, 7.9701e-01, 6.8104e-02, 9.0981e-03, 9.6575e-03,
        1.4445e-04, 2.4544e-05, 9.8874e-04, 3.0812e-05, 2.3485e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,172][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.0050e-04, 7.7895e-05, 7.9375e-01, 6.2586e-04, 1.8689e-01, 1.4671e-03,
        7.8147e-03, 1.0914e-03, 3.6501e-03, 2.2975e-03, 2.1367e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,173][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([4.4267e-05, 9.8785e-03, 2.3499e-02, 6.0127e-02, 1.9884e-01, 7.5299e-03,
        1.0353e-01, 1.1916e-01, 2.6394e-01, 2.3279e-03, 2.1113e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,175][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([2.8405e-05, 4.6594e-02, 9.7144e-02, 1.2119e-01, 3.0080e-01, 1.1300e-02,
        2.9552e-02, 3.2262e-02, 1.5297e-01, 2.0334e-03, 1.5880e-01, 4.7333e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,176][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([1.1175e-07, 1.8673e-01, 1.4711e-02, 3.5379e-01, 1.6259e-01, 3.1117e-03,
        7.5417e-03, 1.6814e-02, 1.2469e-01, 2.6999e-04, 1.1908e-01, 1.0681e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,177][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([1.7494e-06, 9.9411e-02, 7.2707e-03, 2.7997e-01, 1.0484e-01, 2.9418e-03,
        3.4058e-02, 7.6292e-02, 1.1546e-01, 7.9366e-04, 2.1022e-01, 6.8751e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,178][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([6.8000e-05, 3.6830e-02, 9.9546e-02, 1.3325e-01, 3.4324e-01, 3.8203e-02,
        6.4702e-02, 3.6799e-02, 1.0554e-01, 3.7212e-03, 9.9525e-02, 3.8578e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,180][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0185, 0.2229, 0.0925, 0.4716, 0.0273, 0.0611, 0.0096, 0.0145, 0.0204,
        0.0042, 0.0460, 0.0115], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,181][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([3.0950e-05, 6.4464e-01, 1.1236e-01, 1.4701e-01, 3.0253e-02, 1.0103e-02,
        3.8035e-03, 7.9656e-04, 9.4314e-03, 9.2361e-05, 4.1260e-02, 2.2089e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,182][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([2.7060e-05, 1.1485e-01, 8.9727e-02, 2.5466e-01, 1.3585e-01, 2.2492e-02,
        1.2316e-02, 3.4766e-02, 1.2687e-01, 1.6422e-03, 1.7967e-01, 2.7140e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,184][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0023, 0.0753, 0.1250, 0.2451, 0.0779, 0.0653, 0.0289, 0.0469, 0.1063,
        0.0139, 0.1822, 0.0309], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,186][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([0.0005, 0.0685, 0.0518, 0.1152, 0.1277, 0.0359, 0.0789, 0.0998, 0.1928,
        0.0148, 0.1411, 0.0729], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,187][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([2.1091e-05, 6.3148e-01, 1.2043e-01, 1.9208e-01, 2.2325e-02, 6.3672e-03,
        1.6377e-03, 2.6264e-04, 6.4137e-03, 4.6644e-05, 1.8890e-02, 5.5513e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,188][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([3.9987e-04, 2.9987e-04, 7.8744e-01, 2.0774e-03, 1.7249e-01, 3.7510e-03,
        9.3589e-03, 2.2369e-03, 6.1931e-03, 3.1634e-03, 4.9886e-03, 7.5959e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,189][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([9.0491e-06, 1.4523e-02, 7.8527e-03, 8.4952e-02, 1.6880e-01, 4.1450e-03,
        3.9945e-02, 1.4231e-01, 2.8491e-01, 8.7443e-04, 1.7159e-01, 8.0098e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,191][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([3.1058e-05, 4.5078e-02, 1.1000e-01, 8.7952e-02, 2.5984e-01, 8.9148e-03,
        3.2399e-02, 3.3829e-02, 1.6840e-01, 2.3263e-03, 1.4544e-01, 3.4291e-02,
        7.1494e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,192][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([1.9956e-07, 1.2082e-01, 2.8865e-02, 3.1144e-01, 2.1205e-01, 2.6840e-03,
        1.2944e-02, 2.3038e-02, 1.4071e-01, 4.9696e-04, 1.1015e-01, 1.0415e-02,
        2.6378e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,193][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([6.7107e-06, 4.1924e-02, 1.0961e-02, 2.4668e-01, 1.1413e-01, 4.2398e-03,
        5.3389e-02, 9.8894e-02, 1.5927e-01, 2.0106e-03, 1.7602e-01, 5.1797e-02,
        4.0694e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,194][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([1.8617e-04, 1.5265e-02, 1.8710e-01, 8.9343e-02, 2.8486e-01, 5.4100e-02,
        8.8814e-02, 4.4674e-02, 9.3723e-02, 6.4237e-03, 7.1734e-02, 3.0070e-02,
        3.3711e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,196][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0506, 0.2393, 0.0787, 0.4910, 0.0086, 0.0682, 0.0035, 0.0073, 0.0117,
        0.0027, 0.0284, 0.0035, 0.0066], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,197][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([9.0302e-05, 1.9028e-01, 6.8170e-01, 7.5594e-02, 1.5763e-02, 1.8106e-02,
        2.9917e-04, 1.0155e-04, 3.3754e-03, 5.0631e-05, 1.4452e-02, 2.2730e-05,
        1.7128e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,198][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([3.7524e-05, 2.1976e-01, 1.0707e-01, 2.5064e-01, 6.7171e-02, 1.5645e-02,
        1.8302e-02, 3.0172e-02, 1.1729e-01, 1.7850e-03, 1.2752e-01, 1.2537e-02,
        3.2067e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,200][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0148, 0.0940, 0.1965, 0.1914, 0.0344, 0.0866, 0.0324, 0.0402, 0.0921,
        0.0218, 0.1375, 0.0130, 0.0452], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,202][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0014, 0.0531, 0.0629, 0.1460, 0.0746, 0.0445, 0.0911, 0.1167, 0.1616,
        0.0213, 0.1259, 0.0396, 0.0613], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,203][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([6.9968e-06, 2.6009e-01, 3.7856e-01, 2.8898e-01, 1.8423e-02, 8.5527e-03,
        4.2586e-04, 1.1692e-04, 9.6162e-03, 8.7922e-06, 3.4899e-02, 1.0417e-05,
        3.0917e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,204][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([7.0496e-04, 5.2532e-05, 8.8129e-01, 3.5876e-04, 8.9039e-02, 1.6554e-03,
        7.2118e-03, 1.1017e-03, 3.3240e-03, 3.6113e-03, 1.3963e-03, 3.0594e-03,
        7.1948e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,206][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([1.5449e-05, 1.5651e-02, 1.1213e-02, 5.6671e-02, 1.2164e-01, 3.8023e-03,
        4.4421e-02, 1.1012e-01, 3.6635e-01, 1.1586e-03, 1.6570e-01, 7.6692e-02,
        2.6563e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,207][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0750e-05, 2.7637e-02, 7.6794e-02, 7.1378e-02, 2.6354e-01, 6.2220e-03,
        4.7491e-02, 3.5880e-02, 1.6786e-01, 2.0438e-03, 1.5176e-01, 3.3610e-02,
        7.4489e-02, 4.1278e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,208][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.6420e-07, 1.1225e-01, 1.7245e-02, 3.0862e-01, 1.9215e-01, 2.4562e-03,
        2.2470e-02, 2.1947e-02, 1.4067e-01, 4.1834e-04, 1.1509e-01, 1.1901e-02,
        3.7503e-02, 1.7275e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,209][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.7899e-06, 4.6971e-02, 1.0152e-02, 1.8417e-01, 1.1731e-01, 3.9397e-03,
        5.1624e-02, 9.1343e-02, 1.5913e-01, 1.7926e-03, 1.9370e-01, 5.8010e-02,
        4.6719e-02, 3.5138e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,211][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.1266e-05, 2.7115e-02, 1.2690e-01, 1.0685e-01, 2.7815e-01, 4.3140e-02,
        1.0578e-01, 4.3932e-02, 8.4593e-02, 4.2374e-03, 8.4140e-02, 3.1391e-02,
        4.2571e-02, 2.1122e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,212][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0153, 0.2133, 0.0915, 0.4622, 0.0242, 0.0643, 0.0081, 0.0141, 0.0209,
        0.0035, 0.0451, 0.0093, 0.0195, 0.0088], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,213][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.1099e-05, 2.9063e-01, 4.4720e-01, 1.7996e-01, 1.8838e-02, 1.7091e-02,
        5.4248e-04, 3.1500e-04, 8.8096e-03, 9.4444e-05, 3.5404e-02, 8.8218e-05,
        7.0592e-04, 2.5112e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,214][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0245e-05, 1.5133e-01, 5.4031e-02, 3.2553e-01, 6.2821e-02, 9.8657e-03,
        2.8503e-02, 3.3858e-02, 1.1289e-01, 1.0589e-03, 1.4758e-01, 1.1797e-02,
        3.3971e-02, 2.6745e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,215][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0053, 0.1198, 0.1223, 0.2333, 0.0487, 0.0679, 0.0288, 0.0403, 0.0813,
        0.0146, 0.1341, 0.0225, 0.0411, 0.0400], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,217][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0016, 0.0513, 0.0432, 0.1263, 0.0825, 0.0432, 0.0732, 0.1036, 0.1370,
        0.0206, 0.0931, 0.0481, 0.0605, 0.1157], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,218][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.4023e-05, 3.4484e-01, 2.9538e-01, 3.1370e-01, 1.2272e-02, 8.4070e-03,
        1.7212e-04, 8.9624e-05, 4.1295e-03, 2.3021e-05, 2.0639e-02, 2.2318e-05,
        2.2063e-04, 6.8848e-05], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,219][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.3421e-04, 6.6331e-05, 8.1920e-01, 4.7380e-04, 1.3701e-01, 2.2381e-03,
        1.1086e-02, 1.4048e-03, 4.2479e-03, 4.5785e-03, 1.8494e-03, 4.4080e-03,
        1.1486e-02, 1.2224e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,220][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.5060e-05, 1.0310e-02, 1.9520e-02, 4.0310e-02, 1.3078e-01, 6.9117e-03,
        7.0110e-02, 1.1465e-01, 2.2324e-01, 3.0018e-03, 1.5534e-01, 1.1530e-01,
        3.9716e-02, 7.0751e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,221][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.1333e-05, 3.4979e-02, 1.2788e-01, 1.0804e-01, 2.7589e-01, 7.8426e-03,
        2.4390e-02, 2.1701e-02, 1.1021e-01, 1.4747e-03, 1.5396e-01, 2.1267e-02,
        5.5046e-02, 2.9542e-02, 2.7774e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,223][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.1466e-07, 1.0927e-01, 2.9826e-02, 4.0174e-01, 1.6813e-01, 2.9454e-03,
        8.4885e-03, 1.6378e-02, 1.2343e-01, 3.2005e-04, 9.0368e-02, 5.5530e-03,
        2.2727e-02, 1.0329e-02, 1.0498e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,224][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([2.0117e-05, 4.0992e-02, 2.7422e-02, 2.4253e-01, 1.8703e-01, 7.2001e-03,
        4.6047e-02, 6.9484e-02, 1.2184e-01, 2.6650e-03, 1.2956e-01, 5.2077e-02,
        3.9296e-02, 2.0680e-02, 1.3159e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,225][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([8.1706e-05, 1.5396e-02, 1.9051e-01, 1.0292e-01, 3.0915e-01, 4.5833e-02,
        7.8583e-02, 2.9659e-02, 6.7301e-02, 3.6845e-03, 7.2034e-02, 2.4433e-02,
        3.0761e-02, 1.2666e-02, 1.6988e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,227][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0166, 0.2067, 0.0973, 0.5280, 0.0144, 0.0601, 0.0027, 0.0066, 0.0122,
        0.0019, 0.0317, 0.0041, 0.0117, 0.0052, 0.0010], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,228][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.3293e-05, 3.2654e-01, 3.8414e-01, 2.0628e-01, 1.6056e-02, 1.8440e-02,
        4.3129e-04, 1.7102e-04, 7.4280e-03, 3.1106e-05, 3.8978e-02, 2.7620e-05,
        1.2283e-03, 1.9111e-04, 4.1315e-05], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,229][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([1.2635e-05, 1.2690e-01, 1.2626e-01, 2.9766e-01, 1.0077e-01, 1.4263e-02,
        1.7162e-02, 2.1652e-02, 9.5982e-02, 1.1594e-03, 1.1439e-01, 9.9935e-03,
        3.0595e-02, 1.8591e-02, 2.4609e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,231][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0054, 0.1010, 0.1811, 0.2494, 0.0351, 0.0588, 0.0217, 0.0345, 0.0791,
        0.0181, 0.1233, 0.0117, 0.0291, 0.0282, 0.0234], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,233][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0009, 0.0291, 0.0759, 0.1037, 0.0910, 0.0456, 0.0870, 0.0915, 0.1423,
        0.0253, 0.0901, 0.0422, 0.0706, 0.0815, 0.0232], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,234][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([3.5536e-07, 3.2898e-01, 9.4992e-02, 5.1151e-01, 1.1875e-02, 3.3907e-03,
        1.6590e-04, 6.8301e-05, 6.9004e-03, 2.3766e-06, 4.1539e-02, 6.6221e-06,
        4.7049e-04, 9.2005e-05, 9.0135e-06], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,235][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([3.6387e-04, 6.0602e-05, 8.5882e-01, 5.2998e-04, 1.1307e-01, 1.7075e-03,
        5.5236e-03, 7.3666e-04, 2.3053e-03, 2.6094e-03, 1.2581e-03, 2.2438e-03,
        6.5633e-03, 6.2487e-04, 3.5771e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,237][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([2.2705e-05, 4.4354e-03, 9.9925e-03, 3.2675e-02, 9.4695e-02, 4.0867e-03,
        4.6110e-02, 1.0482e-01, 2.9335e-01, 1.2158e-03, 1.7193e-01, 8.3802e-02,
        3.8249e-02, 5.4243e-02, 6.0368e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,238][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.2680e-05, 2.3877e-02, 1.8220e-01, 5.8501e-02, 3.3164e-01, 7.2668e-03,
        2.3564e-02, 1.8651e-02, 9.5494e-02, 1.5569e-03, 8.4943e-02, 1.9361e-02,
        4.6232e-02, 2.6013e-02, 1.7007e-02, 6.3683e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,239][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3199e-08, 1.1582e-01, 2.6294e-02, 3.9388e-01, 1.4280e-01, 2.5596e-03,
        1.0344e-02, 1.3614e-02, 1.0607e-01, 2.2900e-04, 8.9712e-02, 4.7686e-03,
        2.4295e-02, 1.1081e-02, 8.3808e-03, 5.0153e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,240][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.5100e-06, 3.1670e-02, 2.0257e-02, 2.2513e-01, 1.2925e-01, 4.9193e-03,
        5.1368e-02, 7.4589e-02, 1.4697e-01, 2.3046e-03, 1.6689e-01, 4.0965e-02,
        4.2703e-02, 2.1220e-02, 1.4449e-02, 2.7302e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,242][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.9190e-05, 1.9195e-02, 2.5733e-01, 9.9588e-02, 2.2464e-01, 5.3232e-02,
        7.3903e-02, 2.7369e-02, 7.8695e-02, 3.6915e-03, 7.5556e-02, 1.5083e-02,
        2.3155e-02, 1.2738e-02, 1.0986e-02, 2.4751e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,243][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0260, 0.1519, 0.1955, 0.4303, 0.0205, 0.0801, 0.0041, 0.0075, 0.0153,
        0.0031, 0.0325, 0.0051, 0.0137, 0.0053, 0.0011, 0.0079],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,245][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([5.1635e-05, 1.9433e-01, 6.0361e-01, 1.4288e-01, 1.2323e-02, 1.3790e-02,
        2.2363e-04, 1.0892e-04, 4.8655e-03, 3.5727e-05, 2.7194e-02, 2.6316e-05,
        3.3664e-04, 1.0033e-04, 1.3846e-05, 1.1197e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,246][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.3074e-05, 1.1003e-01, 1.1869e-01, 2.6798e-01, 7.1092e-02, 1.2618e-02,
        2.0861e-02, 2.1033e-02, 1.0534e-01, 1.2721e-03, 1.1529e-01, 7.7201e-03,
        3.3123e-02, 1.8411e-02, 2.4378e-02, 7.2161e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,248][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0070, 0.1028, 0.1601, 0.2863, 0.0258, 0.0713, 0.0259, 0.0323, 0.0657,
        0.0152, 0.1014, 0.0100, 0.0272, 0.0224, 0.0115, 0.0352],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,249][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0007, 0.0524, 0.0572, 0.1774, 0.0569, 0.0436, 0.0500, 0.0684, 0.1438,
        0.0154, 0.0918, 0.0268, 0.0452, 0.0838, 0.0109, 0.0757],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,251][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.1699e-05, 2.7290e-01, 3.5191e-01, 3.4218e-01, 7.0504e-03, 6.2126e-03,
        1.0748e-04, 3.7049e-05, 2.8744e-03, 6.0048e-06, 1.6546e-02, 4.3892e-06,
        1.0514e-04, 3.4205e-05, 3.1164e-06, 2.0841e-05], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,252][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.6747e-04, 1.3469e-05, 9.3092e-01, 1.1789e-04, 5.7860e-02, 8.6588e-04,
        2.3806e-03, 2.0923e-04, 8.3899e-04, 1.6536e-03, 3.9226e-04, 8.5257e-04,
        2.0789e-03, 1.7212e-04, 1.1064e-03, 1.6907e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,253][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.4831e-05, 3.1899e-03, 2.5191e-02, 2.1612e-02, 1.4392e-01, 6.0767e-03,
        4.8988e-02, 5.8622e-02, 1.5237e-01, 1.9744e-03, 1.1767e-01, 1.1636e-01,
        3.7480e-02, 4.1633e-02, 6.2227e-02, 1.6265e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,255][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0005, 0.0318, 0.2613, 0.0848, 0.1038, 0.0245, 0.0190, 0.0256, 0.0890,
        0.0045, 0.1095, 0.0157, 0.0284, 0.0202, 0.0150, 0.0512, 0.1152],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,256][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.7324e-06, 1.0108e-01, 5.4718e-02, 3.5779e-01, 1.1967e-01, 6.8778e-03,
        9.5242e-03, 1.7142e-02, 1.1833e-01, 1.0440e-03, 9.1646e-02, 8.7004e-03,
        1.3755e-02, 7.7030e-03, 7.0994e-03, 5.4454e-02, 3.0463e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,257][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([2.1076e-05, 2.8626e-02, 1.3205e-02, 2.1336e-01, 1.0318e-01, 5.1611e-03,
        5.5292e-02, 8.5756e-02, 1.0571e-01, 2.5898e-03, 1.6346e-01, 5.4578e-02,
        3.8956e-02, 2.5281e-02, 1.2877e-02, 2.9907e-02, 6.2028e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,258][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0020, 0.0186, 0.2281, 0.0901, 0.1768, 0.0919, 0.0752, 0.0303, 0.0647,
        0.0090, 0.0720, 0.0222, 0.0186, 0.0143, 0.0142, 0.0275, 0.0446],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,259][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0871, 0.1732, 0.1153, 0.4299, 0.0126, 0.0846, 0.0033, 0.0085, 0.0133,
        0.0035, 0.0317, 0.0041, 0.0118, 0.0062, 0.0010, 0.0066, 0.0071],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,261][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([2.9025e-04, 2.2661e-01, 6.1253e-01, 9.7196e-02, 1.8916e-02, 2.1706e-02,
        6.2164e-04, 1.7331e-04, 3.8676e-03, 5.6306e-05, 1.6515e-02, 4.3966e-05,
        3.7833e-04, 1.3795e-04, 1.4290e-05, 1.0471e-04, 8.3558e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,262][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0003, 0.1205, 0.1809, 0.1978, 0.0637, 0.0263, 0.0152, 0.0275, 0.0878,
        0.0023, 0.1230, 0.0129, 0.0160, 0.0125, 0.0104, 0.0500, 0.0526],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,264][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0409, 0.0687, 0.1717, 0.1676, 0.0303, 0.1044, 0.0315, 0.0347, 0.0519,
        0.0252, 0.0855, 0.0135, 0.0323, 0.0242, 0.0154, 0.0287, 0.0734],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,266][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0021, 0.0524, 0.0975, 0.1054, 0.0922, 0.0501, 0.0741, 0.0661, 0.1002,
        0.0259, 0.0847, 0.0464, 0.0282, 0.0448, 0.0077, 0.0455, 0.0767],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,267][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([9.6008e-06, 4.8325e-01, 2.8207e-01, 1.8759e-01, 1.5330e-02, 4.7078e-03,
        4.5270e-04, 9.8132e-05, 7.4908e-03, 9.7471e-06, 1.7755e-02, 1.6181e-05,
        1.8159e-04, 1.1092e-04, 5.8050e-06, 4.3320e-05, 8.7070e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,268][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([3.7429e-03, 2.1596e-05, 9.2380e-01, 1.8893e-04, 4.5764e-02, 2.0536e-03,
        3.6182e-03, 3.5897e-04, 9.9209e-04, 4.4890e-03, 7.2098e-04, 1.7530e-03,
        2.2886e-03, 2.1190e-04, 1.3738e-03, 2.8930e-04, 8.3304e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,269][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([5.3113e-05, 2.3124e-03, 7.8983e-03, 1.6635e-02, 1.0248e-01, 3.6712e-03,
        2.9060e-02, 9.3418e-02, 2.1871e-01, 8.6586e-04, 9.4994e-02, 9.9476e-02,
        1.2372e-02, 3.2650e-02, 3.5306e-02, 1.5174e-01, 9.8363e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,271][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.6969e-05, 2.3670e-02, 1.3354e-01, 5.3303e-02, 1.9478e-01, 8.1024e-03,
        2.9962e-02, 1.9820e-02, 8.6026e-02, 2.2805e-03, 8.8561e-02, 2.0617e-02,
        3.9048e-02, 2.2631e-02, 1.7064e-02, 5.5121e-02, 1.6087e-01, 4.4562e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,272][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.8840e-07, 1.1674e-01, 2.6065e-02, 3.4063e-01, 1.5356e-01, 3.1216e-03,
        1.6701e-02, 1.6089e-02, 8.7109e-02, 4.2091e-04, 8.6088e-02, 8.2713e-03,
        2.5873e-02, 1.1861e-02, 9.4141e-03, 4.2598e-02, 3.4198e-02, 2.1255e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,273][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.7430e-05, 4.4772e-02, 1.6965e-02, 1.6780e-01, 1.0900e-01, 5.2805e-03,
        4.3526e-02, 7.1255e-02, 1.2334e-01, 2.2872e-03, 1.5912e-01, 5.3299e-02,
        4.4350e-02, 3.0207e-02, 1.1863e-02, 2.8501e-02, 6.2749e-02, 2.5663e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,275][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.2842e-04, 2.4953e-02, 1.6842e-01, 9.5978e-02, 2.2973e-01, 5.1953e-02,
        8.6606e-02, 3.4241e-02, 6.1961e-02, 4.6000e-03, 6.6003e-02, 2.3872e-02,
        3.0486e-02, 1.7206e-02, 1.5562e-02, 2.6381e-02, 3.8863e-02, 2.2954e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,276][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0369, 0.1739, 0.1318, 0.4229, 0.0263, 0.0737, 0.0067, 0.0110, 0.0159,
        0.0038, 0.0353, 0.0085, 0.0157, 0.0067, 0.0014, 0.0089, 0.0129, 0.0078],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,278][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.2706e-05, 2.6492e-01, 4.8984e-01, 1.7117e-01, 1.7507e-02, 1.3734e-02,
        4.7896e-04, 2.6585e-04, 7.4958e-03, 7.1501e-05, 3.1507e-02, 7.8320e-05,
        5.6314e-04, 2.1211e-04, 3.0261e-05, 2.0984e-04, 1.5809e-03, 2.5717e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,279][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.3878e-05, 1.3425e-01, 8.2996e-02, 2.5702e-01, 5.3816e-02, 1.3003e-02,
        2.4130e-02, 2.4635e-02, 7.9232e-02, 1.3096e-03, 1.1029e-01, 9.7486e-03,
        2.4477e-02, 1.8590e-02, 1.8828e-02, 5.4189e-02, 6.2863e-02, 3.0582e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,281][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0093, 0.1045, 0.1469, 0.2008, 0.0373, 0.0760, 0.0254, 0.0319, 0.0564,
        0.0137, 0.1073, 0.0176, 0.0287, 0.0303, 0.0111, 0.0324, 0.0390, 0.0316],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,282][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0018, 0.0440, 0.0468, 0.1085, 0.0592, 0.0398, 0.0557, 0.0675, 0.0842,
        0.0168, 0.0626, 0.0343, 0.0350, 0.0764, 0.0137, 0.0643, 0.0789, 0.1107],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,284][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.9857e-05, 3.2835e-01, 3.3278e-01, 3.0414e-01, 8.6714e-03, 5.7402e-03,
        1.4101e-04, 5.8327e-05, 2.9920e-03, 1.7245e-05, 1.5282e-02, 1.7369e-05,
        1.1182e-04, 4.6400e-05, 5.4958e-06, 3.2509e-05, 1.5368e-03, 4.8336e-05],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,285][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.2170e-03, 3.0433e-05, 8.8249e-01, 2.2347e-04, 8.1969e-02, 1.6055e-03,
        5.8241e-03, 5.7158e-04, 1.5250e-03, 3.1980e-03, 7.9317e-04, 2.0851e-03,
        5.0498e-03, 5.0194e-04, 2.5569e-03, 4.0439e-04, 9.3789e-03, 5.7174e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,287][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0002, 0.0046, 0.0326, 0.0204, 0.0975, 0.0076, 0.0561, 0.0637, 0.1174,
        0.0032, 0.0834, 0.1000, 0.0276, 0.0412, 0.0376, 0.0814, 0.1809, 0.0446],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,290][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:09,292][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[407],
        [  8],
        [ 12],
        [ 11],
        [  7],
        [  3],
        [  1],
        [  2],
        [  1],
        [  3],
        [  1],
        [ 12],
        [  1],
        [  2],
        [  1],
        [  2],
        [  1],
        [  2]], device='cuda:0')
[2024-07-24 10:26:09,294][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[39],
        [ 8],
        [ 4],
        [ 7],
        [ 5],
        [ 2],
        [ 1],
        [ 2],
        [ 1],
        [ 1],
        [ 1],
        [ 6],
        [ 1],
        [ 1],
        [ 1],
        [ 2],
        [ 1],
        [ 2]], device='cuda:0')
[2024-07-24 10:26:09,296][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39328],
        [27831],
        [50157],
        [41378],
        [48509],
        [48083],
        [38795],
        [42462],
        [46546],
        [46901],
        [46820],
        [46956],
        [46973],
        [46546],
        [47178],
        [48590],
        [48814],
        [48055]], device='cuda:0')
[2024-07-24 10:26:09,298][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 2403],
        [43325],
        [46492],
        [46517],
        [47786],
        [47960],
        [47347],
        [47682],
        [47688],
        [47451],
        [48231],
        [48252],
        [48314],
        [48318],
        [48282],
        [48257],
        [48091],
        [48156]], device='cuda:0')
[2024-07-24 10:26:09,299][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7888],
        [ 9076],
        [34164],
        [19849],
        [19257],
        [16884],
        [14294],
        [12004],
        [10666],
        [ 9556],
        [10105],
        [10437],
        [10408],
        [10072],
        [ 9857],
        [ 9897],
        [ 9231],
        [ 9097]], device='cuda:0')
[2024-07-24 10:26:09,301][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13242],
        [12464],
        [17988],
        [13426],
        [12766],
        [12418],
        [11392],
        [12172],
        [13592],
        [12546],
        [13760],
        [13990],
        [14201],
        [14440],
        [14198],
        [14267],
        [13890],
        [13801]], device='cuda:0')
[2024-07-24 10:26:09,302][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[5181],
        [2391],
        [2364],
        [2012],
        [2034],
        [1817],
        [1594],
        [1302],
        [1277],
        [1169],
        [1196],
        [1180],
        [1131],
        [1134],
        [1179],
        [1144],
        [1117],
        [1113]], device='cuda:0')
[2024-07-24 10:26:09,304][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[18870],
        [16793],
        [14257],
        [12919],
        [10445],
        [12116],
        [11263],
        [11678],
        [11660],
        [12006],
        [11133],
        [11017],
        [12047],
        [12257],
        [12750],
        [12942],
        [12903],
        [12447]], device='cuda:0')
[2024-07-24 10:26:09,306][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 7596],
        [31012],
        [39203],
        [35676],
        [30160],
        [33244],
        [32094],
        [33243],
        [33273],
        [32014],
        [33586],
        [33517],
        [32069],
        [32699],
        [30151],
        [33038],
        [21331],
        [31865]], device='cuda:0')
[2024-07-24 10:26:09,308][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 4664],
        [38075],
        [42789],
        [45224],
        [35550],
        [29321],
        [33445],
        [32959],
        [31038],
        [27143],
        [31313],
        [26717],
        [28545],
        [29957],
        [31211],
        [31643],
        [27987],
        [30762]], device='cuda:0')
[2024-07-24 10:26:09,309][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17438],
        [26516],
        [27899],
        [36452],
        [37869],
        [38048],
        [39302],
        [38001],
        [36626],
        [36788],
        [37572],
        [38053],
        [38828],
        [38830],
        [39025],
        [38689],
        [39299],
        [38955]], device='cuda:0')
[2024-07-24 10:26:09,311][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40070],
        [37609],
        [43427],
        [45508],
        [44702],
        [45010],
        [43706],
        [43237],
        [45200],
        [43818],
        [45722],
        [41501],
        [44639],
        [43945],
        [43727],
        [44474],
        [42925],
        [44087]], device='cuda:0')
[2024-07-24 10:26:09,313][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[9998],
        [2047],
        [ 131],
        [ 150],
        [ 141],
        [ 235],
        [ 402],
        [ 389],
        [ 378],
        [ 284],
        [ 395],
        [ 505],
        [ 378],
        [ 446],
        [ 451],
        [ 399],
        [ 415],
        [ 437]], device='cuda:0')
[2024-07-24 10:26:09,315][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[36340],
        [14440],
        [36002],
        [37109],
        [44921],
        [45295],
        [42884],
        [44186],
        [43970],
        [44439],
        [44761],
        [45293],
        [45143],
        [45870],
        [45784],
        [47166],
        [47269],
        [47734]], device='cuda:0')
[2024-07-24 10:26:09,317][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12082],
        [28822],
        [38806],
        [20029],
        [33972],
        [33372],
        [38216],
        [29117],
        [24689],
        [33555],
        [22812],
        [31331],
        [22660],
        [22643],
        [29579],
        [26744],
        [28817],
        [23164]], device='cuda:0')
[2024-07-24 10:26:09,319][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35010],
        [26546],
        [39019],
        [33333],
        [35037],
        [34327],
        [34275],
        [35050],
        [33808],
        [34262],
        [33185],
        [32900],
        [33074],
        [33208],
        [33432],
        [34153],
        [32508],
        [31606]], device='cuda:0')
[2024-07-24 10:26:09,321][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25128],
        [ 2597],
        [ 2163],
        [ 2041],
        [ 1704],
        [ 1851],
        [ 1843],
        [ 1825],
        [ 2045],
        [ 2924],
        [ 2372],
        [ 2276],
        [ 2526],
        [ 2614],
        [ 2390],
        [ 2451],
        [ 2598],
        [ 2634]], device='cuda:0')
[2024-07-24 10:26:09,322][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33036],
        [32724],
        [28713],
        [34504],
        [29566],
        [29113],
        [29067],
        [27468],
        [25341],
        [25054],
        [25910],
        [28117],
        [26762],
        [26009],
        [26082],
        [26689],
        [28660],
        [28180]], device='cuda:0')
[2024-07-24 10:26:09,324][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[44235],
        [38577],
        [33600],
        [26870],
        [25744],
        [26099],
        [24628],
        [23463],
        [23502],
        [24301],
        [24221],
        [24801],
        [24468],
        [25016],
        [24875],
        [25795],
        [26122],
        [25758]], device='cuda:0')
[2024-07-24 10:26:09,326][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24673],
        [25502],
        [22875],
        [20433],
        [21160],
        [20336],
        [20831],
        [20300],
        [19767],
        [19695],
        [19609],
        [19809],
        [20321],
        [20065],
        [19865],
        [19230],
        [20333],
        [20037]], device='cuda:0')
[2024-07-24 10:26:09,328][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19823],
        [22741],
        [30808],
        [33648],
        [31306],
        [32938],
        [29877],
        [29898],
        [33898],
        [27684],
        [34409],
        [24903],
        [32923],
        [30772],
        [30068],
        [32765],
        [32162],
        [31346]], device='cuda:0')
[2024-07-24 10:26:09,330][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14869],
        [20802],
        [12575],
        [18306],
        [12024],
        [16418],
        [18090],
        [18012],
        [17430],
        [15289],
        [17013],
        [16117],
        [16655],
        [17345],
        [15565],
        [15743],
        [15076],
        [17089]], device='cuda:0')
[2024-07-24 10:26:09,332][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23589],
        [36995],
        [23809],
        [35480],
        [32002],
        [27200],
        [35364],
        [35431],
        [34608],
        [31945],
        [34662],
        [36120],
        [34424],
        [37257],
        [35516],
        [35366],
        [34010],
        [36379]], device='cuda:0')
[2024-07-24 10:26:09,334][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33193],
        [22419],
        [18615],
        [13546],
        [ 8225],
        [ 9660],
        [ 7215],
        [12185],
        [15280],
        [16836],
        [16192],
        [14539],
        [15428],
        [16294],
        [14914],
        [13679],
        [11452],
        [14015]], device='cuda:0')
[2024-07-24 10:26:09,336][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31208],
        [39035],
        [35062],
        [31243],
        [33032],
        [32675],
        [34854],
        [35640],
        [32033],
        [34609],
        [30328],
        [36912],
        [33150],
        [34557],
        [34536],
        [33765],
        [35760],
        [34415]], device='cuda:0')
[2024-07-24 10:26:09,338][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34635],
        [ 7637],
        [33512],
        [33627],
        [35281],
        [42079],
        [39430],
        [37838],
        [35848],
        [42425],
        [37410],
        [37625],
        [35656],
        [36897],
        [36041],
        [34763],
        [34753],
        [35548]], device='cuda:0')
[2024-07-24 10:26:09,339][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6164],
        [21738],
        [22022],
        [22287],
        [11691],
        [10822],
        [15520],
        [19419],
        [19963],
        [20408],
        [18038],
        [17113],
        [17208],
        [14852],
        [15568],
        [12091],
        [14285],
        [13496]], device='cuda:0')
[2024-07-24 10:26:09,341][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4393],
        [ 9625],
        [10116],
        [ 8303],
        [15077],
        [13035],
        [11493],
        [10410],
        [10942],
        [10094],
        [10593],
        [10861],
        [10907],
        [10461],
        [11671],
        [12133],
        [11790],
        [11567]], device='cuda:0')
[2024-07-24 10:26:09,343][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31238],
        [17637],
        [17017],
        [34657],
        [18299],
        [28343],
        [16406],
        [22108],
        [26602],
        [18357],
        [27722],
        [20454],
        [27524],
        [27093],
        [20429],
        [22592],
        [18351],
        [23752]], device='cuda:0')
[2024-07-24 10:26:09,345][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852],
        [16852]], device='cuda:0')
[2024-07-24 10:26:09,472][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:09,473][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,475][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,476][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,477][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,477][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,478][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,479][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,479][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,480][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,481][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,482][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,483][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,483][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5225, 0.4775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,484][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,485][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([3.0600e-04, 9.9969e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,486][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4930, 0.5070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,486][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,487][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([4.2676e-05, 9.9996e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,489][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,490][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([4.2187e-04, 9.9958e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,491][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0185, 0.9815], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,492][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([5.2581e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,494][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0032, 0.9968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,495][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([5.4731e-04, 9.9945e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,496][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Amber] are: tensor([0.2901, 0.0454, 0.6646], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,498][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Amber] are: tensor([0.0180, 0.0722, 0.9098], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,499][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Amber] are: tensor([0.0036, 0.0508, 0.9456], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,501][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Amber] are: tensor([0.7913, 0.0593, 0.1494], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,503][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Amber] are: tensor([0.0031, 0.1738, 0.8231], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,504][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Amber] are: tensor([2.9638e-04, 2.6625e-02, 9.7308e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,505][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Amber] are: tensor([0.0056, 0.1670, 0.8274], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,507][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Amber] are: tensor([0.0019, 0.0478, 0.9503], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,508][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Amber] are: tensor([3.5775e-04, 4.4879e-01, 5.5086e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,509][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Amber] are: tensor([2.9861e-05, 3.2332e-02, 9.6764e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,511][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Amber] are: tensor([0.0010, 0.0502, 0.9488], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,512][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Amber] are: tensor([0.0451, 0.0416, 0.9133], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,514][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0302, 0.0292, 0.7431, 0.1975], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,515][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.4769e-04, 5.9127e-02, 6.8550e-01, 2.5513e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,516][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([7.6532e-05, 8.9924e-02, 7.1009e-01, 1.9991e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,518][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0823, 0.0634, 0.7754, 0.0789], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,519][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([1.9069e-04, 1.6614e-01, 1.8447e-01, 6.4920e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,520][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.0458e-05, 3.0566e-02, 5.2861e-01, 4.4082e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,521][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([2.1096e-04, 1.7282e-01, 3.5962e-01, 4.6735e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,522][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.9768e-04, 1.9285e-01, 3.1946e-01, 4.8750e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,524][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0005, 0.2719, 0.3376, 0.3901], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,524][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.1496e-06, 2.6125e-02, 7.0745e-01, 2.6642e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,525][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0026, 0.1855, 0.3880, 0.4239], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,526][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.0327e-04, 9.7248e-02, 4.9191e-01, 4.1064e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,527][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0114, 0.0233, 0.6037, 0.1414, 0.2202], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,527][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([0.0032, 0.0634, 0.6270, 0.1692, 0.1373], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,529][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([0.0008, 0.1012, 0.5863, 0.1529, 0.1588], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,531][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.1830, 0.2802, 0.3444, 0.1670, 0.0253], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,532][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([0.0003, 0.2238, 0.2223, 0.2978, 0.2557], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,533][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([2.9327e-05, 1.8159e-02, 5.4273e-01, 7.6647e-02, 3.6244e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,535][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0057, 0.1660, 0.4972, 0.2056, 0.1256], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,536][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([0.0007, 0.0559, 0.6013, 0.0830, 0.2592], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,538][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([2.0210e-04, 2.0591e-01, 2.0240e-01, 3.1936e-01, 2.7213e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,539][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([6.6268e-05, 3.8442e-02, 5.5589e-01, 1.7998e-01, 2.2562e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,541][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([0.0036, 0.1245, 0.6679, 0.1833, 0.0208], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,542][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([0.0017, 0.1234, 0.4508, 0.3084, 0.1157], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,544][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0418, 0.0061, 0.5696, 0.0263, 0.0534, 0.3028], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,545][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0010, 0.0231, 0.6297, 0.0648, 0.1231, 0.1583], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,546][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ were] are: tensor([1.0463e-04, 3.4222e-02, 7.4716e-01, 4.3033e-02, 8.9858e-02, 8.5626e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,548][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0679, 0.0665, 0.6535, 0.0715, 0.0223, 0.1183], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,549][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ were] are: tensor([1.2791e-04, 5.2734e-02, 3.2190e-01, 2.7454e-01, 2.5379e-01, 9.6914e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,550][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ were] are: tensor([1.0006e-05, 7.4428e-03, 3.1924e-01, 6.9905e-02, 4.6780e-01, 1.3560e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,551][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ were] are: tensor([8.6394e-05, 2.5276e-02, 6.6497e-01, 9.1911e-02, 4.8837e-02, 1.6892e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,552][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ were] are: tensor([2.3998e-04, 3.6143e-02, 5.4142e-01, 8.9881e-02, 1.4682e-01, 1.8550e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,554][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0006, 0.1304, 0.1860, 0.2183, 0.2212, 0.2434], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,555][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ were] are: tensor([7.2818e-06, 1.0057e-02, 6.0247e-01, 6.5543e-02, 2.4397e-01, 7.7954e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,557][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ were] are: tensor([5.7844e-04, 2.8365e-02, 6.8111e-01, 5.1009e-02, 4.0405e-03, 2.3490e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,558][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0041, 0.0183, 0.6645, 0.1337, 0.1038, 0.0756], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,560][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0016, 0.0081, 0.4200, 0.0761, 0.2216, 0.2514, 0.0212],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,561][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ working] are: tensor([1.5657e-04, 3.2761e-02, 3.6514e-01, 1.5653e-01, 1.8900e-01, 1.3385e-01,
        1.2256e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,562][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ working] are: tensor([2.1862e-05, 6.4501e-02, 2.8149e-01, 1.9519e-01, 1.8341e-01, 1.6272e-01,
        1.1268e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,564][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0165, 0.2076, 0.1851, 0.2505, 0.0632, 0.2709, 0.0061],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,565][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ working] are: tensor([2.0122e-05, 1.0638e-01, 1.1908e-01, 3.1721e-01, 2.5168e-01, 7.4949e-02,
        1.3068e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,566][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ working] are: tensor([1.6447e-06, 1.9266e-02, 2.2906e-01, 1.4681e-01, 4.4847e-01, 9.0509e-02,
        6.5884e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,567][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0005, 0.0717, 0.3678, 0.1888, 0.1363, 0.1675, 0.0674],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,568][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ working] are: tensor([2.3232e-04, 6.9189e-02, 2.1299e-01, 1.3378e-01, 3.4940e-01, 1.3839e-01,
        9.6018e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,568][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ working] are: tensor([1.8836e-04, 1.0696e-01, 1.0929e-01, 1.7820e-01, 1.7648e-01, 1.9250e-01,
        2.3638e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,569][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ working] are: tensor([1.1236e-05, 1.5656e-02, 4.5619e-01, 1.1371e-01, 2.8571e-01, 9.9265e-02,
        2.9462e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,570][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ working] are: tensor([7.8529e-05, 9.7734e-02, 2.9631e-01, 1.7848e-01, 1.1712e-02, 4.0467e-01,
        1.1016e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,571][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ working] are: tensor([4.5128e-05, 5.1867e-02, 1.5812e-01, 5.6671e-01, 1.0438e-01, 5.2128e-02,
        6.6747e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,573][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0009, 0.0062, 0.4021, 0.0647, 0.2116, 0.2860, 0.0144, 0.0140],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,574][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([6.1837e-05, 2.9289e-02, 3.4517e-01, 1.6325e-01, 1.7160e-01, 1.3759e-01,
        9.7582e-02, 5.5451e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,575][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([6.4472e-06, 5.1492e-02, 1.9887e-01, 2.2566e-01, 1.7943e-01, 1.4887e-01,
        1.2040e-01, 7.5279e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,576][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0150, 0.1674, 0.3627, 0.1789, 0.0473, 0.2210, 0.0056, 0.0022],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,578][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([1.0742e-05, 8.5461e-02, 9.3568e-02, 2.6711e-01, 2.0066e-01, 6.1585e-02,
        1.3087e-01, 1.6073e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,579][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([6.8970e-07, 1.8796e-02, 2.2271e-01, 1.1787e-01, 4.4204e-01, 9.8180e-02,
        5.5685e-02, 4.4714e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,580][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0003, 0.0615, 0.2873, 0.1667, 0.1430, 0.1768, 0.0598, 0.1046],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,582][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([5.5981e-05, 5.6097e-02, 2.1134e-01, 1.3041e-01, 3.2590e-01, 9.7064e-02,
        1.0400e-01, 7.5138e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,583][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0077, 0.0770, 0.1610, 0.1512, 0.1598, 0.1401, 0.1633, 0.1398],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,584][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.0977e-05, 1.6770e-02, 5.4642e-01, 8.4432e-02, 2.1890e-01, 8.5758e-02,
        2.9926e-02, 1.7783e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,586][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([1.6998e-04, 1.2054e-01, 2.9604e-01, 1.6312e-01, 1.3156e-02, 3.8747e-01,
        1.0600e-02, 8.9070e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,587][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.0014e-05, 3.1284e-02, 2.4707e-01, 4.7160e-01, 9.5919e-02, 3.2996e-02,
        9.4334e-02, 2.6783e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,589][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0011, 0.0045, 0.3810, 0.0568, 0.1450, 0.2679, 0.0073, 0.0084, 0.1281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,590][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([8.1742e-05, 8.2449e-03, 4.4477e-01, 6.8015e-02, 1.1521e-01, 8.7755e-02,
        5.7423e-02, 2.1325e-02, 1.9717e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,591][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([6.6951e-06, 1.7927e-02, 1.7625e-01, 9.1189e-02, 1.0956e-01, 8.2753e-02,
        5.5248e-02, 2.2017e-02, 4.4505e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,592][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([3.7965e-02, 5.9698e-02, 6.3257e-01, 8.2110e-02, 2.3144e-02, 1.5243e-01,
        2.0860e-03, 6.1773e-04, 9.3775e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,593][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([6.2089e-06, 3.1273e-02, 6.4885e-02, 1.2230e-01, 6.2112e-02, 3.0495e-02,
        3.6644e-02, 4.3179e-02, 6.0910e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,594][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([8.0174e-07, 7.3804e-03, 2.5122e-01, 5.2470e-02, 2.7701e-01, 5.0095e-02,
        2.4531e-02, 1.9691e-02, 3.1760e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,596][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([2.9791e-04, 3.4392e-02, 3.6676e-01, 1.1597e-01, 1.1281e-01, 1.4171e-01,
        4.0770e-02, 5.7235e-02, 1.3005e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,597][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.3405e-04, 2.6830e-02, 2.8519e-01, 4.9826e-02, 1.7895e-01, 5.7133e-02,
        5.7383e-02, 2.4024e-02, 3.2053e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,599][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2528, 0.0478, 0.1678, 0.1137, 0.1224, 0.0908, 0.1122, 0.0612, 0.0313],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,600][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([8.3953e-06, 7.5465e-03, 7.2332e-01, 3.7188e-02, 9.9157e-02, 4.5483e-02,
        1.0212e-02, 4.3262e-03, 7.2760e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,601][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0004, 0.0911, 0.3405, 0.1271, 0.0074, 0.3624, 0.0065, 0.0047, 0.0598],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,603][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([7.4717e-05, 4.8752e-02, 3.7063e-01, 2.8335e-01, 5.0393e-02, 2.8453e-02,
        3.2746e-02, 6.9611e-03, 1.7864e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,604][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ restaurant] are: tensor([0.0032, 0.0025, 0.5041, 0.0232, 0.0986, 0.2800, 0.0057, 0.0029, 0.0188,
        0.0611], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,605][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ restaurant] are: tensor([2.0003e-04, 1.9157e-02, 4.1724e-01, 6.8294e-02, 9.1030e-02, 9.4698e-02,
        4.3614e-02, 2.1942e-02, 2.1474e-01, 2.9082e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,607][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ restaurant] are: tensor([7.2050e-06, 2.2913e-02, 4.3513e-01, 5.4256e-02, 1.5133e-01, 7.5698e-02,
        3.5382e-02, 1.6235e-02, 1.7502e-01, 3.4029e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,609][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ restaurant] are: tensor([0.0101, 0.1418, 0.4090, 0.1978, 0.0450, 0.1452, 0.0036, 0.0024, 0.0427,
        0.0023], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,609][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ restaurant] are: tensor([1.4288e-05, 1.3877e-02, 7.8591e-02, 7.0783e-02, 1.1159e-01, 2.5515e-02,
        5.8617e-02, 5.8307e-02, 5.3865e-01, 4.4056e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,610][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ restaurant] are: tensor([1.5554e-06, 2.7635e-03, 1.8687e-01, 3.7319e-02, 3.6836e-01, 9.5456e-02,
        5.4723e-02, 2.3607e-02, 2.1855e-01, 1.2350e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,611][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ restaurant] are: tensor([2.3201e-04, 2.6563e-02, 5.2822e-01, 7.5542e-02, 6.8518e-02, 1.3775e-01,
        2.2346e-02, 4.1561e-02, 8.7699e-02, 1.1573e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,612][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ restaurant] are: tensor([9.2954e-05, 7.4974e-03, 3.1895e-01, 4.1875e-02, 1.7846e-01, 7.3470e-02,
        6.5248e-02, 3.6547e-02, 2.3344e-01, 4.4419e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,614][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ restaurant] are: tensor([0.2163, 0.0422, 0.1710, 0.1172, 0.1317, 0.0895, 0.1138, 0.0676, 0.0334,
        0.0172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,615][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ restaurant] are: tensor([1.1664e-05, 3.9595e-03, 5.3351e-01, 2.2841e-02, 2.6303e-01, 5.3345e-02,
        2.6700e-02, 9.6412e-03, 7.5087e-02, 1.1873e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,616][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ restaurant] are: tensor([5.1521e-06, 5.2731e-02, 6.8435e-01, 7.8699e-02, 7.0644e-03, 1.1544e-01,
        2.2878e-03, 2.7601e-03, 5.1253e-02, 5.4091e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,617][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ restaurant] are: tensor([2.1657e-05, 7.3206e-03, 5.1978e-02, 6.9988e-02, 6.1752e-02, 1.1518e-02,
        1.3560e-01, 5.6834e-02, 6.0226e-01, 2.7325e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,619][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0012, 0.0035, 0.3366, 0.0405, 0.1438, 0.2216, 0.0064, 0.0064, 0.1051,
        0.0760, 0.0589], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,620][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([5.8999e-05, 6.8577e-03, 3.4462e-01, 5.7105e-02, 1.2493e-01, 9.3386e-02,
        5.3348e-02, 1.9595e-02, 1.8483e-01, 1.3583e-02, 1.0168e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,621][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([1.2043e-05, 1.4669e-02, 1.8151e-01, 7.5122e-02, 1.1092e-01, 6.3034e-02,
        5.3316e-02, 1.8651e-02, 2.7431e-01, 2.2840e-02, 1.8561e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,622][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([4.4719e-02, 5.0706e-02, 6.4499e-01, 7.3224e-02, 2.4076e-02, 1.3301e-01,
        1.2942e-03, 4.5383e-04, 8.1514e-03, 1.3804e-03, 1.7996e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,623][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([6.6739e-06, 2.0790e-02, 5.3138e-02, 8.8831e-02, 4.9157e-02, 2.6252e-02,
        2.8988e-02, 3.5790e-02, 4.5113e-01, 2.6124e-02, 2.1979e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,625][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([1.0019e-06, 4.7960e-03, 1.9708e-01, 5.2049e-02, 3.0226e-01, 5.9380e-02,
        3.1633e-02, 1.8848e-02, 1.7718e-01, 5.4588e-03, 1.5132e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,626][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([1.7282e-04, 3.1328e-02, 2.7887e-01, 1.1752e-01, 8.4868e-02, 1.1852e-01,
        3.3664e-02, 5.6629e-02, 1.1768e-01, 1.1352e-02, 1.4940e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,627][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([4.1807e-05, 1.5060e-02, 1.9261e-01, 5.0041e-02, 1.7452e-01, 5.5916e-02,
        6.1389e-02, 3.0550e-02, 2.9647e-01, 1.2705e-02, 1.1069e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,629][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0012, 0.0632, 0.0826, 0.1041, 0.1090, 0.1020, 0.1353, 0.1292, 0.1002,
        0.0768, 0.0963], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,630][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([6.5025e-06, 5.6002e-03, 5.5064e-01, 5.3861e-02, 1.6688e-01, 4.9211e-02,
        1.4713e-02, 7.0097e-03, 8.3339e-02, 4.3384e-03, 6.4407e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,631][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([3.2742e-04, 9.1486e-02, 3.5185e-01, 1.2116e-01, 5.5298e-03, 2.8498e-01,
        3.9729e-03, 3.0127e-03, 3.9158e-02, 1.6175e-02, 8.2348e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,632][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([8.7865e-05, 2.1709e-02, 4.9650e-01, 1.5485e-01, 5.2270e-02, 2.0744e-02,
        1.9426e-02, 4.3548e-03, 1.0108e-01, 4.6867e-03, 1.2430e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:09,634][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Lisa] are: tensor([0.0005, 0.0080, 0.1874, 0.0616, 0.1474, 0.1538, 0.0117, 0.0160, 0.1836,
        0.0916, 0.1073, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,635][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Lisa] are: tensor([1.3189e-04, 2.3127e-02, 1.5850e-01, 1.0465e-01, 9.4256e-02, 9.5085e-02,
        4.5651e-02, 2.9243e-02, 2.4909e-01, 1.2744e-02, 1.7501e-01, 1.2508e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,636][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Lisa] are: tensor([9.4538e-06, 2.4092e-02, 6.6567e-02, 9.0582e-02, 8.8780e-02, 4.4158e-02,
        3.8208e-02, 2.6697e-02, 3.4755e-01, 9.4337e-03, 2.4495e-01, 1.8969e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,638][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Lisa] are: tensor([0.0093, 0.2913, 0.2167, 0.2205, 0.0559, 0.0989, 0.0069, 0.0023, 0.0366,
        0.0025, 0.0570, 0.0021], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,639][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Lisa] are: tensor([8.3095e-06, 3.5012e-02, 3.7124e-02, 6.6273e-02, 7.3694e-02, 2.2421e-02,
        2.3409e-02, 2.8944e-02, 4.3034e-01, 1.3034e-02, 2.2899e-01, 4.0748e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,640][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Lisa] are: tensor([1.8446e-06, 1.1916e-02, 1.6859e-01, 5.2556e-02, 2.6817e-01, 3.0289e-02,
        1.3552e-02, 1.7543e-02, 2.5819e-01, 3.6814e-03, 1.5393e-01, 2.1580e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,642][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Lisa] are: tensor([0.0009, 0.0933, 0.1391, 0.1377, 0.0969, 0.0848, 0.0373, 0.0643, 0.1252,
        0.0046, 0.1597, 0.0560], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,643][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Lisa] are: tensor([3.8633e-05, 1.6566e-02, 1.2961e-01, 4.5992e-02, 2.2313e-01, 4.4258e-02,
        2.7494e-02, 3.4444e-02, 3.1144e-01, 1.3725e-02, 1.2187e-01, 3.1442e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,645][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Lisa] are: tensor([2.9658e-05, 5.0109e-02, 4.7143e-02, 7.2933e-02, 7.0516e-02, 8.3077e-02,
        9.9762e-02, 1.4748e-01, 1.4856e-01, 1.4303e-01, 7.1622e-02, 6.5735e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,646][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Lisa] are: tensor([2.9549e-05, 2.3457e-02, 2.9532e-01, 1.0924e-01, 2.1842e-01, 5.6977e-02,
        1.6255e-02, 1.4116e-02, 1.4530e-01, 4.8191e-03, 9.1062e-02, 2.4992e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,647][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Lisa] are: tensor([8.9373e-05, 1.0714e-01, 2.8183e-01, 9.7271e-02, 7.7131e-03, 3.0748e-01,
        4.6745e-03, 3.2466e-03, 4.6965e-02, 2.8483e-02, 9.6618e-02, 1.8486e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,648][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Lisa] are: tensor([7.1010e-06, 3.4919e-02, 9.4818e-02, 1.6918e-01, 1.1987e-01, 1.0840e-02,
        3.8921e-02, 9.9102e-03, 2.8515e-01, 3.4790e-03, 2.0784e-01, 2.5070e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:09,650][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0005, 0.0026, 0.3960, 0.0284, 0.1494, 0.1674, 0.0059, 0.0064, 0.0965,
        0.0774, 0.0503, 0.0138, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,651][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0003, 0.0188, 0.2853, 0.0997, 0.0672, 0.0971, 0.0501, 0.0241, 0.1964,
        0.0112, 0.1086, 0.0073, 0.0338], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,652][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([1.9435e-05, 1.6795e-02, 1.3009e-01, 6.8850e-02, 7.1808e-02, 5.7624e-02,
        4.2546e-02, 2.5280e-02, 3.1484e-01, 1.6809e-02, 1.7554e-01, 1.1160e-02,
        6.8631e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,653][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0155, 0.0765, 0.4132, 0.1523, 0.0297, 0.2416, 0.0022, 0.0010, 0.0250,
        0.0014, 0.0377, 0.0005, 0.0035], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,653][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([1.5534e-05, 2.6322e-02, 3.7668e-02, 6.2537e-02, 4.3721e-02, 1.8061e-02,
        2.6504e-02, 3.5424e-02, 4.0359e-01, 1.3715e-02, 1.8247e-01, 2.3508e-02,
        1.2646e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,655][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([3.5241e-06, 5.0330e-03, 2.6091e-01, 5.0279e-02, 1.7798e-01, 7.4182e-02,
        3.2266e-02, 1.9786e-02, 2.0235e-01, 6.9839e-03, 1.1965e-01, 1.4527e-02,
        3.6052e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,656][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0012, 0.0492, 0.1997, 0.1036, 0.0762, 0.0823, 0.0430, 0.0665, 0.1161,
        0.0098, 0.1142, 0.0460, 0.0922], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,658][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([1.9880e-04, 2.8845e-02, 2.1061e-01, 6.4570e-02, 1.6009e-01, 5.1395e-02,
        4.3669e-02, 3.8737e-02, 2.7182e-01, 1.5534e-02, 7.1831e-02, 1.4635e-02,
        2.8077e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,659][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([4.9211e-05, 4.8934e-02, 4.7040e-02, 7.0685e-02, 6.8157e-02, 8.1620e-02,
        9.4033e-02, 1.2617e-01, 1.1949e-01, 1.0559e-01, 6.9919e-02, 5.9560e-02,
        1.0875e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,660][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([5.0223e-05, 6.9261e-03, 6.3671e-01, 3.1869e-02, 1.4172e-01, 4.4146e-02,
        1.8500e-02, 7.4025e-03, 5.2188e-02, 4.4542e-03, 3.2086e-02, 1.1951e-02,
        1.1996e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,661][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0006, 0.0455, 0.2669, 0.0833, 0.0055, 0.3667, 0.0042, 0.0042, 0.0536,
        0.0246, 0.1103, 0.0161, 0.0184], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,663][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([1.7073e-05, 1.6287e-02, 1.4549e-01, 1.5618e-01, 5.9358e-02, 2.3452e-02,
        2.2255e-02, 6.2270e-03, 2.7655e-01, 3.7574e-03, 1.7506e-01, 1.1062e-02,
        1.0430e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:09,664][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0005, 0.0055, 0.2168, 0.0634, 0.1303, 0.1950, 0.0075, 0.0110, 0.1672,
        0.0731, 0.0951, 0.0161, 0.0062, 0.0122], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,666][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.9967e-05, 1.0767e-02, 1.8967e-01, 7.9554e-02, 1.1477e-01, 7.8369e-02,
        6.3028e-02, 2.2925e-02, 2.1533e-01, 1.3286e-02, 1.3034e-01, 1.2484e-02,
        4.8099e-02, 2.1320e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,667][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([5.7215e-06, 1.3137e-02, 7.8657e-02, 7.1326e-02, 8.8824e-02, 4.4539e-02,
        5.1796e-02, 2.4090e-02, 2.6923e-01, 1.2112e-02, 1.7882e-01, 1.5599e-02,
        9.7750e-02, 5.4112e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,668][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0102, 0.0810, 0.3863, 0.1344, 0.0399, 0.2456, 0.0036, 0.0017, 0.0245,
        0.0025, 0.0610, 0.0012, 0.0053, 0.0030], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,670][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([5.7374e-06, 3.1501e-02, 2.7283e-02, 8.8755e-02, 4.4624e-02, 1.7217e-02,
        2.7124e-02, 3.2264e-02, 3.2713e-01, 1.1681e-02, 1.9758e-01, 2.2949e-02,
        1.2159e-01, 5.0294e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,671][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.8016e-07, 1.3408e-02, 1.0940e-01, 6.9296e-02, 1.7913e-01, 4.2435e-02,
        2.9101e-02, 2.2857e-02, 2.6583e-01, 4.2817e-03, 1.8614e-01, 1.5105e-02,
        3.3771e-02, 2.9245e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,673][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0002, 0.0349, 0.1293, 0.0993, 0.0794, 0.0748, 0.0421, 0.0617, 0.1185,
        0.0104, 0.1366, 0.0446, 0.1001, 0.0681], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,674][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.2482e-05, 2.0729e-02, 1.0455e-01, 6.5491e-02, 1.5159e-01, 3.6205e-02,
        4.3390e-02, 3.1099e-02, 3.4999e-01, 1.1050e-02, 1.1149e-01, 1.5640e-02,
        2.3479e-02, 3.5259e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,676][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0044, 0.0456, 0.0944, 0.0851, 0.0910, 0.0848, 0.0969, 0.0846, 0.0586,
        0.0424, 0.0746, 0.0693, 0.1021, 0.0662], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,677][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.9843e-05, 1.6410e-02, 3.8774e-01, 6.2257e-02, 1.8211e-01, 5.3770e-02,
        3.0266e-02, 1.2722e-02, 1.1172e-01, 4.8743e-03, 7.8662e-02, 1.9532e-02,
        2.3472e-02, 1.6424e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,679][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0004, 0.0923, 0.2014, 0.1198, 0.0062, 0.3434, 0.0048, 0.0042, 0.0467,
        0.0243, 0.1032, 0.0143, 0.0154, 0.0236], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,680][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.6093e-06, 1.9583e-02, 1.5115e-01, 1.7543e-01, 6.3154e-02, 1.6852e-02,
        2.6790e-02, 4.8751e-03, 2.0279e-01, 4.0374e-03, 2.1505e-01, 9.6283e-03,
        7.1394e-02, 3.9256e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:09,681][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([3.5812e-04, 3.2609e-03, 3.6048e-01, 3.9805e-02, 1.1022e-01, 2.2958e-01,
        5.8055e-03, 5.9000e-03, 9.2413e-02, 6.5649e-02, 5.2616e-02, 8.0963e-03,
        4.5573e-03, 6.4545e-03, 1.4807e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,683][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([3.1247e-05, 1.1299e-02, 3.1638e-01, 7.0009e-02, 7.7254e-02, 7.5120e-02,
        3.6239e-02, 1.4896e-02, 2.0280e-01, 9.0850e-03, 1.2439e-01, 6.9864e-03,
        3.3894e-02, 1.2538e-02, 9.0791e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,684][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([3.1070e-06, 1.4136e-02, 1.8768e-01, 5.7949e-02, 7.4030e-02, 4.4331e-02,
        2.7795e-02, 1.3998e-02, 2.5964e-01, 1.3042e-02, 1.7099e-01, 8.9358e-03,
        7.6933e-02, 3.6816e-02, 1.3722e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,686][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0035, 0.0671, 0.3688, 0.1698, 0.0346, 0.2482, 0.0017, 0.0009, 0.0310,
        0.0017, 0.0608, 0.0007, 0.0072, 0.0030, 0.0009], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,687][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([2.7229e-06, 2.2312e-02, 4.5215e-02, 6.2124e-02, 4.4301e-02, 1.4852e-02,
        2.0456e-02, 2.1818e-02, 3.6796e-01, 1.0686e-02, 1.6194e-01, 1.9207e-02,
        1.2382e-01, 4.3397e-02, 4.1917e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,688][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([4.2866e-07, 5.3416e-03, 2.3928e-01, 4.7317e-02, 1.8124e-01, 4.6784e-02,
        3.0365e-02, 1.4377e-02, 2.1941e-01, 4.8018e-03, 1.4220e-01, 1.1959e-02,
        2.9700e-02, 1.3734e-02, 1.3487e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,690][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0003, 0.0277, 0.2588, 0.0691, 0.0692, 0.0908, 0.0306, 0.0438, 0.0886,
        0.0114, 0.1065, 0.0380, 0.0852, 0.0454, 0.0347], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,691][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([2.0756e-05, 8.7971e-03, 1.9018e-01, 4.9499e-02, 1.3629e-01, 4.4151e-02,
        3.9543e-02, 2.8484e-02, 3.0712e-01, 1.7102e-02, 9.8208e-02, 1.4682e-02,
        2.7291e-02, 2.2366e-02, 1.6269e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,693][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0007, 0.0442, 0.0717, 0.0693, 0.0742, 0.0749, 0.0877, 0.0904, 0.0717,
        0.0575, 0.0654, 0.0583, 0.0960, 0.0693, 0.0688], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,694][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([9.8842e-06, 5.4769e-03, 6.7371e-01, 2.7481e-02, 1.1977e-01, 3.5287e-02,
        1.2171e-02, 4.8370e-03, 5.1235e-02, 2.9265e-03, 3.8240e-02, 8.3931e-03,
        1.2535e-02, 4.6375e-03, 3.2894e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,695][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([3.8712e-05, 9.1449e-02, 3.7889e-01, 9.5391e-02, 3.7944e-03, 2.1879e-01,
        3.0621e-03, 2.5229e-03, 4.2999e-02, 1.3552e-02, 9.5750e-02, 1.0064e-02,
        1.3037e-02, 1.8404e-02, 1.2264e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,695][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([1.4622e-06, 9.7377e-03, 1.2177e-01, 1.3812e-01, 3.5276e-02, 8.4912e-03,
        2.4422e-02, 4.1975e-03, 2.3290e-01, 1.3045e-03, 1.9240e-01, 6.6986e-03,
        1.2142e-01, 4.6661e-02, 5.6599e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:09,697][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0004, 0.0027, 0.3851, 0.0431, 0.0975, 0.2091, 0.0038, 0.0047, 0.0952,
        0.0626, 0.0488, 0.0078, 0.0031, 0.0045, 0.0089, 0.0226],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,698][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.1359e-05, 4.2157e-03, 3.7202e-01, 5.1144e-02, 8.1855e-02, 9.0073e-02,
        3.6366e-02, 1.1979e-02, 1.5007e-01, 1.2401e-02, 8.7754e-02, 5.2242e-03,
        2.4710e-02, 9.0121e-03, 5.9134e-03, 5.7230e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,699][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.3844e-06, 1.1206e-02, 1.7681e-01, 5.9582e-02, 7.4760e-02, 5.0600e-02,
        2.7354e-02, 1.0056e-02, 2.0895e-01, 1.1615e-02, 1.2328e-01, 5.6185e-03,
        5.6934e-02, 3.0559e-02, 9.9095e-03, 1.4277e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,700][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.0395e-03, 6.2853e-02, 5.2499e-01, 1.2586e-01, 2.4664e-02, 1.9977e-01,
        9.9065e-04, 4.7415e-04, 1.2269e-02, 1.1160e-03, 3.1989e-02, 3.5860e-04,
        2.3669e-03, 1.2019e-03, 3.1608e-04, 3.7404e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,701][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.6585e-06, 1.1806e-02, 3.4331e-02, 5.9290e-02, 2.7129e-02, 1.4315e-02,
        1.3622e-02, 1.6790e-02, 3.1075e-01, 1.1952e-02, 1.3346e-01, 1.2247e-02,
        8.5412e-02, 3.1429e-02, 2.8393e-02, 2.0907e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,703][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.6298e-07, 3.3675e-03, 2.2661e-01, 3.8470e-02, 1.4253e-01, 6.5234e-02,
        2.8217e-02, 1.4998e-02, 2.2189e-01, 5.1668e-03, 1.3227e-01, 8.0037e-03,
        2.6000e-02, 1.4745e-02, 8.7757e-03, 6.3725e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,704][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.4632e-04, 1.6601e-02, 2.3559e-01, 6.9999e-02, 6.8836e-02, 8.7338e-02,
        2.7553e-02, 3.6019e-02, 8.5460e-02, 1.0197e-02, 9.5222e-02, 2.8208e-02,
        7.4575e-02, 4.0784e-02, 2.5147e-02, 9.8324e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,705][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.2948e-05, 7.6709e-03, 2.4641e-01, 3.6795e-02, 1.1458e-01, 4.3947e-02,
        4.4916e-02, 2.0740e-02, 2.6920e-01, 1.5730e-02, 7.3088e-02, 8.4438e-03,
        1.4481e-02, 1.8899e-02, 1.0234e-02, 7.4839e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,707][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0003, 0.0348, 0.0571, 0.0581, 0.0625, 0.0687, 0.0783, 0.0889, 0.0747,
        0.0634, 0.0581, 0.0518, 0.0858, 0.0683, 0.0648, 0.0845],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,708][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.0515e-06, 2.0885e-03, 7.2009e-01, 1.8214e-02, 9.2527e-02, 4.2458e-02,
        9.4374e-03, 3.2825e-03, 4.4116e-02, 3.5780e-03, 2.6455e-02, 6.3521e-03,
        1.0980e-02, 3.7215e-03, 1.8872e-03, 1.4808e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,710][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.5841e-05, 5.0786e-02, 2.8852e-01, 7.7663e-02, 3.0857e-03, 2.6238e-01,
        2.4521e-03, 1.7075e-03, 3.1753e-02, 1.4898e-02, 7.7532e-02, 7.8225e-03,
        9.5100e-03, 1.2947e-02, 7.2668e-03, 1.5163e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,711][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.5759e-06, 7.7628e-03, 1.4721e-01, 7.1171e-02, 3.5384e-02, 9.9018e-03,
        1.4095e-02, 2.4764e-03, 1.3233e-01, 2.1242e-03, 1.2337e-01, 5.8395e-03,
        5.7949e-02, 2.6290e-02, 2.9478e-02, 3.3461e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:09,713][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0028, 0.0016, 0.4550, 0.0309, 0.1062, 0.1911, 0.0060, 0.0048, 0.0560,
        0.0596, 0.0353, 0.0101, 0.0035, 0.0048, 0.0071, 0.0154, 0.0097],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,714][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([2.7054e-04, 9.1696e-03, 3.7503e-01, 7.1286e-02, 4.1201e-02, 6.8472e-02,
        2.8251e-02, 1.2481e-02, 1.4707e-01, 1.0233e-02, 8.6291e-02, 4.9406e-03,
        1.5868e-02, 7.9491e-03, 6.4673e-03, 4.5767e-02, 6.9243e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,715][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([7.0337e-05, 1.4023e-02, 2.9732e-01, 5.5841e-02, 6.0131e-02, 5.4484e-02,
        2.7178e-02, 1.2907e-02, 1.2883e-01, 1.4088e-02, 1.0051e-01, 9.4528e-03,
        5.1717e-02, 2.7680e-02, 7.2798e-03, 7.9445e-02, 5.9041e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,717][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([6.4497e-02, 7.2481e-02, 4.9270e-01, 1.2291e-01, 2.6438e-02, 1.6276e-01,
        1.5791e-03, 9.3880e-04, 1.5152e-02, 7.6489e-04, 2.6336e-02, 3.7238e-04,
        2.3954e-03, 1.9146e-03, 2.9758e-04, 5.1832e-03, 3.2717e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,718][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([1.2471e-05, 1.1499e-02, 3.6617e-02, 4.2111e-02, 3.8773e-02, 1.2897e-02,
        1.5732e-02, 1.7052e-02, 2.6233e-01, 9.4126e-03, 1.1296e-01, 2.0756e-02,
        8.8715e-02, 3.4823e-02, 2.7096e-02, 1.6633e-01, 1.0289e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,719][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([2.4357e-06, 5.7727e-03, 2.7887e-01, 5.0856e-02, 1.2132e-01, 5.0363e-02,
        2.1978e-02, 1.4345e-02, 1.8769e-01, 5.4352e-03, 1.0507e-01, 1.1258e-02,
        1.4960e-02, 1.0528e-02, 7.4714e-03, 4.0623e-02, 7.3455e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,721][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0042, 0.0357, 0.2367, 0.0852, 0.0585, 0.0585, 0.0299, 0.0436, 0.0690,
        0.0064, 0.0878, 0.0461, 0.0575, 0.0406, 0.0196, 0.0798, 0.0408],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,723][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0004, 0.0065, 0.2951, 0.0349, 0.1346, 0.0316, 0.0281, 0.0261, 0.1894,
        0.0165, 0.0535, 0.0121, 0.0117, 0.0175, 0.0077, 0.0458, 0.0884],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,725][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0002, 0.0311, 0.0474, 0.0525, 0.0557, 0.0592, 0.0711, 0.0870, 0.0745,
        0.0604, 0.0527, 0.0468, 0.0817, 0.0654, 0.0618, 0.0813, 0.0713],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,726][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([1.0825e-04, 3.2384e-03, 7.9123e-01, 1.9753e-02, 6.3190e-02, 3.4329e-02,
        7.9551e-03, 3.7522e-03, 2.6021e-02, 3.5550e-03, 1.7591e-02, 6.1664e-03,
        6.2613e-03, 1.9671e-03, 1.2385e-03, 7.7384e-03, 5.9066e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,727][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([1.5432e-04, 6.5351e-02, 2.5501e-01, 9.5517e-02, 4.0049e-03, 1.6457e-01,
        2.6209e-03, 2.6584e-03, 4.1798e-02, 9.2880e-03, 9.5120e-02, 1.1620e-02,
        1.1353e-02, 1.9722e-02, 1.0564e-02, 1.7907e-01, 3.1587e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,729][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([6.5365e-05, 1.0584e-02, 1.1403e-01, 5.5370e-02, 2.5494e-02, 1.3066e-02,
        2.6312e-02, 7.7723e-03, 2.0402e-01, 2.0786e-03, 9.8086e-02, 4.9839e-03,
        3.7327e-02, 2.7412e-02, 1.6025e-02, 2.3613e-01, 1.2125e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:09,730][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0008, 0.0039, 0.2839, 0.0444, 0.1164, 0.1888, 0.0066, 0.0086, 0.1105,
        0.0706, 0.0640, 0.0125, 0.0046, 0.0079, 0.0131, 0.0288, 0.0200, 0.0145],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,732][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.5973e-05, 7.0604e-03, 2.8084e-01, 7.0686e-02, 7.1575e-02, 7.4864e-02,
        4.2231e-02, 1.2876e-02, 1.2577e-01, 1.1032e-02, 8.4204e-02, 7.1597e-03,
        2.5361e-02, 1.0861e-02, 7.0712e-03, 5.2035e-02, 9.6636e-02, 1.9678e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,733][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([8.6643e-06, 1.1153e-02, 9.2797e-02, 5.8862e-02, 6.9222e-02, 3.6833e-02,
        3.2763e-02, 1.3714e-02, 1.4490e-01, 8.3952e-03, 1.0688e-01, 9.3080e-03,
        5.9079e-02, 3.3645e-02, 9.9936e-03, 1.2716e-01, 7.3834e-02, 1.1145e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,735][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0108, 0.0717, 0.4962, 0.1144, 0.0309, 0.1892, 0.0023, 0.0011, 0.0152,
        0.0018, 0.0446, 0.0008, 0.0031, 0.0018, 0.0005, 0.0055, 0.0069, 0.0034],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,736][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([5.3272e-06, 2.0057e-02, 2.3380e-02, 6.8737e-02, 3.1601e-02, 1.2098e-02,
        1.6664e-02, 1.8756e-02, 2.0382e-01, 8.0747e-03, 1.3342e-01, 1.5982e-02,
        7.3785e-02, 3.3137e-02, 2.4397e-02, 1.6231e-01, 9.8438e-02, 5.5343e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,737][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.0241e-06, 1.1357e-02, 1.4228e-01, 6.3163e-02, 1.2660e-01, 4.3448e-02,
        2.1405e-02, 1.5696e-02, 1.9240e-01, 3.8592e-03, 1.3837e-01, 1.0398e-02,
        2.4993e-02, 1.9643e-02, 9.8356e-03, 6.2181e-02, 8.7469e-02, 2.6896e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,738][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0003, 0.0248, 0.1482, 0.0780, 0.0627, 0.0585, 0.0298, 0.0405, 0.0763,
        0.0069, 0.0915, 0.0337, 0.0655, 0.0472, 0.0236, 0.0897, 0.0517, 0.0711],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,738][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.6186e-05, 1.3444e-02, 1.4082e-01, 5.4515e-02, 1.2338e-01, 3.7657e-02,
        3.6097e-02, 2.1922e-02, 2.1624e-01, 9.3593e-03, 8.1805e-02, 1.2526e-02,
        1.5421e-02, 2.7265e-02, 8.7498e-03, 7.2275e-02, 7.6005e-02, 5.2434e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,740][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0010, 0.0347, 0.0655, 0.0575, 0.0630, 0.0605, 0.0720, 0.0704, 0.0541,
        0.0424, 0.0533, 0.0495, 0.0716, 0.0528, 0.0526, 0.0718, 0.0743, 0.0529],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,741][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.2485e-05, 1.0070e-02, 5.1233e-01, 4.5564e-02, 1.3008e-01, 5.0645e-02,
        2.1464e-02, 8.0533e-03, 6.5121e-02, 4.3634e-03, 4.9594e-02, 1.5085e-02,
        1.5819e-02, 9.4033e-03, 3.7672e-03, 2.5344e-02, 1.5663e-02, 1.7566e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,743][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.6141e-04, 7.4383e-02, 1.9901e-01, 9.0947e-02, 4.1932e-03, 2.6694e-01,
        2.7314e-03, 2.3496e-03, 3.1785e-02, 1.4967e-02, 7.7079e-02, 9.9507e-03,
        8.5858e-03, 1.5826e-02, 6.4028e-03, 1.3113e-01, 2.9022e-02, 3.4526e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,744][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([8.6885e-06, 9.0378e-03, 1.1792e-01, 7.6721e-02, 3.1504e-02, 8.1347e-03,
        1.3709e-02, 2.3684e-03, 8.2266e-02, 2.2387e-03, 8.3738e-02, 4.7078e-03,
        2.9629e-02, 1.7209e-02, 1.5396e-02, 1.8132e-01, 2.8715e-01, 3.6927e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:09,872][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:26:09,873][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,874][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,874][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,875][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,876][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,877][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,878][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,878][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,879][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,880][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,880][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,881][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:26:09,882][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5225, 0.4775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,882][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,883][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([3.0600e-04, 9.9969e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,884][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4930, 0.5070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,885][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,885][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.2676e-05, 9.9996e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,886][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([6.7831e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,887][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([4.2187e-04, 9.9958e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,888][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9735, 0.0265], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,889][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([5.2581e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,889][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([3.4770e-04, 9.9965e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,890][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5683, 0.4317], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:26:09,891][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Amber] are: tensor([0.2901, 0.0454, 0.6646], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,892][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Amber] are: tensor([0.0180, 0.0722, 0.9098], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,892][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Amber] are: tensor([0.0036, 0.0508, 0.9456], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,893][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Amber] are: tensor([0.7913, 0.0593, 0.1494], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,894][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Amber] are: tensor([0.0031, 0.1738, 0.8231], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,895][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Amber] are: tensor([2.9638e-04, 2.6625e-02, 9.7308e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,896][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Amber] are: tensor([1.5951e-04, 1.1504e-01, 8.8480e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,898][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Amber] are: tensor([0.0019, 0.0478, 0.9503], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,899][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Amber] are: tensor([1.8759e-05, 9.7863e-01, 2.1354e-02], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,900][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Amber] are: tensor([2.9861e-05, 3.2332e-02, 9.6764e-01], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,901][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Amber] are: tensor([0.0018, 0.0299, 0.9683], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,903][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Amber] are: tensor([0.7765, 0.0016, 0.2219], device='cuda:0') for source tokens [Then, Amber]
[2024-07-24 10:26:09,904][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0302, 0.0292, 0.7431, 0.1975], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,906][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.4769e-04, 5.9127e-02, 6.8550e-01, 2.5513e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,907][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([7.6532e-05, 8.9924e-02, 7.1009e-01, 1.9991e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,908][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0823, 0.0634, 0.7754, 0.0789], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,910][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.9069e-04, 1.6614e-01, 1.8447e-01, 6.4920e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,911][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.0458e-05, 3.0566e-02, 5.2861e-01, 4.4082e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,912][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([3.8136e-06, 1.2903e-01, 3.6654e-01, 5.0443e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,913][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.9768e-04, 1.9285e-01, 3.1946e-01, 4.8750e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,914][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.9058e-06, 8.7570e-01, 1.4737e-02, 1.0955e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,915][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.1496e-06, 2.6125e-02, 7.0745e-01, 2.6642e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,916][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([5.6952e-04, 7.1517e-02, 7.6092e-01, 1.6700e-01], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,918][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0123, 0.0080, 0.9151, 0.0646], device='cuda:0') for source tokens [Then, Amber and]
[2024-07-24 10:26:09,920][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0114, 0.0233, 0.6037, 0.1414, 0.2202], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,921][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([0.0032, 0.0634, 0.6270, 0.1692, 0.1373], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,923][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([0.0008, 0.1012, 0.5863, 0.1529, 0.1588], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,924][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.1830, 0.2802, 0.3444, 0.1670, 0.0253], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,926][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([0.0003, 0.2238, 0.2223, 0.2978, 0.2557], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,927][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([2.9327e-05, 1.8159e-02, 5.4273e-01, 7.6647e-02, 3.6244e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,928][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([1.2642e-04, 1.4066e-01, 5.2146e-01, 1.7827e-01, 1.5948e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,930][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([0.0007, 0.0559, 0.6013, 0.0830, 0.2592], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,931][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([2.3035e-04, 7.6222e-01, 4.5872e-02, 1.8212e-01, 9.5570e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,931][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([6.6268e-05, 3.8442e-02, 5.5589e-01, 1.7998e-01, 2.2562e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,932][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([0.0012, 0.0710, 0.8081, 0.1048, 0.0148], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,933][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0301, 0.0272, 0.7632, 0.1104, 0.0692], device='cuda:0') for source tokens [Then, Amber and Lisa]
[2024-07-24 10:26:09,934][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0418, 0.0061, 0.5696, 0.0263, 0.0534, 0.3028], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,935][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0010, 0.0231, 0.6297, 0.0648, 0.1231, 0.1583], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,936][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([1.0463e-04, 3.4222e-02, 7.4716e-01, 4.3033e-02, 8.9858e-02, 8.5626e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,938][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0679, 0.0665, 0.6535, 0.0715, 0.0223, 0.1183], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,939][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([1.2791e-04, 5.2734e-02, 3.2190e-01, 2.7454e-01, 2.5379e-01, 9.6914e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,940][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([1.0006e-05, 7.4428e-03, 3.1924e-01, 6.9905e-02, 4.6780e-01, 1.3560e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,941][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([5.1107e-06, 3.9902e-02, 5.7463e-01, 1.7493e-01, 1.4706e-01, 6.3473e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,942][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([2.3998e-04, 3.6143e-02, 5.4142e-01, 8.9881e-02, 1.4682e-01, 1.8550e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,944][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([1.0846e-04, 6.1380e-01, 1.1668e-01, 2.2211e-01, 3.6361e-02, 1.0940e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,945][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([7.2818e-06, 1.0057e-02, 6.0247e-01, 6.5543e-02, 2.4397e-01, 7.7954e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,946][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([1.7191e-04, 1.6555e-02, 9.0406e-01, 2.9451e-02, 1.5330e-02, 3.4434e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,947][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.1243, 0.0011, 0.8019, 0.0115, 0.0091, 0.0521], device='cuda:0') for source tokens [Then, Amber and Lisa were]
[2024-07-24 10:26:09,949][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0016, 0.0081, 0.4200, 0.0761, 0.2216, 0.2514, 0.0212],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,950][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([1.5657e-04, 3.2761e-02, 3.6514e-01, 1.5653e-01, 1.8900e-01, 1.3385e-01,
        1.2256e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,951][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([2.1862e-05, 6.4501e-02, 2.8149e-01, 1.9519e-01, 1.8341e-01, 1.6272e-01,
        1.1268e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,953][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0165, 0.2076, 0.1851, 0.2505, 0.0632, 0.2709, 0.0061],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,954][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([2.0122e-05, 1.0638e-01, 1.1908e-01, 3.1721e-01, 2.5168e-01, 7.4949e-02,
        1.3068e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,955][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([1.6447e-06, 1.9266e-02, 2.2906e-01, 1.4681e-01, 4.4847e-01, 9.0509e-02,
        6.5884e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,956][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([3.7034e-06, 7.8278e-02, 3.1264e-01, 2.6055e-01, 2.6652e-01, 4.8112e-02,
        3.3895e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,958][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([2.3232e-04, 6.9189e-02, 2.1299e-01, 1.3378e-01, 3.4940e-01, 1.3839e-01,
        9.6018e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,959][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([6.6731e-06, 8.0731e-01, 9.7671e-03, 1.7548e-01, 3.4538e-03, 2.4810e-03,
        1.5080e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,960][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([1.1236e-05, 1.5656e-02, 4.5619e-01, 1.1371e-01, 2.8571e-01, 9.9265e-02,
        2.9462e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,961][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([1.8721e-05, 4.5892e-02, 5.6312e-01, 2.0765e-01, 3.2064e-02, 1.4150e-01,
        9.7525e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,963][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0047, 0.0096, 0.5821, 0.1344, 0.0596, 0.1439, 0.0658],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working]
[2024-07-24 10:26:09,964][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0009, 0.0062, 0.4021, 0.0647, 0.2116, 0.2860, 0.0144, 0.0140],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,966][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([6.1837e-05, 2.9289e-02, 3.4517e-01, 1.6325e-01, 1.7160e-01, 1.3759e-01,
        9.7582e-02, 5.5451e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,967][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([6.4472e-06, 5.1492e-02, 1.9887e-01, 2.2566e-01, 1.7943e-01, 1.4887e-01,
        1.2040e-01, 7.5279e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,969][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0150, 0.1674, 0.3627, 0.1789, 0.0473, 0.2210, 0.0056, 0.0022],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,970][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([1.0742e-05, 8.5461e-02, 9.3568e-02, 2.6711e-01, 2.0066e-01, 6.1585e-02,
        1.3087e-01, 1.6073e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,971][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([6.8970e-07, 1.8796e-02, 2.2271e-01, 1.1787e-01, 4.4204e-01, 9.8180e-02,
        5.5685e-02, 4.4714e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,972][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([4.3376e-06, 7.1501e-02, 3.0185e-01, 2.2717e-01, 2.6205e-01, 5.4035e-02,
        3.0342e-02, 5.3057e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,973][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([5.5981e-05, 5.6097e-02, 2.1134e-01, 1.3041e-01, 3.2590e-01, 9.7064e-02,
        1.0400e-01, 7.5138e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,974][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.1179e-04, 7.6992e-01, 1.2234e-02, 2.0288e-01, 2.7733e-03, 2.6211e-03,
        1.0982e-03, 8.3606e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,975][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.0977e-05, 1.6770e-02, 5.4642e-01, 8.4432e-02, 2.1890e-01, 8.5758e-02,
        2.9926e-02, 1.7783e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,975][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([2.5959e-05, 5.1124e-02, 6.2287e-01, 1.4905e-01, 3.7365e-02, 1.1086e-01,
        7.9954e-03, 2.0713e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,977][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0020, 0.0035, 0.7119, 0.0638, 0.0365, 0.0884, 0.0529, 0.0409],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at]
[2024-07-24 10:26:09,978][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0011, 0.0045, 0.3810, 0.0568, 0.1450, 0.2679, 0.0073, 0.0084, 0.1281],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,979][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([8.1742e-05, 8.2449e-03, 4.4477e-01, 6.8015e-02, 1.1521e-01, 8.7755e-02,
        5.7423e-02, 2.1325e-02, 1.9717e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,980][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([6.6951e-06, 1.7927e-02, 1.7625e-01, 9.1189e-02, 1.0956e-01, 8.2753e-02,
        5.5248e-02, 2.2017e-02, 4.4505e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,982][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.7965e-02, 5.9698e-02, 6.3257e-01, 8.2110e-02, 2.3144e-02, 1.5243e-01,
        2.0860e-03, 6.1773e-04, 9.3775e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,983][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([6.2089e-06, 3.1273e-02, 6.4885e-02, 1.2230e-01, 6.2112e-02, 3.0495e-02,
        3.6644e-02, 4.3179e-02, 6.0910e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,984][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([8.0174e-07, 7.3804e-03, 2.5122e-01, 5.2470e-02, 2.7701e-01, 5.0095e-02,
        2.4531e-02, 1.9691e-02, 3.1760e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,985][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([5.5804e-06, 2.8075e-02, 4.5120e-01, 1.1981e-01, 1.6518e-01, 3.8763e-02,
        1.3693e-02, 1.7787e-02, 1.6549e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,986][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.3405e-04, 2.6830e-02, 2.8519e-01, 4.9826e-02, 1.7895e-01, 5.7133e-02,
        5.7383e-02, 2.4024e-02, 3.2053e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,987][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([3.8352e-04, 7.5657e-01, 2.7513e-02, 1.8973e-01, 1.6248e-03, 2.5268e-03,
        7.1739e-04, 4.0345e-03, 1.6903e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,988][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([8.3953e-06, 7.5465e-03, 7.2332e-01, 3.7188e-02, 9.9157e-02, 4.5483e-02,
        1.0212e-02, 4.3262e-03, 7.2760e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,990][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.3155e-04, 2.9863e-02, 6.5372e-01, 8.8518e-02, 1.1256e-02, 9.8129e-02,
        3.5627e-03, 7.0992e-03, 1.0772e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,991][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0039, 0.0022, 0.7841, 0.0276, 0.0149, 0.0454, 0.0173, 0.0107, 0.0939],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the]
[2024-07-24 10:26:09,993][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ restaurant] are: tensor([0.0032, 0.0025, 0.5041, 0.0232, 0.0986, 0.2800, 0.0057, 0.0029, 0.0188,
        0.0611], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,994][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ restaurant] are: tensor([2.0003e-04, 1.9157e-02, 4.1724e-01, 6.8294e-02, 9.1030e-02, 9.4698e-02,
        4.3614e-02, 2.1942e-02, 2.1474e-01, 2.9082e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,995][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ restaurant] are: tensor([7.2050e-06, 2.2913e-02, 4.3513e-01, 5.4256e-02, 1.5133e-01, 7.5698e-02,
        3.5382e-02, 1.6235e-02, 1.7502e-01, 3.4029e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,997][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ restaurant] are: tensor([0.0101, 0.1418, 0.4090, 0.1978, 0.0450, 0.1452, 0.0036, 0.0024, 0.0427,
        0.0023], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:09,999][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ restaurant] are: tensor([1.4288e-05, 1.3877e-02, 7.8591e-02, 7.0783e-02, 1.1159e-01, 2.5515e-02,
        5.8617e-02, 5.8307e-02, 5.3865e-01, 4.4056e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,000][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ restaurant] are: tensor([1.5554e-06, 2.7635e-03, 1.8687e-01, 3.7319e-02, 3.6836e-01, 9.5456e-02,
        5.4723e-02, 2.3607e-02, 2.1855e-01, 1.2350e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,001][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ restaurant] are: tensor([4.2471e-06, 3.2952e-02, 3.5632e-01, 8.4927e-02, 2.0479e-01, 4.0596e-02,
        2.0159e-02, 2.7168e-02, 2.2651e-01, 6.5707e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,002][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ restaurant] are: tensor([9.2954e-05, 7.4974e-03, 3.1895e-01, 4.1875e-02, 1.7846e-01, 7.3470e-02,
        6.5248e-02, 3.6547e-02, 2.3344e-01, 4.4419e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,003][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ restaurant] are: tensor([9.4187e-06, 6.0295e-01, 5.4581e-02, 2.2349e-01, 6.1462e-03, 4.8470e-03,
        2.1428e-03, 1.5020e-02, 9.0345e-02, 4.5934e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,005][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ restaurant] are: tensor([1.1664e-05, 3.9595e-03, 5.3351e-01, 2.2841e-02, 2.6303e-01, 5.3345e-02,
        2.6700e-02, 9.6412e-03, 7.5087e-02, 1.1873e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,006][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ restaurant] are: tensor([5.2095e-06, 2.6960e-02, 6.0668e-01, 6.1374e-02, 3.3137e-02, 3.3419e-02,
        3.9876e-03, 1.1950e-02, 2.1915e-01, 3.3314e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,008][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ restaurant] are: tensor([0.0060, 0.0021, 0.4548, 0.0228, 0.0235, 0.0528, 0.0531, 0.0468, 0.3288,
        0.0092], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant]
[2024-07-24 10:26:10,009][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0012, 0.0035, 0.3366, 0.0405, 0.1438, 0.2216, 0.0064, 0.0064, 0.1051,
        0.0760, 0.0589], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,010][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([5.8999e-05, 6.8577e-03, 3.4462e-01, 5.7105e-02, 1.2493e-01, 9.3386e-02,
        5.3348e-02, 1.9595e-02, 1.8483e-01, 1.3583e-02, 1.0168e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,012][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.2043e-05, 1.4669e-02, 1.8151e-01, 7.5122e-02, 1.1092e-01, 6.3034e-02,
        5.3316e-02, 1.8651e-02, 2.7431e-01, 2.2840e-02, 1.8561e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,013][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([4.4719e-02, 5.0706e-02, 6.4499e-01, 7.3224e-02, 2.4076e-02, 1.3301e-01,
        1.2942e-03, 4.5383e-04, 8.1514e-03, 1.3804e-03, 1.7996e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,014][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([6.6739e-06, 2.0790e-02, 5.3138e-02, 8.8831e-02, 4.9157e-02, 2.6252e-02,
        2.8988e-02, 3.5790e-02, 4.5113e-01, 2.6124e-02, 2.1979e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,015][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.0019e-06, 4.7960e-03, 1.9708e-01, 5.2049e-02, 3.0226e-01, 5.9380e-02,
        3.1633e-02, 1.8848e-02, 1.7718e-01, 5.4588e-03, 1.5132e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,016][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.2767e-06, 2.5520e-02, 3.0183e-01, 1.2463e-01, 1.2369e-01, 3.3070e-02,
        1.2133e-02, 1.9518e-02, 1.5524e-01, 2.4772e-03, 2.0188e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,017][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.1807e-05, 1.5060e-02, 1.9261e-01, 5.0041e-02, 1.7452e-01, 5.5916e-02,
        6.1389e-02, 3.0550e-02, 2.9647e-01, 1.2705e-02, 1.1069e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,018][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([5.9103e-06, 7.1797e-01, 2.1698e-02, 1.5966e-01, 4.7490e-03, 2.2741e-03,
        1.5783e-03, 8.6279e-03, 2.9040e-02, 1.7088e-04, 5.4224e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,019][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([6.5025e-06, 5.6002e-03, 5.5064e-01, 5.3861e-02, 1.6688e-01, 4.9211e-02,
        1.4713e-02, 7.0097e-03, 8.3339e-02, 4.3384e-03, 6.4407e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,020][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([5.8425e-05, 1.9082e-02, 7.1828e-01, 4.9038e-02, 1.3716e-02, 4.3381e-02,
        2.3623e-03, 4.5633e-03, 6.0786e-02, 2.8108e-03, 8.5920e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,021][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0072, 0.0012, 0.7731, 0.0168, 0.0171, 0.0301, 0.0133, 0.0084, 0.0674,
        0.0080, 0.0575], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant.]
[2024-07-24 10:26:10,023][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Lisa] are: tensor([0.0005, 0.0080, 0.1874, 0.0616, 0.1474, 0.1538, 0.0117, 0.0160, 0.1836,
        0.0916, 0.1073, 0.0310], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,024][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Lisa] are: tensor([1.3189e-04, 2.3127e-02, 1.5850e-01, 1.0465e-01, 9.4256e-02, 9.5085e-02,
        4.5651e-02, 2.9243e-02, 2.4909e-01, 1.2744e-02, 1.7501e-01, 1.2508e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,025][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Lisa] are: tensor([9.4538e-06, 2.4092e-02, 6.6567e-02, 9.0582e-02, 8.8780e-02, 4.4158e-02,
        3.8208e-02, 2.6697e-02, 3.4755e-01, 9.4337e-03, 2.4495e-01, 1.8969e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,027][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Lisa] are: tensor([0.0093, 0.2913, 0.2167, 0.2205, 0.0559, 0.0989, 0.0069, 0.0023, 0.0366,
        0.0025, 0.0570, 0.0021], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,028][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Lisa] are: tensor([8.3095e-06, 3.5012e-02, 3.7124e-02, 6.6273e-02, 7.3694e-02, 2.2421e-02,
        2.3409e-02, 2.8944e-02, 4.3034e-01, 1.3034e-02, 2.2899e-01, 4.0748e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,030][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Lisa] are: tensor([1.8446e-06, 1.1916e-02, 1.6859e-01, 5.2556e-02, 2.6817e-01, 3.0289e-02,
        1.3552e-02, 1.7543e-02, 2.5819e-01, 3.6814e-03, 1.5393e-01, 2.1580e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,031][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Lisa] are: tensor([1.7127e-05, 8.9171e-02, 1.7340e-01, 1.3085e-01, 1.5411e-01, 3.0081e-02,
        1.2710e-02, 2.0271e-02, 1.5081e-01, 1.6496e-03, 2.0311e-01, 3.3823e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,032][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Lisa] are: tensor([3.8633e-05, 1.6566e-02, 1.2961e-01, 4.5992e-02, 2.2313e-01, 4.4258e-02,
        2.7494e-02, 3.4444e-02, 3.1144e-01, 1.3725e-02, 1.2187e-01, 3.1442e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,033][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Lisa] are: tensor([1.3912e-05, 7.1173e-01, 1.4293e-02, 1.5146e-01, 2.4319e-03, 1.3701e-03,
        9.1055e-04, 6.7550e-03, 3.3333e-02, 9.5481e-05, 7.5669e-02, 1.9384e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,035][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Lisa] are: tensor([2.9549e-05, 2.3457e-02, 2.9532e-01, 1.0924e-01, 2.1842e-01, 5.6977e-02,
        1.6255e-02, 1.4116e-02, 1.4530e-01, 4.8191e-03, 9.1062e-02, 2.4992e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,036][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Lisa] are: tensor([1.2456e-05, 5.8208e-02, 3.4666e-01, 1.0580e-01, 2.1575e-02, 5.6223e-02,
        5.2053e-03, 9.4619e-03, 1.6882e-01, 6.2435e-03, 2.0332e-01, 1.8470e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,038][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Lisa] are: tensor([0.0010, 0.0081, 0.3039, 0.0507, 0.0639, 0.0366, 0.0445, 0.0295, 0.2783,
        0.0125, 0.1539, 0.0172], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa]
[2024-07-24 10:26:10,039][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0005, 0.0026, 0.3960, 0.0284, 0.1494, 0.1674, 0.0059, 0.0064, 0.0965,
        0.0774, 0.0503, 0.0138, 0.0054], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,041][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0003, 0.0188, 0.2853, 0.0997, 0.0672, 0.0971, 0.0501, 0.0241, 0.1964,
        0.0112, 0.1086, 0.0073, 0.0338], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,042][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([1.9435e-05, 1.6795e-02, 1.3009e-01, 6.8850e-02, 7.1808e-02, 5.7624e-02,
        4.2546e-02, 2.5280e-02, 3.1484e-01, 1.6809e-02, 1.7554e-01, 1.1160e-02,
        6.8631e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,044][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0155, 0.0765, 0.4132, 0.1523, 0.0297, 0.2416, 0.0022, 0.0010, 0.0250,
        0.0014, 0.0377, 0.0005, 0.0035], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,045][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([1.5534e-05, 2.6322e-02, 3.7668e-02, 6.2537e-02, 4.3721e-02, 1.8061e-02,
        2.6504e-02, 3.5424e-02, 4.0359e-01, 1.3715e-02, 1.8247e-01, 2.3508e-02,
        1.2646e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,047][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([3.5241e-06, 5.0330e-03, 2.6091e-01, 5.0279e-02, 1.7798e-01, 7.4182e-02,
        3.2266e-02, 1.9786e-02, 2.0235e-01, 6.9839e-03, 1.1965e-01, 1.4527e-02,
        3.6052e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,048][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([2.2828e-05, 5.0384e-02, 2.2638e-01, 1.2542e-01, 1.2068e-01, 2.9463e-02,
        1.7434e-02, 2.5644e-02, 1.6979e-01, 2.6970e-03, 1.5444e-01, 2.4951e-02,
        5.2694e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,049][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([1.9880e-04, 2.8845e-02, 2.1061e-01, 6.4570e-02, 1.6009e-01, 5.1395e-02,
        4.3669e-02, 3.8737e-02, 2.7182e-01, 1.5534e-02, 7.1831e-02, 1.4635e-02,
        2.8077e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,050][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([1.6143e-06, 6.2510e-01, 2.3882e-02, 1.7827e-01, 1.7879e-03, 3.1106e-03,
        1.1621e-03, 8.2097e-03, 5.7472e-02, 1.9264e-04, 9.8715e-02, 1.3526e-03,
        7.4919e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,052][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([5.0223e-05, 6.9261e-03, 6.3671e-01, 3.1869e-02, 1.4172e-01, 4.4146e-02,
        1.8500e-02, 7.4025e-03, 5.2188e-02, 4.4542e-03, 3.2086e-02, 1.1951e-02,
        1.1996e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,053][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([3.4809e-05, 1.5648e-02, 5.8211e-01, 6.2507e-02, 7.5443e-03, 6.4020e-02,
        1.5414e-03, 5.0499e-03, 1.0231e-01, 3.7220e-03, 1.4203e-01, 8.2463e-03,
        5.2411e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,055][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0020, 0.0030, 0.4375, 0.0389, 0.0271, 0.0605, 0.0235, 0.0183, 0.2149,
        0.0109, 0.1053, 0.0074, 0.0506], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided]
[2024-07-24 10:26:10,057][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0005, 0.0055, 0.2168, 0.0634, 0.1303, 0.1950, 0.0075, 0.0110, 0.1672,
        0.0731, 0.0951, 0.0161, 0.0062, 0.0122], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,058][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.9967e-05, 1.0767e-02, 1.8967e-01, 7.9554e-02, 1.1477e-01, 7.8369e-02,
        6.3028e-02, 2.2925e-02, 2.1533e-01, 1.3286e-02, 1.3034e-01, 1.2484e-02,
        4.8099e-02, 2.1320e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,059][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.7215e-06, 1.3137e-02, 7.8657e-02, 7.1326e-02, 8.8824e-02, 4.4539e-02,
        5.1796e-02, 2.4090e-02, 2.6923e-01, 1.2112e-02, 1.7882e-01, 1.5599e-02,
        9.7750e-02, 5.4112e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,061][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0102, 0.0810, 0.3863, 0.1344, 0.0399, 0.2456, 0.0036, 0.0017, 0.0245,
        0.0025, 0.0610, 0.0012, 0.0053, 0.0030], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,062][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.7374e-06, 3.1501e-02, 2.7283e-02, 8.8755e-02, 4.4624e-02, 1.7217e-02,
        2.7124e-02, 3.2264e-02, 3.2713e-01, 1.1681e-02, 1.9758e-01, 2.2949e-02,
        1.2159e-01, 5.0294e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,063][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.8016e-07, 1.3408e-02, 1.0940e-01, 6.9296e-02, 1.7913e-01, 4.2435e-02,
        2.9101e-02, 2.2857e-02, 2.6583e-01, 4.2817e-03, 1.8614e-01, 1.5105e-02,
        3.3771e-02, 2.9245e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,064][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.8336e-06, 3.4174e-02, 1.6629e-01, 1.2199e-01, 1.1496e-01, 2.9930e-02,
        1.7073e-02, 2.6569e-02, 1.6518e-01, 3.2612e-03, 1.9484e-01, 2.7209e-02,
        6.5675e-02, 3.2830e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,065][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.2482e-05, 2.0729e-02, 1.0455e-01, 6.5491e-02, 1.5159e-01, 3.6205e-02,
        4.3390e-02, 3.1099e-02, 3.4999e-01, 1.1050e-02, 1.1149e-01, 1.5640e-02,
        2.3479e-02, 3.5259e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,066][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.2157e-05, 6.8942e-01, 1.5747e-02, 1.6729e-01, 1.8835e-03, 1.5798e-03,
        7.8864e-04, 5.3294e-03, 2.6361e-02, 7.6516e-05, 7.9619e-02, 1.3644e-03,
        3.3568e-04, 1.0188e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,067][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.9843e-05, 1.6410e-02, 3.8774e-01, 6.2257e-02, 1.8211e-01, 5.3770e-02,
        3.0266e-02, 1.2722e-02, 1.1172e-01, 4.8743e-03, 7.8662e-02, 1.9532e-02,
        2.3472e-02, 1.6424e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,068][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.0461e-05, 3.2781e-02, 3.9023e-01, 1.0975e-01, 1.2489e-02, 8.5488e-02,
        2.6897e-03, 8.1572e-03, 1.0506e-01, 4.8007e-03, 2.0377e-01, 1.2009e-02,
        7.0900e-03, 2.5632e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,070][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0007, 0.0025, 0.4249, 0.0353, 0.0308, 0.0533, 0.0274, 0.0143, 0.1767,
        0.0145, 0.1377, 0.0077, 0.0442, 0.0300], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to]
[2024-07-24 10:26:10,071][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([3.5812e-04, 3.2609e-03, 3.6048e-01, 3.9805e-02, 1.1022e-01, 2.2958e-01,
        5.8055e-03, 5.9000e-03, 9.2413e-02, 6.5649e-02, 5.2616e-02, 8.0963e-03,
        4.5573e-03, 6.4545e-03, 1.4807e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,072][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([3.1247e-05, 1.1299e-02, 3.1638e-01, 7.0009e-02, 7.7254e-02, 7.5120e-02,
        3.6239e-02, 1.4896e-02, 2.0280e-01, 9.0850e-03, 1.2439e-01, 6.9864e-03,
        3.3894e-02, 1.2538e-02, 9.0791e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,074][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([3.1070e-06, 1.4136e-02, 1.8768e-01, 5.7949e-02, 7.4030e-02, 4.4331e-02,
        2.7795e-02, 1.3998e-02, 2.5964e-01, 1.3042e-02, 1.7099e-01, 8.9358e-03,
        7.6933e-02, 3.6816e-02, 1.3722e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,075][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0035, 0.0671, 0.3688, 0.1698, 0.0346, 0.2482, 0.0017, 0.0009, 0.0310,
        0.0017, 0.0608, 0.0007, 0.0072, 0.0030, 0.0009], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,077][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([2.7229e-06, 2.2312e-02, 4.5215e-02, 6.2124e-02, 4.4301e-02, 1.4852e-02,
        2.0456e-02, 2.1818e-02, 3.6796e-01, 1.0686e-02, 1.6194e-01, 1.9207e-02,
        1.2382e-01, 4.3397e-02, 4.1917e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,078][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([4.2866e-07, 5.3416e-03, 2.3928e-01, 4.7317e-02, 1.8124e-01, 4.6784e-02,
        3.0365e-02, 1.4377e-02, 2.1941e-01, 4.8018e-03, 1.4220e-01, 1.1959e-02,
        2.9700e-02, 1.3734e-02, 1.3487e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,079][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([3.3162e-06, 2.4871e-02, 3.1307e-01, 7.7786e-02, 1.2016e-01, 2.6926e-02,
        9.9989e-03, 1.4260e-02, 1.3396e-01, 2.0445e-03, 1.6638e-01, 2.1999e-02,
        5.0859e-02, 1.8705e-02, 1.8978e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,081][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([2.0756e-05, 8.7971e-03, 1.9018e-01, 4.9499e-02, 1.3629e-01, 4.4151e-02,
        3.9543e-02, 2.8484e-02, 3.0712e-01, 1.7102e-02, 9.8208e-02, 1.4682e-02,
        2.7291e-02, 2.2366e-02, 1.6269e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,082][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([2.5685e-07, 7.4082e-01, 1.1810e-02, 1.2747e-01, 1.1247e-03, 1.2880e-03,
        3.7375e-04, 3.0812e-03, 3.5024e-02, 6.3595e-05, 7.1085e-02, 6.4889e-04,
        3.1734e-04, 6.6249e-03, 2.6264e-04], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,083][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([9.8842e-06, 5.4769e-03, 6.7371e-01, 2.7481e-02, 1.1977e-01, 3.5287e-02,
        1.2171e-02, 4.8370e-03, 5.1235e-02, 2.9265e-03, 3.8240e-02, 8.3931e-03,
        1.2535e-02, 4.6375e-03, 3.2894e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,085][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([3.6911e-06, 1.4828e-02, 6.6001e-01, 3.9155e-02, 5.4497e-03, 2.9300e-02,
        9.1703e-04, 3.0005e-03, 7.7921e-02, 1.6697e-03, 1.4202e-01, 5.7478e-03,
        4.4311e-03, 1.1809e-02, 3.7391e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,086][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([5.0542e-04, 1.1626e-03, 5.4287e-01, 1.8520e-02, 1.4414e-02, 3.4435e-02,
        2.0352e-02, 1.0582e-02, 1.5473e-01, 6.3065e-03, 9.1862e-02, 4.2866e-03,
        4.7567e-02, 2.5533e-02, 2.6874e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give]
[2024-07-24 10:26:10,088][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0004, 0.0027, 0.3851, 0.0431, 0.0975, 0.2091, 0.0038, 0.0047, 0.0952,
        0.0626, 0.0488, 0.0078, 0.0031, 0.0045, 0.0089, 0.0226],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,089][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.1359e-05, 4.2157e-03, 3.7202e-01, 5.1144e-02, 8.1855e-02, 9.0073e-02,
        3.6366e-02, 1.1979e-02, 1.5007e-01, 1.2401e-02, 8.7754e-02, 5.2242e-03,
        2.4710e-02, 9.0121e-03, 5.9134e-03, 5.7230e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,090][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.3844e-06, 1.1206e-02, 1.7681e-01, 5.9582e-02, 7.4760e-02, 5.0600e-02,
        2.7354e-02, 1.0056e-02, 2.0895e-01, 1.1615e-02, 1.2328e-01, 5.6185e-03,
        5.6934e-02, 3.0559e-02, 9.9095e-03, 1.4277e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,091][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.0395e-03, 6.2853e-02, 5.2499e-01, 1.2586e-01, 2.4664e-02, 1.9977e-01,
        9.9065e-04, 4.7415e-04, 1.2269e-02, 1.1160e-03, 3.1989e-02, 3.5860e-04,
        2.3669e-03, 1.2019e-03, 3.1608e-04, 3.7404e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,093][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.6585e-06, 1.1806e-02, 3.4331e-02, 5.9290e-02, 2.7129e-02, 1.4315e-02,
        1.3622e-02, 1.6790e-02, 3.1075e-01, 1.1952e-02, 1.3346e-01, 1.2247e-02,
        8.5412e-02, 3.1429e-02, 2.8393e-02, 2.0907e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,094][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.6298e-07, 3.3675e-03, 2.2661e-01, 3.8470e-02, 1.4253e-01, 6.5234e-02,
        2.8217e-02, 1.4998e-02, 2.2189e-01, 5.1668e-03, 1.3227e-01, 8.0037e-03,
        2.6000e-02, 1.4745e-02, 8.7757e-03, 6.3725e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,095][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.9511e-06, 1.2106e-02, 3.3982e-01, 7.7762e-02, 9.9460e-02, 3.1999e-02,
        8.0824e-03, 1.0905e-02, 1.1509e-01, 2.4606e-03, 1.2911e-01, 1.3855e-02,
        4.2804e-02, 1.5109e-02, 1.1452e-02, 8.9985e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,097][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.2948e-05, 7.6709e-03, 2.4641e-01, 3.6795e-02, 1.1458e-01, 4.3947e-02,
        4.4916e-02, 2.0740e-02, 2.6920e-01, 1.5730e-02, 7.3088e-02, 8.4438e-03,
        1.4481e-02, 1.8899e-02, 1.0234e-02, 7.4839e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,098][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([8.5133e-07, 7.2309e-01, 2.0881e-02, 1.5476e-01, 8.1630e-04, 1.1060e-03,
        2.4454e-04, 2.3875e-03, 2.2453e-02, 3.5621e-05, 6.7179e-02, 4.7300e-04,
        1.2799e-04, 5.1784e-03, 1.1840e-04, 1.1521e-03], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,100][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.0515e-06, 2.0885e-03, 7.2009e-01, 1.8214e-02, 9.2527e-02, 4.2458e-02,
        9.4374e-03, 3.2825e-03, 4.4116e-02, 3.5780e-03, 2.6455e-02, 6.3521e-03,
        1.0980e-02, 3.7215e-03, 1.8872e-03, 1.4808e-02], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,101][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([7.1166e-06, 9.0511e-03, 6.2534e-01, 3.5068e-02, 4.3237e-03, 3.7725e-02,
        7.5040e-04, 1.9595e-03, 5.0990e-02, 1.8882e-03, 8.8309e-02, 4.0999e-03,
        2.7763e-03, 7.2685e-03, 1.9790e-03, 1.2846e-01], device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,103][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0010, 0.0008, 0.5608, 0.0119, 0.0150, 0.0317, 0.0133, 0.0069, 0.1035,
        0.0079, 0.0708, 0.0037, 0.0296, 0.0178, 0.0168, 0.1084],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a]
[2024-07-24 10:26:10,105][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0028, 0.0016, 0.4550, 0.0309, 0.1062, 0.1911, 0.0060, 0.0048, 0.0560,
        0.0596, 0.0353, 0.0101, 0.0035, 0.0048, 0.0071, 0.0154, 0.0097],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,105][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.7054e-04, 9.1696e-03, 3.7503e-01, 7.1286e-02, 4.1201e-02, 6.8472e-02,
        2.8251e-02, 1.2481e-02, 1.4707e-01, 1.0233e-02, 8.6291e-02, 4.9406e-03,
        1.5868e-02, 7.9491e-03, 6.4673e-03, 4.5767e-02, 6.9243e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,106][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([7.0337e-05, 1.4023e-02, 2.9732e-01, 5.5841e-02, 6.0131e-02, 5.4484e-02,
        2.7178e-02, 1.2907e-02, 1.2883e-01, 1.4088e-02, 1.0051e-01, 9.4528e-03,
        5.1717e-02, 2.7680e-02, 7.2798e-03, 7.9445e-02, 5.9041e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,107][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([6.4497e-02, 7.2481e-02, 4.9270e-01, 1.2291e-01, 2.6438e-02, 1.6276e-01,
        1.5791e-03, 9.3880e-04, 1.5152e-02, 7.6489e-04, 2.6336e-02, 3.7238e-04,
        2.3954e-03, 1.9146e-03, 2.9758e-04, 5.1832e-03, 3.2717e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,108][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([1.2471e-05, 1.1499e-02, 3.6617e-02, 4.2111e-02, 3.8773e-02, 1.2897e-02,
        1.5732e-02, 1.7052e-02, 2.6233e-01, 9.4126e-03, 1.1296e-01, 2.0756e-02,
        8.8715e-02, 3.4823e-02, 2.7096e-02, 1.6633e-01, 1.0289e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,109][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([2.4357e-06, 5.7727e-03, 2.7887e-01, 5.0856e-02, 1.2132e-01, 5.0363e-02,
        2.1978e-02, 1.4345e-02, 1.8769e-01, 5.4352e-03, 1.0507e-01, 1.1258e-02,
        1.4960e-02, 1.0528e-02, 7.4714e-03, 4.0623e-02, 7.3455e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,111][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([6.6476e-05, 3.1643e-02, 3.5842e-01, 8.5549e-02, 9.8013e-02, 2.5045e-02,
        9.1061e-03, 1.2119e-02, 9.5195e-02, 1.9357e-03, 1.1676e-01, 2.3951e-02,
        2.2650e-02, 1.1811e-02, 6.9257e-03, 6.3238e-02, 3.7573e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,112][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0004, 0.0065, 0.2951, 0.0349, 0.1346, 0.0316, 0.0281, 0.0261, 0.1894,
        0.0165, 0.0535, 0.0121, 0.0117, 0.0175, 0.0077, 0.0458, 0.0884],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,114][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([4.8210e-06, 6.5975e-01, 2.1927e-02, 1.8419e-01, 8.9719e-04, 1.1435e-03,
        2.3891e-04, 3.7531e-03, 4.2058e-02, 3.5384e-05, 7.5665e-02, 3.9588e-04,
        2.1664e-04, 7.0547e-03, 1.8509e-04, 1.9740e-03, 5.0885e-04],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,115][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([1.0825e-04, 3.2384e-03, 7.9123e-01, 1.9753e-02, 6.3190e-02, 3.4329e-02,
        7.9551e-03, 3.7522e-03, 2.6021e-02, 3.5550e-03, 1.7591e-02, 6.1664e-03,
        6.2613e-03, 1.9671e-03, 1.2385e-03, 7.7384e-03, 5.9066e-03],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,116][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([3.6436e-05, 2.2067e-02, 5.1363e-01, 4.6669e-02, 6.7268e-03, 3.1628e-02,
        8.3904e-04, 3.1837e-03, 7.1810e-02, 1.3754e-03, 1.0016e-01, 6.4548e-03,
        3.4571e-03, 1.1195e-02, 2.7983e-03, 1.4931e-01, 2.8661e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,118][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0137, 0.0018, 0.4042, 0.0161, 0.0145, 0.0392, 0.0239, 0.0178, 0.1674,
        0.0074, 0.0623, 0.0038, 0.0273, 0.0230, 0.0135, 0.0916, 0.0725],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink]
[2024-07-24 10:26:10,120][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0008, 0.0039, 0.2839, 0.0444, 0.1164, 0.1888, 0.0066, 0.0086, 0.1105,
        0.0706, 0.0640, 0.0125, 0.0046, 0.0079, 0.0131, 0.0288, 0.0200, 0.0145],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,121][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.5973e-05, 7.0604e-03, 2.8084e-01, 7.0686e-02, 7.1575e-02, 7.4864e-02,
        4.2231e-02, 1.2876e-02, 1.2577e-01, 1.1032e-02, 8.4204e-02, 7.1597e-03,
        2.5361e-02, 1.0861e-02, 7.0712e-03, 5.2035e-02, 9.6636e-02, 1.9678e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,122][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([8.6643e-06, 1.1153e-02, 9.2797e-02, 5.8862e-02, 6.9222e-02, 3.6833e-02,
        3.2763e-02, 1.3714e-02, 1.4490e-01, 8.3952e-03, 1.0688e-01, 9.3080e-03,
        5.9079e-02, 3.3645e-02, 9.9936e-03, 1.2716e-01, 7.3834e-02, 1.1145e-01],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,124][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0108, 0.0717, 0.4962, 0.1144, 0.0309, 0.1892, 0.0023, 0.0011, 0.0152,
        0.0018, 0.0446, 0.0008, 0.0031, 0.0018, 0.0005, 0.0055, 0.0069, 0.0034],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,126][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.3272e-06, 2.0057e-02, 2.3380e-02, 6.8737e-02, 3.1601e-02, 1.2098e-02,
        1.6664e-02, 1.8756e-02, 2.0382e-01, 8.0747e-03, 1.3342e-01, 1.5982e-02,
        7.3785e-02, 3.3137e-02, 2.4397e-02, 1.6231e-01, 9.8438e-02, 5.5343e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,127][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.0241e-06, 1.1357e-02, 1.4228e-01, 6.3163e-02, 1.2660e-01, 4.3448e-02,
        2.1405e-02, 1.5696e-02, 1.9240e-01, 3.8592e-03, 1.3837e-01, 1.0398e-02,
        2.4993e-02, 1.9643e-02, 9.8356e-03, 6.2181e-02, 8.7469e-02, 2.6896e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,128][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.3632e-05, 2.1873e-02, 2.4497e-01, 9.5510e-02, 8.6179e-02, 2.8166e-02,
        1.0690e-02, 1.6262e-02, 9.8643e-02, 2.3835e-03, 1.2851e-01, 1.9133e-02,
        3.9124e-02, 2.0886e-02, 1.0789e-02, 7.8491e-02, 5.6979e-02, 4.1395e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,130][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.6186e-05, 1.3444e-02, 1.4082e-01, 5.4515e-02, 1.2338e-01, 3.7657e-02,
        3.6097e-02, 2.1922e-02, 2.1624e-01, 9.3593e-03, 8.1805e-02, 1.2526e-02,
        1.5421e-02, 2.7265e-02, 8.7498e-03, 7.2275e-02, 7.6005e-02, 5.2434e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,131][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.5348e-05, 6.6315e-01, 2.2450e-02, 1.4876e-01, 1.8253e-03, 1.5353e-03,
        6.2682e-04, 4.6530e-03, 2.7758e-02, 6.4029e-05, 1.0052e-01, 1.3570e-03,
        2.6463e-04, 9.9206e-03, 2.7201e-04, 1.8942e-03, 6.3570e-04, 1.4298e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,132][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.2485e-05, 1.0070e-02, 5.1233e-01, 4.5564e-02, 1.3008e-01, 5.0645e-02,
        2.1464e-02, 8.0533e-03, 6.5121e-02, 4.3634e-03, 4.9594e-02, 1.5085e-02,
        1.5819e-02, 9.4033e-03, 3.7672e-03, 2.5344e-02, 1.5663e-02, 1.7566e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,134][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.3652e-05, 2.5339e-02, 3.8530e-01, 6.8551e-02, 8.8060e-03, 5.3737e-02,
        1.4896e-03, 4.3731e-03, 6.1066e-02, 2.7478e-03, 1.2417e-01, 7.6969e-03,
        3.7535e-03, 1.4494e-02, 2.7881e-03, 1.4456e-01, 4.3027e-02, 4.8067e-02],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,136][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0013, 0.0013, 0.4601, 0.0181, 0.0191, 0.0291, 0.0157, 0.0077, 0.0801,
        0.0086, 0.0629, 0.0042, 0.0219, 0.0154, 0.0119, 0.0797, 0.1348, 0.0282],
       device='cuda:0') for source tokens [Then, Amber and Lisa were working at the restaurant. Lisa decided to give a drink to]
[2024-07-24 10:26:10,139][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:26:10,141][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[196],
        [  2],
        [ 36],
        [ 25],
        [ 16],
        [ 14],
        [  2],
        [  2],
        [  6],
        [  5],
        [  2],
        [ 12],
        [  2],
        [  1],
        [  1],
        [  1],
        [  1],
        [  1]], device='cuda:0')
[2024-07-24 10:26:10,143][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[68],
        [ 2],
        [11],
        [10],
        [ 9],
        [ 4],
        [ 2],
        [ 1],
        [ 1],
        [ 4],
        [ 1],
        [13],
        [ 1],
        [ 1],
        [ 1],
        [ 1],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-24 10:26:10,144][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[24545],
        [30288],
        [18141],
        [22701],
        [22288],
        [18768],
        [21886],
        [21653],
        [23579],
        [20467],
        [24971],
        [29236],
        [24116],
        [28242],
        [24477],
        [24313],
        [22499],
        [25849]], device='cuda:0')
[2024-07-24 10:26:10,146][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5676],
        [ 8273],
        [40631],
        [31610],
        [35466],
        [35438],
        [25971],
        [23752],
        [27132],
        [24081],
        [21946],
        [12357],
        [16835],
        [14818],
        [18864],
        [21558],
        [18434],
        [14985]], device='cuda:0')
[2024-07-24 10:26:10,148][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[48764],
        [40467],
        [50251],
        [50245],
        [50238],
        [50246],
        [50127],
        [49979],
        [50032],
        [50233],
        [50098],
        [49855],
        [50000],
        [49860],
        [50111],
        [50132],
        [50207],
        [50019]], device='cuda:0')
[2024-07-24 10:26:10,150][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33160],
        [44284],
        [46479],
        [49253],
        [47836],
        [49065],
        [46901],
        [47958],
        [48949],
        [47950],
        [48960],
        [46588],
        [48054],
        [47938],
        [47757],
        [48496],
        [48452],
        [48385]], device='cuda:0')
[2024-07-24 10:26:10,152][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 8279],
        [11228],
        [10604],
        [10983],
        [13761],
        [13648],
        [14004],
        [13943],
        [12511],
        [12893],
        [11378],
        [11799],
        [11582],
        [11295],
        [11495],
        [11602],
        [11464],
        [10910]], device='cuda:0')
[2024-07-24 10:26:10,153][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[22559],
        [25796],
        [ 3044],
        [ 9953],
        [ 6333],
        [ 9344],
        [12376],
        [12595],
        [14573],
        [14928],
        [15519],
        [17272],
        [14182],
        [20151],
        [15182],
        [15451],
        [12613],
        [16432]], device='cuda:0')
[2024-07-24 10:26:10,155][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 3294],
        [ 9839],
        [47093],
        [15734],
        [33359],
        [40827],
        [18598],
        [ 9935],
        [13685],
        [28953],
        [ 6350],
        [ 2042],
        [ 2868],
        [ 1294],
        [ 5095],
        [ 3671],
        [ 4080],
        [ 1464]], device='cuda:0')
[2024-07-24 10:26:10,157][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[33080],
        [32277],
        [12784],
        [21380],
        [13776],
        [15624],
        [16983],
        [16711],
        [15596],
        [15661],
        [16320],
        [16489],
        [16777],
        [17720],
        [17055],
        [17172],
        [17707],
        [20244]], device='cuda:0')
[2024-07-24 10:26:10,159][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10156],
        [12088],
        [12922],
        [12427],
        [11947],
        [11883],
        [11137],
        [10785],
        [10864],
        [11244],
        [ 9741],
        [ 9514],
        [ 9609],
        [ 9923],
        [ 9666],
        [ 9554],
        [ 9519],
        [ 9591]], device='cuda:0')
[2024-07-24 10:26:10,160][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[45173],
        [39558],
        [49334],
        [48755],
        [48018],
        [48233],
        [47212],
        [47806],
        [48601],
        [47492],
        [47643],
        [44805],
        [48210],
        [46024],
        [48405],
        [48624],
        [48900],
        [47413]], device='cuda:0')
[2024-07-24 10:26:10,162][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[34298],
        [ 1508],
        [    2],
        [   55],
        [    7],
        [    7],
        [  281],
        [  265],
        [  174],
        [    7],
        [  150],
        [  357],
        [  532],
        [ 1026],
        [  107],
        [  382],
        [  565],
        [ 1224]], device='cuda:0')
[2024-07-24 10:26:10,164][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13039],
        [35376],
        [49623],
        [47614],
        [47918],
        [49104],
        [44185],
        [45781],
        [47064],
        [42565],
        [48285],
        [44705],
        [44268],
        [44617],
        [43270],
        [42459],
        [41881],
        [41278]], device='cuda:0')
[2024-07-24 10:26:10,166][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[35990],
        [  984],
        [ 2100],
        [ 1141],
        [ 2018],
        [ 1628],
        [ 2866],
        [ 3903],
        [ 2681],
        [ 1417],
        [ 2276],
        [ 2486],
        [ 4701],
        [ 4354],
        [ 3896],
        [ 7833],
        [ 3978],
        [ 4549]], device='cuda:0')
[2024-07-24 10:26:10,168][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12343],
        [ 9782],
        [ 5073],
        [ 5198],
        [ 6036],
        [ 6066],
        [ 6935],
        [ 7135],
        [ 7951],
        [ 6404],
        [ 7993],
        [ 9761],
        [ 7525],
        [ 9434],
        [ 7686],
        [ 7653],
        [ 6848],
        [ 8324]], device='cuda:0')
[2024-07-24 10:26:10,169][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19654],
        [26557],
        [18555],
        [26289],
        [25296],
        [23234],
        [29727],
        [30420],
        [28183],
        [29266],
        [30139],
        [33662],
        [31737],
        [32530],
        [30763],
        [29443],
        [31064],
        [32692]], device='cuda:0')
[2024-07-24 10:26:10,171][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23518],
        [13662],
        [ 2835],
        [ 3826],
        [ 4970],
        [ 3981],
        [ 8775],
        [10180],
        [10612],
        [ 6545],
        [ 9524],
        [11480],
        [10047],
        [10921],
        [ 8783],
        [ 8513],
        [ 6713],
        [ 9518]], device='cuda:0')
[2024-07-24 10:26:10,173][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11985],
        [ 7798],
        [ 9217],
        [ 6615],
        [ 6795],
        [ 6990],
        [ 7982],
        [ 7463],
        [ 7247],
        [ 7749],
        [ 7355],
        [ 8005],
        [ 8221],
        [ 8438],
        [ 8648],
        [ 7813],
        [ 7771],
        [ 7960]], device='cuda:0')
[2024-07-24 10:26:10,175][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18904],
        [40221],
        [33389],
        [41784],
        [37516],
        [33367],
        [36398],
        [36206],
        [38524],
        [35569],
        [37479],
        [36952],
        [37207],
        [37270],
        [36531],
        [35102],
        [31734],
        [32336]], device='cuda:0')
[2024-07-24 10:26:10,177][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 6260],
        [15516],
        [11014],
        [12747],
        [ 9733],
        [10692],
        [11774],
        [11760],
        [11922],
        [12124],
        [11979],
        [11958],
        [12109],
        [12698],
        [12122],
        [12398],
        [11363],
        [11624]], device='cuda:0')
[2024-07-24 10:26:10,179][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26505],
        [43889],
        [22949],
        [33947],
        [30584],
        [30220],
        [33779],
        [34677],
        [34008],
        [35960],
        [37282],
        [39560],
        [39228],
        [40528],
        [37445],
        [37707],
        [37372],
        [39958]], device='cuda:0')
[2024-07-24 10:26:10,181][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24064],
        [ 8096],
        [19142],
        [18144],
        [18191],
        [21193],
        [19181],
        [18733],
        [21054],
        [21615],
        [20711],
        [20231],
        [20823],
        [20171],
        [20807],
        [20751],
        [19964],
        [18752]], device='cuda:0')
[2024-07-24 10:26:10,183][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24318],
        [24315],
        [19534],
        [19384],
        [19156],
        [18631],
        [19285],
        [19223],
        [19176],
        [18880],
        [19156],
        [19165],
        [19013],
        [19128],
        [19220],
        [19165],
        [19063],
        [19075]], device='cuda:0')
[2024-07-24 10:26:10,185][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17168],
        [11668],
        [ 7974],
        [ 8915],
        [ 9081],
        [ 8619],
        [ 8883],
        [ 8646],
        [ 8425],
        [ 8645],
        [ 8760],
        [ 9725],
        [ 8508],
        [ 9206],
        [ 8470],
        [ 8309],
        [ 8238],
        [ 8664]], device='cuda:0')
[2024-07-24 10:26:10,186][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18737],
        [ 8216],
        [15919],
        [12337],
        [12900],
        [15083],
        [11841],
        [12011],
        [12296],
        [12657],
        [12513],
        [12309],
        [12115],
        [12038],
        [12217],
        [11034],
        [10456],
        [10169]], device='cuda:0')
[2024-07-24 10:26:10,188][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6029],
        [ 7071],
        [10069],
        [12195],
        [11705],
        [12208],
        [11441],
        [11852],
        [12336],
        [12805],
        [12509],
        [12993],
        [12691],
        [12745],
        [12498],
        [12835],
        [12512],
        [12167]], device='cuda:0')
[2024-07-24 10:26:10,190][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22600],
        [31431],
        [33653],
        [31849],
        [32328],
        [31232],
        [27894],
        [27320],
        [26648],
        [27024],
        [25994],
        [23747],
        [24929],
        [23798],
        [25531],
        [26842],
        [28584],
        [26656]], device='cuda:0')
[2024-07-24 10:26:10,192][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[14036],
        [50008],
        [49493],
        [49033],
        [48392],
        [49861],
        [45252],
        [40369],
        [42744],
        [49101],
        [43267],
        [45405],
        [40985],
        [38755],
        [41837],
        [35180],
        [43758],
        [37981]], device='cuda:0')
[2024-07-24 10:26:10,194][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892],
        [8892]], device='cuda:0')
