[2024-07-24 10:25:25,576][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Christina and Jesse had a long argument, and afterwards Jesse said to
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Christina
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,577][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,578][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:25:25,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit27']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,580][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12']
[2024-07-24 10:25:25,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12']
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit20', 'circuit21']
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit26']
[2024-07-24 10:25:25,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit24']
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:25:25,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:25:25,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit22', 'circuit26']
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:25:25,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit14']
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:25:25,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit26']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:25:25,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:25:25,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit24']
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17']
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16']
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,591][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit23']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit23']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit12', 'circuit14']
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit6', 'circuit12']
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:25:25,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,594][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:25:25,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,596][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18']
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit26']
[2024-07-24 10:25:25,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:25:25,598][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit19', 'circuit24']
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:25:25,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit27']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,606][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,608][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:25:25,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit10', 'circuit13']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:25:25,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,618][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,620][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit4', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,621][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,622][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:25:25,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,624][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,626][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit27']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:25:25,628][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,629][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,630][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13']
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit11']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit13']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit28']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit10', 'circuit27']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,632][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:25:25,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,634][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,635][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit24']
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit8', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,637][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20']
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:25:25,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,641][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,642][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,643][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,646][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit22']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit21']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit26']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,647][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit18']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit26']
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:25:25,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,649][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15']
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:25:25,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,652][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit16', 'circuit23']
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit19']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,654][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,657][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,659][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,660][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,662][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,663][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:25:25,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit19', 'circuit21']
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit18', 'circuit24']
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,666][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit8', 'circuit11', 'circuit12']
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit9', 'circuit11', 'circuit13', 'circuit26']
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,667][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,668][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20']
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit25']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit27']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,670][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit17']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit14', 'circuit19']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit23']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,672][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16']
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit21', 'circuit26']
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,673][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,674][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,676][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:25:25,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,682][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,683][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit24']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:25:25,686][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,688][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit5']
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,689][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,691][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,692][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:25:25,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit9', 'circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,695][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,697][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,698][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,701][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,704][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit8', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit26']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,707][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit3']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit4', 'circuit15', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit21']
[2024-07-24 10:25:25,708][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit4', 'circuit25']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit22', 'circuit25']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:25:25,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:25:25,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19']
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,712][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,713][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,714][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit26']
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,716][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit16', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,717][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:25:25,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,721][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,722][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,725][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:25:25,726][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:25:25,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,728][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:25,729][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:25:26,548][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:26,549][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,549][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,550][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,551][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,552][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,556][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,557][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,558][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,558][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,561][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,564][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,565][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,566][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,567][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,568][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,568][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,570][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,573][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,577][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,581][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,584][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,586][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,587][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,588][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,588][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.4050, 0.3493, 0.2457], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,589][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([8.8617e-05, 9.9314e-05, 9.9981e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,591][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.5381, 0.2808, 0.1811], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,593][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([5.3234e-03, 2.9423e-05, 9.9465e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,597][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.0220, 0.0013, 0.9767], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,599][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([1.3357e-02, 7.8681e-07, 9.8664e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,603][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.4134, 0.3257, 0.2609], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,606][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.5648, 0.3336, 0.1016], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,607][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.5894, 0.2712, 0.1395], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,608][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.6205, 0.3465, 0.0330], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,609][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.4124, 0.2526, 0.3350], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,609][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.4196, 0.4280, 0.1524], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,612][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6845, 0.0775, 0.1775, 0.0605], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,613][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3033e-03, 3.9261e-02, 1.3271e-04, 9.5830e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,618][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2391, 0.1790, 0.0311, 0.5508], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,622][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1126, 0.3847, 0.0321, 0.4706], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,625][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3229, 0.1463, 0.2659, 0.2649], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,627][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1230, 0.1969, 0.0075, 0.6726], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,628][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6176, 0.0295, 0.3305, 0.0224], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,628][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2214, 0.1684, 0.3568, 0.2534], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,629][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0671, 0.4700, 0.0222, 0.4407], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,630][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4366, 0.2438, 0.0931, 0.2265], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,633][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4211, 0.3137, 0.0583, 0.2069], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,637][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4515, 0.1972, 0.0936, 0.2577], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:26,641][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.1940, 0.2429, 0.1286, 0.2899, 0.1446], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,643][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([4.2392e-05, 7.9441e-05, 8.8134e-05, 8.3525e-05, 9.9971e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,647][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.3435, 0.2929, 0.0624, 0.1512, 0.1500], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,648][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([4.7430e-03, 3.1660e-05, 2.4470e-03, 1.3529e-04, 9.9264e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,648][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([8.4815e-03, 8.1367e-04, 2.5067e-02, 6.5874e-04, 9.6498e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,649][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([9.1501e-03, 2.3862e-07, 3.4954e-04, 1.0188e-07, 9.9050e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,650][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.1741, 0.1895, 0.2309, 0.1047, 0.3009], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,652][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.2380, 0.1962, 0.1379, 0.3352, 0.0927], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,654][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.3660, 0.2647, 0.0855, 0.1839, 0.1000], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,658][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.3851, 0.2333, 0.1684, 0.1950, 0.0182], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,663][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.3052, 0.2070, 0.0598, 0.1266, 0.3014], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,666][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.2676, 0.2135, 0.0734, 0.2774, 0.1682], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:26,668][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4259, 0.0374, 0.1063, 0.0373, 0.0649, 0.3281], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,668][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2215e-04, 1.6753e-03, 3.6680e-04, 2.8615e-03, 1.4241e-04, 9.9463e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,669][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4885, 0.1246, 0.0521, 0.1474, 0.0414, 0.1460], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,670][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9371e-03, 5.4262e-03, 7.2393e-04, 1.1482e-02, 2.1245e-03, 9.7531e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,672][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2266, 0.0644, 0.0513, 0.1166, 0.0600, 0.4811], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,674][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9783e-02, 1.8565e-03, 1.3089e-03, 1.2907e-03, 3.2784e-05, 9.5573e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,678][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3426, 0.0256, 0.3264, 0.0240, 0.2470, 0.0344], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,681][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1269, 0.0988, 0.1103, 0.2294, 0.1494, 0.2852], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,686][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0951, 0.2670, 0.0475, 0.3508, 0.0226, 0.2170], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,688][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3132, 0.1888, 0.0861, 0.1946, 0.0858, 0.1315], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,689][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2562, 0.1976, 0.0511, 0.1447, 0.0361, 0.3142], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,689][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4315, 0.1441, 0.0647, 0.1797, 0.0891, 0.0908], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:26,690][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4858, 0.0560, 0.2207, 0.0423, 0.0880, 0.0697, 0.0375],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,691][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5617e-04, 4.3027e-03, 4.8234e-04, 4.3007e-03, 8.1307e-04, 4.6860e-04,
        9.8878e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,694][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3063, 0.1900, 0.0515, 0.2240, 0.0540, 0.1268, 0.0473],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,698][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0295, 0.0181, 0.0057, 0.0332, 0.0136, 0.1797, 0.7201],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,702][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1390, 0.0306, 0.0585, 0.0431, 0.0840, 0.4346, 0.2102],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,706][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0561, 0.1301, 0.0024, 0.0973, 0.0007, 0.0449, 0.6685],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,708][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3416, 0.0113, 0.2964, 0.0097, 0.2797, 0.0502, 0.0111],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,709][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1044, 0.0627, 0.0581, 0.1402, 0.0755, 0.2352, 0.3238],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,709][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0240, 0.1307, 0.0106, 0.1941, 0.0084, 0.1418, 0.4903],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,710][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2678, 0.1715, 0.0745, 0.1740, 0.0670, 0.1079, 0.1372],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,712][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2273, 0.1938, 0.0484, 0.1643, 0.0550, 0.0841, 0.2272],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,714][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3336, 0.1337, 0.0840, 0.1436, 0.1082, 0.0862, 0.1106],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:26,715][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.3066, 0.0734, 0.1678, 0.0680, 0.0723, 0.1263, 0.0963, 0.0893],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,716][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8418e-04, 9.8777e-04, 1.7372e-03, 1.4091e-03, 8.6089e-04, 3.2475e-03,
        9.3710e-04, 9.9054e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,720][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3066, 0.1580, 0.0442, 0.1598, 0.1004, 0.1116, 0.0798, 0.0397],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,723][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5087e-03, 4.5930e-04, 5.3822e-04, 8.0226e-04, 1.5880e-03, 9.0920e-03,
        7.2430e-03, 9.7377e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,727][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0959, 0.0218, 0.0734, 0.0287, 0.0430, 0.1431, 0.0758, 0.5183],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,729][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.3988e-03, 1.8772e-04, 1.1376e-03, 1.0295e-04, 1.3082e-05, 1.9165e-04,
        8.2290e-05, 9.9289e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,730][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2713, 0.0292, 0.3722, 0.0203, 0.1626, 0.0449, 0.0210, 0.0785],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,731][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1065, 0.0463, 0.0476, 0.0971, 0.0311, 0.1952, 0.3605, 0.1158],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,732][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1245, 0.1247, 0.0534, 0.1584, 0.0280, 0.1533, 0.3116, 0.0461],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,734][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2453, 0.1604, 0.0674, 0.1552, 0.0741, 0.0947, 0.1361, 0.0668],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,736][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2247, 0.1591, 0.0551, 0.1115, 0.0265, 0.0773, 0.0874, 0.2585],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,741][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3832, 0.1031, 0.0800, 0.1283, 0.0654, 0.0635, 0.0650, 0.1114],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:26,745][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3710, 0.0887, 0.1241, 0.0700, 0.0743, 0.0757, 0.0595, 0.0756, 0.0611],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,747][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8402e-03, 3.0493e-04, 2.6456e-03, 2.0726e-04, 8.3641e-03, 3.4568e-04,
        1.9345e-04, 3.4031e-05, 9.8606e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,750][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.3267, 0.1111, 0.0440, 0.0814, 0.0402, 0.1070, 0.1253, 0.1036, 0.0606],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,750][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3825e-03, 4.0851e-05, 1.9253e-04, 9.1196e-05, 1.9686e-03, 2.4673e-04,
        6.2907e-04, 4.3021e-03, 9.8915e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,751][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1280, 0.0058, 0.0082, 0.0050, 0.0474, 0.0155, 0.0131, 0.1715, 0.6055],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,752][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2026e-02, 1.5132e-05, 1.3400e-04, 4.1244e-06, 6.9699e-05, 2.0251e-06,
        1.5987e-06, 6.3669e-07, 9.8775e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,753][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1703, 0.0443, 0.2231, 0.0387, 0.2228, 0.0292, 0.0313, 0.0703, 0.1700],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,755][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0873, 0.0501, 0.0130, 0.0932, 0.0757, 0.1285, 0.2050, 0.2468, 0.1004],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,757][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2528, 0.0977, 0.0260, 0.1143, 0.0752, 0.2384, 0.1220, 0.0659, 0.0076],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,761][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2359, 0.1374, 0.0548, 0.1287, 0.0910, 0.1118, 0.1151, 0.0830, 0.0421],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,766][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2100, 0.1308, 0.0565, 0.1105, 0.0574, 0.0755, 0.0729, 0.0382, 0.2481],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,770][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3158, 0.1400, 0.0944, 0.1014, 0.0727, 0.0401, 0.0387, 0.0855, 0.1114],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:26,771][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4499, 0.0154, 0.1092, 0.0179, 0.0938, 0.0797, 0.0345, 0.0639, 0.1225,
        0.0131], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,772][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8445e-03, 4.4357e-01, 9.8084e-05, 1.1171e-02, 9.0763e-05, 3.9672e-04,
        1.7962e-04, 5.1706e-05, 7.8250e-06, 5.4259e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,773][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2015, 0.3171, 0.0167, 0.0775, 0.0103, 0.0369, 0.0076, 0.0103, 0.0102,
        0.3119], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,774][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([3.3283e-02, 7.7307e-03, 6.9180e-04, 7.7758e-03, 1.4347e-03, 6.0820e-02,
        4.9928e-02, 5.5327e-02, 8.6741e-02, 6.9627e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,776][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2733, 0.0265, 0.0183, 0.0228, 0.0605, 0.1320, 0.0322, 0.1129, 0.0473,
        0.2741], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,779][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0979, 0.3460, 0.0083, 0.1248, 0.0047, 0.0695, 0.1027, 0.0303, 0.0102,
        0.2055], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,782][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2860, 0.0084, 0.2379, 0.0082, 0.2144, 0.0268, 0.0104, 0.0690, 0.1334,
        0.0056], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,786][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0378, 0.0143, 0.0274, 0.0388, 0.0436, 0.0709, 0.1130, 0.1482, 0.1416,
        0.3644], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,791][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0192, 0.1652, 0.0040, 0.1855, 0.0060, 0.0644, 0.1664, 0.0292, 0.0076,
        0.3524], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,792][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2156, 0.1233, 0.0591, 0.1281, 0.0613, 0.0864, 0.0942, 0.0704, 0.0569,
        0.1049], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,793][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1752, 0.1612, 0.0566, 0.1481, 0.0564, 0.0959, 0.0928, 0.0595, 0.0425,
        0.1117], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,793][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2442, 0.0945, 0.0732, 0.1072, 0.0826, 0.0681, 0.0649, 0.0793, 0.0737,
        0.1123], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:26,795][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3652, 0.0298, 0.0952, 0.0256, 0.0808, 0.0718, 0.0433, 0.0954, 0.1326,
        0.0292, 0.0311], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,796][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0615e-03, 1.2477e-02, 3.0610e-05, 5.1190e-01, 8.0363e-05, 6.9048e-04,
        2.3422e-04, 1.8328e-04, 8.4975e-06, 7.4683e-03, 4.6587e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,800][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0825, 0.0617, 0.0179, 0.3090, 0.0291, 0.0430, 0.0173, 0.0147, 0.0231,
        0.0548, 0.3469], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,802][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0825e-02, 6.0668e-03, 1.7316e-04, 3.9897e-03, 1.9364e-04, 7.8496e-03,
        1.3929e-02, 1.5644e-02, 7.4119e-03, 4.9320e-01, 4.4071e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,805][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0355, 0.0130, 0.0099, 0.0246, 0.0139, 0.1622, 0.0658, 0.1200, 0.1780,
        0.1218, 0.2553], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,809][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0326, 0.0873, 0.0043, 0.3882, 0.0015, 0.0543, 0.1212, 0.0254, 0.0037,
        0.0307, 0.2508], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,812][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2415, 0.0098, 0.2095, 0.0093, 0.2216, 0.0306, 0.0113, 0.0854, 0.1634,
        0.0074, 0.0103], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,812][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0333, 0.0120, 0.0243, 0.0201, 0.0230, 0.0425, 0.0639, 0.0800, 0.0985,
        0.2462, 0.3561], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,813][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.1001, 0.0053, 0.1175, 0.0049, 0.0609, 0.1999, 0.0256, 0.0109,
        0.2626, 0.2009], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,814][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1775, 0.1107, 0.0517, 0.1117, 0.0526, 0.0773, 0.0888, 0.0597, 0.0584,
        0.0979, 0.1138], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,816][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1450, 0.1313, 0.0422, 0.1396, 0.0497, 0.0981, 0.0991, 0.0527, 0.0354,
        0.0952, 0.1115], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,820][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2162, 0.0881, 0.0577, 0.1015, 0.0731, 0.0527, 0.0468, 0.0606, 0.0773,
        0.1114, 0.1144], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:26,823][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2387, 0.0435, 0.0476, 0.0481, 0.1454, 0.1267, 0.0494, 0.0347, 0.1524,
        0.0377, 0.0575, 0.0183], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,826][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7392e-03, 4.1714e-04, 2.2353e-03, 1.5583e-04, 9.5495e-04, 1.7359e-04,
        9.0104e-05, 1.4329e-04, 6.0541e-04, 9.2265e-05, 7.0699e-05, 9.9332e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,830][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2476, 0.0809, 0.0677, 0.0768, 0.0858, 0.1563, 0.0641, 0.0566, 0.0327,
        0.0513, 0.0618, 0.0186], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,832][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2686e-02, 5.1778e-05, 4.1425e-04, 7.1981e-05, 4.9089e-04, 1.1414e-03,
        2.1214e-04, 3.4349e-03, 1.4243e-03, 2.2486e-03, 4.8142e-03, 9.7301e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,834][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0410, 0.0033, 0.0252, 0.0068, 0.0095, 0.0111, 0.0106, 0.0287, 0.0149,
        0.0124, 0.0427, 0.7938], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,835][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2289e-02, 4.3663e-06, 1.9501e-03, 1.6903e-06, 5.8314e-05, 4.4227e-06,
        4.7466e-07, 4.6401e-06, 4.9959e-06, 9.8259e-08, 2.7194e-07, 9.0568e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,836][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1427, 0.0597, 0.1533, 0.0444, 0.1181, 0.0372, 0.0633, 0.0556, 0.1282,
        0.0527, 0.0489, 0.0960], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,838][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0494, 0.0177, 0.0093, 0.0274, 0.0787, 0.0314, 0.0667, 0.0458, 0.0258,
        0.1800, 0.3666, 0.1011], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,840][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0955, 0.1079, 0.0431, 0.1366, 0.0215, 0.0386, 0.1194, 0.0358, 0.0978,
        0.1272, 0.1639, 0.0126], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,845][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1791, 0.1012, 0.0731, 0.0930, 0.0426, 0.0771, 0.0678, 0.0581, 0.0879,
        0.0858, 0.0933, 0.0411], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,849][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1907, 0.0927, 0.0532, 0.0887, 0.0416, 0.0830, 0.0551, 0.0515, 0.0386,
        0.0660, 0.0686, 0.1701], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,854][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1800, 0.1427, 0.0534, 0.0946, 0.0614, 0.0325, 0.0416, 0.0419, 0.0383,
        0.1631, 0.1016, 0.0490], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:26,854][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.1106, 0.1082, 0.0679, 0.1408, 0.0974, 0.0374, 0.0515, 0.0165, 0.0079,
        0.0840, 0.1491, 0.0262, 0.1025], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,855][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([2.1036e-05, 2.0861e-05, 2.6824e-05, 2.6339e-05, 5.2413e-01, 1.0271e-05,
        1.1639e-05, 5.2813e-06, 3.4117e-05, 3.5895e-06, 1.1154e-05, 1.4821e-05,
        4.7568e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,856][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.1468, 0.1121, 0.0360, 0.0740, 0.1006, 0.0577, 0.0917, 0.0330, 0.0482,
        0.0761, 0.0655, 0.0536, 0.1047], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,858][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([3.6980e-04, 2.5920e-07, 1.4124e-05, 4.9206e-07, 5.8094e-03, 4.3728e-06,
        7.7236e-06, 2.3536e-05, 7.8582e-05, 1.5765e-05, 3.5057e-05, 3.0645e-04,
        9.9333e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,860][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([1.2057e-03, 6.9025e-05, 1.4643e-03, 4.5134e-05, 6.5918e-02, 7.3880e-05,
        7.2113e-05, 2.6258e-04, 2.2733e-04, 3.2723e-04, 2.9158e-04, 1.3326e-03,
        9.2871e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,862][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([1.8079e-03, 3.3073e-08, 1.1703e-04, 1.5512e-08, 5.7303e-01, 1.3228e-08,
        2.5729e-09, 5.0328e-08, 7.6167e-07, 6.3005e-10, 2.6303e-09, 9.8974e-08,
        4.2505e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,865][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0788, 0.0787, 0.1345, 0.0495, 0.2076, 0.0096, 0.0462, 0.0125, 0.0543,
        0.0517, 0.0405, 0.0148, 0.2214], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,870][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0710, 0.0215, 0.0137, 0.0297, 0.0094, 0.0421, 0.0625, 0.0284, 0.0289,
        0.1377, 0.2947, 0.1454, 0.1151], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,874][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.1752, 0.1148, 0.0447, 0.0922, 0.0544, 0.0474, 0.1088, 0.0612, 0.0345,
        0.0884, 0.0859, 0.0381, 0.0545], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,875][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.1811, 0.1127, 0.0991, 0.0995, 0.0106, 0.0666, 0.0720, 0.0595, 0.0599,
        0.0890, 0.0972, 0.0424, 0.0104], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,876][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.1049, 0.0737, 0.0348, 0.0650, 0.2571, 0.0325, 0.0504, 0.0187, 0.0267,
        0.0473, 0.0491, 0.0166, 0.2232], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,877][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0902, 0.0709, 0.0303, 0.0799, 0.0636, 0.0622, 0.0613, 0.0545, 0.1016,
        0.0716, 0.0994, 0.1278, 0.0865], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:26,880][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3823, 0.0331, 0.0585, 0.0191, 0.0292, 0.0697, 0.0204, 0.0505, 0.0487,
        0.0326, 0.0203, 0.1107, 0.0398, 0.0851], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,883][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4460e-03, 3.5545e-03, 5.9275e-04, 1.2020e-03, 3.3567e-04, 8.4981e-03,
        1.4059e-03, 4.5823e-05, 1.5934e-03, 1.5521e-03, 7.2286e-04, 1.1248e-04,
        2.2241e-04, 9.7872e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,887][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2297, 0.0513, 0.0208, 0.0443, 0.0209, 0.1057, 0.0349, 0.0255, 0.0502,
        0.0424, 0.0413, 0.0415, 0.0208, 0.2706], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,889][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([2.0018e-03, 7.4042e-05, 5.3776e-06, 5.5118e-05, 2.7091e-05, 3.1028e-04,
        4.3108e-04, 4.9002e-04, 1.2632e-03, 2.5580e-03, 3.5758e-03, 1.3269e-03,
        2.7884e-03, 9.8509e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,893][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0820, 0.0125, 0.0039, 0.0179, 0.0090, 0.0255, 0.0207, 0.0241, 0.0408,
        0.0538, 0.1144, 0.0231, 0.0745, 0.4977], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,894][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2078e-02, 2.4347e-03, 1.2797e-04, 8.9071e-04, 1.1070e-04, 8.6989e-03,
        2.0765e-04, 2.9482e-05, 6.7259e-04, 2.4888e-04, 2.8125e-04, 6.2025e-06,
        3.8276e-05, 9.7418e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,895][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.2105, 0.0103, 0.1196, 0.0104, 0.1338, 0.0138, 0.0084, 0.0376, 0.0993,
        0.0078, 0.0102, 0.1442, 0.1737, 0.0204], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,896][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0334, 0.0063, 0.0031, 0.0106, 0.0099, 0.0143, 0.0303, 0.0131, 0.0208,
        0.1102, 0.1722, 0.1775, 0.2241, 0.1742], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,898][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0503, 0.1042, 0.0200, 0.1022, 0.0270, 0.0995, 0.1347, 0.0306, 0.0272,
        0.1724, 0.1349, 0.0244, 0.0361, 0.0365], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,901][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1460, 0.0785, 0.0454, 0.0806, 0.0569, 0.0645, 0.0614, 0.0456, 0.0536,
        0.0730, 0.0835, 0.0542, 0.0637, 0.0934], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,905][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1014, 0.0731, 0.0370, 0.0771, 0.0412, 0.0794, 0.0595, 0.0249, 0.0477,
        0.0618, 0.0665, 0.0284, 0.0351, 0.2668], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,909][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2399, 0.0571, 0.0483, 0.0763, 0.0651, 0.0365, 0.0306, 0.0551, 0.0654,
        0.0606, 0.0775, 0.0803, 0.0690, 0.0384], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:26,914][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2739, 0.0266, 0.0626, 0.0222, 0.0540, 0.0715, 0.0238, 0.0386, 0.0763,
        0.0265, 0.0272, 0.0883, 0.0772, 0.1138, 0.0175], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,914][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1216e-03, 1.1780e-02, 8.3078e-05, 3.4319e-02, 1.0444e-04, 3.0536e-04,
        1.4493e-03, 1.7849e-04, 5.7937e-05, 8.2851e-03, 3.0209e-02, 2.4507e-04,
        6.8388e-05, 1.4516e-04, 9.0865e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,915][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1625, 0.0714, 0.0218, 0.0981, 0.0215, 0.0596, 0.0256, 0.0383, 0.0312,
        0.0610, 0.0966, 0.0397, 0.0214, 0.0759, 0.1755], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,916][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.6986e-03, 2.4362e-04, 9.9271e-05, 1.6694e-04, 6.8529e-04, 6.6820e-04,
        1.1052e-03, 2.2224e-04, 1.0521e-03, 6.5984e-03, 1.0941e-02, 1.5189e-02,
        8.6262e-02, 2.6887e-01, 6.0520e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,920][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0341, 0.0022, 0.0028, 0.0036, 0.0049, 0.0323, 0.0099, 0.0250, 0.0545,
        0.0117, 0.0301, 0.0697, 0.0589, 0.3959, 0.2644], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,924][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0433, 0.0611, 0.0025, 0.0783, 0.0021, 0.0312, 0.2263, 0.0343, 0.0048,
        0.0212, 0.0412, 0.0007, 0.0010, 0.0326, 0.4194], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,928][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1322, 0.0064, 0.0808, 0.0055, 0.0534, 0.0185, 0.0052, 0.0342, 0.0590,
        0.0047, 0.0069, 0.1202, 0.0868, 0.0355, 0.3508], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,933][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0218, 0.0041, 0.0033, 0.0068, 0.0071, 0.0089, 0.0118, 0.0182, 0.0265,
        0.0486, 0.0788, 0.0923, 0.1460, 0.2554, 0.2703], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,934][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0081, 0.0598, 0.0026, 0.1041, 0.0030, 0.0468, 0.1318, 0.0199, 0.0090,
        0.1515, 0.1823, 0.0048, 0.0044, 0.0340, 0.2380], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,935][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1216, 0.0754, 0.0342, 0.0829, 0.0373, 0.0553, 0.0705, 0.0484, 0.0435,
        0.0711, 0.0870, 0.0467, 0.0414, 0.0845, 0.1002], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,936][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1017, 0.0836, 0.0256, 0.1001, 0.0384, 0.0742, 0.0853, 0.0501, 0.0332,
        0.0759, 0.0925, 0.0275, 0.0346, 0.0640, 0.1132], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,938][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1782, 0.0705, 0.0494, 0.0723, 0.0506, 0.0502, 0.0456, 0.0535, 0.0537,
        0.0724, 0.0688, 0.0741, 0.0513, 0.0368, 0.0727], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:26,950][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:26,954][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,957][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,958][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,958][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,959][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,960][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,960][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,961][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,962][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,962][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,963][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,964][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:26,964][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,965][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,966][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,966][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,970][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,974][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,974][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,975][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,976][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,978][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,980][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,985][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:26,989][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.4050, 0.3493, 0.2457], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,991][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([8.8617e-05, 9.9314e-05, 9.9981e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,994][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.5381, 0.2808, 0.1811], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,994][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([5.3234e-03, 2.9423e-05, 9.9465e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,995][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.0220, 0.0013, 0.9767], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,996][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([1.3357e-02, 7.8681e-07, 9.8664e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,997][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.4134, 0.3257, 0.2609], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:26,998][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.5648, 0.3336, 0.1016], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,001][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.5894, 0.2712, 0.1395], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,005][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.6205, 0.3465, 0.0330], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,009][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.4124, 0.2526, 0.3350], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,012][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.4196, 0.4280, 0.1524], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,014][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6845, 0.0775, 0.1775, 0.0605], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,015][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3033e-03, 3.9261e-02, 1.3271e-04, 9.5830e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,016][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2391, 0.1790, 0.0311, 0.5508], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,016][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1126, 0.3847, 0.0321, 0.4706], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,019][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3229, 0.1463, 0.2659, 0.2649], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,022][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1230, 0.1969, 0.0075, 0.6726], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,025][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6176, 0.0295, 0.3305, 0.0224], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,029][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2214, 0.1684, 0.3568, 0.2534], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,034][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0671, 0.4700, 0.0222, 0.4407], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,035][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4366, 0.2438, 0.0931, 0.2265], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,035][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4211, 0.3137, 0.0583, 0.2069], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,036][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4515, 0.1972, 0.0936, 0.2577], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,037][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.1940, 0.2429, 0.1286, 0.2899, 0.1446], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,038][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([4.2392e-05, 7.9441e-05, 8.8134e-05, 8.3525e-05, 9.9971e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,041][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.3435, 0.2929, 0.0624, 0.1512, 0.1500], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,043][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([4.7430e-03, 3.1660e-05, 2.4470e-03, 1.3529e-04, 9.9264e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,046][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([8.4815e-03, 8.1367e-04, 2.5067e-02, 6.5874e-04, 9.6498e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,048][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([9.1501e-03, 2.3862e-07, 3.4954e-04, 1.0188e-07, 9.9050e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,053][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.1741, 0.1895, 0.2309, 0.1047, 0.3009], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,054][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.2380, 0.1962, 0.1379, 0.3352, 0.0927], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,055][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.3660, 0.2647, 0.0855, 0.1839, 0.1000], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,056][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.3851, 0.2333, 0.1684, 0.1950, 0.0182], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,057][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.3052, 0.2070, 0.0598, 0.1266, 0.3014], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,059][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.2676, 0.2135, 0.0734, 0.2774, 0.1682], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,062][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4259, 0.0374, 0.1063, 0.0373, 0.0649, 0.3281], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,065][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2215e-04, 1.6753e-03, 3.6680e-04, 2.8615e-03, 1.4241e-04, 9.9463e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,068][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4885, 0.1246, 0.0521, 0.1474, 0.0414, 0.1460], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,070][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9371e-03, 5.4262e-03, 7.2393e-04, 1.1482e-02, 2.1245e-03, 9.7531e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,074][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2266, 0.0644, 0.0513, 0.1166, 0.0600, 0.4811], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,075][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9783e-02, 1.8565e-03, 1.3089e-03, 1.2907e-03, 3.2784e-05, 9.5573e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,076][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3426, 0.0256, 0.3264, 0.0240, 0.2470, 0.0344], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,076][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1269, 0.0988, 0.1103, 0.2294, 0.1494, 0.2852], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,077][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0951, 0.2670, 0.0475, 0.3508, 0.0226, 0.2170], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,079][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3132, 0.1888, 0.0861, 0.1946, 0.0858, 0.1315], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,083][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2562, 0.1976, 0.0511, 0.1447, 0.0361, 0.3142], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,086][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4315, 0.1441, 0.0647, 0.1797, 0.0891, 0.0908], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,090][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4858, 0.0560, 0.2207, 0.0423, 0.0880, 0.0697, 0.0375],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,092][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5617e-04, 4.3027e-03, 4.8234e-04, 4.3007e-03, 8.1307e-04, 4.6860e-04,
        9.8878e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,095][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3063, 0.1900, 0.0515, 0.2240, 0.0540, 0.1268, 0.0473],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,095][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0295, 0.0181, 0.0057, 0.0332, 0.0136, 0.1797, 0.7201],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,096][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1390, 0.0306, 0.0585, 0.0431, 0.0840, 0.4346, 0.2102],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,097][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0561, 0.1301, 0.0024, 0.0973, 0.0007, 0.0449, 0.6685],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,099][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3416, 0.0113, 0.2964, 0.0097, 0.2797, 0.0502, 0.0111],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,102][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1044, 0.0627, 0.0581, 0.1402, 0.0755, 0.2352, 0.3238],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,106][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0240, 0.1307, 0.0106, 0.1941, 0.0084, 0.1418, 0.4903],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,110][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2678, 0.1715, 0.0745, 0.1740, 0.0670, 0.1079, 0.1372],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,113][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2273, 0.1938, 0.0484, 0.1643, 0.0550, 0.0841, 0.2272],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,115][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3336, 0.1337, 0.0840, 0.1436, 0.1082, 0.0862, 0.1106],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,116][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.3066, 0.0734, 0.1678, 0.0680, 0.0723, 0.1263, 0.0963, 0.0893],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,116][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8418e-04, 9.8777e-04, 1.7372e-03, 1.4091e-03, 8.6089e-04, 3.2475e-03,
        9.3710e-04, 9.9054e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,117][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3066, 0.1580, 0.0442, 0.1598, 0.1004, 0.1116, 0.0798, 0.0397],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,118][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5087e-03, 4.5930e-04, 5.3822e-04, 8.0226e-04, 1.5880e-03, 9.0920e-03,
        7.2430e-03, 9.7377e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,121][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0959, 0.0218, 0.0734, 0.0287, 0.0430, 0.1431, 0.0758, 0.5183],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,124][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.3988e-03, 1.8772e-04, 1.1376e-03, 1.0295e-04, 1.3082e-05, 1.9165e-04,
        8.2290e-05, 9.9289e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,128][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2713, 0.0292, 0.3722, 0.0203, 0.1626, 0.0449, 0.0210, 0.0785],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,131][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1065, 0.0463, 0.0476, 0.0971, 0.0311, 0.1952, 0.3605, 0.1158],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,135][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1245, 0.1247, 0.0534, 0.1584, 0.0280, 0.1533, 0.3116, 0.0461],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,136][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2453, 0.1604, 0.0674, 0.1552, 0.0741, 0.0947, 0.1361, 0.0668],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,137][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2247, 0.1591, 0.0551, 0.1115, 0.0265, 0.0773, 0.0874, 0.2585],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,138][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3832, 0.1031, 0.0800, 0.1283, 0.0654, 0.0635, 0.0650, 0.1114],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,140][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3710, 0.0887, 0.1241, 0.0700, 0.0743, 0.0757, 0.0595, 0.0756, 0.0611],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,142][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8402e-03, 3.0493e-04, 2.6456e-03, 2.0726e-04, 8.3641e-03, 3.4568e-04,
        1.9345e-04, 3.4031e-05, 9.8606e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,146][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.3267, 0.1111, 0.0440, 0.0814, 0.0402, 0.1070, 0.1253, 0.1036, 0.0606],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,149][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3825e-03, 4.0851e-05, 1.9253e-04, 9.1196e-05, 1.9686e-03, 2.4673e-04,
        6.2907e-04, 4.3021e-03, 9.8915e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,153][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1280, 0.0058, 0.0082, 0.0050, 0.0474, 0.0155, 0.0131, 0.1715, 0.6055],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,155][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2026e-02, 1.5132e-05, 1.3400e-04, 4.1244e-06, 6.9699e-05, 2.0251e-06,
        1.5987e-06, 6.3669e-07, 9.8775e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,156][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1703, 0.0443, 0.2231, 0.0387, 0.2228, 0.0292, 0.0313, 0.0703, 0.1700],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,156][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0873, 0.0501, 0.0130, 0.0932, 0.0757, 0.1285, 0.2050, 0.2468, 0.1004],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,157][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2528, 0.0977, 0.0260, 0.1143, 0.0752, 0.2384, 0.1220, 0.0659, 0.0076],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,159][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2359, 0.1374, 0.0548, 0.1287, 0.0910, 0.1118, 0.1151, 0.0830, 0.0421],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,162][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2100, 0.1308, 0.0565, 0.1105, 0.0574, 0.0755, 0.0729, 0.0382, 0.2481],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,166][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3158, 0.1400, 0.0944, 0.1014, 0.0727, 0.0401, 0.0387, 0.0855, 0.1114],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,170][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4499, 0.0154, 0.1092, 0.0179, 0.0938, 0.0797, 0.0345, 0.0639, 0.1225,
        0.0131], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,173][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8445e-03, 4.4357e-01, 9.8084e-05, 1.1171e-02, 9.0763e-05, 3.9672e-04,
        1.7962e-04, 5.1706e-05, 7.8250e-06, 5.4259e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,175][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2015, 0.3171, 0.0167, 0.0775, 0.0103, 0.0369, 0.0076, 0.0103, 0.0102,
        0.3119], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,176][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.3283e-02, 7.7307e-03, 6.9180e-04, 7.7758e-03, 1.4347e-03, 6.0820e-02,
        4.9928e-02, 5.5327e-02, 8.6741e-02, 6.9627e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,177][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2733, 0.0265, 0.0183, 0.0228, 0.0605, 0.1320, 0.0322, 0.1129, 0.0473,
        0.2741], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,178][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0979, 0.3460, 0.0083, 0.1248, 0.0047, 0.0695, 0.1027, 0.0303, 0.0102,
        0.2055], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,180][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2860, 0.0084, 0.2379, 0.0082, 0.2144, 0.0268, 0.0104, 0.0690, 0.1334,
        0.0056], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,183][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0378, 0.0143, 0.0274, 0.0388, 0.0436, 0.0709, 0.1130, 0.1482, 0.1416,
        0.3644], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,187][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0192, 0.1652, 0.0040, 0.1855, 0.0060, 0.0644, 0.1664, 0.0292, 0.0076,
        0.3524], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,191][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2156, 0.1233, 0.0591, 0.1281, 0.0613, 0.0864, 0.0942, 0.0704, 0.0569,
        0.1049], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,195][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1752, 0.1612, 0.0566, 0.1481, 0.0564, 0.0959, 0.0928, 0.0595, 0.0425,
        0.1117], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,196][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2442, 0.0945, 0.0732, 0.1072, 0.0826, 0.0681, 0.0649, 0.0793, 0.0737,
        0.1123], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,197][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3652, 0.0298, 0.0952, 0.0256, 0.0808, 0.0718, 0.0433, 0.0954, 0.1326,
        0.0292, 0.0311], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,198][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0615e-03, 1.2477e-02, 3.0610e-05, 5.1190e-01, 8.0363e-05, 6.9048e-04,
        2.3422e-04, 1.8328e-04, 8.4975e-06, 7.4683e-03, 4.6587e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,200][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0825, 0.0617, 0.0179, 0.3090, 0.0291, 0.0430, 0.0173, 0.0147, 0.0231,
        0.0548, 0.3469], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,202][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0825e-02, 6.0668e-03, 1.7316e-04, 3.9897e-03, 1.9364e-04, 7.8496e-03,
        1.3929e-02, 1.5644e-02, 7.4119e-03, 4.9320e-01, 4.4071e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,206][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0355, 0.0130, 0.0099, 0.0246, 0.0139, 0.1622, 0.0658, 0.1200, 0.1780,
        0.1218, 0.2553], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,209][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0326, 0.0873, 0.0043, 0.3882, 0.0015, 0.0543, 0.1212, 0.0254, 0.0037,
        0.0307, 0.2508], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,213][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2415, 0.0098, 0.2095, 0.0093, 0.2216, 0.0306, 0.0113, 0.0854, 0.1634,
        0.0074, 0.0103], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,215][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0333, 0.0120, 0.0243, 0.0201, 0.0230, 0.0425, 0.0639, 0.0800, 0.0985,
        0.2462, 0.3561], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,216][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.1001, 0.0053, 0.1175, 0.0049, 0.0609, 0.1999, 0.0256, 0.0109,
        0.2626, 0.2009], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,217][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1775, 0.1107, 0.0517, 0.1117, 0.0526, 0.0773, 0.0888, 0.0597, 0.0584,
        0.0979, 0.1138], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,218][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1450, 0.1313, 0.0422, 0.1396, 0.0497, 0.0981, 0.0991, 0.0527, 0.0354,
        0.0952, 0.1115], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,220][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2162, 0.0881, 0.0577, 0.1015, 0.0731, 0.0527, 0.0468, 0.0606, 0.0773,
        0.1114, 0.1144], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,224][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2387, 0.0435, 0.0476, 0.0481, 0.1454, 0.1267, 0.0494, 0.0347, 0.1524,
        0.0377, 0.0575, 0.0183], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,226][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7392e-03, 4.1714e-04, 2.2353e-03, 1.5583e-04, 9.5495e-04, 1.7359e-04,
        9.0104e-05, 1.4329e-04, 6.0541e-04, 9.2265e-05, 7.0699e-05, 9.9332e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,229][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2476, 0.0809, 0.0677, 0.0768, 0.0858, 0.1563, 0.0641, 0.0566, 0.0327,
        0.0513, 0.0618, 0.0186], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,232][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2686e-02, 5.1778e-05, 4.1425e-04, 7.1981e-05, 4.9089e-04, 1.1414e-03,
        2.1214e-04, 3.4349e-03, 1.4243e-03, 2.2486e-03, 4.8142e-03, 9.7301e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,236][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0410, 0.0033, 0.0252, 0.0068, 0.0095, 0.0111, 0.0106, 0.0287, 0.0149,
        0.0124, 0.0427, 0.7938], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,236][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2289e-02, 4.3663e-06, 1.9501e-03, 1.6903e-06, 5.8314e-05, 4.4227e-06,
        4.7466e-07, 4.6401e-06, 4.9959e-06, 9.8259e-08, 2.7194e-07, 9.0568e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,237][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1427, 0.0597, 0.1533, 0.0444, 0.1181, 0.0372, 0.0633, 0.0556, 0.1282,
        0.0527, 0.0489, 0.0960], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,238][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0494, 0.0177, 0.0093, 0.0274, 0.0787, 0.0314, 0.0667, 0.0458, 0.0258,
        0.1800, 0.3666, 0.1011], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,240][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0955, 0.1079, 0.0431, 0.1366, 0.0215, 0.0386, 0.1194, 0.0358, 0.0978,
        0.1272, 0.1639, 0.0126], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,243][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1791, 0.1012, 0.0731, 0.0930, 0.0426, 0.0771, 0.0678, 0.0581, 0.0879,
        0.0858, 0.0933, 0.0411], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,247][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1907, 0.0927, 0.0532, 0.0887, 0.0416, 0.0830, 0.0551, 0.0515, 0.0386,
        0.0660, 0.0686, 0.1701], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,251][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1800, 0.1427, 0.0534, 0.0946, 0.0614, 0.0325, 0.0416, 0.0419, 0.0383,
        0.1631, 0.1016, 0.0490], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,256][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.1106, 0.1082, 0.0679, 0.1408, 0.0974, 0.0374, 0.0515, 0.0165, 0.0079,
        0.0840, 0.1491, 0.0262, 0.1025], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,257][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([2.1036e-05, 2.0861e-05, 2.6824e-05, 2.6339e-05, 5.2413e-01, 1.0271e-05,
        1.1639e-05, 5.2813e-06, 3.4117e-05, 3.5895e-06, 1.1154e-05, 1.4821e-05,
        4.7568e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,258][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.1468, 0.1121, 0.0360, 0.0740, 0.1006, 0.0577, 0.0917, 0.0330, 0.0482,
        0.0761, 0.0655, 0.0536, 0.1047], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,258][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([3.6980e-04, 2.5920e-07, 1.4124e-05, 4.9206e-07, 5.8094e-03, 4.3728e-06,
        7.7236e-06, 2.3536e-05, 7.8582e-05, 1.5765e-05, 3.5057e-05, 3.0645e-04,
        9.9333e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,260][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([1.2057e-03, 6.9025e-05, 1.4643e-03, 4.5134e-05, 6.5918e-02, 7.3880e-05,
        7.2113e-05, 2.6258e-04, 2.2733e-04, 3.2723e-04, 2.9158e-04, 1.3326e-03,
        9.2871e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,262][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([1.8079e-03, 3.3073e-08, 1.1703e-04, 1.5512e-08, 5.7303e-01, 1.3228e-08,
        2.5729e-09, 5.0328e-08, 7.6167e-07, 6.3005e-10, 2.6303e-09, 9.8974e-08,
        4.2505e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,266][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0788, 0.0787, 0.1345, 0.0495, 0.2076, 0.0096, 0.0462, 0.0125, 0.0543,
        0.0517, 0.0405, 0.0148, 0.2214], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,271][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0710, 0.0215, 0.0137, 0.0297, 0.0094, 0.0421, 0.0625, 0.0284, 0.0289,
        0.1377, 0.2947, 0.1454, 0.1151], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,275][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.1752, 0.1148, 0.0447, 0.0922, 0.0544, 0.0474, 0.1088, 0.0612, 0.0345,
        0.0884, 0.0859, 0.0381, 0.0545], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,276][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.1811, 0.1127, 0.0991, 0.0995, 0.0106, 0.0666, 0.0720, 0.0595, 0.0599,
        0.0890, 0.0972, 0.0424, 0.0104], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,277][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.1049, 0.0737, 0.0348, 0.0650, 0.2571, 0.0325, 0.0504, 0.0187, 0.0267,
        0.0473, 0.0491, 0.0166, 0.2232], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,278][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0902, 0.0709, 0.0303, 0.0799, 0.0636, 0.0622, 0.0613, 0.0545, 0.1016,
        0.0716, 0.0994, 0.1278, 0.0865], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,280][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3823, 0.0331, 0.0585, 0.0191, 0.0292, 0.0697, 0.0204, 0.0505, 0.0487,
        0.0326, 0.0203, 0.1107, 0.0398, 0.0851], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,282][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4460e-03, 3.5545e-03, 5.9275e-04, 1.2020e-03, 3.3567e-04, 8.4981e-03,
        1.4059e-03, 4.5823e-05, 1.5934e-03, 1.5521e-03, 7.2286e-04, 1.1248e-04,
        2.2241e-04, 9.7872e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,286][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2297, 0.0513, 0.0208, 0.0443, 0.0209, 0.1057, 0.0349, 0.0255, 0.0502,
        0.0424, 0.0413, 0.0415, 0.0208, 0.2706], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,289][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.0018e-03, 7.4042e-05, 5.3776e-06, 5.5118e-05, 2.7091e-05, 3.1028e-04,
        4.3108e-04, 4.9002e-04, 1.2632e-03, 2.5580e-03, 3.5758e-03, 1.3269e-03,
        2.7884e-03, 9.8509e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,293][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0820, 0.0125, 0.0039, 0.0179, 0.0090, 0.0255, 0.0207, 0.0241, 0.0408,
        0.0538, 0.1144, 0.0231, 0.0745, 0.4977], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,295][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2078e-02, 2.4347e-03, 1.2797e-04, 8.9071e-04, 1.1070e-04, 8.6989e-03,
        2.0765e-04, 2.9482e-05, 6.7259e-04, 2.4888e-04, 2.8125e-04, 6.2025e-06,
        3.8276e-05, 9.7418e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,296][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2105, 0.0103, 0.1196, 0.0104, 0.1338, 0.0138, 0.0084, 0.0376, 0.0993,
        0.0078, 0.0102, 0.1442, 0.1737, 0.0204], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,297][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0334, 0.0063, 0.0031, 0.0106, 0.0099, 0.0143, 0.0303, 0.0131, 0.0208,
        0.1102, 0.1722, 0.1775, 0.2241, 0.1742], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,299][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0503, 0.1042, 0.0200, 0.1022, 0.0270, 0.0995, 0.1347, 0.0306, 0.0272,
        0.1724, 0.1349, 0.0244, 0.0361, 0.0365], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,302][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1460, 0.0785, 0.0454, 0.0806, 0.0569, 0.0645, 0.0614, 0.0456, 0.0536,
        0.0730, 0.0835, 0.0542, 0.0637, 0.0934], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,306][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1014, 0.0731, 0.0370, 0.0771, 0.0412, 0.0794, 0.0595, 0.0249, 0.0477,
        0.0618, 0.0665, 0.0284, 0.0351, 0.2668], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,310][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2399, 0.0571, 0.0483, 0.0763, 0.0651, 0.0365, 0.0306, 0.0551, 0.0654,
        0.0606, 0.0775, 0.0803, 0.0690, 0.0384], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,315][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2739, 0.0266, 0.0626, 0.0222, 0.0540, 0.0715, 0.0238, 0.0386, 0.0763,
        0.0265, 0.0272, 0.0883, 0.0772, 0.1138, 0.0175], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,316][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1216e-03, 1.1780e-02, 8.3078e-05, 3.4319e-02, 1.0444e-04, 3.0536e-04,
        1.4493e-03, 1.7849e-04, 5.7937e-05, 8.2851e-03, 3.0209e-02, 2.4507e-04,
        6.8388e-05, 1.4516e-04, 9.0865e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,317][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1625, 0.0714, 0.0218, 0.0981, 0.0215, 0.0596, 0.0256, 0.0383, 0.0312,
        0.0610, 0.0966, 0.0397, 0.0214, 0.0759, 0.1755], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,318][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.6986e-03, 2.4362e-04, 9.9271e-05, 1.6694e-04, 6.8529e-04, 6.6820e-04,
        1.1052e-03, 2.2224e-04, 1.0521e-03, 6.5984e-03, 1.0941e-02, 1.5189e-02,
        8.6262e-02, 2.6887e-01, 6.0520e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,320][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0341, 0.0022, 0.0028, 0.0036, 0.0049, 0.0323, 0.0099, 0.0250, 0.0545,
        0.0117, 0.0301, 0.0697, 0.0589, 0.3959, 0.2644], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,322][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0433, 0.0611, 0.0025, 0.0783, 0.0021, 0.0312, 0.2263, 0.0343, 0.0048,
        0.0212, 0.0412, 0.0007, 0.0010, 0.0326, 0.4194], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,326][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1322, 0.0064, 0.0808, 0.0055, 0.0534, 0.0185, 0.0052, 0.0342, 0.0590,
        0.0047, 0.0069, 0.1202, 0.0868, 0.0355, 0.3508], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,331][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0218, 0.0041, 0.0033, 0.0068, 0.0071, 0.0089, 0.0118, 0.0182, 0.0265,
        0.0486, 0.0788, 0.0923, 0.1460, 0.2554, 0.2703], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,335][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0081, 0.0598, 0.0026, 0.1041, 0.0030, 0.0468, 0.1318, 0.0199, 0.0090,
        0.1515, 0.1823, 0.0048, 0.0044, 0.0340, 0.2380], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,336][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1216, 0.0754, 0.0342, 0.0829, 0.0373, 0.0553, 0.0705, 0.0484, 0.0435,
        0.0711, 0.0870, 0.0467, 0.0414, 0.0845, 0.1002], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,337][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1017, 0.0836, 0.0256, 0.1001, 0.0384, 0.0742, 0.0853, 0.0501, 0.0332,
        0.0759, 0.0925, 0.0275, 0.0346, 0.0640, 0.1132], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,339][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1782, 0.0705, 0.0494, 0.0723, 0.0506, 0.0502, 0.0456, 0.0535, 0.0537,
        0.0724, 0.0688, 0.0741, 0.0513, 0.0368, 0.0727], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,342][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:27,345][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[47116],
        [31486],
        [    1],
        [34785],
        [23795],
        [30519],
        [26410],
        [17940],
        [33205],
        [32228],
        [35850],
        [48190],
        [31057],
        [20949],
        [22255]], device='cuda:0')
[2024-07-24 10:25:27,348][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[30710],
        [32003],
        [    1],
        [42386],
        [ 3524],
        [43687],
        [37766],
        [28676],
        [38776],
        [39847],
        [40144],
        [38654],
        [ 1793],
        [34457],
        [39815]], device='cuda:0')
[2024-07-24 10:25:27,350][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[8199],
        [7266],
        [ 506],
        [1619],
        [1484],
        [ 972],
        [ 679],
        [ 879],
        [1448],
        [2662],
        [2545],
        [2471],
        [2178],
        [1590],
        [1345]], device='cuda:0')
[2024-07-24 10:25:27,353][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[11131],
        [23788],
        [  509],
        [40455],
        [42329],
        [40235],
        [46888],
        [33844],
        [45003],
        [21243],
        [40533],
        [41415],
        [42126],
        [22392],
        [37527]], device='cuda:0')
[2024-07-24 10:25:27,356][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11175],
        [13166],
        [11220],
        [39425],
        [23770],
        [21604],
        [28303],
        [25658],
        [20839],
        [22370],
        [43112],
        [25758],
        [28594],
        [21381],
        [30269]], device='cuda:0')
[2024-07-24 10:25:27,358][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[43143],
        [44141],
        [ 9457],
        [35239],
        [22653],
        [10293],
        [28822],
        [21739],
        [13076],
        [35362],
        [34354],
        [38562],
        [23013],
        [ 8864],
        [28685]], device='cuda:0')
[2024-07-24 10:25:27,360][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[36818],
        [36690],
        [ 1134],
        [12572],
        [ 7247],
        [29275],
        [21447],
        [21550],
        [47481],
        [27078],
        [32708],
        [32543],
        [ 6576],
        [26326],
        [27125]], device='cuda:0')
[2024-07-24 10:25:27,361][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28120],
        [24317],
        [ 1119],
        [27365],
        [ 5787],
        [21927],
        [16127],
        [12063],
        [ 1680],
        [24040],
        [26736],
        [45468],
        [ 6550],
        [18448],
        [19498]], device='cuda:0')
[2024-07-24 10:25:27,363][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23320],
        [23532],
        [17658],
        [ 8926],
        [ 8438],
        [ 5161],
        [ 5404],
        [ 6206],
        [ 3138],
        [ 3909],
        [ 3712],
        [11023],
        [ 6322],
        [ 6032],
        [ 8606]], device='cuda:0')
[2024-07-24 10:25:27,365][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28029],
        [27984],
        [22984],
        [12618],
        [26456],
        [30667],
        [37146],
        [35943],
        [37984],
        [33753],
        [34020],
        [35361],
        [36673],
        [38719],
        [33319]], device='cuda:0')
[2024-07-24 10:25:27,368][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19883],
        [18719],
        [14767],
        [26360],
        [19009],
        [28986],
        [21755],
        [21837],
        [25626],
        [23168],
        [24162],
        [22861],
        [20958],
        [24182],
        [25441]], device='cuda:0')
[2024-07-24 10:25:27,371][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41998],
        [43536],
        [43378],
        [42174],
        [40304],
        [38178],
        [38464],
        [37291],
        [34416],
        [36584],
        [37335],
        [35781],
        [37115],
        [31531],
        [35673]], device='cuda:0')
[2024-07-24 10:25:27,373][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10814],
        [ 7707],
        [14271],
        [ 4084],
        [26037],
        [ 8087],
        [ 7674],
        [14440],
        [18123],
        [ 6737],
        [ 4775],
        [ 9470],
        [41807],
        [10424],
        [ 4717]], device='cuda:0')
[2024-07-24 10:25:27,376][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[47531],
        [47478],
        [45572],
        [46834],
        [46115],
        [47470],
        [47023],
        [48069],
        [47387],
        [46744],
        [46026],
        [45052],
        [44313],
        [47536],
        [45824]], device='cuda:0')
[2024-07-24 10:25:27,378][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[49840],
        [ 5591],
        [    2],
        [19883],
        [41032],
        [20912],
        [20043],
        [26007],
        [28153],
        [ 7367],
        [21733],
        [49560],
        [41672],
        [10031],
        [ 7785]], device='cuda:0')
[2024-07-24 10:25:27,381][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 8132],
        [ 7930],
        [14644],
        [10252],
        [13834],
        [24097],
        [15667],
        [16350],
        [13692],
        [14320],
        [13030],
        [13876],
        [14112],
        [15785],
        [14506]], device='cuda:0')
[2024-07-24 10:25:27,382][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[38149],
        [20617],
        [41775],
        [ 8995],
        [29733],
        [12651],
        [ 7903],
        [35135],
        [26986],
        [19450],
        [ 7037],
        [28357],
        [30585],
        [39375],
        [14093]], device='cuda:0')
[2024-07-24 10:25:27,384][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23384],
        [22477],
        [15158],
        [24296],
        [18703],
        [29241],
        [28355],
        [29285],
        [31452],
        [19994],
        [28268],
        [31400],
        [25924],
        [31928],
        [25843]], device='cuda:0')
[2024-07-24 10:25:27,386][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14752],
        [14175],
        [27631],
        [24155],
        [17221],
        [21969],
        [30350],
        [29726],
        [30971],
        [27380],
        [29983],
        [30703],
        [29206],
        [35542],
        [35779]], device='cuda:0')
[2024-07-24 10:25:27,388][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28479],
        [29042],
        [18643],
        [41596],
        [47449],
        [37538],
        [38839],
        [34513],
        [14656],
        [38884],
        [34685],
        [44297],
        [47307],
        [39562],
        [38985]], device='cuda:0')
[2024-07-24 10:25:27,390][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13906],
        [ 8260],
        [14620],
        [ 8849],
        [11769],
        [ 5473],
        [14379],
        [16535],
        [28584],
        [10357],
        [ 8678],
        [ 4827],
        [10868],
        [ 8326],
        [10683]], device='cuda:0')
[2024-07-24 10:25:27,393][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22735],
        [23320],
        [18613],
        [14213],
        [18114],
        [11507],
        [12043],
        [10772],
        [ 7309],
        [ 7118],
        [ 6738],
        [17421],
        [19562],
        [15283],
        [35193]], device='cuda:0')
[2024-07-24 10:25:27,396][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[20574],
        [22844],
        [34158],
        [24797],
        [25912],
        [21294],
        [30779],
        [33526],
        [27640],
        [29772],
        [26550],
        [27158],
        [27273],
        [24606],
        [24613]], device='cuda:0')
[2024-07-24 10:25:27,398][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30953],
        [ 3245],
        [14046],
        [ 3458],
        [ 8620],
        [ 4525],
        [ 3746],
        [ 4441],
        [ 7242],
        [ 2810],
        [ 2737],
        [ 3200],
        [ 5202],
        [ 3180],
        [ 2696]], device='cuda:0')
[2024-07-24 10:25:27,401][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12906],
        [ 4021],
        [ 3294],
        [ 2513],
        [ 2638],
        [ 3109],
        [ 3130],
        [ 3751],
        [ 4792],
        [ 3802],
        [ 3285],
        [ 3942],
        [ 3569],
        [ 4521],
        [ 3695]], device='cuda:0')
[2024-07-24 10:25:27,404][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[29505],
        [43355],
        [36438],
        [46282],
        [42324],
        [46129],
        [46169],
        [43132],
        [40107],
        [46348],
        [46469],
        [44697],
        [40888],
        [45595],
        [47260]], device='cuda:0')
[2024-07-24 10:25:27,405][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20593],
        [16857],
        [23600],
        [15498],
        [20941],
        [14073],
        [18329],
        [13748],
        [16011],
        [19909],
        [21376],
        [24028],
        [15573],
        [12112],
        [16696]], device='cuda:0')
[2024-07-24 10:25:27,406][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26672],
        [27047],
        [23683],
        [26351],
        [22088],
        [28139],
        [24785],
        [21825],
        [24725],
        [25064],
        [28069],
        [20431],
        [24326],
        [22204],
        [21162]], device='cuda:0')
[2024-07-24 10:25:27,408][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[  624],
        [42721],
        [50256],
        [28271],
        [ 8862],
        [27093],
        [27841],
        [21694],
        [21118],
        [40812],
        [26366],
        [ 1055],
        [ 8556],
        [39163],
        [40446]], device='cuda:0')
[2024-07-24 10:25:27,410][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151],
        [15151]], device='cuda:0')
[2024-07-24 10:25:27,429][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:27,430][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,431][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,432][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,432][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,433][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,434][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,434][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,435][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,436][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,436][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,437][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,438][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,438][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2562, 0.7438], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,439][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9036, 0.0964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,440][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4672, 0.5328], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,442][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4946, 0.5054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,445][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5190, 0.4810], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,446][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6901, 0.3099], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,447][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.9942e-01, 5.7523e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,447][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9824, 0.0176], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,449][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9523, 0.0477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,453][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9526, 0.0474], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,454][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.6849e-05, 9.9998e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,458][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1321, 0.8679], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,462][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.0298, 0.3726, 0.5977], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,464][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([9.2675e-01, 7.2644e-02, 6.0588e-04], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,467][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.3258, 0.4054, 0.2688], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,468][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.3831, 0.3923, 0.2246], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,469][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.7008, 0.1525, 0.1468], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,469][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.4226, 0.3812, 0.1961], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,470][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([9.9773e-01, 9.7334e-05, 2.1682e-03], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,472][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.6281, 0.2968, 0.0751], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,474][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.8777, 0.1019, 0.0204], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,478][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.1776, 0.7984, 0.0240], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,481][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([1.7168e-04, 6.8322e-01, 3.1661e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,483][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([3.0888e-04, 2.4720e-02, 9.7497e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,487][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0342, 0.2377, 0.4179, 0.3101], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,488][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8172, 0.1542, 0.0018, 0.0268], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,489][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2122, 0.2498, 0.1695, 0.3684], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,489][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2634, 0.2648, 0.1578, 0.3140], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,490][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3395, 0.1264, 0.1115, 0.4226], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,491][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3032, 0.4345, 0.0157, 0.2466], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,492][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.9572e-01, 1.6752e-04, 3.7363e-03, 3.7242e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,495][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3922, 0.0629, 0.2710, 0.2739], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,499][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7242, 0.0559, 0.0371, 0.1827], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,502][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5713, 0.0664, 0.0588, 0.3035], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,504][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.8062e-04, 4.0035e-01, 2.9090e-01, 3.0848e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,506][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.6808e-03, 5.2801e-03, 4.9554e-07, 9.8904e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,508][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0141, 0.1909, 0.3199, 0.2916, 0.1834], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,509][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([8.7663e-01, 9.8941e-02, 9.8575e-04, 2.2981e-02, 4.5838e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,510][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.1592, 0.2093, 0.1434, 0.3020, 0.1860], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,511][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.2199, 0.2222, 0.1282, 0.2606, 0.1691], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,512][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.4551, 0.0950, 0.0843, 0.2472, 0.1184], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,514][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.3372, 0.1953, 0.2659, 0.1551, 0.0465], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,516][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([9.8261e-01, 8.5393e-04, 1.0132e-02, 1.1014e-03, 5.3016e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,520][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.3369, 0.1141, 0.3270, 0.1874, 0.0346], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,524][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.6191, 0.1319, 0.0329, 0.1804, 0.0357], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,527][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.1654, 0.4781, 0.0138, 0.3262, 0.0166], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,529][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([2.7563e-04, 3.0254e-01, 2.1502e-01, 2.7670e-01, 2.0546e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,529][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([4.8702e-03, 2.2837e-02, 1.1255e-04, 1.4012e-01, 8.3206e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,530][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0303, 0.1081, 0.1181, 0.1947, 0.1135, 0.4353], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,531][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([8.7952e-01, 9.2654e-02, 9.5895e-04, 2.4777e-02, 4.9653e-04, 1.5965e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,532][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1295, 0.1671, 0.1144, 0.2434, 0.1495, 0.1961], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,534][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1793, 0.1794, 0.1061, 0.2134, 0.1406, 0.1813], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,537][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3433, 0.0868, 0.0775, 0.2624, 0.1095, 0.1205], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,540][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2970, 0.4914, 0.0769, 0.0556, 0.0171, 0.0619], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,543][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([9.2798e-01, 1.4368e-03, 5.3458e-02, 3.9292e-03, 1.3022e-02, 1.7115e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,547][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2019, 0.0698, 0.1485, 0.1526, 0.2702, 0.1569], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,549][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5669, 0.0821, 0.0509, 0.1239, 0.0615, 0.1147], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,549][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3905, 0.1419, 0.0632, 0.2239, 0.0639, 0.1167], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,550][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0003, 0.2083, 0.1812, 0.1940, 0.1812, 0.2349], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,551][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.1779e-04, 1.2745e-02, 7.8747e-06, 5.0903e-02, 6.0383e-07, 9.3623e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,552][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0077, 0.0570, 0.0755, 0.0946, 0.0696, 0.4378, 0.2576],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,554][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.5400e-01, 3.3695e-02, 4.1231e-04, 1.0804e-02, 2.0478e-04, 7.0720e-04,
        1.7781e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,557][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1040, 0.1300, 0.0899, 0.1858, 0.1181, 0.1505, 0.2216],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,560][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1525, 0.1516, 0.0902, 0.1810, 0.1199, 0.1536, 0.1512],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,564][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3245, 0.0796, 0.0678, 0.2281, 0.0953, 0.0987, 0.1060],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,569][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2906, 0.4593, 0.0526, 0.0789, 0.0088, 0.0242, 0.0856],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,569][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([8.2953e-01, 4.3535e-03, 1.0544e-01, 1.2683e-02, 4.6429e-02, 4.9435e-04,
        1.0674e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,570][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2069, 0.0848, 0.1099, 0.1263, 0.1746, 0.1394, 0.1581],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,571][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5588, 0.0572, 0.0390, 0.1136, 0.0605, 0.0727, 0.0981],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,572][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3541, 0.0928, 0.0396, 0.2270, 0.0656, 0.1068, 0.1140],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,574][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0004, 0.1684, 0.1501, 0.1645, 0.1621, 0.1809, 0.1737],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,576][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.1829e-05, 4.3320e-04, 3.2181e-06, 3.4421e-03, 2.8656e-08, 1.2765e-06,
        9.9609e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,580][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0029, 0.0268, 0.0419, 0.0556, 0.0378, 0.3149, 0.3517, 0.1684],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,583][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.8189, 0.1304, 0.0019, 0.0393, 0.0009, 0.0027, 0.0009, 0.0050],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,587][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0848, 0.1154, 0.0787, 0.1631, 0.1023, 0.1312, 0.1930, 0.1316],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,589][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1348, 0.1347, 0.0793, 0.1604, 0.1054, 0.1356, 0.1334, 0.1166],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,590][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2644, 0.0708, 0.0619, 0.1905, 0.0868, 0.0889, 0.0960, 0.1407],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,591][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.2583, 0.4200, 0.0045, 0.0759, 0.0028, 0.0134, 0.1499, 0.0751],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,592][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.6772, 0.0105, 0.1772, 0.0399, 0.0851, 0.0013, 0.0038, 0.0050],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,594][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1833, 0.0906, 0.0512, 0.1208, 0.1206, 0.2185, 0.1706, 0.0443],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,597][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.4905, 0.0268, 0.0359, 0.1019, 0.0492, 0.0850, 0.0925, 0.1182],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,601][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2695, 0.1257, 0.0251, 0.2247, 0.0389, 0.0925, 0.1904, 0.0331],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,605][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0003, 0.1398, 0.1419, 0.1470, 0.1475, 0.1555, 0.1508, 0.1171],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,607][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([6.6155e-05, 1.5666e-04, 1.5215e-07, 8.5129e-04, 7.9606e-09, 2.4024e-05,
        3.9755e-07, 9.9890e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,610][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0017, 0.0262, 0.0535, 0.0509, 0.0436, 0.2340, 0.2552, 0.2485, 0.0864],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,610][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([8.8696e-01, 7.6294e-02, 1.3386e-03, 2.7479e-02, 7.4771e-04, 2.0061e-03,
        7.7260e-04, 4.0212e-03, 3.8166e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,611][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0797, 0.1020, 0.0713, 0.1469, 0.0927, 0.1191, 0.1763, 0.1190, 0.0929],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,612][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1235, 0.1236, 0.0715, 0.1472, 0.0950, 0.1231, 0.1216, 0.1056, 0.0889],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,614][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.3321, 0.0569, 0.0521, 0.1504, 0.0767, 0.0704, 0.0782, 0.1177, 0.0656],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,617][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.3053, 0.2261, 0.0500, 0.0570, 0.0353, 0.0327, 0.2046, 0.0219, 0.0671],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,621][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.6872, 0.0092, 0.1788, 0.0229, 0.0607, 0.0009, 0.0026, 0.0032, 0.0344],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,625][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1153, 0.0336, 0.0700, 0.1184, 0.1155, 0.2953, 0.1141, 0.1096, 0.0283],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,628][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.4435, 0.0523, 0.0282, 0.0975, 0.0485, 0.1111, 0.0876, 0.0799, 0.0514],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,630][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2589, 0.0876, 0.0304, 0.2021, 0.0593, 0.1484, 0.1421, 0.0481, 0.0230],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,631][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0003, 0.1316, 0.1142, 0.1360, 0.1205, 0.1381, 0.1233, 0.0993, 0.1367],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,632][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([6.3080e-05, 5.3159e-05, 2.4359e-06, 3.5203e-04, 9.2937e-08, 4.2479e-08,
        2.0295e-07, 5.2155e-10, 9.9953e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:27,633][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0070, 0.0269, 0.0624, 0.0517, 0.0557, 0.1309, 0.2037, 0.1556, 0.1804,
        0.1257], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,634][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.5168e-01, 3.3411e-02, 5.4869e-04, 1.1243e-02, 2.8677e-04, 7.8866e-04,
        2.2291e-04, 1.5742e-03, 1.4927e-04, 9.9076e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,637][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0724, 0.0842, 0.0582, 0.1206, 0.0749, 0.0969, 0.1442, 0.0977, 0.0764,
        0.1744], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,641][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1063, 0.1063, 0.0638, 0.1261, 0.0849, 0.1084, 0.1072, 0.0937, 0.0797,
        0.1235], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,644][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2544, 0.0578, 0.0520, 0.1379, 0.0718, 0.0651, 0.0736, 0.1054, 0.0658,
        0.1163], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,648][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0446, 0.3481, 0.0104, 0.0225, 0.0011, 0.0041, 0.0383, 0.0024, 0.0052,
        0.5231], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,650][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.6352e-01, 6.5733e-04, 1.9832e-02, 1.6084e-03, 9.1083e-03, 1.0235e-04,
        1.6704e-04, 2.9437e-04, 2.8485e-03, 1.8639e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,651][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1843, 0.0333, 0.1399, 0.0908, 0.1662, 0.0804, 0.1080, 0.0490, 0.1029,
        0.0453], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,652][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4577, 0.0412, 0.0274, 0.1076, 0.0413, 0.0443, 0.0701, 0.0839, 0.0686,
        0.0580], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,653][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2138, 0.0579, 0.0580, 0.2995, 0.0730, 0.0625, 0.0735, 0.0326, 0.0321,
        0.0972], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,655][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0006, 0.0950, 0.1006, 0.1132, 0.1144, 0.1310, 0.1027, 0.0823, 0.1123,
        0.1479], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,657][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.5884e-02, 7.1574e-02, 2.2603e-04, 7.5947e-01, 6.5923e-05, 7.5412e-04,
        1.6592e-04, 3.1736e-05, 3.1054e-05, 1.4180e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:27,661][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0040, 0.0293, 0.0525, 0.0385, 0.0500, 0.1222, 0.2058, 0.1719, 0.1422,
        0.1268, 0.0567], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,664][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.5364e-01, 3.2352e-02, 5.7462e-04, 1.0012e-02, 3.4024e-04, 7.5905e-04,
        2.2392e-04, 1.6320e-03, 1.6838e-04, 1.1459e-04, 1.8054e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,667][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0611, 0.0716, 0.0504, 0.1035, 0.0649, 0.0831, 0.1228, 0.0836, 0.0660,
        0.1472, 0.1459], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,671][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0950, 0.0946, 0.0568, 0.1131, 0.0754, 0.0963, 0.0960, 0.0836, 0.0706,
        0.1100, 0.1085], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,672][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2609, 0.0369, 0.0408, 0.1012, 0.0626, 0.0506, 0.0599, 0.0861, 0.0565,
        0.1029, 0.1416], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,673][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0838, 0.2295, 0.0096, 0.0975, 0.0012, 0.0029, 0.0456, 0.0041, 0.0073,
        0.4279, 0.0906], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,673][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.2068e-01, 1.7679e-03, 3.3992e-02, 4.0007e-03, 2.2456e-02, 2.6674e-04,
        3.9752e-04, 7.8274e-04, 5.7911e-03, 3.7359e-03, 6.1343e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,675][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1323, 0.0441, 0.1017, 0.0924, 0.1064, 0.1410, 0.1143, 0.0659, 0.0957,
        0.0525, 0.0538], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,678][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4372, 0.0347, 0.0231, 0.0854, 0.0325, 0.0364, 0.0663, 0.0772, 0.0664,
        0.0469, 0.0939], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,682][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2738, 0.0286, 0.0306, 0.1473, 0.0556, 0.0649, 0.1091, 0.0364, 0.0409,
        0.0618, 0.1510], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,686][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0005, 0.0836, 0.0862, 0.1031, 0.0966, 0.1156, 0.0878, 0.0696, 0.0958,
        0.1208, 0.1404], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,689][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.5629e-03, 1.8827e-03, 1.9930e-07, 3.9732e-01, 1.7798e-07, 5.4874e-05,
        6.4204e-07, 1.9146e-07, 8.9859e-08, 4.0123e-03, 5.9417e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:27,692][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0020, 0.0221, 0.0227, 0.0430, 0.0264, 0.1848, 0.1357, 0.2161, 0.0924,
        0.1334, 0.0674, 0.0541], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,692][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([9.2245e-01, 5.2279e-02, 8.7642e-04, 1.9133e-02, 5.1324e-04, 1.0094e-03,
        3.3546e-04, 2.4944e-03, 2.7028e-04, 1.9809e-04, 3.4341e-04, 9.4234e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,693][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0529, 0.0673, 0.0469, 0.0948, 0.0596, 0.0754, 0.1116, 0.0763, 0.0596,
        0.1367, 0.1352, 0.0838], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,694][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0883, 0.0883, 0.0519, 0.1044, 0.0689, 0.0882, 0.0875, 0.0763, 0.0644,
        0.1011, 0.0991, 0.0817], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,696][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.2915, 0.0350, 0.0347, 0.0878, 0.0553, 0.0435, 0.0528, 0.0751, 0.0486,
        0.0889, 0.1157, 0.0713], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,699][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.3247, 0.1083, 0.0058, 0.0508, 0.0035, 0.0387, 0.0736, 0.0600, 0.0349,
        0.0954, 0.0391, 0.1651], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,701][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([8.2784e-01, 9.8750e-03, 5.8761e-02, 7.4035e-03, 2.3634e-02, 6.4061e-04,
        1.2952e-03, 2.0566e-03, 8.9010e-03, 8.6906e-03, 9.8924e-03, 4.1014e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,705][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1250, 0.0491, 0.1161, 0.0664, 0.1025, 0.1582, 0.1130, 0.0602, 0.0689,
        0.0513, 0.0455, 0.0437], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,710][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.3629, 0.0389, 0.0181, 0.0624, 0.0239, 0.0909, 0.0921, 0.0501, 0.0398,
        0.0881, 0.0866, 0.0461], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,712][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0562, 0.1764, 0.0186, 0.1309, 0.0286, 0.1168, 0.1590, 0.0209, 0.0315,
        0.1470, 0.1009, 0.0133], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,713][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0004, 0.0788, 0.0772, 0.0930, 0.0862, 0.0958, 0.0864, 0.0733, 0.0960,
        0.1134, 0.1262, 0.0733], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,714][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([2.7510e-01, 8.1696e-03, 1.7326e-05, 8.4613e-02, 7.4313e-06, 4.5114e-06,
        1.7259e-07, 2.2614e-05, 1.0319e-06, 2.0308e-02, 1.5801e-01, 4.5375e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:27,715][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0018, 0.0257, 0.0426, 0.0392, 0.0228, 0.1246, 0.1849, 0.1380, 0.0886,
        0.1555, 0.0716, 0.0737, 0.0311], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,716][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([9.2984e-01, 4.4655e-02, 9.4932e-04, 1.8595e-02, 5.2419e-04, 1.2509e-03,
        4.4592e-04, 2.5467e-03, 3.3356e-04, 2.7120e-04, 4.1126e-04, 1.2765e-04,
        4.5929e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,720][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0482, 0.0624, 0.0439, 0.0884, 0.0555, 0.0706, 0.1049, 0.0709, 0.0554,
        0.1277, 0.1274, 0.0788, 0.0659], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,723][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0833, 0.0838, 0.0482, 0.0987, 0.0636, 0.0830, 0.0823, 0.0714, 0.0599,
        0.0955, 0.0942, 0.0772, 0.0589], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,727][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.2930, 0.0299, 0.0320, 0.0684, 0.0519, 0.0366, 0.0456, 0.0625, 0.0452,
        0.0803, 0.1025, 0.0709, 0.0812], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,731][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0436, 0.1360, 0.1545, 0.0765, 0.0194, 0.0158, 0.0553, 0.0117, 0.0317,
        0.2610, 0.1294, 0.0290, 0.0361], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,732][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.4411, 0.0134, 0.1715, 0.0184, 0.0634, 0.0011, 0.0024, 0.0030, 0.0259,
        0.0237, 0.0327, 0.1146, 0.0888], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,733][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0536, 0.0648, 0.1078, 0.0473, 0.0084, 0.2597, 0.0777, 0.0799, 0.1265,
        0.0728, 0.0359, 0.0636, 0.0020], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,734][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.2473, 0.0815, 0.0112, 0.0513, 0.0119, 0.0965, 0.1617, 0.0258, 0.0237,
        0.1691, 0.0687, 0.0355, 0.0157], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,736][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0276, 0.1578, 0.0022, 0.0397, 0.0064, 0.0900, 0.4519, 0.0239, 0.0172,
        0.1331, 0.0270, 0.0082, 0.0151], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,739][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0004, 0.0687, 0.0715, 0.0894, 0.0766, 0.1040, 0.0871, 0.0587, 0.0792,
        0.1064, 0.1208, 0.0690, 0.0682], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,741][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([1.4653e-03, 1.0479e-02, 6.3522e-05, 4.7866e-02, 5.2650e-01, 3.5945e-06,
        5.9729e-07, 4.4501e-08, 2.3466e-06, 2.5838e-02, 8.6699e-02, 1.0543e-05,
        3.0107e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:27,745][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0039, 0.0246, 0.0388, 0.0414, 0.0297, 0.1596, 0.1340, 0.1337, 0.0608,
        0.1123, 0.0678, 0.0616, 0.0376, 0.0941], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,748][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([9.4721e-01, 3.6597e-02, 4.8414e-04, 1.1942e-02, 3.1813e-04, 8.5185e-04,
        2.7376e-04, 1.7576e-03, 1.6794e-04, 1.1306e-04, 1.7965e-04, 5.8034e-05,
        1.8676e-05, 2.6484e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,752][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0464, 0.0565, 0.0401, 0.0811, 0.0509, 0.0647, 0.0972, 0.0655, 0.0508,
        0.1171, 0.1166, 0.0716, 0.0606, 0.0808], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,753][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0767, 0.0764, 0.0453, 0.0907, 0.0599, 0.0770, 0.0764, 0.0666, 0.0563,
        0.0879, 0.0870, 0.0715, 0.0554, 0.0731], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,754][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.2276, 0.0353, 0.0321, 0.0869, 0.0491, 0.0434, 0.0481, 0.0711, 0.0429,
        0.0790, 0.1025, 0.0610, 0.0687, 0.0524], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,754][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1129, 0.2412, 0.0212, 0.0416, 0.0132, 0.0359, 0.1128, 0.0188, 0.0459,
        0.2100, 0.0310, 0.0237, 0.0078, 0.0840], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,755][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([7.7481e-01, 3.8348e-03, 6.4810e-02, 6.3489e-03, 1.6575e-02, 5.3006e-04,
        8.9213e-04, 1.5095e-03, 1.3661e-02, 1.0510e-02, 1.6483e-02, 4.6003e-02,
        3.7458e-02, 6.5741e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,757][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.1002, 0.0395, 0.0921, 0.1129, 0.1807, 0.0615, 0.0645, 0.0990, 0.0624,
        0.0375, 0.0595, 0.0540, 0.0184, 0.0178], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,761][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.3932, 0.0248, 0.0182, 0.0528, 0.0326, 0.0566, 0.0736, 0.0510, 0.0401,
        0.0568, 0.0697, 0.0347, 0.0424, 0.0534], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,764][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1617, 0.0426, 0.0155, 0.1065, 0.0378, 0.0698, 0.1368, 0.0457, 0.0341,
        0.0854, 0.1075, 0.0401, 0.0409, 0.0758], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,768][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0005, 0.0552, 0.0637, 0.0754, 0.0732, 0.0824, 0.0667, 0.0521, 0.0695,
        0.0928, 0.1078, 0.0664, 0.0669, 0.1273], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,771][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.9076e-06, 5.3779e-06, 2.5070e-08, 1.3997e-05, 3.6289e-08, 6.3338e-08,
        4.4851e-07, 2.6063e-10, 1.4489e-05, 1.8847e-05, 3.7929e-05, 1.3699e-08,
        2.7343e-08, 9.9991e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:27,773][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0029, 0.0200, 0.0294, 0.0296, 0.0322, 0.1615, 0.1201, 0.1152, 0.0914,
        0.0933, 0.0444, 0.0515, 0.0361, 0.1437, 0.0289], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,774][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.5943e-01, 2.5812e-02, 5.6274e-04, 9.5438e-03, 3.4495e-04, 9.5445e-04,
        3.3377e-04, 2.2028e-03, 2.5827e-04, 1.5375e-04, 2.2089e-04, 8.7216e-05,
        2.9568e-05, 4.2540e-05, 2.7856e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,774][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0468, 0.0511, 0.0364, 0.0730, 0.0464, 0.0586, 0.0881, 0.0592, 0.0464,
        0.1048, 0.1028, 0.0634, 0.0542, 0.0720, 0.0967], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,775][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0713, 0.0710, 0.0419, 0.0837, 0.0556, 0.0722, 0.0712, 0.0623, 0.0526,
        0.0812, 0.0801, 0.0656, 0.0516, 0.0678, 0.0719], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,778][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2420, 0.0308, 0.0294, 0.0730, 0.0456, 0.0363, 0.0423, 0.0609, 0.0396,
        0.0713, 0.0924, 0.0575, 0.0639, 0.0466, 0.0684], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,781][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0982, 0.0604, 0.0104, 0.0497, 0.0039, 0.0061, 0.0708, 0.0069, 0.0102,
        0.0899, 0.0315, 0.0098, 0.0019, 0.0152, 0.5352], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,784][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.5843, 0.0046, 0.0997, 0.0107, 0.0413, 0.0008, 0.0016, 0.0030, 0.0248,
        0.0163, 0.0229, 0.0890, 0.0802, 0.0118, 0.0088], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,788][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1227, 0.0613, 0.1262, 0.0846, 0.0692, 0.0607, 0.0961, 0.0449, 0.0778,
        0.0536, 0.0371, 0.0492, 0.0080, 0.0472, 0.0614], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,793][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3695, 0.0219, 0.0231, 0.0537, 0.0355, 0.0400, 0.0702, 0.0632, 0.0455,
        0.0298, 0.0639, 0.0443, 0.0358, 0.0534, 0.0503], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,794][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2181, 0.0242, 0.0118, 0.0693, 0.0338, 0.0758, 0.1668, 0.0383, 0.0319,
        0.0439, 0.0669, 0.0513, 0.0271, 0.1113, 0.0296], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,794][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0005, 0.0493, 0.0541, 0.0698, 0.0681, 0.0802, 0.0653, 0.0449, 0.0652,
        0.0837, 0.0931, 0.0587, 0.0582, 0.1209, 0.0879], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,795][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.6433e-06, 1.6118e-04, 1.3438e-08, 4.3451e-03, 1.4875e-09, 2.2709e-07,
        4.5459e-07, 1.7619e-09, 1.7223e-08, 6.2665e-04, 6.6017e-03, 1.8160e-08,
        8.9917e-10, 5.8127e-08, 9.8826e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:27,814][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:27,814][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,815][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,816][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,817][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,817][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,818][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,819][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,819][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,820][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,821][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,821][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,822][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:27,823][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9229, 0.0771], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,823][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9189, 0.0811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,824][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6345, 0.3655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,827][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3640, 0.6360], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,831][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2676, 0.7324], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,834][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5304, 0.4696], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,834][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9486, 0.0514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,835][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5592, 0.4408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,836][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9281, 0.0719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,837][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2526, 0.7474], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,839][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1632, 0.8368], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,842][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2934, 0.7066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:27,845][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.0053, 0.0499, 0.9448], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,849][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.8180, 0.0912, 0.0907], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,853][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.4491, 0.2837, 0.2672], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,854][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.2848, 0.4967, 0.2185], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,855][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.1090, 0.3877, 0.5033], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,856][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.2563, 0.7157, 0.0280], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,856][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.5095, 0.3379, 0.1526], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,858][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.4186, 0.2807, 0.3007], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,861][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.8975, 0.0823, 0.0202], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,865][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.0892, 0.2321, 0.6788], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,868][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.1008, 0.4290, 0.4702], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,870][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([5.6876e-05, 7.3047e-03, 9.9264e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:27,874][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0131, 0.0437, 0.9270, 0.0161], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,875][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8440, 0.0322, 0.0866, 0.0371], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,876][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3411, 0.2052, 0.2215, 0.2321], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,877][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1857, 0.3180, 0.1434, 0.3529], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,877][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0943, 0.2617, 0.4009, 0.2432], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,879][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1261, 0.0853, 0.0023, 0.7863], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,883][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7159, 0.0618, 0.1835, 0.0388], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,886][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2693, 0.2272, 0.3267, 0.1769], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,890][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9061, 0.0665, 0.0166, 0.0109], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,894][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0867, 0.2150, 0.2982, 0.4002], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,895][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0701, 0.3016, 0.3685, 0.2598], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,896][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.7216e-03, 2.4413e-03, 9.6637e-07, 9.9084e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:27,896][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0022, 0.0273, 0.8535, 0.0274, 0.0897], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,897][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.3694, 0.0832, 0.1682, 0.1831, 0.1961], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,899][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.2791, 0.1815, 0.1756, 0.1935, 0.1703], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,902][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.1626, 0.2810, 0.1221, 0.3087, 0.1256], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,906][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0644, 0.2368, 0.3012, 0.2144, 0.1833], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,910][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.1022, 0.1152, 0.0065, 0.7426, 0.0335], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,913][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0991, 0.1749, 0.0734, 0.4089, 0.2436], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,915][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.3221, 0.1989, 0.2027, 0.1125, 0.1639], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,916][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.8533, 0.0922, 0.0260, 0.0190, 0.0095], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,916][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0428, 0.1093, 0.3125, 0.4522, 0.0833], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,917][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0606, 0.2373, 0.2679, 0.2040, 0.2301], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,918][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([3.4883e-04, 1.1967e-03, 2.8631e-05, 1.7302e-02, 9.8112e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:27,921][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2065, 0.0695, 0.1947, 0.1229, 0.1429, 0.2636], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,925][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.6221, 0.0430, 0.0662, 0.0573, 0.1857, 0.0256], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,928][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2315, 0.1514, 0.1538, 0.1610, 0.1531, 0.1492], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,933][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1281, 0.2181, 0.0964, 0.2427, 0.0995, 0.2153], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,935][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0612, 0.1838, 0.2471, 0.1583, 0.1711, 0.1786], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,935][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1175, 0.1375, 0.0023, 0.4226, 0.0124, 0.3076], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,936][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.6268, 0.0124, 0.0038, 0.0530, 0.0056, 0.2983], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,937][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2423, 0.1813, 0.2074, 0.1201, 0.1803, 0.0686], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,939][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8629, 0.0738, 0.0223, 0.0140, 0.0075, 0.0195], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,942][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0604, 0.1532, 0.2255, 0.2932, 0.0841, 0.1836], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,946][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0415, 0.1935, 0.2250, 0.1618, 0.1955, 0.1827], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,948][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.4705e-05, 1.2828e-03, 3.6659e-06, 1.1925e-02, 1.3819e-06, 9.8677e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:27,952][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0022, 0.0076, 0.0705, 0.0103, 0.0387, 0.8303, 0.0404],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,955][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6821, 0.0355, 0.0506, 0.0385, 0.1487, 0.0189, 0.0258],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,956][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2092, 0.1278, 0.1323, 0.1417, 0.1334, 0.1239, 0.1317],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,956][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1054, 0.1775, 0.0800, 0.1976, 0.0823, 0.1756, 0.1817],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,957][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0556, 0.1529, 0.2123, 0.1409, 0.1488, 0.1490, 0.1405],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,959][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0692, 0.0674, 0.0023, 0.4419, 0.0058, 0.0618, 0.3517],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,962][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3963, 0.0187, 0.0896, 0.0322, 0.0261, 0.2912, 0.1460],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,966][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1866, 0.1513, 0.1926, 0.1088, 0.1775, 0.0792, 0.1040],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,970][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8403, 0.0741, 0.0221, 0.0146, 0.0075, 0.0194, 0.0219],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,973][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0480, 0.1256, 0.1720, 0.2256, 0.0659, 0.1470, 0.2158],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,975][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0387, 0.1622, 0.1967, 0.1397, 0.1706, 0.1543, 0.1378],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,976][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.7902e-07, 1.1147e-05, 3.6244e-07, 2.1268e-04, 1.7179e-08, 4.3939e-07,
        9.9977e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:27,977][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0007, 0.0009, 0.0317, 0.0020, 0.0113, 0.3665, 0.5756, 0.0113],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,978][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.4516, 0.0342, 0.0581, 0.0466, 0.1602, 0.0224, 0.0391, 0.1879],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,980][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1893, 0.1155, 0.1160, 0.1219, 0.1160, 0.1101, 0.1115, 0.1197],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,982][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0954, 0.1601, 0.0710, 0.1777, 0.0736, 0.1580, 0.1634, 0.1009],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,987][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0426, 0.1409, 0.1842, 0.1213, 0.1213, 0.1313, 0.1178, 0.1406],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,991][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1123, 0.1184, 0.0007, 0.3523, 0.0022, 0.0443, 0.2771, 0.0927],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,993][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([1.8051e-01, 1.3015e-02, 1.9710e-04, 2.1352e-02, 1.4093e-03, 3.1255e-01,
        2.4173e-01, 2.2923e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,996][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1620, 0.1487, 0.1809, 0.0996, 0.1654, 0.0669, 0.0916, 0.0849],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,996][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.8225, 0.0783, 0.0237, 0.0171, 0.0080, 0.0212, 0.0230, 0.0062],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,997][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0359, 0.0960, 0.1792, 0.2257, 0.0598, 0.1257, 0.1799, 0.0978],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,998][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0343, 0.1456, 0.1683, 0.1223, 0.1454, 0.1344, 0.1210, 0.1287],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:27,999][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([4.2582e-06, 4.7220e-06, 2.3392e-08, 5.8840e-05, 6.0320e-09, 9.3041e-06,
        5.6259e-07, 9.9992e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,001][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([1.3614e-04, 1.5688e-03, 2.3544e-01, 5.7965e-03, 8.3982e-02, 2.5356e-01,
        2.2440e-01, 1.8847e-01, 6.6417e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,004][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.4370, 0.0144, 0.0694, 0.0302, 0.1436, 0.0177, 0.0342, 0.1852, 0.0683],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,007][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1742, 0.1015, 0.1020, 0.1058, 0.1004, 0.0945, 0.0974, 0.1041, 0.1201],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,012][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0869, 0.1465, 0.0642, 0.1618, 0.0668, 0.1448, 0.1493, 0.0914, 0.0884],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,016][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0338, 0.1150, 0.1593, 0.0956, 0.1037, 0.1090, 0.0923, 0.1136, 0.1777],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,017][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1172, 0.0759, 0.0020, 0.3129, 0.0071, 0.0690, 0.3235, 0.0280, 0.0644],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,017][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1820, 0.0244, 0.0460, 0.1035, 0.0180, 0.0881, 0.1999, 0.0117, 0.3264],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,018][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1735, 0.1400, 0.1603, 0.0911, 0.1467, 0.0579, 0.0806, 0.0760, 0.0738],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,020][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.8034, 0.0747, 0.0243, 0.0173, 0.0090, 0.0238, 0.0243, 0.0065, 0.0167],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,023][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0257, 0.0634, 0.1775, 0.2428, 0.0506, 0.1222, 0.1691, 0.0784, 0.0703],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,027][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0307, 0.1244, 0.1437, 0.1043, 0.1265, 0.1137, 0.1027, 0.1088, 0.1451],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,029][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([1.5536e-05, 1.0169e-05, 2.2208e-06, 1.5658e-04, 4.0988e-07, 1.2174e-07,
        1.7355e-06, 4.9811e-09, 9.9981e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,034][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0126, 0.0026, 0.1292, 0.0099, 0.0777, 0.0351, 0.1430, 0.0568, 0.5256,
        0.0074], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,036][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4383, 0.0209, 0.0489, 0.0261, 0.1052, 0.0178, 0.0249, 0.1442, 0.1459,
        0.0278], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,037][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1439, 0.0863, 0.0942, 0.0946, 0.0941, 0.0868, 0.0885, 0.0951, 0.1099,
        0.1066], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,038][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0738, 0.1226, 0.0557, 0.1355, 0.0578, 0.1220, 0.1270, 0.0788, 0.0763,
        0.1504], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,039][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0342, 0.0970, 0.1429, 0.0888, 0.0988, 0.0975, 0.0849, 0.1051, 0.1541,
        0.0966], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,041][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0947, 0.0682, 0.0024, 0.3684, 0.0065, 0.0338, 0.2176, 0.0291, 0.0174,
        0.1620], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,043][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1769, 0.0175, 0.0442, 0.0109, 0.0959, 0.3985, 0.1037, 0.0764, 0.0396,
        0.0363], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,047][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1541, 0.1212, 0.1540, 0.0862, 0.1378, 0.0576, 0.0783, 0.0744, 0.0706,
        0.0659], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,052][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7912, 0.0667, 0.0206, 0.0149, 0.0075, 0.0185, 0.0198, 0.0053, 0.0147,
        0.0407], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,055][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0360, 0.0925, 0.1243, 0.1623, 0.0496, 0.1045, 0.1506, 0.0882, 0.0554,
        0.1367], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,057][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0263, 0.1115, 0.1329, 0.0945, 0.1166, 0.1055, 0.0904, 0.1010, 0.1333,
        0.0880], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,057][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([3.6273e-02, 3.4559e-02, 4.0049e-04, 8.5810e-01, 6.5533e-04, 4.0172e-03,
        3.2094e-03, 5.8881e-04, 6.4455e-05, 6.2137e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,058][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0016, 0.0070, 0.1378, 0.0025, 0.0877, 0.0335, 0.2122, 0.1619, 0.3355,
        0.0178, 0.0024], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,059][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4797, 0.0169, 0.0380, 0.0182, 0.1131, 0.0136, 0.0181, 0.1282, 0.1305,
        0.0204, 0.0233], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,061][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1278, 0.0773, 0.0862, 0.0873, 0.0859, 0.0790, 0.0804, 0.0856, 0.1009,
        0.0966, 0.0930], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,065][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0636, 0.1070, 0.0483, 0.1190, 0.0501, 0.1068, 0.1114, 0.0688, 0.0664,
        0.1322, 0.1263], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,068][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0321, 0.0868, 0.1327, 0.0820, 0.0923, 0.0880, 0.0778, 0.0963, 0.1441,
        0.0880, 0.0800], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,071][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.3798e-02, 1.9610e-02, 5.9916e-04, 1.9858e-01, 1.5012e-03, 6.8082e-03,
        6.2855e-02, 7.7176e-03, 5.3994e-03, 5.0350e-02, 6.1278e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,075][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1588, 0.0133, 0.0353, 0.0077, 0.0484, 0.4528, 0.1582, 0.0429, 0.0472,
        0.0273, 0.0081], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,079][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1313, 0.1169, 0.1411, 0.0816, 0.1267, 0.0535, 0.0737, 0.0691, 0.0639,
        0.0606, 0.0816], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,080][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7576, 0.0657, 0.0209, 0.0153, 0.0078, 0.0187, 0.0200, 0.0054, 0.0150,
        0.0415, 0.0320], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,081][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0310, 0.0827, 0.1053, 0.1353, 0.0444, 0.0898, 0.1298, 0.0796, 0.0486,
        0.1175, 0.1361], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,082][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0246, 0.1001, 0.1227, 0.0875, 0.1068, 0.0969, 0.0825, 0.0940, 0.1243,
        0.0801, 0.0806], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,083][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([3.4554e-03, 8.6967e-04, 3.7955e-07, 4.1622e-01, 1.8336e-06, 2.6674e-04,
        1.3647e-05, 3.7201e-06, 1.8667e-07, 1.7124e-03, 5.7745e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,086][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0053, 0.0113, 0.0103, 0.0138, 0.2451, 0.0278, 0.5543, 0.0545,
        0.0248, 0.0102, 0.0418], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,090][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.1239, 0.0185, 0.0470, 0.0375, 0.1351, 0.0229, 0.0367, 0.1972, 0.1273,
        0.0394, 0.0611, 0.1535], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,094][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1294, 0.0756, 0.0760, 0.0787, 0.0752, 0.0710, 0.0735, 0.0781, 0.0901,
        0.0892, 0.0829, 0.0804], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,099][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0607, 0.1034, 0.0446, 0.1137, 0.0465, 0.1018, 0.1048, 0.0636, 0.0617,
        0.1253, 0.1191, 0.0548], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,100][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0275, 0.0908, 0.1065, 0.0782, 0.0731, 0.0816, 0.0757, 0.0859, 0.1290,
        0.0878, 0.0749, 0.0891], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,100][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0556, 0.0454, 0.0005, 0.1531, 0.0020, 0.0270, 0.1025, 0.0317, 0.0096,
        0.0679, 0.3986, 0.1060], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,101][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1221, 0.0414, 0.0035, 0.0667, 0.0222, 0.1669, 0.0526, 0.1765, 0.0071,
        0.1447, 0.0772, 0.1191], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,103][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1856, 0.1351, 0.1282, 0.0762, 0.1042, 0.0383, 0.0600, 0.0572, 0.0515,
        0.0498, 0.0600, 0.0539], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,106][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.5804, 0.0719, 0.0254, 0.0216, 0.0117, 0.0270, 0.0278, 0.0081, 0.0175,
        0.0533, 0.0432, 0.1122], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,110][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0238, 0.0568, 0.1122, 0.1505, 0.0372, 0.0805, 0.1142, 0.0600, 0.0451,
        0.1114, 0.1536, 0.0549], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,115][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0239, 0.0950, 0.1075, 0.0798, 0.0938, 0.0855, 0.0778, 0.0827, 0.1090,
        0.0734, 0.0722, 0.0995], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,117][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.3848e-01, 3.5169e-03, 3.7670e-05, 8.8455e-02, 8.4919e-05, 2.6807e-05,
        3.7330e-06, 3.9051e-04, 2.0295e-06, 8.3647e-03, 1.6264e-01, 4.9800e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,119][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0007, 0.0093, 0.2608, 0.0103, 0.0289, 0.0663, 0.1676, 0.1172, 0.0886,
        0.0411, 0.0121, 0.1550, 0.0420], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,120][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.1074, 0.0256, 0.0505, 0.0565, 0.0600, 0.0274, 0.0469, 0.1795, 0.1268,
        0.0524, 0.0843, 0.1117, 0.0711], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,121][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.1139, 0.0721, 0.0705, 0.0758, 0.0683, 0.0662, 0.0678, 0.0700, 0.0832,
        0.0836, 0.0793, 0.0764, 0.0729], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,123][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0589, 0.0997, 0.0430, 0.1092, 0.0446, 0.0980, 0.1002, 0.0611, 0.0593,
        0.1195, 0.1136, 0.0529, 0.0399], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,126][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0220, 0.0843, 0.1086, 0.0755, 0.0658, 0.0748, 0.0677, 0.0737, 0.1154,
        0.0800, 0.0718, 0.0785, 0.0818], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,130][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0188, 0.0223, 0.0014, 0.1500, 0.0073, 0.0229, 0.1101, 0.0080, 0.0145,
        0.0481, 0.5112, 0.0795, 0.0059], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,134][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0287, 0.0580, 0.0217, 0.1282, 0.0691, 0.0398, 0.1246, 0.0016, 0.1178,
        0.1305, 0.1626, 0.0390, 0.0784], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,138][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1480, 0.1220, 0.1219, 0.0718, 0.1031, 0.0372, 0.0586, 0.0524, 0.0495,
        0.0481, 0.0607, 0.0529, 0.0738], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,139][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.6274, 0.0731, 0.0221, 0.0170, 0.0087, 0.0233, 0.0269, 0.0068, 0.0165,
        0.0461, 0.0334, 0.0824, 0.0163], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,140][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0145, 0.0400, 0.1194, 0.1692, 0.0302, 0.0740, 0.1093, 0.0447, 0.0409,
        0.1103, 0.1763, 0.0509, 0.0203], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,141][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0230, 0.0867, 0.0981, 0.0747, 0.0850, 0.0787, 0.0709, 0.0732, 0.0959,
        0.0689, 0.0679, 0.0903, 0.0866], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,142][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([1.0973e-04, 4.5570e-04, 1.3092e-05, 5.6498e-03, 4.8727e-01, 2.3128e-06,
        1.4672e-06, 9.9537e-08, 5.7151e-07, 1.0501e-03, 1.0077e-02, 1.9029e-06,
        4.9537e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,145][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0065, 0.0097, 0.2021, 0.0230, 0.0525, 0.2596, 0.0865, 0.0930, 0.0123,
        0.0376, 0.0276, 0.0905, 0.0632, 0.0360], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,150][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.2412, 0.0152, 0.0256, 0.0185, 0.0927, 0.0112, 0.0153, 0.1088, 0.1113,
        0.0201, 0.0240, 0.1928, 0.1154, 0.0079], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,154][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1049, 0.0630, 0.0670, 0.0666, 0.0655, 0.0614, 0.0623, 0.0660, 0.0775,
        0.0760, 0.0703, 0.0704, 0.0697, 0.0793], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,158][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0544, 0.0919, 0.0400, 0.1018, 0.0417, 0.0913, 0.0944, 0.0573, 0.0553,
        0.1120, 0.1066, 0.0489, 0.0376, 0.0666], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,159][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0209, 0.0701, 0.0993, 0.0599, 0.0666, 0.0664, 0.0590, 0.0686, 0.1048,
        0.0688, 0.0575, 0.0795, 0.0802, 0.0982], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,160][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0312, 0.0206, 0.0007, 0.1052, 0.0044, 0.0221, 0.1212, 0.0114, 0.0168,
        0.0486, 0.3007, 0.0362, 0.0031, 0.2777], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,162][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1503, 0.0096, 0.0309, 0.0207, 0.0020, 0.0875, 0.0044, 0.0021, 0.3186,
        0.0136, 0.0270, 0.0692, 0.0020, 0.2620], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,165][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1248, 0.1008, 0.1099, 0.0708, 0.0986, 0.0407, 0.0624, 0.0562, 0.0495,
        0.0514, 0.0680, 0.0532, 0.0728, 0.0409], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,169][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.5910, 0.0638, 0.0218, 0.0168, 0.0097, 0.0231, 0.0245, 0.0066, 0.0146,
        0.0452, 0.0328, 0.0942, 0.0192, 0.0368], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,173][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0227, 0.0566, 0.0923, 0.1211, 0.0340, 0.0713, 0.1019, 0.0565, 0.0384,
        0.0951, 0.1214, 0.0476, 0.0291, 0.1121], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,178][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0181, 0.0765, 0.0913, 0.0659, 0.0811, 0.0736, 0.0631, 0.0703, 0.0930,
        0.0612, 0.0603, 0.0878, 0.0822, 0.0756], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,178][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([3.6480e-07, 3.8892e-07, 9.7849e-09, 2.3539e-06, 6.6908e-08, 7.0557e-08,
        1.4676e-06, 1.0011e-09, 6.2528e-06, 1.1659e-06, 5.8265e-06, 3.6782e-09,
        7.3944e-08, 9.9998e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,179][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.3044e-03, 1.5289e-03, 3.0415e-02, 8.7686e-04, 2.4215e-02, 2.9608e-01,
        3.1916e-02, 3.6894e-02, 7.4255e-02, 4.9367e-03, 1.0618e-03, 3.5686e-02,
        3.2885e-02, 4.2789e-01, 5.5624e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,180][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3419, 0.0149, 0.0263, 0.0168, 0.0769, 0.0098, 0.0136, 0.0922, 0.0966,
        0.0177, 0.0206, 0.1563, 0.0935, 0.0082, 0.0148], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,182][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0945, 0.0575, 0.0619, 0.0619, 0.0619, 0.0575, 0.0594, 0.0643, 0.0738,
        0.0712, 0.0660, 0.0684, 0.0663, 0.0733, 0.0622], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,185][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0497, 0.0828, 0.0369, 0.0915, 0.0385, 0.0825, 0.0858, 0.0527, 0.0511,
        0.1014, 0.0971, 0.0449, 0.0349, 0.0605, 0.0894], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,189][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0241, 0.0626, 0.0888, 0.0572, 0.0628, 0.0629, 0.0589, 0.0693, 0.0973,
        0.0642, 0.0560, 0.0766, 0.0746, 0.0862, 0.0585], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,193][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0416, 0.0181, 0.0007, 0.1515, 0.0035, 0.0165, 0.0923, 0.0169, 0.0128,
        0.0365, 0.4327, 0.0666, 0.0022, 0.0908, 0.0172], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,198][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4545, 0.0019, 0.0027, 0.0069, 0.0181, 0.1034, 0.0619, 0.0155, 0.0081,
        0.0043, 0.0091, 0.0333, 0.0191, 0.2582, 0.0031], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,199][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1205, 0.0971, 0.1092, 0.0665, 0.0955, 0.0396, 0.0586, 0.0528, 0.0484,
        0.0488, 0.0634, 0.0517, 0.0711, 0.0396, 0.0371], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,199][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2846, 0.0344, 0.0158, 0.0125, 0.0071, 0.0124, 0.0141, 0.0042, 0.0095,
        0.0252, 0.0229, 0.0720, 0.0152, 0.0244, 0.4455], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,201][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0258, 0.0665, 0.0792, 0.1022, 0.0330, 0.0674, 0.0978, 0.0587, 0.0340,
        0.0876, 0.1016, 0.0438, 0.0314, 0.1060, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,204][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0175, 0.0725, 0.0862, 0.0611, 0.0769, 0.0689, 0.0605, 0.0663, 0.0881,
        0.0581, 0.0562, 0.0815, 0.0783, 0.0721, 0.0557], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,207][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.4917e-07, 1.9126e-05, 7.5236e-09, 1.1593e-03, 4.4740e-09, 3.4967e-07,
        2.3215e-06, 1.0025e-08, 1.0759e-08, 6.6585e-05, 1.7018e-03, 7.1434e-09,
        3.8167e-09, 8.8551e-08, 9.9705e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,210][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:28,213][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[27105],
        [11642],
        [ 2440],
        [14634],
        [23016],
        [14647],
        [17330],
        [12726],
        [23027],
        [15118],
        [16272],
        [32172],
        [32178],
        [18364],
        [11223]], device='cuda:0')
[2024-07-24 10:25:28,215][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[46707],
        [23083],
        [    1],
        [27080],
        [33417],
        [30108],
        [18838],
        [16867],
        [33993],
        [33327],
        [22559],
        [47804],
        [42272],
        [25508],
        [14504]], device='cuda:0')
[2024-07-24 10:25:28,218][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[31383],
        [32353],
        [30570],
        [32150],
        [32308],
        [21515],
        [21213],
        [25671],
        [27839],
        [29342],
        [30037],
        [30380],
        [31853],
        [31378],
        [30919]], device='cuda:0')
[2024-07-24 10:25:28,220][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[36319],
        [34849],
        [35197],
        [33051],
        [34136],
        [34151],
        [35479],
        [32911],
        [34239],
        [35433],
        [35477],
        [34896],
        [35009],
        [35359],
        [35574]], device='cuda:0')
[2024-07-24 10:25:28,222][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18534],
        [25091],
        [25727],
        [24010],
        [24262],
        [22658],
        [21633],
        [21123],
        [20879],
        [21510],
        [21672],
        [21769],
        [21785],
        [21624],
        [22042]], device='cuda:0')
[2024-07-24 10:25:28,223][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[6267],
        [5684],
        [4762],
        [4778],
        [4173],
        [3847],
        [3617],
        [3537],
        [3344],
        [3255],
        [3201],
        [3174],
        [3044],
        [2971],
        [2850]], device='cuda:0')
[2024-07-24 10:25:28,225][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[39713],
        [45664],
        [44707],
        [45994],
        [45696],
        [46260],
        [46499],
        [47005],
        [46765],
        [47186],
        [46869],
        [46842],
        [46918],
        [47160],
        [47161]], device='cuda:0')
[2024-07-24 10:25:28,227][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[36140],
        [36986],
        [41023],
        [39931],
        [43885],
        [41073],
        [41455],
        [42322],
        [42357],
        [35196],
        [36720],
        [40961],
        [39515],
        [40880],
        [30118]], device='cuda:0')
[2024-07-24 10:25:28,230][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[6788],
        [6784],
        [6749],
        [6718],
        [6532],
        [5729],
        [4790],
        [4069],
        [4027],
        [6266],
        [5855],
        [5619],
        [6194],
        [5577],
        [5965]], device='cuda:0')
[2024-07-24 10:25:28,233][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[9273],
        [9906],
        [8131],
        [ 289],
        [  36],
        [ 314],
        [1425],
        [8823],
        [5660],
        [ 311],
        [3162],
        [1840],
        [7105],
        [2126],
        [3053]], device='cuda:0')
[2024-07-24 10:25:28,235][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22791],
        [21523],
        [21549],
        [21265],
        [20859],
        [23464],
        [24806],
        [27217],
        [25750],
        [25806],
        [25267],
        [21805],
        [18037],
        [27858],
        [29182]], device='cuda:0')
[2024-07-24 10:25:28,238][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20909],
        [20813],
        [21503],
        [22119],
        [18227],
        [26509],
        [21372],
        [17205],
        [21268],
        [22382],
        [21662],
        [18322],
        [12997],
        [18661],
        [16489]], device='cuda:0')
[2024-07-24 10:25:28,240][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12933],
        [12059],
        [18897],
        [15100],
        [18454],
        [23603],
        [21715],
        [19655],
        [17497],
        [19227],
        [17720],
        [18117],
        [20268],
        [20403],
        [19518]], device='cuda:0')
[2024-07-24 10:25:28,243][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12113],
        [22404],
        [41011],
        [18931],
        [21247],
        [23696],
        [17606],
        [13693],
        [27781],
        [19777],
        [18880],
        [13908],
        [21843],
        [25846],
        [21397]], device='cuda:0')
[2024-07-24 10:25:28,244][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26727],
        [ 3131],
        [ 5515],
        [ 8319],
        [19294],
        [14195],
        [10725],
        [13167],
        [10735],
        [14707],
        [15803],
        [45411],
        [38268],
        [11860],
        [ 7506]], device='cuda:0')
[2024-07-24 10:25:28,246][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21338],
        [21913],
        [34010],
        [33987],
        [34988],
        [45333],
        [46276],
        [40359],
        [37197],
        [18243],
        [23377],
        [30243],
        [25035],
        [39645],
        [38021]], device='cuda:0')
[2024-07-24 10:25:28,247][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41747],
        [41529],
        [41827],
        [41922],
        [43923],
        [42629],
        [42089],
        [43799],
        [43803],
        [43961],
        [43869],
        [44122],
        [44674],
        [44456],
        [45104]], device='cuda:0')
[2024-07-24 10:25:28,250][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15155],
        [16461],
        [15718],
        [16303],
        [16241],
        [16281],
        [16665],
        [16991],
        [17212],
        [17400],
        [17549],
        [17301],
        [17129],
        [17364],
        [17342]], device='cuda:0')
[2024-07-24 10:25:28,252][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10279],
        [14595],
        [15289],
        [17584],
        [18306],
        [19051],
        [20378],
        [20715],
        [20777],
        [21476],
        [22117],
        [22075],
        [22206],
        [22202],
        [22276]], device='cuda:0')
[2024-07-24 10:25:28,255][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30577],
        [22659],
        [23418],
        [24375],
        [24133],
        [24361],
        [24889],
        [23495],
        [23325],
        [23276],
        [23601],
        [23489],
        [23721],
        [23870],
        [23878]], device='cuda:0')
[2024-07-24 10:25:28,258][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12512],
        [ 8076],
        [ 6535],
        [ 7969],
        [ 7787],
        [ 8199],
        [10359],
        [ 8794],
        [ 9269],
        [ 8941],
        [ 8386],
        [ 8027],
        [ 8334],
        [ 8428],
        [ 7963]], device='cuda:0')
[2024-07-24 10:25:28,260][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30977],
        [31402],
        [35452],
        [31244],
        [22350],
        [33110],
        [33596],
        [32260],
        [36100],
        [36026],
        [34483],
        [28959],
        [23576],
        [46274],
        [38489]], device='cuda:0')
[2024-07-24 10:25:28,263][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[14496],
        [15065],
        [15764],
        [15790],
        [15745],
        [15938],
        [15991],
        [16082],
        [16188],
        [16132],
        [15943],
        [15914],
        [15992],
        [15970],
        [16001]], device='cuda:0')
[2024-07-24 10:25:28,266][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19527],
        [19321],
        [19275],
        [19186],
        [18905],
        [18804],
        [18542],
        [18349],
        [18206],
        [18239],
        [18034],
        [16558],
        [17007],
        [16439],
        [13678]], device='cuda:0')
[2024-07-24 10:25:28,267][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[25392],
        [38478],
        [36978],
        [39282],
        [39404],
        [38570],
        [38629],
        [38388],
        [38361],
        [38762],
        [38984],
        [39255],
        [39374],
        [39014],
        [38998]], device='cuda:0')
[2024-07-24 10:25:28,268][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17231],
        [10130],
        [11504],
        [11077],
        [10981],
        [10862],
        [10523],
        [10614],
        [10860],
        [10725],
        [10662],
        [10768],
        [10792],
        [10897],
        [10899]], device='cuda:0')
[2024-07-24 10:25:28,270][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25216],
        [31415],
        [36365],
        [31699],
        [30514],
        [28096],
        [25081],
        [22035],
        [35759],
        [31674],
        [31842],
        [29839],
        [30654],
        [25764],
        [26262]], device='cuda:0')
[2024-07-24 10:25:28,273][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27876],
        [26076],
        [24502],
        [22342],
        [27405],
        [19684],
        [20112],
        [23355],
        [21244],
        [23395],
        [21996],
        [26132],
        [28910],
        [17618],
        [19550]], device='cuda:0')
[2024-07-24 10:25:28,275][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4881],
        [47379],
        [50082],
        [43402],
        [34954],
        [31876],
        [42939],
        [32765],
        [40533],
        [34764],
        [32378],
        [ 4024],
        [17449],
        [37324],
        [45455]], device='cuda:0')
[2024-07-24 10:25:28,278][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082],
        [15082]], device='cuda:0')
[2024-07-24 10:25:28,309][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:28,309][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,310][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,310][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,310][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,311][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,311][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,311][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,312][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,312][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,312][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,312][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,313][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,313][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2881, 0.7119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,313][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7933, 0.2067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,314][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([2.5606e-05, 9.9997e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,314][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4064, 0.5936], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,314][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9788, 0.0212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,315][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,315][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3185, 0.6815], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,315][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5948, 0.4052], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,316][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6881, 0.3119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,318][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,318][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8115, 0.1885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,318][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5508, 0.4492], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,319][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.1313, 0.3549, 0.5138], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,319][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.0117, 0.1608, 0.8274], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,319][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([2.9584e-08, 7.7498e-01, 2.2502e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,322][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.0677, 0.1857, 0.7466], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,326][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.8802, 0.0258, 0.0941], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,327][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.0007, 0.4326, 0.5667], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,327][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.0771, 0.1628, 0.7601], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,327][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.3363, 0.3600, 0.3037], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,328][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.4454, 0.5310, 0.0237], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,328][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([8.8515e-05, 4.6414e-01, 5.3578e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,328][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.0389, 0.3989, 0.5622], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,328][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.3450, 0.3087, 0.3464], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,329][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1004, 0.2464, 0.4032, 0.2500], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,329][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1523, 0.1610, 0.6777, 0.0089], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,329][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.4974e-08, 3.4184e-02, 2.5622e-01, 7.0960e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,330][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0259, 0.0887, 0.8785, 0.0069], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,331][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8920, 0.0181, 0.0495, 0.0404], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,333][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.5531e-04, 6.6299e-02, 2.4113e-01, 6.9221e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,336][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0578, 0.1509, 0.5839, 0.2073], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,340][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3136, 0.2102, 0.3389, 0.1373], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,343][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3693, 0.3730, 0.1619, 0.0958], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,345][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.0129e-05, 3.2735e-02, 3.7338e-01, 5.9386e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,347][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2975, 0.1907, 0.2938, 0.2180], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,347][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2366, 0.2458, 0.2454, 0.2722], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,348][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0699, 0.1827, 0.2636, 0.1786, 0.3052], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,348][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0177, 0.1065, 0.8063, 0.0035, 0.0659], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,348][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([2.6636e-09, 9.6360e-03, 2.9870e-02, 8.1584e-01, 1.4465e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,349][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0308, 0.0916, 0.5221, 0.0221, 0.3334], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,349][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.8216, 0.0139, 0.0607, 0.0443, 0.0596], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,349][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([6.1484e-05, 1.3188e-02, 7.1831e-02, 4.9297e-01, 4.2195e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,349][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0279, 0.0725, 0.2950, 0.0866, 0.5179], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,351][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.2285, 0.2736, 0.1996, 0.1379, 0.1605], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,354][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.3097, 0.2903, 0.1239, 0.2381, 0.0381], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,356][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([4.9660e-06, 1.4134e-02, 1.2968e-01, 5.4189e-01, 3.1428e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,360][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0180, 0.2210, 0.3316, 0.1502, 0.2792], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,364][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.1920, 0.1794, 0.2332, 0.2298, 0.1657], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,367][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0521, 0.1312, 0.2192, 0.1401, 0.2499, 0.2076], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,367][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0424, 0.0326, 0.0692, 0.0091, 0.0385, 0.8082], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,367][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([9.3493e-11, 1.4274e-03, 5.3820e-03, 1.6215e-01, 1.7657e-01, 6.5448e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,368][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0334, 0.0951, 0.4974, 0.0204, 0.3334, 0.0203], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,368][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.8813, 0.0089, 0.0310, 0.0307, 0.0324, 0.0158], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,368][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.7145e-05, 4.6618e-03, 1.9998e-02, 1.3587e-01, 6.3809e-01, 2.0136e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,369][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0223, 0.0660, 0.2294, 0.0797, 0.4369, 0.1656], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,369][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1574, 0.1712, 0.1786, 0.1005, 0.1757, 0.2167], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,369][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2577, 0.4498, 0.0764, 0.0906, 0.0396, 0.0859], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,370][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.8913e-06, 3.9700e-03, 2.5747e-02, 1.2762e-01, 5.1393e-01, 3.2874e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,373][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0967, 0.1278, 0.2312, 0.1006, 0.2832, 0.1605], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,376][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1616, 0.1822, 0.1789, 0.1780, 0.1637, 0.1357], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,380][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0401, 0.1074, 0.1768, 0.1150, 0.2093, 0.1771, 0.1744],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,384][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0143, 0.0155, 0.1417, 0.0097, 0.0894, 0.7274, 0.0020],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,387][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.0414e-11, 3.2580e-05, 9.9472e-05, 1.1261e-02, 7.6902e-03, 8.3188e-01,
        1.4904e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,387][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0191, 0.0650, 0.4896, 0.0073, 0.3382, 0.0198, 0.0610],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,387][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8219, 0.0127, 0.0322, 0.0367, 0.0345, 0.0238, 0.0382],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,388][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.0225e-05, 2.3862e-03, 1.2753e-02, 8.2072e-02, 2.3667e-01, 3.4192e-01,
        3.2418e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,388][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0180, 0.0565, 0.1889, 0.0786, 0.3947, 0.1767, 0.0867],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,388][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1431, 0.1258, 0.1651, 0.0783, 0.1587, 0.1858, 0.1433],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,388][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1613, 0.1992, 0.0808, 0.1326, 0.0541, 0.3565, 0.0156],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,389][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.2660e-06, 1.6632e-03, 1.2832e-02, 4.5196e-02, 1.8648e-01, 3.7988e-01,
        3.7395e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,389][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1367, 0.1022, 0.1646, 0.1152, 0.1995, 0.1440, 0.1378],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,389][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1474, 0.1402, 0.1448, 0.1853, 0.1354, 0.1427, 0.1042],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,391][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0323, 0.0847, 0.1320, 0.0919, 0.1652, 0.1419, 0.1443, 0.2076],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,393][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.3214, 0.0773, 0.0848, 0.0506, 0.0404, 0.3363, 0.0122, 0.0769],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,395][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([1.0298e-12, 9.7927e-07, 8.4502e-06, 1.3051e-04, 7.8858e-04, 3.0915e-02,
        1.1901e-01, 8.4914e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,399][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0193, 0.0871, 0.3361, 0.0261, 0.2779, 0.0249, 0.1682, 0.0605],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,403][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.7839, 0.0108, 0.0309, 0.0323, 0.0377, 0.0216, 0.0359, 0.0468],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,405][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([1.9553e-06, 3.5541e-04, 2.2039e-03, 1.6247e-02, 5.6075e-02, 1.0405e-01,
        2.7156e-01, 5.4950e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,407][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0182, 0.0526, 0.1810, 0.0646, 0.3404, 0.1326, 0.0693, 0.1412],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,407][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1365, 0.1521, 0.1354, 0.0713, 0.1042, 0.1342, 0.1027, 0.1636],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,408][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1386, 0.2749, 0.0389, 0.0834, 0.0449, 0.3593, 0.0442, 0.0157],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,408][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.9088e-07, 1.4632e-04, 1.2160e-03, 5.8375e-03, 2.3205e-02, 6.7740e-02,
        1.6466e-01, 7.3719e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,408][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0578, 0.1240, 0.1478, 0.1028, 0.1658, 0.1256, 0.1047, 0.1714],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,409][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1297, 0.1349, 0.1182, 0.1580, 0.1049, 0.1273, 0.0952, 0.1318],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,409][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0238, 0.0601, 0.0937, 0.0659, 0.1178, 0.1160, 0.1142, 0.1725, 0.2359],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,409][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0027, 0.0026, 0.1386, 0.0006, 0.0450, 0.3538, 0.0006, 0.0141, 0.4420],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,410][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.3046e-14, 1.5032e-07, 1.2184e-06, 2.4408e-05, 4.9314e-05, 1.8837e-03,
        7.7227e-03, 6.0307e-01, 3.8725e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,410][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0103, 0.0502, 0.2371, 0.0161, 0.1656, 0.0186, 0.1034, 0.0421, 0.3567],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,412][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.7589, 0.0104, 0.0343, 0.0322, 0.0366, 0.0215, 0.0391, 0.0496, 0.0174],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,414][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.1434e-06, 1.4421e-04, 4.3563e-04, 4.9824e-03, 1.4481e-02, 2.1889e-02,
        7.7383e-02, 4.7900e-01, 4.0169e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,417][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0170, 0.0479, 0.1483, 0.0560, 0.2732, 0.1067, 0.0574, 0.1139, 0.1797],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,421][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0968, 0.1153, 0.1054, 0.0584, 0.0884, 0.1199, 0.0911, 0.1367, 0.1880],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,425][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0870, 0.1865, 0.1430, 0.0810, 0.0203, 0.3686, 0.0686, 0.0270, 0.0179],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,427][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([4.1051e-08, 6.3861e-05, 5.3871e-04, 2.2587e-03, 1.1838e-02, 2.0544e-02,
        3.7203e-02, 6.8095e-01, 2.4660e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,428][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0671, 0.0978, 0.1231, 0.0823, 0.1495, 0.1170, 0.0963, 0.1505, 0.1166],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,428][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0991, 0.0977, 0.0917, 0.1308, 0.0887, 0.1108, 0.0896, 0.1474, 0.1442],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,428][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0218, 0.0571, 0.0926, 0.0600, 0.1080, 0.0959, 0.0928, 0.1504, 0.2184,
        0.1031], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,429][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0241, 0.0072, 0.0350, 0.0020, 0.0346, 0.3613, 0.0025, 0.0829, 0.4487,
        0.0017], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,429][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.7812e-12, 3.5716e-08, 2.8991e-06, 6.8504e-05, 9.6985e-05, 2.2417e-03,
        6.7158e-03, 3.3249e-01, 4.9078e-01, 1.6761e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,429][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0125, 0.0094, 0.1482, 0.0034, 0.1289, 0.0195, 0.0642, 0.0499, 0.4876,
        0.0764], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,430][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6017, 0.0175, 0.0363, 0.0393, 0.0440, 0.0303, 0.0459, 0.0619, 0.0325,
        0.0908], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,431][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([4.1384e-07, 6.1248e-06, 7.2391e-05, 8.7801e-04, 1.5659e-03, 4.2327e-03,
        1.7032e-02, 5.7010e-02, 1.4755e-01, 7.7165e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,434][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0125, 0.0391, 0.1169, 0.0540, 0.2479, 0.1158, 0.0569, 0.1114, 0.1833,
        0.0622], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,437][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0870, 0.0658, 0.0971, 0.0475, 0.0955, 0.1221, 0.0798, 0.1366, 0.2139,
        0.0546], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,441][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2002, 0.0789, 0.0625, 0.0801, 0.0281, 0.2635, 0.0698, 0.0555, 0.1377,
        0.0238], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,443][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.9182e-08, 4.3341e-06, 1.9319e-04, 5.1200e-04, 2.2673e-03, 4.3251e-03,
        1.8224e-02, 8.7367e-02, 2.5695e-01, 6.3016e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,447][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1845, 0.0648, 0.0734, 0.0889, 0.0974, 0.1043, 0.0892, 0.1324, 0.0847,
        0.0805], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,448][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0969, 0.0867, 0.0927, 0.1242, 0.0757, 0.0885, 0.0725, 0.1059, 0.1387,
        0.1182], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,448][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0210, 0.0549, 0.0901, 0.0574, 0.1039, 0.0890, 0.0853, 0.1374, 0.2010,
        0.0951, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,448][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.4814e-03, 8.0559e-03, 1.6002e-02, 5.2774e-04, 1.5664e-02, 2.0040e-01,
        7.9886e-04, 2.0378e-02, 7.2631e-01, 1.9797e-03, 4.0436e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,449][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([7.2094e-12, 6.1451e-08, 1.7014e-06, 1.8805e-06, 4.1896e-05, 2.7920e-04,
        1.5449e-03, 4.0760e-02, 1.3076e-01, 3.8149e-01, 4.4511e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,449][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0071, 0.0145, 0.1882, 0.0008, 0.1253, 0.0110, 0.0392, 0.0314, 0.4426,
        0.1275, 0.0124], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,449][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5169, 0.0190, 0.0349, 0.0364, 0.0430, 0.0284, 0.0396, 0.0538, 0.0326,
        0.0784, 0.1172], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,450][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.4284e-07, 1.9236e-06, 1.6148e-05, 2.6125e-05, 2.5184e-04, 6.3451e-04,
        3.7192e-03, 8.8905e-03, 3.1274e-02, 3.8660e-01, 5.6859e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,450][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0118, 0.0359, 0.1119, 0.0518, 0.2330, 0.1105, 0.0555, 0.1060, 0.1696,
        0.0604, 0.0536], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,450][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0809, 0.0676, 0.1014, 0.0437, 0.0901, 0.1151, 0.0763, 0.1236, 0.2059,
        0.0523, 0.0432], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,452][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1245, 0.1409, 0.0709, 0.0341, 0.0261, 0.2785, 0.0778, 0.0692, 0.1026,
        0.0590, 0.0164], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,453][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.1672e-08, 1.8718e-06, 3.9058e-05, 3.6764e-05, 4.4952e-04, 1.0765e-03,
        3.1770e-03, 1.8540e-02, 4.6966e-02, 2.8541e-01, 6.4430e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,456][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2150, 0.0526, 0.0661, 0.0657, 0.0888, 0.0959, 0.0868, 0.1039, 0.0759,
        0.0648, 0.0845], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,460][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0837, 0.0894, 0.0826, 0.0926, 0.0727, 0.0887, 0.0693, 0.0854, 0.1293,
        0.1157, 0.0905], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,464][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0181, 0.0481, 0.0729, 0.0515, 0.0877, 0.0819, 0.0787, 0.1219, 0.1717,
        0.0908, 0.0611, 0.1155], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,468][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0082, 0.0331, 0.1795, 0.0333, 0.0194, 0.4547, 0.0022, 0.0441, 0.1394,
        0.0119, 0.0417, 0.0323], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,468][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([2.6915e-12, 1.8368e-08, 4.9117e-08, 3.1458e-06, 2.9731e-06, 5.4192e-05,
        7.2884e-04, 3.8364e-03, 5.4383e-02, 9.3416e-02, 6.0248e-01, 2.4509e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,469][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0075, 0.0214, 0.1116, 0.0038, 0.0735, 0.0089, 0.0492, 0.0179, 0.2185,
        0.1856, 0.0431, 0.2588], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,469][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.4772, 0.0128, 0.0381, 0.0348, 0.0434, 0.0257, 0.0405, 0.0467, 0.0228,
        0.0741, 0.1272, 0.0566], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,469][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([4.4277e-08, 8.2083e-07, 5.3427e-06, 2.8586e-05, 1.1992e-04, 1.7649e-04,
        7.2524e-04, 2.2362e-03, 7.8956e-03, 1.3017e-01, 6.1649e-01, 2.4216e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,470][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0110, 0.0316, 0.1024, 0.0424, 0.1988, 0.0812, 0.0441, 0.0874, 0.1338,
        0.0479, 0.0412, 0.1783], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,470][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0867, 0.1038, 0.0859, 0.0501, 0.0666, 0.0998, 0.0692, 0.1131, 0.1481,
        0.0582, 0.0428, 0.0757], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,470][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1027, 0.1544, 0.0310, 0.0713, 0.0226, 0.3478, 0.0216, 0.0394, 0.1157,
        0.0441, 0.0387, 0.0108], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,471][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([2.9571e-09, 9.4850e-07, 7.0586e-06, 2.5486e-05, 8.7441e-05, 2.4561e-04,
        8.5662e-04, 5.6372e-03, 1.3407e-02, 1.0863e-01, 4.5594e-01, 4.1516e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,474][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0230, 0.1038, 0.0967, 0.0690, 0.1092, 0.0950, 0.0685, 0.1150, 0.1136,
        0.0747, 0.0629, 0.0685], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,477][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0645, 0.0715, 0.0735, 0.0770, 0.0657, 0.0760, 0.0529, 0.0938, 0.1141,
        0.0998, 0.0777, 0.1334], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,481][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0161, 0.0427, 0.0639, 0.0438, 0.0753, 0.0744, 0.0730, 0.1163, 0.1648,
        0.0840, 0.0540, 0.1056, 0.0862], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,483][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([1.0812e-03, 9.0379e-03, 7.1004e-02, 2.2349e-04, 5.5064e-03, 4.7523e-01,
        1.3441e-04, 4.2799e-03, 3.6106e-01, 1.7588e-03, 2.5490e-04, 6.3405e-02,
        7.0293e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,485][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([1.4253e-12, 9.8884e-09, 1.1051e-07, 1.0506e-06, 2.0540e-07, 8.5630e-06,
        6.6219e-05, 2.2717e-03, 7.6512e-03, 2.1535e-02, 1.2835e-01, 8.0420e-01,
        3.5915e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,488][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0042, 0.0084, 0.0407, 0.0018, 0.0270, 0.0043, 0.0286, 0.0106, 0.1217,
        0.0946, 0.0247, 0.2051, 0.4283], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,488][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.5325, 0.0090, 0.0336, 0.0264, 0.0343, 0.0175, 0.0320, 0.0340, 0.0153,
        0.0609, 0.1131, 0.0498, 0.0415], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,489][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([2.2578e-08, 3.6745e-07, 2.7255e-06, 1.2452e-05, 1.2632e-05, 9.7855e-05,
        3.3349e-04, 1.6990e-03, 3.7557e-03, 4.5584e-02, 2.1146e-01, 5.0321e-01,
        2.3384e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,489][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0093, 0.0259, 0.0890, 0.0332, 0.1601, 0.0649, 0.0372, 0.0711, 0.1096,
        0.0402, 0.0341, 0.1531, 0.1724], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,490][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0754, 0.1126, 0.0700, 0.0531, 0.0547, 0.1033, 0.0707, 0.1026, 0.1322,
        0.0531, 0.0440, 0.0725, 0.0558], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,490][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.1085, 0.0998, 0.0439, 0.0868, 0.0130, 0.2299, 0.0363, 0.0481, 0.1207,
        0.0359, 0.0468, 0.1184, 0.0120], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,490][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([2.9188e-09, 4.7318e-07, 7.7524e-06, 1.6225e-05, 1.3999e-05, 1.7735e-04,
        3.5202e-04, 1.9465e-03, 5.7241e-03, 4.5254e-02, 2.2628e-01, 4.4013e-01,
        2.8010e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,491][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0092, 0.0868, 0.1194, 0.0562, 0.1048, 0.0900, 0.0569, 0.1076, 0.1014,
        0.0454, 0.0424, 0.0765, 0.1034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,491][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0647, 0.0606, 0.0762, 0.0776, 0.0545, 0.0804, 0.0529, 0.0785, 0.1011,
        0.0874, 0.0796, 0.1259, 0.0607], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,493][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0149, 0.0386, 0.0625, 0.0423, 0.0742, 0.0659, 0.0654, 0.0980, 0.1456,
        0.0739, 0.0515, 0.1023, 0.0874, 0.0774], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,495][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([9.3738e-04, 9.1316e-03, 4.5699e-02, 3.1013e-04, 3.8919e-02, 9.5763e-02,
        4.0438e-05, 1.1474e-02, 1.9135e-01, 9.0037e-04, 2.1806e-04, 1.4457e-01,
        2.7974e-02, 4.3272e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,497][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([4.3258e-14, 5.8769e-10, 2.6102e-09, 1.0166e-07, 1.0051e-07, 8.2533e-06,
        1.2832e-05, 1.9484e-04, 2.8630e-03, 9.7686e-03, 5.8589e-02, 3.0386e-01,
        7.5182e-02, 5.4952e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,500][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0031, 0.0145, 0.0463, 0.0031, 0.0366, 0.0023, 0.0186, 0.0080, 0.1043,
        0.1135, 0.0272, 0.1488, 0.4267, 0.0471], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,504][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.5308, 0.0095, 0.0289, 0.0267, 0.0294, 0.0189, 0.0336, 0.0369, 0.0134,
        0.0621, 0.1111, 0.0449, 0.0333, 0.0205], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,506][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([2.2292e-08, 3.9130e-07, 1.0395e-06, 8.6740e-06, 1.4985e-05, 2.2085e-05,
        1.8197e-04, 8.7282e-04, 7.1794e-04, 5.0595e-02, 2.0513e-01, 1.5447e-01,
        4.1548e-01, 1.7250e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,509][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0069, 0.0231, 0.0694, 0.0303, 0.1442, 0.0628, 0.0339, 0.0646, 0.1041,
        0.0365, 0.0322, 0.1410, 0.1679, 0.0830], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,509][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0620, 0.0700, 0.0739, 0.0375, 0.0607, 0.0815, 0.0583, 0.0935, 0.1341,
        0.0462, 0.0346, 0.0748, 0.0627, 0.1102], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,509][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0900, 0.2491, 0.0851, 0.0651, 0.0259, 0.0946, 0.0247, 0.0506, 0.0597,
        0.0840, 0.0349, 0.0671, 0.0219, 0.0471], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,510][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.3103e-09, 1.8508e-07, 3.3331e-06, 6.3891e-06, 1.9028e-05, 2.4416e-05,
        1.1591e-04, 6.1014e-04, 2.1233e-03, 3.3630e-02, 1.2373e-01, 2.0596e-01,
        4.4642e-01, 1.8736e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,510][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1099, 0.0523, 0.0685, 0.0421, 0.0848, 0.0604, 0.0705, 0.1130, 0.0718,
        0.0532, 0.0543, 0.0631, 0.0938, 0.0623], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,510][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0576, 0.0592, 0.0664, 0.0591, 0.0572, 0.0597, 0.0510, 0.0906, 0.0960,
        0.0826, 0.0626, 0.1346, 0.0647, 0.0587], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,511][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0166, 0.0396, 0.0661, 0.0433, 0.0735, 0.0645, 0.0628, 0.0959, 0.1333,
        0.0680, 0.0479, 0.0955, 0.0798, 0.0712, 0.0421], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,511][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0115, 0.0173, 0.0171, 0.0037, 0.0178, 0.1265, 0.0030, 0.0169, 0.4585,
        0.0092, 0.0033, 0.2175, 0.0159, 0.0784, 0.0034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,512][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.0634e-13, 4.0964e-11, 2.1901e-10, 7.2458e-09, 9.0402e-09, 5.7095e-07,
        8.3490e-07, 2.9043e-05, 2.7061e-04, 3.2660e-04, 2.3048e-03, 9.4848e-03,
        3.7678e-03, 2.6902e-01, 7.1479e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,515][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0036, 0.0063, 0.0360, 0.0009, 0.0289, 0.0028, 0.0112, 0.0086, 0.0893,
        0.0530, 0.0083, 0.1461, 0.4212, 0.0606, 0.1232], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,518][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5551, 0.0103, 0.0227, 0.0257, 0.0259, 0.0155, 0.0284, 0.0349, 0.0162,
        0.0541, 0.0951, 0.0411, 0.0342, 0.0208, 0.0199], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,520][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.0490e-08, 4.9357e-08, 1.9680e-07, 1.3961e-06, 2.4736e-06, 6.2902e-06,
        2.1844e-05, 9.6399e-05, 1.7218e-04, 5.4810e-03, 3.0164e-02, 3.7641e-02,
        7.6618e-02, 1.3527e-01, 7.1452e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,524][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0061, 0.0208, 0.0593, 0.0308, 0.1258, 0.0681, 0.0347, 0.0615, 0.0963,
        0.0388, 0.0339, 0.1336, 0.1492, 0.0827, 0.0584], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,528][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0624, 0.0529, 0.0684, 0.0334, 0.0587, 0.0806, 0.0540, 0.0843, 0.1168,
        0.0398, 0.0315, 0.0823, 0.0614, 0.1256, 0.0478], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,529][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0276, 0.0483, 0.0389, 0.0324, 0.0280, 0.1846, 0.0143, 0.0095, 0.0419,
        0.0214, 0.0198, 0.0283, 0.0238, 0.4800, 0.0011], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,529][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.4093e-10, 3.2497e-08, 4.1849e-07, 6.5018e-07, 4.0218e-06, 3.3115e-06,
        1.7645e-05, 1.3948e-04, 2.9620e-04, 3.4847e-03, 1.2417e-02, 4.9207e-02,
        8.8944e-02, 1.6475e-01, 6.8074e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,530][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2098, 0.0428, 0.0363, 0.0551, 0.0512, 0.0599, 0.0604, 0.0684, 0.0450,
        0.0651, 0.0783, 0.0387, 0.0566, 0.0675, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,530][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0519, 0.0618, 0.0521, 0.0786, 0.0499, 0.0608, 0.0476, 0.0635, 0.0802,
        0.0863, 0.0811, 0.0918, 0.0558, 0.0668, 0.0717], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,548][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:28,550][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,550][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,551][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,552][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,556][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,559][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,562][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,567][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,568][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,569][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,569][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,569][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,569][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2564, 0.7436], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,570][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5934, 0.4066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,570][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.0000e+00, 6.0526e-10], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,570][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,571][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7934, 0.2066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,571][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,572][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0536, 0.9464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,575][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5187, 0.4813], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,579][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3329, 0.6671], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,582][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1439, 0.8561], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,586][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3288, 0.6712], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,588][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,589][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.1191, 0.3864, 0.4945], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,589][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.0062, 0.1879, 0.8059], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,589][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([1.0000e+00, 1.5938e-15, 6.1422e-08], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,589][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.0017, 0.2555, 0.7428], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,590][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.2856, 0.6224, 0.0920], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,590][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.0007, 0.4326, 0.5667], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,590][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.0087, 0.1497, 0.8416], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,591][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.2939, 0.2730, 0.4331], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,592][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.1775, 0.6887, 0.1338], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,594][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.0818, 0.6201, 0.2981], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,597][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.2344, 0.3428, 0.4229], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,601][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.0198, 0.5207, 0.4595], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,605][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0876, 0.2483, 0.3617, 0.3024], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,608][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0781, 0.1899, 0.7239, 0.0082], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,608][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9768e-01, 5.5829e-08, 1.0365e-04, 2.2193e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,608][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0006, 0.0470, 0.4644, 0.4880], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,609][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0629, 0.5486, 0.3503, 0.0383], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,609][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.5531e-04, 6.6299e-02, 2.4113e-01, 6.9221e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,609][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0048, 0.0832, 0.5575, 0.3546], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,610][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2104, 0.1963, 0.3204, 0.2729], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,610][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1048, 0.3392, 0.2633, 0.2927], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,610][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0441, 0.2648, 0.1734, 0.5177], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,610][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1693, 0.2548, 0.2983, 0.2776], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,611][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0200, 0.4054, 0.3268, 0.2478], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,612][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0600, 0.1829, 0.2434, 0.2348, 0.2789], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,615][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0076, 0.1255, 0.8160, 0.0040, 0.0470], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,617][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([9.9601e-01, 8.9295e-13, 3.3457e-04, 8.3126e-05, 3.5743e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,620][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([1.0081e-04, 1.4501e-02, 1.1379e-01, 3.6152e-01, 5.1009e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,624][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.1019, 0.6283, 0.0528, 0.2085, 0.0085], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,626][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([6.1484e-05, 1.3188e-02, 7.1831e-02, 4.9297e-01, 4.2195e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,628][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0021, 0.0452, 0.1840, 0.2116, 0.5570], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,628][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1597, 0.1500, 0.2410, 0.2045, 0.2448], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,629][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0792, 0.2712, 0.1551, 0.3695, 0.1250], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,629][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0318, 0.2041, 0.0961, 0.5049, 0.1632], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,629][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.1159, 0.1796, 0.2109, 0.2064, 0.2872], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,630][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0136, 0.2564, 0.2109, 0.2112, 0.3079], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,630][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0398, 0.1260, 0.1993, 0.1694, 0.2176, 0.2478], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,630][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0278, 0.0493, 0.1079, 0.0113, 0.0369, 0.7668], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,631][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([8.9104e-01, 6.9582e-13, 9.4745e-04, 2.0071e-04, 1.0781e-01, 1.0655e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,632][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([9.1808e-05, 9.7389e-03, 6.1271e-02, 1.7040e-01, 5.6932e-01, 1.8918e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,634][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3948, 0.1814, 0.0017, 0.4000, 0.0009, 0.0211], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,635][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.7145e-05, 4.6618e-03, 1.9998e-02, 1.3587e-01, 6.3809e-01, 2.0136e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,639][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0017, 0.0355, 0.1843, 0.1358, 0.4850, 0.1576], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,643][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1257, 0.1173, 0.1857, 0.1597, 0.1899, 0.2217], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,646][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0738, 0.2625, 0.1092, 0.1985, 0.1132, 0.2428], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,648][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0214, 0.1295, 0.0799, 0.2658, 0.1393, 0.3641], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,648][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1282, 0.2336, 0.0869, 0.0979, 0.1297, 0.3237], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,649][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0106, 0.2178, 0.1704, 0.1216, 0.2578, 0.2217], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,649][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0317, 0.0985, 0.1453, 0.1269, 0.1662, 0.2044, 0.2269],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,649][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0094, 0.0227, 0.2277, 0.0122, 0.0855, 0.6410, 0.0015],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,650][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.9435e-01, 3.5582e-10, 9.3106e-05, 7.3987e-04, 3.6752e-03, 9.6390e-06,
        1.1289e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,650][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.8976e-05, 3.1405e-03, 3.8431e-02, 7.7443e-02, 4.1551e-01, 1.6018e-01,
        3.0524e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,650][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3015, 0.1993, 0.0133, 0.3476, 0.0234, 0.0832, 0.0317],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,651][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.0225e-05, 2.3862e-03, 1.2753e-02, 8.2072e-02, 2.3667e-01, 3.4192e-01,
        3.2418e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,651][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0012, 0.0231, 0.1213, 0.0956, 0.3802, 0.1214, 0.2571],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,653][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1033, 0.0959, 0.1506, 0.1305, 0.1540, 0.1795, 0.1861],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,655][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0380, 0.1314, 0.0892, 0.1755, 0.1052, 0.3858, 0.0750],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,659][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0153, 0.0957, 0.0633, 0.1846, 0.1115, 0.2824, 0.2472],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,663][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0994, 0.1684, 0.0854, 0.0847, 0.1215, 0.1942, 0.2464],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,667][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0107, 0.1577, 0.1325, 0.1061, 0.1972, 0.1676, 0.2281],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,668][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0243, 0.0766, 0.1139, 0.1019, 0.1370, 0.1620, 0.1863, 0.1980],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,669][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.2132, 0.1187, 0.1501, 0.0640, 0.0470, 0.3027, 0.0123, 0.0921],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,669][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([6.0435e-01, 2.8674e-15, 3.2550e-05, 1.4489e-05, 5.0645e-03, 7.1825e-08,
        7.2116e-05, 3.9047e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,669][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([5.4085e-06, 3.5379e-04, 4.5021e-03, 1.2683e-02, 8.0194e-02, 3.6283e-02,
        4.5292e-01, 4.1306e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,670][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1726, 0.1914, 0.0278, 0.2724, 0.0007, 0.0860, 0.2456, 0.0036],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,670][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([1.9553e-06, 3.5541e-04, 2.2039e-03, 1.6247e-02, 5.6075e-02, 1.0405e-01,
        2.7156e-01, 5.4950e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,670][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0012, 0.0174, 0.0705, 0.0508, 0.1687, 0.0729, 0.1471, 0.4715],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,671][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0838, 0.0779, 0.1235, 0.1062, 0.1262, 0.1468, 0.1520, 0.1836],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,672][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0305, 0.1366, 0.0455, 0.1372, 0.0775, 0.3619, 0.1158, 0.0950],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,675][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0146, 0.0750, 0.0423, 0.1656, 0.0705, 0.2569, 0.2579, 0.1171],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,678][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0730, 0.1327, 0.0749, 0.0802, 0.1100, 0.1494, 0.2200, 0.1598],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,682][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0096, 0.1123, 0.0806, 0.0688, 0.1330, 0.1020, 0.1401, 0.3536],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,686][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0167, 0.0527, 0.0773, 0.0763, 0.0932, 0.1393, 0.1586, 0.1678, 0.2180],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,690][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0023, 0.0043, 0.2074, 0.0009, 0.0465, 0.2961, 0.0006, 0.0186, 0.4234],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,690][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([4.9055e-01, 2.5267e-16, 5.1849e-06, 2.0323e-06, 1.9880e-04, 2.0784e-09,
        4.8618e-06, 4.2786e-02, 4.6645e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,691][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.5626e-06, 2.7644e-04, 2.5316e-03, 7.7842e-03, 3.2096e-02, 3.8375e-02,
        1.4180e-01, 4.6531e-01, 3.1182e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,691][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0608, 0.1543, 0.0973, 0.2260, 0.0702, 0.2099, 0.1607, 0.0173, 0.0035],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,691][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.1434e-06, 1.4421e-04, 4.3563e-04, 4.9824e-03, 1.4481e-02, 2.1889e-02,
        7.7383e-02, 4.7900e-01, 4.0169e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,692][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0010, 0.0080, 0.0462, 0.0298, 0.1153, 0.0366, 0.0963, 0.3496, 0.3173],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,692][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0704, 0.0659, 0.1051, 0.0900, 0.1072, 0.1241, 0.1283, 0.1552, 0.1538],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,692][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0231, 0.0980, 0.0761, 0.1137, 0.0505, 0.3225, 0.1151, 0.1033, 0.0977],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,693][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0099, 0.0624, 0.0303, 0.1552, 0.0524, 0.2327, 0.2775, 0.1058, 0.0739],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,696][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0520, 0.0871, 0.0789, 0.0736, 0.1169, 0.1054, 0.1310, 0.1105, 0.2448],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,700][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0064, 0.0866, 0.0501, 0.0610, 0.0777, 0.0836, 0.1265, 0.2538, 0.2544],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,706][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0168, 0.0499, 0.0718, 0.0664, 0.0810, 0.1132, 0.1260, 0.1406, 0.1743,
        0.1600], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,708][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0177, 0.0127, 0.0706, 0.0027, 0.0382, 0.3813, 0.0020, 0.1146, 0.3574,
        0.0029], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,709][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.1527e-01, 7.7976e-09, 7.0809e-06, 8.5182e-04, 1.0256e-04, 2.3061e-06,
        3.7017e-04, 2.2665e-04, 1.1497e-03, 8.2024e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,709][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.0130e-06, 3.3242e-05, 9.0535e-04, 2.1075e-03, 1.0686e-02, 1.0220e-02,
        5.5784e-02, 1.5158e-01, 1.6657e-01, 6.0211e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,709][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2122, 0.0592, 0.2164, 0.1137, 0.0398, 0.0211, 0.2537, 0.0118, 0.0212,
        0.0508], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,710][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.1384e-07, 6.1248e-06, 7.2391e-05, 8.7801e-04, 1.5659e-03, 4.2327e-03,
        1.7032e-02, 5.7010e-02, 1.4755e-01, 7.7165e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,710][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0005, 0.0056, 0.0397, 0.0298, 0.1070, 0.0396, 0.0728, 0.2934, 0.2806,
        0.1309], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,710][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0595, 0.0561, 0.0924, 0.0780, 0.0961, 0.1115, 0.1152, 0.1423, 0.1419,
        0.1071], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,711][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0300, 0.0658, 0.0642, 0.0930, 0.0596, 0.2185, 0.0978, 0.1149, 0.1634,
        0.0928], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,711][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0092, 0.0530, 0.0366, 0.1042, 0.0637, 0.1544, 0.1487, 0.0982, 0.0971,
        0.2349], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,711][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0310, 0.0578, 0.0483, 0.0518, 0.0717, 0.1058, 0.1198, 0.0997, 0.2943,
        0.1198], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,712][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0059, 0.0612, 0.0519, 0.0429, 0.0684, 0.0614, 0.0871, 0.2089, 0.2021,
        0.2101], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,717][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0150, 0.0467, 0.0691, 0.0605, 0.0778, 0.0992, 0.1067, 0.1237, 0.1558,
        0.1407, 0.1049], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,721][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.8254e-03, 1.9072e-02, 3.8033e-02, 8.6344e-04, 2.0642e-02, 2.4865e-01,
        7.8205e-04, 3.5042e-02, 6.2228e-01, 4.2348e-03, 5.8070e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,723][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([7.9207e-01, 1.5684e-07, 1.8696e-05, 9.6276e-04, 1.2341e-04, 3.8430e-06,
        3.3260e-04, 8.4465e-05, 5.5629e-04, 4.1528e-02, 1.6432e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,727][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.2474e-06, 1.3954e-05, 2.7492e-04, 1.6291e-04, 2.9932e-03, 1.9156e-03,
        1.3121e-02, 3.0613e-02, 4.7041e-02, 2.4690e-01, 6.5696e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,727][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0230, 0.3313, 0.2202, 0.0231, 0.0107, 0.0064, 0.1276, 0.0015, 0.0010,
        0.2430, 0.0122], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,728][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.4284e-07, 1.9236e-06, 1.6148e-05, 2.6125e-05, 2.5184e-04, 6.3451e-04,
        3.7192e-03, 8.8905e-03, 3.1274e-02, 3.8660e-01, 5.6859e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,728][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0006, 0.0050, 0.0296, 0.0175, 0.0815, 0.0285, 0.0493, 0.1821, 0.1841,
        0.0934, 0.3284], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,728][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0526, 0.0494, 0.0828, 0.0695, 0.0864, 0.1005, 0.1037, 0.1287, 0.1289,
        0.0963, 0.1012], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,729][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0208, 0.0716, 0.0609, 0.0576, 0.0499, 0.2008, 0.0996, 0.1158, 0.1425,
        0.1204, 0.0601], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,729][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0076, 0.0443, 0.0333, 0.0812, 0.0586, 0.1215, 0.1067, 0.0821, 0.0889,
        0.1813, 0.1945], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,729][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0287, 0.0522, 0.0539, 0.0565, 0.0794, 0.0877, 0.1043, 0.0859, 0.2225,
        0.0908, 0.1380], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,730][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0066, 0.0645, 0.0445, 0.0301, 0.0660, 0.0566, 0.0716, 0.1683, 0.1672,
        0.2019, 0.1226], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:28,733][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0136, 0.0400, 0.0561, 0.0534, 0.0670, 0.0895, 0.0952, 0.1096, 0.1431,
        0.1240, 0.0952, 0.1133], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,738][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0070, 0.0505, 0.2743, 0.0444, 0.0201, 0.3573, 0.0019, 0.0415, 0.1127,
        0.0165, 0.0485, 0.0253], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,741][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([1.2961e-03, 7.5238e-13, 7.9404e-08, 2.1023e-07, 3.5542e-07, 2.3572e-10,
        1.5453e-07, 1.9218e-06, 3.9970e-05, 4.7291e-04, 2.0551e-03, 9.9613e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,744][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([3.6105e-07, 7.8341e-06, 6.8138e-05, 1.1495e-04, 6.0847e-04, 7.9800e-04,
        4.3470e-03, 7.4892e-03, 1.5069e-02, 1.3046e-01, 4.5732e-01, 3.8372e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,745][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([9.4792e-03, 9.2670e-02, 7.7122e-04, 9.0178e-02, 1.9966e-04, 8.0153e-02,
        7.5038e-03, 5.5432e-01, 3.1190e-04, 1.1267e-01, 4.8477e-02, 3.2640e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,746][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([4.4277e-08, 8.2083e-07, 5.3427e-06, 2.8586e-05, 1.1992e-04, 1.7649e-04,
        7.2524e-04, 2.2362e-03, 7.8956e-03, 1.3017e-01, 6.1649e-01, 2.4216e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,746][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0004, 0.0030, 0.0166, 0.0134, 0.0575, 0.0211, 0.0397, 0.1117, 0.1227,
        0.0709, 0.2334, 0.3095], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,746][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0498, 0.0465, 0.0738, 0.0632, 0.0747, 0.0880, 0.0911, 0.1102, 0.1091,
        0.0842, 0.0887, 0.1207], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,747][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0169, 0.0660, 0.0324, 0.0771, 0.0391, 0.2348, 0.0577, 0.0914, 0.1285,
        0.1020, 0.0855, 0.0689], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,747][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0057, 0.0320, 0.0191, 0.0748, 0.0337, 0.1133, 0.1146, 0.0561, 0.0504,
        0.1827, 0.2269, 0.0907], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,748][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0320, 0.0516, 0.0448, 0.0449, 0.0638, 0.0706, 0.0862, 0.0670, 0.1545,
        0.0628, 0.0883, 0.2335], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,748][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0063, 0.0594, 0.0356, 0.0294, 0.0553, 0.0507, 0.0643, 0.1525, 0.1539,
        0.1862, 0.1123, 0.0940], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:28,748][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0105, 0.0330, 0.0454, 0.0447, 0.0535, 0.0873, 0.0909, 0.1045, 0.1398,
        0.1210, 0.0899, 0.1079, 0.0715], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,749][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([6.2969e-04, 1.4239e-02, 1.0100e-01, 3.4225e-04, 5.4542e-03, 5.0637e-01,
        1.4486e-04, 4.6429e-03, 3.0948e-01, 2.9838e-03, 3.7590e-04, 4.7949e-02,
        6.3922e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,752][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([1.6287e-08, 4.6779e-25, 1.0094e-17, 8.8648e-16, 5.2952e-17, 3.7014e-22,
        7.0622e-17, 1.5355e-17, 9.1493e-15, 7.8185e-11, 2.1412e-09, 1.3207e-04,
        9.9987e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,756][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([1.0624e-07, 1.9616e-06, 1.8405e-05, 3.9672e-05, 7.3132e-05, 2.5236e-04,
        1.2887e-03, 3.9118e-03, 5.1424e-03, 4.8625e-02, 1.7614e-01, 4.2318e-01,
        3.4133e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,760][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0398, 0.2229, 0.0151, 0.0835, 0.0031, 0.0137, 0.2282, 0.0057, 0.0367,
        0.2473, 0.0466, 0.0539, 0.0034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,764][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([2.2578e-08, 3.6745e-07, 2.7255e-06, 1.2452e-05, 1.2632e-05, 9.7855e-05,
        3.3349e-04, 1.6990e-03, 3.7557e-03, 4.5584e-02, 2.1146e-01, 5.0321e-01,
        2.3384e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,764][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([1.6729e-04, 2.1896e-03, 7.8910e-03, 9.3341e-03, 2.1063e-02, 1.4514e-02,
        1.7187e-02, 5.2113e-02, 5.4774e-02, 5.3467e-02, 1.5128e-01, 2.4993e-01,
        3.6609e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,764][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0442, 0.0418, 0.0667, 0.0567, 0.0669, 0.0792, 0.0820, 0.0994, 0.0982,
        0.0757, 0.0798, 0.1090, 0.1005], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,765][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0151, 0.0539, 0.0298, 0.0731, 0.0245, 0.1867, 0.0689, 0.0816, 0.1210,
        0.0856, 0.0795, 0.1490, 0.0311], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,765][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0037, 0.0244, 0.0124, 0.0698, 0.0221, 0.1096, 0.1156, 0.0459, 0.0357,
        0.1845, 0.2614, 0.0815, 0.0333], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,766][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0222, 0.0399, 0.0345, 0.0356, 0.0524, 0.0570, 0.0752, 0.0562, 0.1252,
        0.0450, 0.0712, 0.1999, 0.1858], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,766][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0035, 0.0350, 0.0263, 0.0246, 0.0352, 0.0435, 0.0508, 0.1204, 0.1041,
        0.1272, 0.1020, 0.0721, 0.2552], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:28,766][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0106, 0.0326, 0.0493, 0.0440, 0.0550, 0.0731, 0.0809, 0.0879, 0.1163,
        0.1061, 0.0822, 0.1007, 0.0760, 0.0852], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,767][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([8.8096e-04, 1.7380e-02, 7.9966e-02, 4.5021e-04, 4.1714e-02, 1.0520e-01,
        3.5697e-05, 1.5387e-02, 1.8354e-01, 1.6886e-03, 2.9520e-04, 1.5060e-01,
        2.7385e-02, 3.7548e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,770][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([3.3659e-04, 8.6728e-14, 5.9519e-10, 6.4989e-09, 7.5217e-10, 3.6410e-13,
        8.5838e-10, 1.7638e-10, 2.1425e-09, 2.4216e-06, 2.2828e-05, 2.6382e-03,
        9.9597e-01, 1.0252e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,772][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.4614e-07, 1.6710e-06, 9.5116e-06, 3.4782e-05, 9.5683e-05, 2.6879e-05,
        3.9384e-04, 1.6145e-03, 2.6180e-03, 3.0823e-02, 1.6124e-01, 2.2383e-01,
        4.2406e-01, 1.5525e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,776][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([5.3260e-01, 8.0184e-02, 3.2626e-03, 7.3229e-02, 1.1105e-02, 4.5943e-02,
        3.4038e-02, 3.9588e-02, 4.1943e-04, 5.6569e-02, 5.1383e-02, 6.2263e-02,
        9.0311e-03, 3.9156e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,778][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([2.2292e-08, 3.9130e-07, 1.0395e-06, 8.6740e-06, 1.4985e-05, 2.2085e-05,
        1.8197e-04, 8.7282e-04, 7.1794e-04, 5.0595e-02, 2.0513e-01, 1.5447e-01,
        4.1548e-01, 1.7250e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,782][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([1.6502e-04, 1.1149e-03, 6.6571e-03, 4.5983e-03, 1.6823e-02, 6.9167e-03,
        1.4205e-02, 4.6010e-02, 4.2556e-02, 2.6387e-02, 9.8199e-02, 2.0899e-01,
        3.8432e-01, 1.4306e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,782][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0372, 0.0342, 0.0548, 0.0470, 0.0552, 0.0646, 0.0670, 0.0806, 0.0802,
        0.0617, 0.0652, 0.0886, 0.0822, 0.1816], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,783][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0181, 0.0740, 0.0437, 0.0630, 0.0382, 0.1071, 0.0457, 0.0774, 0.0923,
        0.1010, 0.0641, 0.1104, 0.0452, 0.1199], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,783][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0049, 0.0283, 0.0176, 0.0656, 0.0312, 0.0916, 0.0960, 0.0518, 0.0435,
        0.1468, 0.1907, 0.0930, 0.0476, 0.0914], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,783][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0210, 0.0353, 0.0212, 0.0206, 0.0318, 0.0503, 0.0635, 0.0484, 0.1232,
        0.0350, 0.0560, 0.1831, 0.1693, 0.1413], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,784][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0056, 0.0463, 0.0253, 0.0205, 0.0341, 0.0347, 0.0436, 0.1039, 0.0869,
        0.1228, 0.0729, 0.0757, 0.2095, 0.1183], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:28,784][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0120, 0.0326, 0.0488, 0.0447, 0.0540, 0.0717, 0.0780, 0.0861, 0.1002,
        0.0954, 0.0748, 0.0931, 0.0708, 0.0776, 0.0603], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,785][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0095, 0.0354, 0.0447, 0.0051, 0.0247, 0.1342, 0.0025, 0.0258, 0.3804,
        0.0170, 0.0038, 0.2408, 0.0191, 0.0526, 0.0043], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,786][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.3553e-02, 4.4289e-10, 5.1483e-08, 6.9864e-06, 1.3033e-07, 1.8918e-09,
        7.8561e-07, 4.1640e-08, 4.2190e-07, 5.4353e-04, 3.5478e-03, 2.9109e-02,
        7.6769e-01, 1.0155e-01, 2.4001e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,788][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.7337e-08, 3.5094e-07, 4.1336e-06, 4.6266e-06, 3.2527e-05, 9.9053e-06,
        1.3967e-04, 3.1291e-04, 4.9339e-04, 5.5243e-03, 1.9105e-02, 4.6809e-02,
        1.6114e-01, 3.3533e-01, 4.3110e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,794][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0407, 0.0578, 0.0191, 0.1099, 0.0877, 0.0895, 0.0473, 0.0299, 0.1826,
        0.0898, 0.0838, 0.0209, 0.1025, 0.0261, 0.0123], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,796][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.0490e-08, 4.9357e-08, 1.9680e-07, 1.3961e-06, 2.4736e-06, 6.2902e-06,
        2.1844e-05, 9.6399e-05, 1.7218e-04, 5.4810e-03, 3.0164e-02, 3.7641e-02,
        7.6618e-02, 1.3527e-01, 7.1452e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,800][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.9531e-04, 1.4571e-03, 7.3866e-03, 4.4148e-03, 1.8133e-02, 6.0818e-03,
        1.3639e-02, 3.3057e-02, 4.0475e-02, 2.4386e-02, 6.8566e-02, 1.1688e-01,
        2.9053e-01, 1.6730e-01, 2.0750e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,800][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0343, 0.0313, 0.0492, 0.0428, 0.0501, 0.0589, 0.0609, 0.0732, 0.0720,
        0.0565, 0.0596, 0.0799, 0.0736, 0.1592, 0.0984], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,801][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0096, 0.0438, 0.0361, 0.0529, 0.0434, 0.1266, 0.0401, 0.0471, 0.0778,
        0.0678, 0.0568, 0.0792, 0.0489, 0.2403, 0.0298], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,801][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0049, 0.0268, 0.0196, 0.0544, 0.0356, 0.0835, 0.0739, 0.0497, 0.0516,
        0.1202, 0.1301, 0.0839, 0.0526, 0.0907, 0.1225], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,802][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0251, 0.0453, 0.0209, 0.0228, 0.0302, 0.0518, 0.0718, 0.0468, 0.1094,
        0.0513, 0.0663, 0.1522, 0.1358, 0.1165, 0.0538], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,802][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0056, 0.0326, 0.0203, 0.0179, 0.0285, 0.0271, 0.0345, 0.0791, 0.0674,
        0.0887, 0.0656, 0.0604, 0.1807, 0.1109, 0.1808], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:28,803][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:28,804][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21208],
        [11527],
        [  387],
        [ 5594],
        [ 6130],
        [ 6686],
        [ 3610],
        [ 3933],
        [ 9139],
        [ 8956],
        [ 9458],
        [19856],
        [11435],
        [ 8845],
        [ 5605]], device='cuda:0')
[2024-07-24 10:25:28,805][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[26369],
        [ 7182],
        [ 1697],
        [14693],
        [26610],
        [16609],
        [14747],
        [ 8919],
        [21453],
        [13318],
        [11792],
        [29176],
        [30999],
        [17292],
        [ 9157]], device='cuda:0')
[2024-07-24 10:25:28,808][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11368],
        [12112],
        [12480],
        [13351],
        [13169],
        [12671],
        [13014],
        [13088],
        [13123],
        [13444],
        [13641],
        [13741],
        [13500],
        [13504],
        [13612]], device='cuda:0')
[2024-07-24 10:25:28,810][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35956],
        [37068],
        [   26],
        [   41],
        [   24],
        [14568],
        [ 7542],
        [19095],
        [ 4511],
        [10788],
        [11033],
        [ 4439],
        [ 9093],
        [13520],
        [13494]], device='cuda:0')
[2024-07-24 10:25:28,813][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[48651],
        [48717],
        [48432],
        [40160],
        [35463],
        [25390],
        [26166],
        [15395],
        [21104],
        [35060],
        [47147],
        [38747],
        [17053],
        [37401],
        [44993]], device='cuda:0')
[2024-07-24 10:25:28,815][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[27213],
        [24520],
        [ 9632],
        [ 7931],
        [ 6179],
        [ 6221],
        [ 5726],
        [ 6197],
        [ 5613],
        [ 5617],
        [ 5870],
        [ 7202],
        [ 4770],
        [ 4730],
        [ 4844]], device='cuda:0')
[2024-07-24 10:25:28,818][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[9841],
        [9261],
        [8063],
        [8391],
        [8528],
        [8695],
        [8448],
        [8937],
        [8955],
        [9872],
        [9997],
        [9544],
        [9176],
        [8912],
        [8692]], device='cuda:0')
[2024-07-24 10:25:28,820][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23247],
        [25018],
        [23394],
        [27006],
        [20025],
        [17164],
        [27923],
        [20558],
        [21475],
        [35225],
        [28411],
        [22997],
        [17023],
        [17068],
        [27431]], device='cuda:0')
[2024-07-24 10:25:28,823][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17459],
        [20740],
        [23917],
        [24512],
        [27854],
        [27566],
        [27450],
        [27238],
        [27329],
        [27343],
        [27317],
        [26658],
        [27241],
        [27274],
        [26726]], device='cuda:0')
[2024-07-24 10:25:28,824][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[14670],
        [14519],
        [17876],
        [16952],
        [15071],
        [16638],
        [16798],
        [16201],
        [17236],
        [17211],
        [16785],
        [15601],
        [15218],
        [16299],
        [16356]], device='cuda:0')
[2024-07-24 10:25:28,825][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[47583],
        [47921],
        [47747],
        [46454],
        [46215],
        [46015],
        [40544],
        [42094],
        [39627],
        [42560],
        [42532],
        [40216],
        [42911],
        [44584],
        [33597]], device='cuda:0')
[2024-07-24 10:25:28,825][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 6021],
        [ 5688],
        [28464],
        [18740],
        [13599],
        [13051],
        [ 5486],
        [ 8012],
        [12558],
        [ 7843],
        [ 5926],
        [ 7760],
        [11205],
        [11098],
        [11508]], device='cuda:0')
[2024-07-24 10:25:28,826][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25374],
        [24544],
        [ 7035],
        [23039],
        [12296],
        [12571],
        [17931],
        [18702],
        [18898],
        [24275],
        [27912],
        [22638],
        [16558],
        [18517],
        [27008]], device='cuda:0')
[2024-07-24 10:25:28,828][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39293],
        [39115],
        [38918],
        [39668],
        [37948],
        [35450],
        [33992],
        [32315],
        [31408],
        [31986],
        [32744],
        [32634],
        [32474],
        [31027],
        [31918]], device='cuda:0')
[2024-07-24 10:25:28,830][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18819],
        [23820],
        [13298],
        [28877],
        [11612],
        [32025],
        [16655],
        [28287],
        [30485],
        [31201],
        [33253],
        [42994],
        [14440],
        [26305],
        [30480]], device='cuda:0')
[2024-07-24 10:25:28,833][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29323],
        [32239],
        [32026],
        [33141],
        [33830],
        [33800],
        [34067],
        [33423],
        [32753],
        [32986],
        [33257],
        [33400],
        [33595],
        [33335],
        [33086]], device='cuda:0')
[2024-07-24 10:25:28,835][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13183],
        [15493],
        [36942],
        [37571],
        [35205],
        [39029],
        [44412],
        [36403],
        [38333],
        [34161],
        [24253],
        [43622],
        [39364],
        [25154],
        [28585]], device='cuda:0')
[2024-07-24 10:25:28,838][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[44600],
        [44600],
        [44600],
        [44615],
        [44683],
        [46331],
        [44701],
        [43516],
        [38014],
        [44975],
        [45375],
        [34073],
        [33977],
        [34068],
        [38212]], device='cuda:0')
[2024-07-24 10:25:28,840][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[27070],
        [14747],
        [22384],
        [21468],
        [21670],
        [20261],
        [17822],
        [18279],
        [21043],
        [16659],
        [16452],
        [14917],
        [19078],
        [21756],
        [23172]], device='cuda:0')
[2024-07-24 10:25:28,843][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16665],
        [13494],
        [12953],
        [14219],
        [16307],
        [11114],
        [11256],
        [14508],
        [13524],
        [11957],
        [18537],
        [ 7059],
        [19497],
        [11741],
        [11328]], device='cuda:0')
[2024-07-24 10:25:28,845][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28041],
        [23175],
        [22262],
        [21344],
        [20838],
        [18467],
        [19815],
        [29949],
        [27417],
        [21490],
        [22500],
        [35069],
        [31637],
        [20428],
        [21977]], device='cuda:0')
[2024-07-24 10:25:28,846][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27548],
        [18832],
        [ 6807],
        [ 6713],
        [ 7993],
        [ 6840],
        [ 5871],
        [ 4445],
        [ 5191],
        [ 6237],
        [ 6864],
        [ 9213],
        [ 7704],
        [ 8110],
        [ 7606]], device='cuda:0')
[2024-07-24 10:25:28,847][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12114],
        [11348],
        [11037],
        [10872],
        [10864],
        [10856],
        [10831],
        [10741],
        [10709],
        [10717],
        [10683],
        [10693],
        [10710],
        [10507],
        [10461]], device='cuda:0')
[2024-07-24 10:25:28,848][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26946],
        [21305],
        [21237],
        [23284],
        [22253],
        [24779],
        [27161],
        [27778],
        [27606],
        [25652],
        [25200],
        [25041],
        [24761],
        [23666],
        [23280]], device='cuda:0')
[2024-07-24 10:25:28,849][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37129],
        [36485],
        [36631],
        [36142],
        [36000],
        [35890],
        [35446],
        [35069],
        [34675],
        [34091],
        [33597],
        [33114],
        [33004],
        [33459],
        [32502]], device='cuda:0')
[2024-07-24 10:25:28,850][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15631],
        [19480],
        [15940],
        [15627],
        [13354],
        [15748],
        [15899],
        [16436],
        [11947],
        [13143],
        [14700],
        [13077],
        [11797],
        [11316],
        [12938]], device='cuda:0')
[2024-07-24 10:25:28,852][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[30524],
        [29057],
        [35020],
        [34705],
        [36852],
        [36222],
        [35065],
        [35789],
        [33548],
        [33711],
        [32902],
        [33491],
        [34657],
        [34440],
        [32926]], device='cuda:0')
[2024-07-24 10:25:28,855][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[16644],
        [20374],
        [18457],
        [17815],
        [18628],
        [18922],
        [19241],
        [18700],
        [20127],
        [19862],
        [19321],
        [19669],
        [19267],
        [24676],
        [22708]], device='cuda:0')
[2024-07-24 10:25:28,857][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17237],
        [22541],
        [31955],
        [18962],
        [25086],
        [ 8224],
        [10580],
        [ 7971],
        [14091],
        [15010],
        [23395],
        [ 4835],
        [13620],
        [12589],
        [14889]], device='cuda:0')
[2024-07-24 10:25:28,860][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795],
        [19795]], device='cuda:0')
[2024-07-24 10:25:28,878][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:28,879][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,880][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,880][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,880][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,881][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,881][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,881][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,882][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,882][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,882][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,882][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,883][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:28,883][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,883][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6759, 0.3241], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,884][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3127, 0.6873], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,884][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,884][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6770, 0.3230], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,885][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7941, 0.2059], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,885][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2621, 0.7379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,885][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2604, 0.7396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,886][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0422, 0.9578], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,886][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4434, 0.5566], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,886][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4736, 0.5264], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,887][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8402, 0.1598], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:28,887][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.9823, 0.0029, 0.0148], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,887][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.5583, 0.2991, 0.1425], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,888][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.1905, 0.4802, 0.3293], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,888][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([9.5419e-04, 5.0229e-03, 9.9402e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,888][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.5152, 0.2475, 0.2373], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,889][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.4140, 0.2463, 0.3397], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,890][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.1127, 0.4506, 0.4367], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,890][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([7.0756e-02, 4.4727e-04, 9.2880e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,890][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([2.7540e-04, 6.0131e-09, 9.9972e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,891][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.2915, 0.3133, 0.3952], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,891][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.3012, 0.3187, 0.3800], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,891][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.6697, 0.0060, 0.3243], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:28,892][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9643, 0.0063, 0.0059, 0.0235], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,892][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4646, 0.2048, 0.1638, 0.1668], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,892][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1366, 0.3403, 0.3021, 0.2210], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,892][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.0978e-05, 4.4698e-03, 9.9194e-01, 3.5017e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,893][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3782, 0.1949, 0.2113, 0.2157], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,894][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4526, 0.1326, 0.2528, 0.1620], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,896][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0771, 0.2841, 0.5428, 0.0960], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,898][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.6177e-04, 4.1601e-05, 9.9795e-01, 1.8437e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,900][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([2.2107e-08, 1.1865e-09, 9.9999e-01, 5.7112e-06], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,904][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2101, 0.2252, 0.2786, 0.2860], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,908][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2281, 0.2523, 0.2921, 0.2274], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,909][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0665, 0.0063, 0.8990, 0.0283], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:28,909][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.9792, 0.0024, 0.0028, 0.0068, 0.0089], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,910][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.3256, 0.1970, 0.1204, 0.2010, 0.1561], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,910][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.1199, 0.2760, 0.2246, 0.2115, 0.1679], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,910][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([2.9230e-04, 3.9309e-03, 8.3722e-01, 6.1252e-03, 1.5243e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,911][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.3167, 0.1672, 0.2091, 0.1790, 0.1280], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,911][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.2378, 0.1285, 0.1779, 0.1594, 0.2964], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,911][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0596, 0.2532, 0.3486, 0.1147, 0.2239], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,912][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([7.0028e-03, 6.9077e-05, 8.9457e-01, 1.0934e-03, 9.7261e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,913][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([1.2415e-04, 9.5303e-10, 3.5053e-01, 2.9290e-06, 6.4935e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,916][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.1594, 0.1748, 0.2191, 0.2291, 0.2176], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,919][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.1844, 0.1930, 0.2264, 0.1833, 0.2128], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,922][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.2507, 0.0041, 0.5372, 0.0190, 0.1889], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:28,925][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.3165e-01, 5.3197e-03, 2.2635e-03, 1.6674e-02, 8.8547e-04, 4.3204e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,929][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.3240, 0.1182, 0.0862, 0.1831, 0.1543, 0.1341], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,929][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1081, 0.2041, 0.2057, 0.1751, 0.1718, 0.1352], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,929][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([7.0034e-05, 5.0118e-03, 8.7454e-01, 4.2555e-03, 1.1082e-01, 5.3022e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,930][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2550, 0.1331, 0.1577, 0.1499, 0.1405, 0.1638], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,930][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1978, 0.0891, 0.1534, 0.1136, 0.2766, 0.1694], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,931][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0545, 0.2051, 0.3199, 0.0714, 0.3014, 0.0476], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,931][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([5.4339e-04, 9.0175e-05, 7.0858e-01, 3.0510e-03, 2.8550e-01, 2.2330e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,931][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([1.4121e-06, 9.7999e-10, 2.8721e-01, 2.7653e-06, 7.1237e-01, 4.1490e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,932][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1322, 0.1393, 0.1796, 0.1836, 0.1771, 0.1882], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,933][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1493, 0.1753, 0.1956, 0.1540, 0.1918, 0.1339], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,936][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0828, 0.0086, 0.6002, 0.0404, 0.2360, 0.0319], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:28,940][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.9118, 0.0039, 0.0047, 0.0122, 0.0017, 0.0095, 0.0563],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,944][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2090, 0.1110, 0.1121, 0.1361, 0.1774, 0.1579, 0.0965],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,947][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0788, 0.1886, 0.1562, 0.1548, 0.1546, 0.1423, 0.1247],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,949][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.0837e-05, 2.7868e-03, 9.1526e-01, 1.8367e-03, 7.7393e-02, 2.2294e-03,
        4.8496e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,949][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2279, 0.1177, 0.1310, 0.1304, 0.1179, 0.1492, 0.1259],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,949][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1959, 0.0763, 0.1382, 0.0868, 0.2313, 0.1403, 0.1312],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,950][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0604, 0.2464, 0.2294, 0.1040, 0.2184, 0.0761, 0.0653],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,950][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([7.4388e-04, 1.2306e-04, 6.4434e-01, 3.0406e-03, 3.4530e-01, 4.1504e-03,
        2.3059e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,950][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([3.0172e-06, 9.7729e-10, 2.6111e-01, 2.6287e-06, 7.3713e-01, 5.8881e-04,
        1.1634e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,951][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1142, 0.1168, 0.1502, 0.1523, 0.1500, 0.1596, 0.1569],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,951][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1319, 0.1517, 0.1692, 0.1361, 0.1651, 0.1191, 0.1270],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,952][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0840, 0.0068, 0.6009, 0.0311, 0.2139, 0.0323, 0.0310],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:28,953][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.3199e-01, 3.2685e-03, 1.6828e-03, 1.1334e-02, 7.7195e-04, 8.5650e-03,
        2.2428e-02, 1.9958e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,955][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1962, 0.1229, 0.0828, 0.1361, 0.1464, 0.1577, 0.0954, 0.0627],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,958][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0901, 0.1626, 0.1108, 0.1302, 0.1080, 0.1268, 0.1698, 0.1016],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,960][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([2.7496e-05, 4.4458e-03, 8.5965e-01, 4.6563e-03, 1.2290e-01, 5.9959e-03,
        1.6843e-03, 6.4275e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,964][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2104, 0.1015, 0.1207, 0.1178, 0.1171, 0.1340, 0.1159, 0.0826],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,969][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1566, 0.0616, 0.1029, 0.0999, 0.2179, 0.1453, 0.1642, 0.0517],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,969][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0563, 0.1922, 0.1681, 0.0872, 0.1863, 0.0512, 0.0912, 0.1674],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,969][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([1.9676e-03, 8.2029e-05, 6.5838e-01, 1.9548e-03, 3.2184e-01, 3.1640e-03,
        2.9508e-03, 9.6642e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,970][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([2.8391e-05, 5.6711e-10, 2.5180e-01, 1.5327e-06, 6.3163e-01, 5.2105e-04,
        1.2601e-03, 1.1475e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,970][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0926, 0.1018, 0.1307, 0.1348, 0.1309, 0.1388, 0.1370, 0.1334],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,971][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1194, 0.1373, 0.1540, 0.1229, 0.1479, 0.1078, 0.1146, 0.0962],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,971][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1630, 0.0048, 0.5153, 0.0174, 0.1448, 0.0191, 0.0423, 0.0933],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:28,971][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.9498, 0.0027, 0.0031, 0.0086, 0.0010, 0.0056, 0.0146, 0.0033, 0.0112],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,972][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1614, 0.1158, 0.0635, 0.1196, 0.1295, 0.1569, 0.0919, 0.0736, 0.0878],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,973][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0583, 0.1440, 0.1382, 0.1172, 0.1126, 0.1153, 0.1518, 0.1101, 0.0525],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,975][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([2.2832e-05, 6.1370e-03, 8.4746e-01, 6.4780e-03, 1.2804e-01, 7.7031e-03,
        2.2020e-03, 9.9899e-04, 9.5681e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,978][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2023, 0.0929, 0.1076, 0.1127, 0.1068, 0.1312, 0.1056, 0.0829, 0.0580],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,982][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1416, 0.0548, 0.1077, 0.0939, 0.2067, 0.1350, 0.1384, 0.0484, 0.0736],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,987][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0358, 0.1664, 0.2070, 0.0677, 0.1798, 0.0486, 0.0780, 0.1896, 0.0270],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,989][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([4.0192e-03, 6.7222e-05, 6.3102e-01, 9.4925e-04, 3.0630e-01, 2.5602e-03,
        2.1211e-03, 2.5973e-02, 2.6990e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,990][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([6.2748e-06, 4.5104e-10, 2.1198e-01, 1.4125e-06, 5.9430e-01, 4.3928e-04,
        1.1022e-03, 1.5741e-01, 3.4769e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,990][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0771, 0.0886, 0.1148, 0.1220, 0.1153, 0.1243, 0.1250, 0.1202, 0.1127],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,990][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1092, 0.1226, 0.1374, 0.1116, 0.1304, 0.1010, 0.1058, 0.0875, 0.0945],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,991][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.2004, 0.0038, 0.3253, 0.0133, 0.0888, 0.0225, 0.0372, 0.2216, 0.0870],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:28,991][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8708, 0.0065, 0.0054, 0.0214, 0.0022, 0.0104, 0.0299, 0.0104, 0.0051,
        0.0379], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,992][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2011, 0.0690, 0.0652, 0.0987, 0.1084, 0.1255, 0.0750, 0.0548, 0.0971,
        0.1052], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,992][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0554, 0.1224, 0.1130, 0.1063, 0.1090, 0.0981, 0.1316, 0.1070, 0.0698,
        0.0873], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,993][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.0818e-05, 2.7891e-03, 8.8654e-01, 2.0586e-03, 1.0161e-01, 3.1337e-03,
        7.3673e-04, 5.1022e-04, 3.6778e-04, 2.2273e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,996][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1765, 0.0864, 0.0984, 0.1030, 0.0905, 0.1146, 0.0978, 0.0752, 0.0586,
        0.0990], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:28,999][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1836, 0.0508, 0.1015, 0.0743, 0.1707, 0.1167, 0.1144, 0.0518, 0.0761,
        0.0601], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,003][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0303, 0.1190, 0.2360, 0.0574, 0.1741, 0.0429, 0.0765, 0.1614, 0.0302,
        0.0722], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,005][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.5600e-04, 1.6273e-05, 6.3104e-01, 6.1604e-04, 2.1212e-01, 2.3050e-03,
        1.4598e-03, 2.0972e-02, 6.9792e-02, 6.0718e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,007][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([2.5654e-06, 1.2116e-10, 2.2641e-01, 7.2299e-07, 5.3473e-01, 3.6841e-04,
        1.1587e-03, 1.6397e-01, 5.1856e-02, 2.1503e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,010][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0771, 0.0882, 0.1001, 0.1057, 0.1002, 0.1079, 0.1063, 0.1038, 0.0945,
        0.1163], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,010][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1009, 0.1166, 0.1295, 0.1029, 0.1255, 0.0894, 0.0939, 0.0795, 0.0870,
        0.0748], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,010][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0746, 0.0014, 0.4320, 0.0100, 0.1699, 0.0125, 0.0231, 0.1030, 0.1023,
        0.0712], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,011][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8403, 0.0058, 0.0050, 0.0223, 0.0020, 0.0104, 0.0298, 0.0076, 0.0043,
        0.0405, 0.0319], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,011][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1897, 0.0792, 0.0663, 0.0675, 0.1031, 0.1073, 0.0601, 0.0525, 0.0835,
        0.1075, 0.0834], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,012][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0511, 0.1245, 0.1095, 0.0812, 0.1037, 0.0936, 0.1175, 0.0992, 0.0681,
        0.0922, 0.0594], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,012][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([6.0374e-06, 2.7779e-03, 9.0612e-01, 1.9310e-03, 8.2511e-02, 2.5372e-03,
        6.3057e-04, 3.0931e-04, 2.7193e-04, 2.7288e-03, 1.7400e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,012][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1707, 0.0837, 0.0912, 0.0957, 0.0752, 0.1061, 0.0873, 0.0648, 0.0522,
        0.0933, 0.0798], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,014][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1885, 0.0500, 0.0887, 0.0664, 0.1519, 0.1040, 0.1127, 0.0491, 0.0665,
        0.0602, 0.0620], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,017][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0260, 0.1252, 0.2077, 0.0408, 0.1654, 0.0444, 0.0745, 0.1668, 0.0284,
        0.0863, 0.0346], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,019][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([5.0785e-04, 9.9583e-06, 5.8413e-01, 3.8131e-04, 2.1652e-01, 1.5825e-03,
        8.1118e-04, 1.7182e-02, 6.3132e-02, 7.5530e-02, 4.0213e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,021][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([6.4404e-06, 8.6951e-11, 2.1506e-01, 3.3931e-07, 5.3610e-01, 2.6725e-04,
        7.7936e-04, 1.1736e-01, 3.1894e-02, 1.5536e-02, 8.2989e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,026][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0719, 0.0771, 0.0908, 0.0936, 0.0889, 0.0972, 0.0949, 0.0932, 0.0870,
        0.1000, 0.1053], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,030][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0947, 0.1091, 0.1212, 0.0952, 0.1177, 0.0822, 0.0866, 0.0733, 0.0800,
        0.0686, 0.0714], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,030][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0549, 0.0013, 0.4042, 0.0053, 0.1669, 0.0137, 0.0190, 0.0900, 0.1122,
        0.0889, 0.0437], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,031][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([9.6011e-01, 1.5091e-03, 1.0999e-03, 4.8255e-03, 8.0428e-04, 2.5415e-03,
        7.0431e-03, 2.6821e-03, 1.0121e-03, 9.9137e-03, 6.1227e-03, 2.3380e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,031][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.1536, 0.0728, 0.0425, 0.0829, 0.0776, 0.1059, 0.0551, 0.0576, 0.0617,
        0.1086, 0.1082, 0.0736], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,032][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0433, 0.1161, 0.0975, 0.0978, 0.0790, 0.0845, 0.1237, 0.0841, 0.0467,
        0.0841, 0.0717, 0.0714], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,032][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([2.2233e-04, 4.2815e-03, 8.1024e-01, 5.6504e-03, 1.2642e-01, 5.9585e-03,
        1.0936e-03, 7.0818e-04, 6.8047e-04, 6.3035e-03, 6.2444e-04, 3.7820e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,032][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1579, 0.0753, 0.0906, 0.0895, 0.0784, 0.0958, 0.0864, 0.0687, 0.0528,
        0.0844, 0.0729, 0.0472], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,033][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0946, 0.0519, 0.0803, 0.0802, 0.1567, 0.1338, 0.1124, 0.0417, 0.0582,
        0.0596, 0.0730, 0.0576], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,035][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0221, 0.1319, 0.1421, 0.0593, 0.1249, 0.0569, 0.0618, 0.1668, 0.0259,
        0.0859, 0.0543, 0.0679], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,037][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([5.5331e-03, 2.6635e-05, 5.8453e-01, 5.8444e-04, 1.1317e-01, 1.8501e-03,
        1.7602e-03, 1.4293e-02, 4.5739e-02, 6.0829e-02, 3.6683e-02, 1.3500e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,039][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([7.1012e-06, 8.5150e-14, 2.0215e-04, 2.4631e-10, 5.0369e-04, 2.2221e-07,
        5.1002e-07, 6.3172e-05, 1.8049e-05, 6.1338e-06, 3.2819e-05, 9.9917e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,042][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0599, 0.0690, 0.0838, 0.0882, 0.0819, 0.0905, 0.0887, 0.0864, 0.0796,
        0.0918, 0.0979, 0.0822], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,046][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0887, 0.0977, 0.1107, 0.0886, 0.1044, 0.0796, 0.0826, 0.0676, 0.0732,
        0.0660, 0.0687, 0.0722], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,050][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1575, 0.0014, 0.2564, 0.0051, 0.0772, 0.0093, 0.0144, 0.1100, 0.0644,
        0.0649, 0.0397, 0.1998], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,051][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.9514, 0.0017, 0.0021, 0.0049, 0.0064, 0.0021, 0.0068, 0.0019, 0.0012,
        0.0097, 0.0065, 0.0018, 0.0035], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,051][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.1127, 0.0785, 0.0471, 0.0794, 0.0552, 0.0978, 0.0568, 0.0527, 0.0683,
        0.0971, 0.1061, 0.0959, 0.0523], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,052][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0467, 0.1078, 0.0890, 0.0845, 0.0664, 0.0793, 0.1083, 0.0817, 0.0454,
        0.0778, 0.0622, 0.0828, 0.0681], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,052][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([5.9342e-05, 3.3064e-03, 7.9779e-01, 4.9789e-03, 1.2287e-01, 5.9627e-03,
        1.1136e-03, 5.8226e-04, 6.7214e-04, 5.3256e-03, 5.6864e-04, 4.3151e-02,
        1.3618e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,052][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.1585, 0.0773, 0.0982, 0.0860, 0.0571, 0.1020, 0.0819, 0.0639, 0.0487,
        0.0787, 0.0674, 0.0406, 0.0398], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,053][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0881, 0.0462, 0.0732, 0.0615, 0.1318, 0.1112, 0.0837, 0.0319, 0.0671,
        0.0547, 0.0569, 0.0659, 0.1280], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,053][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0233, 0.1126, 0.1580, 0.0531, 0.0976, 0.0355, 0.0502, 0.1330, 0.0220,
        0.0726, 0.0499, 0.0746, 0.1176], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,054][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([5.2470e-03, 6.5842e-05, 4.1915e-01, 8.2145e-04, 5.6388e-02, 3.1056e-03,
        3.7208e-03, 2.0794e-02, 5.9649e-02, 4.5302e-02, 3.5492e-02, 3.1306e-01,
        3.7204e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,056][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([9.7149e-06, 3.2579e-13, 1.3939e-04, 6.2975e-10, 3.0346e-04, 2.9696e-07,
        6.4004e-07, 7.3652e-05, 1.9979e-05, 5.4809e-06, 2.9960e-05, 6.4879e-01,
        3.5063e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,059][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0543, 0.0594, 0.0795, 0.0828, 0.0780, 0.0856, 0.0863, 0.0820, 0.0776,
        0.0809, 0.0886, 0.0760, 0.0691], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,062][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0805, 0.0861, 0.0999, 0.0796, 0.0940, 0.0728, 0.0753, 0.0637, 0.0683,
        0.0617, 0.0639, 0.0661, 0.0881], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,066][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.1118, 0.0020, 0.2212, 0.0084, 0.0891, 0.0126, 0.0250, 0.0567, 0.0748,
        0.0475, 0.0432, 0.2205, 0.0872], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,071][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.8316, 0.0044, 0.0038, 0.0128, 0.0019, 0.0106, 0.0340, 0.0052, 0.0045,
        0.0249, 0.0173, 0.0031, 0.0011, 0.0450], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,071][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1392, 0.0608, 0.0385, 0.0753, 0.0703, 0.0690, 0.0591, 0.0499, 0.0438,
        0.0947, 0.1018, 0.0828, 0.0683, 0.0465], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,072][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0403, 0.0965, 0.0926, 0.0732, 0.0836, 0.0642, 0.0940, 0.0830, 0.0474,
        0.0699, 0.0536, 0.0758, 0.0851, 0.0407], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,072][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([7.3197e-06, 3.3166e-03, 8.4646e-01, 3.1865e-03, 1.0062e-01, 3.3715e-03,
        9.6511e-04, 4.6068e-04, 3.9159e-04, 3.9388e-03, 3.5103e-04, 2.8150e-02,
        8.2925e-03, 4.8280e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,073][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1352, 0.0660, 0.0777, 0.0759, 0.0759, 0.0846, 0.0739, 0.0577, 0.0458,
        0.0689, 0.0621, 0.0433, 0.0574, 0.0755], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,073][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0773, 0.0315, 0.0708, 0.0449, 0.1547, 0.0774, 0.0719, 0.0297, 0.0482,
        0.0385, 0.0450, 0.0483, 0.1453, 0.1165], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,073][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0168, 0.1105, 0.1313, 0.0455, 0.1171, 0.0276, 0.0530, 0.1274, 0.0186,
        0.0700, 0.0449, 0.0709, 0.1511, 0.0154], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,074][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([2.7031e-03, 2.1241e-05, 4.5350e-01, 5.3219e-04, 1.4788e-01, 7.0629e-04,
        1.6876e-03, 5.3914e-03, 3.4691e-02, 4.0595e-02, 2.2336e-02, 1.7844e-01,
        8.4951e-02, 2.6571e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,075][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([4.9682e-07, 7.4209e-14, 1.4774e-04, 1.7285e-10, 2.4890e-04, 1.0712e-07,
        2.5225e-07, 3.7103e-05, 8.5219e-06, 3.1267e-06, 1.6250e-05, 5.3792e-01,
        4.5538e-01, 6.2428e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,078][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0538, 0.0563, 0.0727, 0.0754, 0.0719, 0.0774, 0.0779, 0.0747, 0.0703,
        0.0751, 0.0805, 0.0699, 0.0627, 0.0816], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,081][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0741, 0.0856, 0.0945, 0.0753, 0.0919, 0.0669, 0.0701, 0.0591, 0.0642,
        0.0553, 0.0576, 0.0623, 0.0830, 0.0601], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,085][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0735, 0.0018, 0.1343, 0.0074, 0.0371, 0.0106, 0.0125, 0.0698, 0.0776,
        0.0536, 0.0401, 0.3984, 0.0263, 0.0570], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,087][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.6991e-01, 4.0218e-03, 3.0717e-03, 1.1070e-02, 1.1879e-03, 8.4026e-03,
        2.0841e-02, 5.5457e-03, 3.2856e-03, 2.2897e-02, 1.4946e-02, 2.4519e-03,
        6.4463e-04, 1.4055e-02, 1.7671e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,091][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0976, 0.0491, 0.0422, 0.0646, 0.0744, 0.0850, 0.0443, 0.0397, 0.0640,
        0.0713, 0.0800, 0.0761, 0.0776, 0.0837, 0.0506], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,092][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0389, 0.0900, 0.0803, 0.0775, 0.0739, 0.0699, 0.0928, 0.0755, 0.0486,
        0.0671, 0.0560, 0.0696, 0.0777, 0.0440, 0.0383], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,092][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.4950e-06, 2.7489e-03, 9.0373e-01, 2.2114e-03, 6.5105e-02, 2.4697e-03,
        6.3055e-04, 2.6144e-04, 3.0269e-04, 2.5692e-03, 1.5720e-04, 1.4323e-02,
        4.9642e-03, 3.1990e-04, 2.0158e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,093][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1316, 0.0647, 0.0707, 0.0741, 0.0614, 0.0886, 0.0709, 0.0538, 0.0424,
        0.0697, 0.0614, 0.0418, 0.0467, 0.0691, 0.0532], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,093][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1250, 0.0359, 0.0672, 0.0446, 0.1121, 0.0809, 0.0707, 0.0332, 0.0548,
        0.0415, 0.0414, 0.0469, 0.0990, 0.1120, 0.0347], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,094][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0196, 0.1053, 0.1473, 0.0442, 0.0957, 0.0312, 0.0483, 0.1321, 0.0199,
        0.0740, 0.0416, 0.0701, 0.1189, 0.0258, 0.0260], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,094][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.1494e-03, 5.7686e-05, 3.8081e-01, 8.6506e-04, 1.1118e-01, 1.4655e-03,
        1.9585e-03, 1.3063e-02, 4.2895e-02, 6.6901e-02, 3.9403e-02, 1.9541e-01,
        5.9538e-02, 7.8025e-02, 7.2754e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,095][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.4473e-07, 7.7214e-20, 2.4649e-10, 9.1079e-17, 4.2244e-10, 2.6954e-13,
        3.9342e-13, 5.3104e-11, 8.1203e-12, 7.9846e-13, 4.8347e-12, 5.9042e-07,
        1.8856e-06, 2.4530e-08, 1.0000e+00], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,098][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0547, 0.0540, 0.0676, 0.0677, 0.0660, 0.0722, 0.0694, 0.0670, 0.0640,
        0.0671, 0.0732, 0.0663, 0.0597, 0.0773, 0.0741], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,101][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0686, 0.0804, 0.0889, 0.0709, 0.0877, 0.0618, 0.0652, 0.0557, 0.0610,
        0.0519, 0.0539, 0.0598, 0.0790, 0.0559, 0.0592], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,105][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0301, 0.0017, 0.2160, 0.0082, 0.0692, 0.0082, 0.0169, 0.0635, 0.0930,
        0.0698, 0.0504, 0.1887, 0.0556, 0.1057, 0.0232], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,138][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:29,141][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,141][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,142][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,142][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,142][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,143][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,143][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,143][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,144][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,144][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,145][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,147][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,150][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9710, 0.0290], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,154][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2202, 0.7798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,158][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7153, 0.2847], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,162][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0067, 0.9933], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,162][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5246, 0.4754], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,162][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8759, 0.1241], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,163][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1239, 0.8761], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,163][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4904, 0.5096], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,163][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3540, 0.6460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,164][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3843, 0.6157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,164][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9712, 0.0288], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,165][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8402, 0.1598], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,168][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.8224, 0.0159, 0.1617], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,171][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.0988, 0.3760, 0.5252], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,173][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([3.6634e-01, 5.1227e-04, 6.3314e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,175][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([2.4724e-05, 6.6113e-07, 9.9997e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,179][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.3380, 0.3085, 0.3535], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,182][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.5145, 0.0426, 0.4429], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,182][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.0229, 0.0097, 0.9674], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,182][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.4184, 0.4116, 0.1700], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,183][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.2511, 0.4637, 0.2852], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,183][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.6417, 0.0059, 0.3524], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,183][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.8444, 0.0067, 0.1489], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,184][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.6697, 0.0060, 0.3243], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,184][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9434, 0.0239, 0.0153, 0.0174], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,184][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0515, 0.2394, 0.5717, 0.1374], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,185][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.2215e-03, 7.9819e-05, 9.9797e-01, 7.2545e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,185][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.6574e-04, 4.8366e-05, 9.7828e-01, 2.1501e-02], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,187][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2469, 0.2247, 0.2493, 0.2792], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,189][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3311, 0.0358, 0.5913, 0.0418], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,193][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0048, 0.0127, 0.9361, 0.0464], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,197][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1648, 0.2359, 0.4084, 0.1909], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,201][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1714, 0.3006, 0.2617, 0.2663], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,202][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0042, 0.0031, 0.9877, 0.0050], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,203][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6498, 0.0137, 0.3043, 0.0322], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,203][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0665, 0.0063, 0.8990, 0.0283], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,203][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.7148, 0.0090, 0.0144, 0.0056, 0.2562], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,204][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0364, 0.1780, 0.4575, 0.1552, 0.1730], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,204][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([6.7066e-02, 2.1684e-04, 7.6564e-01, 1.6404e-03, 1.6543e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,204][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([1.1890e-05, 5.8065e-07, 6.5330e-01, 7.3015e-03, 3.3938e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,205][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.1906, 0.1752, 0.2011, 0.2198, 0.2133], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,207][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.2517, 0.0259, 0.2682, 0.0520, 0.4023], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,209][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0126, 0.0052, 0.4174, 0.0253, 0.5395], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,213][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1727, 0.2408, 0.2711, 0.2254, 0.0900], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,217][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.1344, 0.2589, 0.1932, 0.2610, 0.1526], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,221][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.1672, 0.0030, 0.7350, 0.0009, 0.0939], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,222][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.7012, 0.0071, 0.1878, 0.0084, 0.0955], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,223][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.2507, 0.0041, 0.5372, 0.0190, 0.1889], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,223][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.9208, 0.0189, 0.0052, 0.0158, 0.0015, 0.0377], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,224][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0641, 0.1594, 0.2380, 0.1654, 0.2077, 0.1654], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,224][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.7827e-03, 1.6966e-04, 7.3926e-01, 2.1744e-03, 2.5193e-01, 3.6782e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,224][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([1.5300e-08, 1.0645e-07, 7.6219e-01, 5.3680e-04, 2.3707e-01, 2.0455e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,225][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1588, 0.1463, 0.1676, 0.1887, 0.1761, 0.1625], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,225][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2135, 0.0248, 0.2692, 0.0344, 0.4095, 0.0486], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,225][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0030, 0.0041, 0.4095, 0.0174, 0.4886, 0.0773], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,227][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1324, 0.2315, 0.1880, 0.2032, 0.1312, 0.1137], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,230][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1155, 0.2154, 0.1611, 0.2044, 0.1321, 0.1714], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,234][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0081, 0.0621, 0.5658, 0.0046, 0.3411, 0.0183], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,238][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.4344, 0.0151, 0.2889, 0.0317, 0.1597, 0.0703], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,241][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0828, 0.0086, 0.6002, 0.0404, 0.2360, 0.0319], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,243][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.9399, 0.0094, 0.0095, 0.0066, 0.0030, 0.0032, 0.0284],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,243][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0351, 0.1298, 0.3011, 0.1041, 0.2030, 0.1348, 0.0922],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,244][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.0918e-03, 2.9587e-04, 6.7631e-01, 3.3182e-03, 2.9522e-01, 1.5268e-02,
        4.4900e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,244][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.3759e-06, 1.2646e-06, 6.9523e-01, 3.3037e-03, 2.9907e-01, 9.1692e-04,
        1.4731e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,244][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1423, 0.1294, 0.1436, 0.1608, 0.1509, 0.1373, 0.1359],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,245][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2196, 0.0219, 0.2424, 0.0309, 0.3959, 0.0441, 0.0451],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,245][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0038, 0.0033, 0.3565, 0.0157, 0.4525, 0.0738, 0.0944],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,246][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0925, 0.1818, 0.1728, 0.1511, 0.1416, 0.1608, 0.0995],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,246][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0981, 0.1792, 0.1459, 0.1769, 0.1217, 0.1675, 0.1107],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,246][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0013, 0.0014, 0.6699, 0.0029, 0.3000, 0.0217, 0.0028],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,248][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4606, 0.0128, 0.2049, 0.0302, 0.1446, 0.0623, 0.0846],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,251][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0840, 0.0068, 0.6009, 0.0311, 0.2139, 0.0323, 0.0310],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,255][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.9487, 0.0100, 0.0039, 0.0079, 0.0013, 0.0041, 0.0071, 0.0170],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,259][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0326, 0.1360, 0.1677, 0.1332, 0.1432, 0.1394, 0.1108, 0.1370],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,261][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([1.5313e-02, 2.5710e-04, 6.3406e-01, 2.5888e-03, 2.9504e-01, 1.7449e-02,
        1.7735e-02, 1.7554e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,264][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([2.2332e-07, 1.0324e-07, 6.2292e-01, 1.9713e-03, 3.5490e-01, 2.9133e-04,
        7.0168e-04, 1.9221e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,264][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1250, 0.1123, 0.1313, 0.1460, 0.1381, 0.1245, 0.1215, 0.1012],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,264][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2401, 0.0193, 0.1995, 0.0342, 0.2863, 0.0505, 0.0537, 0.1165],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,265][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0054, 0.0023, 0.2847, 0.0117, 0.3640, 0.0515, 0.0726, 0.2078],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,265][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1115, 0.1540, 0.0936, 0.1797, 0.0734, 0.2104, 0.1149, 0.0626],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,266][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0826, 0.1637, 0.1318, 0.1562, 0.0952, 0.1491, 0.1038, 0.1175],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,266][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.1368e-03, 1.3329e-03, 6.0037e-01, 9.5011e-04, 3.8768e-01, 4.6481e-03,
        3.8232e-03, 6.4491e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,266][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.6562, 0.0097, 0.0968, 0.0179, 0.0762, 0.0350, 0.0466, 0.0616],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,267][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1630, 0.0048, 0.5153, 0.0174, 0.1448, 0.0191, 0.0423, 0.0933],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,268][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.8017, 0.0153, 0.0257, 0.0104, 0.0050, 0.0043, 0.0074, 0.0010, 0.1291],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,271][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0207, 0.0989, 0.1607, 0.1029, 0.1522, 0.1405, 0.0997, 0.1480, 0.0764],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,273][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([3.2810e-02, 1.4048e-04, 7.3903e-01, 1.2198e-03, 1.6821e-01, 1.1819e-02,
        1.0651e-02, 1.7788e-02, 1.8339e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,276][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([7.8749e-09, 2.0000e-08, 6.3562e-01, 5.0364e-04, 3.3824e-01, 1.4387e-04,
        1.9702e-04, 1.8419e-02, 6.8759e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,280][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1115, 0.1024, 0.1212, 0.1373, 0.1265, 0.1151, 0.1146, 0.0951, 0.0762],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,284][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1997, 0.0171, 0.1631, 0.0366, 0.2512, 0.0452, 0.0542, 0.1116, 0.1212],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,285][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0034, 0.0023, 0.2277, 0.0106, 0.3010, 0.0451, 0.0634, 0.2008, 0.1458],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,285][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0651, 0.1154, 0.1442, 0.0958, 0.0939, 0.1608, 0.1056, 0.1069, 0.1123],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,285][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0695, 0.1390, 0.1075, 0.1379, 0.0925, 0.1419, 0.0952, 0.1305, 0.0860],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,286][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([2.9437e-04, 3.4952e-04, 8.6503e-01, 2.5818e-04, 1.2677e-01, 2.5495e-03,
        4.2051e-03, 1.6044e-04, 3.7922e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,286][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6123, 0.0106, 0.1148, 0.0157, 0.0821, 0.0280, 0.0378, 0.0410, 0.0576],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,287][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2004, 0.0038, 0.3253, 0.0133, 0.0888, 0.0225, 0.0372, 0.2216, 0.0870],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,287][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8753, 0.0242, 0.0172, 0.0179, 0.0066, 0.0056, 0.0101, 0.0033, 0.0082,
        0.0316], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,287][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0183, 0.0789, 0.1715, 0.0847, 0.1257, 0.1211, 0.0805, 0.1246, 0.0920,
        0.1027], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,288][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([5.8171e-03, 2.0135e-05, 7.0973e-01, 7.1605e-04, 2.0803e-01, 7.9662e-03,
        4.7010e-03, 1.6216e-02, 3.3435e-02, 1.3367e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,290][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.0941e-05, 3.2096e-05, 5.3954e-01, 1.1678e-02, 3.7202e-01, 2.8215e-03,
        5.4113e-03, 3.8068e-02, 2.4208e-02, 6.1306e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,293][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0963, 0.0894, 0.1063, 0.1223, 0.1094, 0.1070, 0.1044, 0.0879, 0.0703,
        0.1067], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,296][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2005, 0.0140, 0.1879, 0.0186, 0.3234, 0.0253, 0.0268, 0.0991, 0.0940,
        0.0104], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,300][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0041, 0.0025, 0.1904, 0.0111, 0.2418, 0.0422, 0.0585, 0.1719, 0.1392,
        0.1385], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,304][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0536, 0.0883, 0.1374, 0.0785, 0.0855, 0.1228, 0.1114, 0.1083, 0.1690,
        0.0451], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,307][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0665, 0.1277, 0.1005, 0.1214, 0.0780, 0.1197, 0.0826, 0.0965, 0.0881,
        0.1191], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,307][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.7010e-05, 1.6645e-04, 7.4909e-01, 9.3615e-04, 2.3170e-01, 1.7521e-03,
        1.3739e-02, 2.5063e-04, 2.2687e-03, 5.1378e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,308][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4998, 0.0072, 0.1128, 0.0129, 0.0735, 0.0320, 0.0377, 0.0503, 0.0486,
        0.1251], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,308][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0746, 0.0014, 0.4320, 0.0100, 0.1699, 0.0125, 0.0231, 0.1030, 0.1023,
        0.0712], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,309][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8780, 0.0201, 0.0140, 0.0150, 0.0049, 0.0041, 0.0076, 0.0016, 0.0057,
        0.0292, 0.0199], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,309][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0155, 0.0785, 0.1737, 0.0419, 0.1566, 0.1146, 0.0626, 0.1178, 0.1039,
        0.1077, 0.0274], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,309][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.0099e-03, 2.0702e-05, 6.5099e-01, 1.8934e-04, 2.4191e-01, 6.7105e-03,
        3.4677e-03, 1.1986e-02, 3.6310e-02, 3.8550e-02, 6.8540e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,310][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.5597e-04, 1.5026e-04, 4.7850e-01, 1.9582e-02, 3.6044e-01, 5.9614e-03,
        9.3324e-03, 6.1927e-02, 3.6842e-02, 1.3288e-02, 1.3514e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,313][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0912, 0.0832, 0.0976, 0.1120, 0.1009, 0.0956, 0.0942, 0.0782, 0.0618,
        0.0939, 0.0914], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,316][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1784, 0.0138, 0.2093, 0.0155, 0.3322, 0.0237, 0.0266, 0.0981, 0.0871,
        0.0095, 0.0057], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,320][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0046, 0.0022, 0.1507, 0.0090, 0.1974, 0.0365, 0.0495, 0.1403, 0.1159,
        0.1218, 0.1722], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,324][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0440, 0.0739, 0.1318, 0.0577, 0.0834, 0.1257, 0.0767, 0.1273, 0.2004,
        0.0450, 0.0341], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,327][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0624, 0.1129, 0.0952, 0.0997, 0.0729, 0.1078, 0.0790, 0.0878, 0.0837,
        0.1127, 0.0859], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,327][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.7804e-05, 3.8109e-04, 8.2941e-01, 4.9646e-04, 1.6075e-01, 1.8066e-03,
        6.1838e-03, 1.5988e-04, 6.8395e-04, 4.3440e-05, 3.7101e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,328][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4521, 0.0051, 0.1164, 0.0098, 0.0759, 0.0305, 0.0322, 0.0395, 0.0500,
        0.1107, 0.0777], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,328][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0549, 0.0013, 0.4042, 0.0053, 0.1669, 0.0137, 0.0190, 0.0900, 0.1122,
        0.0889, 0.0437], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,328][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([9.6996e-01, 4.5266e-03, 3.7730e-03, 2.2717e-03, 2.3688e-03, 6.7730e-04,
        1.0990e-03, 7.0068e-04, 1.3549e-03, 5.3323e-03, 2.6580e-03, 5.2821e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,329][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0150, 0.0728, 0.1550, 0.0670, 0.1012, 0.1038, 0.0579, 0.1478, 0.0667,
        0.1061, 0.0472, 0.0596], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,329][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([3.5927e-02, 5.1364e-05, 6.0456e-01, 4.6550e-04, 1.5480e-01, 3.0998e-03,
        3.6213e-03, 1.2407e-02, 2.5151e-02, 2.1463e-02, 9.4136e-03, 1.2904e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,330][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([7.7810e-06, 1.5233e-06, 5.4302e-01, 6.6028e-03, 3.1921e-01, 5.6177e-04,
        1.3286e-03, 2.8119e-02, 9.6020e-03, 3.8471e-03, 4.5401e-03, 8.3160e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,331][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0833, 0.0774, 0.0911, 0.1018, 0.0947, 0.0882, 0.0846, 0.0710, 0.0581,
        0.0857, 0.0819, 0.0821], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,334][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2246, 0.0115, 0.1211, 0.0238, 0.2387, 0.0290, 0.0356, 0.0850, 0.1003,
        0.0165, 0.0168, 0.0972], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,338][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0040, 0.0007, 0.0484, 0.0033, 0.0709, 0.0134, 0.0152, 0.0464, 0.0414,
        0.0455, 0.0695, 0.6412], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,342][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0485, 0.0980, 0.0799, 0.1053, 0.0427, 0.1395, 0.0970, 0.0969, 0.1423,
        0.0499, 0.0563, 0.0439], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,345][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0525, 0.1076, 0.0756, 0.1052, 0.0643, 0.0975, 0.0638, 0.0868, 0.0728,
        0.1108, 0.0920, 0.0712], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,347][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([3.2855e-03, 1.7164e-03, 8.4966e-01, 2.9928e-04, 9.4445e-02, 9.6521e-03,
        5.5559e-03, 6.0660e-04, 3.1989e-04, 1.7226e-05, 1.1165e-05, 3.4432e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,348][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.5157, 0.0056, 0.0525, 0.0085, 0.0378, 0.0234, 0.0248, 0.0275, 0.0230,
        0.0758, 0.0577, 0.1476], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,348][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1575, 0.0014, 0.2564, 0.0051, 0.0772, 0.0093, 0.0144, 0.1100, 0.0644,
        0.0649, 0.0397, 0.1998], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,348][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([6.8279e-01, 5.6855e-03, 9.5249e-03, 3.3647e-03, 1.8088e-01, 8.5552e-04,
        2.3627e-03, 5.6069e-04, 2.0494e-03, 5.8994e-03, 3.6494e-03, 4.2568e-03,
        9.8121e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,349][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0119, 0.0652, 0.1943, 0.0551, 0.0689, 0.0910, 0.0531, 0.1045, 0.0915,
        0.0836, 0.0375, 0.0947, 0.0487], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,349][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([3.6576e-02, 1.6609e-04, 3.8806e-01, 1.2148e-03, 1.0259e-01, 8.6426e-03,
        6.8836e-03, 1.4085e-02, 3.5034e-02, 3.5730e-02, 1.8235e-02, 2.6820e-01,
        8.4589e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,350][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([2.2393e-07, 9.7128e-08, 6.7902e-01, 1.2436e-03, 2.7780e-01, 1.1069e-04,
        2.1160e-04, 4.4799e-03, 2.5921e-03, 5.6614e-04, 6.3505e-04, 2.4760e-02,
        8.5790e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,351][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0769, 0.0698, 0.0860, 0.0959, 0.0898, 0.0814, 0.0813, 0.0680, 0.0545,
        0.0787, 0.0757, 0.0760, 0.0659], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,353][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.1266, 0.0126, 0.1179, 0.0269, 0.1628, 0.0324, 0.0397, 0.0741, 0.0839,
        0.0226, 0.0210, 0.1026, 0.1766], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,356][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0026, 0.0005, 0.0370, 0.0023, 0.0508, 0.0080, 0.0095, 0.0279, 0.0240,
        0.0288, 0.0465, 0.4079, 0.3543], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,360][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0492, 0.0706, 0.0984, 0.0693, 0.0322, 0.1331, 0.0829, 0.0822, 0.2100,
        0.0386, 0.0411, 0.0645, 0.0279], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,363][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0498, 0.0949, 0.0729, 0.0981, 0.0572, 0.0913, 0.0643, 0.0937, 0.0671,
        0.0962, 0.0819, 0.0885, 0.0441], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,366][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([1.3261e-03, 2.3762e-04, 8.7073e-01, 1.8943e-04, 7.6200e-02, 4.6723e-04,
        1.8401e-03, 6.0777e-05, 2.1244e-04, 8.3786e-06, 1.1542e-05, 4.2241e-02,
        6.4712e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,367][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.3821, 0.0059, 0.1531, 0.0068, 0.0883, 0.0194, 0.0201, 0.0174, 0.0312,
        0.0441, 0.0301, 0.0665, 0.1349], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,368][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.1118, 0.0020, 0.2212, 0.0084, 0.0891, 0.0126, 0.0250, 0.0567, 0.0748,
        0.0475, 0.0432, 0.2205, 0.0872], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,368][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.8060, 0.0148, 0.0166, 0.0111, 0.0077, 0.0052, 0.0151, 0.0013, 0.0101,
        0.0218, 0.0134, 0.0050, 0.0044, 0.0677], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,369][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0143, 0.0651, 0.0835, 0.0697, 0.0916, 0.0657, 0.0663, 0.1208, 0.0407,
        0.1028, 0.0498, 0.0866, 0.0642, 0.0790], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,369][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.4374e-02, 5.1366e-05, 4.7740e-01, 4.0016e-04, 1.4893e-01, 2.8021e-03,
        2.7615e-03, 7.9701e-03, 2.3523e-02, 2.1323e-02, 7.0776e-03, 1.6139e-01,
        1.0911e-01, 2.2885e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,370][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([3.9107e-06, 3.7975e-06, 5.4074e-01, 4.0736e-03, 2.8000e-01, 1.2001e-03,
        1.5350e-03, 3.3425e-02, 1.6829e-02, 2.6289e-03, 2.4400e-03, 8.9742e-02,
        2.3426e-02, 3.9525e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,371][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0779, 0.0698, 0.0789, 0.0901, 0.0824, 0.0752, 0.0761, 0.0631, 0.0499,
        0.0727, 0.0713, 0.0689, 0.0588, 0.0647], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,374][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1014, 0.0156, 0.1094, 0.0275, 0.1764, 0.0287, 0.0358, 0.0755, 0.0827,
        0.0198, 0.0189, 0.0912, 0.1571, 0.0600], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,376][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([7.0807e-04, 1.7975e-04, 2.9034e-02, 1.1417e-03, 4.3140e-02, 4.3143e-03,
        5.8291e-03, 2.2212e-02, 1.5641e-02, 1.9926e-02, 3.0777e-02, 3.7643e-01,
        3.4384e-01, 1.0682e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,380][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0479, 0.0950, 0.0980, 0.0904, 0.0464, 0.0866, 0.1124, 0.0735, 0.1200,
        0.0497, 0.0556, 0.0543, 0.0398, 0.0305], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,384][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0467, 0.0893, 0.0801, 0.0865, 0.0601, 0.0841, 0.0604, 0.0788, 0.0635,
        0.0916, 0.0782, 0.0739, 0.0487, 0.0581], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,387][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([2.7127e-04, 1.5179e-03, 5.8176e-01, 5.3963e-04, 1.2354e-01, 1.5947e-03,
        6.3594e-03, 2.0309e-04, 2.8893e-04, 2.2611e-05, 1.7400e-05, 2.7561e-01,
        6.4535e-03, 1.8290e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,387][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.3255, 0.0057, 0.1258, 0.0078, 0.0571, 0.0192, 0.0233, 0.0216, 0.0346,
        0.0747, 0.0430, 0.1034, 0.0930, 0.0654], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,388][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0735, 0.0018, 0.1343, 0.0074, 0.0371, 0.0106, 0.0125, 0.0698, 0.0776,
        0.0536, 0.0401, 0.3984, 0.0263, 0.0570], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,388][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.3977e-01, 9.6006e-03, 5.6883e-03, 5.1274e-03, 1.6906e-03, 1.9856e-03,
        3.1104e-03, 7.5221e-04, 3.3164e-03, 1.2735e-02, 6.1929e-03, 1.9899e-03,
        8.2873e-04, 4.3245e-03, 2.8907e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,389][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0122, 0.0466, 0.1011, 0.0460, 0.0836, 0.0881, 0.0505, 0.0871, 0.0760,
        0.0728, 0.0365, 0.0657, 0.0652, 0.1485, 0.0200], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,389][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.5074e-03, 9.7834e-05, 3.7617e-01, 9.5730e-04, 1.3201e-01, 5.3770e-03,
        5.8646e-03, 1.3845e-02, 2.8880e-02, 3.7999e-02, 1.7034e-02, 2.0867e-01,
        8.9659e-02, 7.2419e-02, 5.5052e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,390][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.3090e-04, 5.9554e-05, 4.2354e-01, 1.4387e-02, 2.6792e-01, 4.1923e-03,
        6.6951e-03, 5.6224e-02, 3.7196e-02, 1.0823e-02, 1.0467e-02, 1.1003e-01,
        3.1289e-02, 1.8434e-02, 8.6054e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,390][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0722, 0.0643, 0.0734, 0.0827, 0.0763, 0.0702, 0.0705, 0.0595, 0.0481,
        0.0677, 0.0666, 0.0652, 0.0575, 0.0620, 0.0638], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,392][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1135, 0.0108, 0.1159, 0.0191, 0.1787, 0.0227, 0.0289, 0.0665, 0.0760,
        0.0153, 0.0120, 0.0872, 0.1715, 0.0578, 0.0242], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,394][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.3036e-03, 3.9199e-05, 2.2557e-03, 1.8123e-04, 3.1631e-03, 5.5738e-04,
        5.2763e-04, 1.7548e-03, 1.5007e-03, 2.0167e-03, 3.5700e-03, 3.2018e-02,
        2.2914e-02, 1.2957e-02, 9.1524e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,397][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0374, 0.0759, 0.0944, 0.0610, 0.0589, 0.0779, 0.0855, 0.0801, 0.1613,
        0.0431, 0.0370, 0.0503, 0.0524, 0.0643, 0.0206], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,401][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0410, 0.0857, 0.0670, 0.0830, 0.0519, 0.0823, 0.0561, 0.0686, 0.0616,
        0.0868, 0.0739, 0.0729, 0.0421, 0.0630, 0.0642], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,403][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.6626e-03, 1.4019e-02, 4.1722e-01, 2.2268e-03, 1.9054e-01, 1.7233e-02,
        1.7567e-02, 1.1698e-03, 3.7166e-03, 2.4035e-04, 2.4032e-04, 2.5403e-01,
        4.2417e-02, 3.4088e-02, 6.3312e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,407][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2957, 0.0051, 0.0955, 0.0062, 0.0562, 0.0203, 0.0197, 0.0215, 0.0347,
        0.0689, 0.0372, 0.0889, 0.0935, 0.0771, 0.0795], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,407][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0301, 0.0017, 0.2160, 0.0082, 0.0692, 0.0082, 0.0169, 0.0635, 0.0930,
        0.0698, 0.0504, 0.1887, 0.0556, 0.1057, 0.0232], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,409][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:29,410][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21328],
        [11921],
        [ 2745],
        [10035],
        [17204],
        [19381],
        [12686],
        [14051],
        [17566],
        [11510],
        [10094],
        [34154],
        [31795],
        [18413],
        [ 9965]], device='cuda:0')
[2024-07-24 10:25:29,411][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[20480],
        [ 7403],
        [  327],
        [ 3476],
        [ 4529],
        [ 5753],
        [ 2728],
        [ 3094],
        [ 6414],
        [ 7015],
        [ 5874],
        [15441],
        [ 9832],
        [ 7693],
        [ 4444]], device='cuda:0')
[2024-07-24 10:25:29,412][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29201],
        [28970],
        [28355],
        [27486],
        [28264],
        [26443],
        [25681],
        [26348],
        [27037],
        [23827],
        [22394],
        [27411],
        [27034],
        [21654],
        [23373]], device='cuda:0')
[2024-07-24 10:25:29,415][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31164],
        [39650],
        [37686],
        [38608],
        [38031],
        [36912],
        [35269],
        [36103],
        [35728],
        [36578],
        [37773],
        [39187],
        [38662],
        [37704],
        [36720]], device='cuda:0')
[2024-07-24 10:25:29,416][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2145],
        [3472],
        [4881],
        [4411],
        [4265],
        [4568],
        [4973],
        [5271],
        [5630],
        [5444],
        [5216],
        [4744],
        [4643],
        [4821],
        [4914]], device='cuda:0')
[2024-07-24 10:25:29,418][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[44643],
        [32423],
        [35040],
        [35030],
        [34676],
        [34787],
        [34881],
        [34726],
        [34706],
        [34790],
        [34846],
        [34557],
        [34570],
        [34676],
        [34842]], device='cuda:0')
[2024-07-24 10:25:29,421][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7913],
        [10016],
        [11529],
        [13587],
        [12479],
        [11679],
        [12503],
        [12760],
        [12420],
        [12939],
        [13407],
        [12968],
        [12515],
        [12255],
        [12682]], device='cuda:0')
[2024-07-24 10:25:29,423][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39209],
        [37510],
        [24074],
        [25851],
        [24984],
        [26210],
        [27694],
        [28680],
        [27753],
        [28392],
        [28862],
        [29372],
        [28092],
        [26360],
        [27499]], device='cuda:0')
[2024-07-24 10:25:29,426][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41602],
        [39385],
        [38110],
        [37546],
        [39946],
        [40509],
        [39808],
        [39804],
        [39640],
        [39620],
        [39654],
        [39668],
        [40379],
        [40788],
        [40363]], device='cuda:0')
[2024-07-24 10:25:29,428][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8297],
        [12196],
        [19009],
        [19744],
        [19006],
        [17692],
        [17196],
        [17272],
        [17178],
        [17139],
        [16534],
        [15541],
        [13363],
        [14434],
        [14206]], device='cuda:0')
[2024-07-24 10:25:29,431][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[43380],
        [45074],
        [41932],
        [41929],
        [38026],
        [37539],
        [37342],
        [38041],
        [38476],
        [39123],
        [39138],
        [42108],
        [40912],
        [40210],
        [44077]], device='cuda:0')
[2024-07-24 10:25:29,432][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[44655],
        [43926],
        [43409],
        [43106],
        [43096],
        [43114],
        [43437],
        [43646],
        [43695],
        [43514],
        [43450],
        [43461],
        [43593],
        [43633],
        [43610]], device='cuda:0')
[2024-07-24 10:25:29,433][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[37823],
        [35097],
        [34486],
        [33843],
        [33588],
        [33444],
        [33141],
        [32856],
        [32708],
        [32653],
        [32592],
        [32277],
        [32407],
        [32261],
        [32120]], device='cuda:0')
[2024-07-24 10:25:29,433][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30513],
        [32134],
        [43947],
        [49160],
        [48594],
        [48996],
        [48829],
        [48061],
        [46209],
        [48163],
        [48045],
        [46588],
        [47437],
        [46199],
        [47476]], device='cuda:0')
[2024-07-24 10:25:29,435][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25191],
        [14550],
        [38138],
        [29236],
        [34096],
        [40927],
        [38132],
        [40605],
        [38453],
        [18725],
        [22353],
        [38201],
        [41721],
        [16545],
        [28409]], device='cuda:0')
[2024-07-24 10:25:29,436][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[24063],
        [24712],
        [29206],
        [25427],
        [31591],
        [26027],
        [25285],
        [25192],
        [29739],
        [26805],
        [26736],
        [24806],
        [32069],
        [29026],
        [25578]], device='cuda:0')
[2024-07-24 10:25:29,438][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13714],
        [24642],
        [32556],
        [33397],
        [34958],
        [37508],
        [36967],
        [35808],
        [35673],
        [35052],
        [35328],
        [34475],
        [34712],
        [34320],
        [34841]], device='cuda:0')
[2024-07-24 10:25:29,439][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18518],
        [ 7594],
        [18566],
        [16074],
        [14886],
        [13709],
        [13161],
        [13033],
        [14651],
        [14127],
        [13293],
        [16316],
        [16130],
        [14889],
        [14117]], device='cuda:0')
[2024-07-24 10:25:29,442][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22699],
        [21239],
        [23864],
        [23995],
        [24158],
        [24062],
        [24127],
        [24582],
        [24669],
        [25311],
        [25941],
        [27408],
        [25018],
        [27556],
        [28431]], device='cuda:0')
[2024-07-24 10:25:29,444][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[9367],
        [8595],
        [7973],
        [7522],
        [7460],
        [7071],
        [6804],
        [6924],
        [7010],
        [6984],
        [6822],
        [6665],
        [6727],
        [6750],
        [6745]], device='cuda:0')
[2024-07-24 10:25:29,447][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[25544],
        [29199],
        [26746],
        [26725],
        [29398],
        [29833],
        [31064],
        [34997],
        [35914],
        [34667],
        [34329],
        [36560],
        [36739],
        [36985],
        [36553]], device='cuda:0')
[2024-07-24 10:25:29,449][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12919],
        [ 9167],
        [ 5790],
        [ 5809],
        [ 5578],
        [ 5700],
        [ 5795],
        [ 5970],
        [ 6073],
        [ 6315],
        [ 6316],
        [ 5495],
        [ 5295],
        [ 5635],
        [ 5122]], device='cuda:0')
[2024-07-24 10:25:29,452][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[7634],
        [7959],
        [7618],
        [6508],
        [6755],
        [7007],
        [6901],
        [6995],
        [6738],
        [6658],
        [6624],
        [6651],
        [6631],
        [6440],
        [6391]], device='cuda:0')
[2024-07-24 10:25:29,454][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[1577],
        [ 744],
        [ 676],
        [ 773],
        [ 667],
        [ 679],
        [ 714],
        [ 731],
        [ 690],
        [ 673],
        [ 708],
        [ 760],
        [ 733],
        [ 714],
        [ 736]], device='cuda:0')
[2024-07-24 10:25:29,455][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26551],
        [12899],
        [22578],
        [16956],
        [19125],
        [21494],
        [20460],
        [21716],
        [18412],
        [19572],
        [18828],
        [17324],
        [17236],
        [13527],
        [14232]], device='cuda:0')
[2024-07-24 10:25:29,456][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[16206],
        [15910],
        [20064],
        [31778],
        [29135],
        [37920],
        [34172],
        [26478],
        [28189],
        [27756],
        [27471],
        [22737],
        [32613],
        [29517],
        [27196]], device='cuda:0')
[2024-07-24 10:25:29,457][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3705],
        [ 3503],
        [ 5321],
        [10947],
        [ 7232],
        [ 7124],
        [ 6591],
        [ 6174],
        [ 4688],
        [ 5219],
        [ 5102],
        [ 4117],
        [ 3949],
        [ 3187],
        [ 3233]], device='cuda:0')
[2024-07-24 10:25:29,459][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43184],
        [46402],
        [44035],
        [44045],
        [44653],
        [44222],
        [44592],
        [44455],
        [44573],
        [44566],
        [44769],
        [44943],
        [44897],
        [45282],
        [45374]], device='cuda:0')
[2024-07-24 10:25:29,460][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31600],
        [36433],
        [31742],
        [33914],
        [31177],
        [31670],
        [34130],
        [31761],
        [28362],
        [29420],
        [27037],
        [33816],
        [29822],
        [35768],
        [28400]], device='cuda:0')
[2024-07-24 10:25:29,462][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216],
        [3216]], device='cuda:0')
[2024-07-24 10:25:29,487][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:29,489][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,489][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,490][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,491][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,491][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,492][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,493][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,493][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,494][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,495][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,495][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,496][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,497][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1221, 0.8779], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,498][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1176, 0.8824], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,498][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1749, 0.8251], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,501][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0548, 0.9452], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,505][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5909, 0.4091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,509][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7795, 0.2205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,512][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7854, 0.2146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,514][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9667, 0.0333], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,515][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0520, 0.9480], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,515][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5511, 0.4489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,516][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8362, 0.1638], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,517][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([3.8789e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,520][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.0433, 0.5527, 0.4040], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,523][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.0764, 0.3818, 0.5418], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,527][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.0862, 0.4061, 0.5077], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,531][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.0191, 0.2116, 0.7692], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,534][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.3110, 0.2029, 0.4860], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,534][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.2414, 0.0941, 0.6645], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,535][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.5649, 0.1622, 0.2728], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,536][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.8437, 0.0288, 0.1275], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,537][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.0193, 0.3638, 0.6170], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,538][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.3879, 0.0893, 0.5228], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,541][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.8574, 0.0926, 0.0499], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,543][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([8.0094e-06, 8.2006e-04, 9.9917e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,547][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0482, 0.2758, 0.4691, 0.2069], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,551][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0502, 0.2424, 0.3642, 0.3432], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,554][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0567, 0.2660, 0.3283, 0.3490], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,555][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0013, 0.1195, 0.7773, 0.1019], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,556][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3955, 0.2321, 0.1164, 0.2560], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,556][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1903, 0.3090, 0.3887, 0.1121], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,557][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2753, 0.0666, 0.5258, 0.1323], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,558][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6464, 0.0510, 0.1642, 0.1384], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,559][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0167, 0.2235, 0.4165, 0.3434], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,560][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0845, 0.0547, 0.8228, 0.0379], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,563][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7733, 0.1022, 0.0472, 0.0773], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,565][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.2752e-15, 2.5184e-09, 1.0000e+00, 1.4731e-08], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,569][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0131, 0.2970, 0.1740, 0.4166, 0.0994], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,574][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0361, 0.1708, 0.2731, 0.2564, 0.2636], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,576][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0427, 0.1919, 0.2427, 0.2542, 0.2686], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,577][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0042, 0.1231, 0.5982, 0.1782, 0.0963], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,578][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.1407, 0.1907, 0.1852, 0.1621, 0.3213], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,578][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0641, 0.1921, 0.5748, 0.0633, 0.1057], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,580][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.2172, 0.0537, 0.4578, 0.1496, 0.1217], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,583][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.6827, 0.0302, 0.1256, 0.0871, 0.0744], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,587][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0041, 0.1079, 0.2472, 0.2873, 0.3535], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,590][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.1445, 0.0643, 0.5854, 0.0402, 0.1656], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,594][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.7363, 0.0702, 0.0461, 0.0724, 0.0749], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,596][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([2.4520e-09, 1.1195e-05, 9.9984e-01, 1.5893e-05, 1.3278e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:29,597][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0076, 0.1643, 0.2364, 0.2913, 0.2282, 0.0721], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,598][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0221, 0.1405, 0.2250, 0.2219, 0.2269, 0.1635], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,599][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0333, 0.1572, 0.1957, 0.2062, 0.2171, 0.1904], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,600][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0010, 0.0925, 0.6581, 0.0894, 0.1209, 0.0382], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,603][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1673, 0.1336, 0.0952, 0.1012, 0.0925, 0.4101], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,607][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0596, 0.0483, 0.1820, 0.1277, 0.5735, 0.0088], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,611][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1376, 0.0408, 0.4075, 0.1407, 0.2126, 0.0608], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,614][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.6881, 0.0251, 0.0975, 0.0717, 0.0583, 0.0593], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,616][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0039, 0.1094, 0.1817, 0.1977, 0.2112, 0.2960], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,617][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0352, 0.0528, 0.5673, 0.0329, 0.2698, 0.0420], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,618][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.6525, 0.0796, 0.0454, 0.0781, 0.0714, 0.0731], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,619][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([3.5617e-14, 2.9761e-08, 9.9899e-01, 4.3810e-07, 1.0123e-03, 1.5306e-09],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:29,620][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0177, 0.1796, 0.2700, 0.1818, 0.1319, 0.1722, 0.0468],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,623][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0196, 0.1225, 0.1974, 0.1938, 0.1979, 0.1467, 0.1220],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,627][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0291, 0.1315, 0.1634, 0.1723, 0.1821, 0.1594, 0.1622],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,632][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0018, 0.1025, 0.5512, 0.1208, 0.1208, 0.0512, 0.0516],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,635][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2007, 0.1157, 0.1183, 0.1065, 0.1663, 0.1960, 0.0966],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,637][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0228, 0.0670, 0.3787, 0.0419, 0.4491, 0.0053, 0.0353],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,637][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1496, 0.0473, 0.2544, 0.1571, 0.2131, 0.1154, 0.0631],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,638][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.6539, 0.0234, 0.0911, 0.0716, 0.0550, 0.0555, 0.0495],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,639][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0033, 0.0816, 0.1478, 0.1471, 0.1726, 0.2236, 0.2239],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,641][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0480, 0.0566, 0.5112, 0.0347, 0.2706, 0.0540, 0.0250],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,645][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7322, 0.0543, 0.0258, 0.0430, 0.0385, 0.0450, 0.0612],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,647][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.0931e-14, 2.3377e-08, 9.9951e-01, 6.9247e-07, 4.9280e-04, 8.3726e-09,
        1.6104e-10], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:29,650][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0123, 0.1657, 0.1425, 0.2913, 0.1620, 0.1227, 0.0737, 0.0298],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,654][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0163, 0.1122, 0.1767, 0.1749, 0.1745, 0.1343, 0.1093, 0.1017],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,657][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0232, 0.1127, 0.1415, 0.1503, 0.1581, 0.1380, 0.1405, 0.1356],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,657][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0022, 0.1376, 0.4935, 0.1495, 0.0947, 0.0320, 0.0482, 0.0423],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,658][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1959, 0.0986, 0.0652, 0.1004, 0.0686, 0.2462, 0.0511, 0.1740],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,659][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0682, 0.0490, 0.1475, 0.0805, 0.3382, 0.0039, 0.2255, 0.0872],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,661][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1624, 0.0360, 0.2666, 0.1469, 0.1740, 0.0822, 0.1051, 0.0269],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,664][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.6800, 0.0185, 0.0732, 0.0578, 0.0438, 0.0424, 0.0379, 0.0465],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,668][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0044, 0.0826, 0.1359, 0.1287, 0.1422, 0.1838, 0.1844, 0.1381],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,672][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0741, 0.0583, 0.4713, 0.0283, 0.1961, 0.0516, 0.0281, 0.0921],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,675][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.7054, 0.0427, 0.0284, 0.0411, 0.0448, 0.0415, 0.0575, 0.0387],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,677][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([3.5074e-12, 6.4744e-08, 9.9944e-01, 3.7713e-07, 5.6302e-04, 1.3106e-08,
        2.5579e-09, 3.7425e-07], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:29,678][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0043, 0.1196, 0.2345, 0.1587, 0.1347, 0.1314, 0.0586, 0.1048, 0.0534],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,679][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0121, 0.0918, 0.1665, 0.1595, 0.1667, 0.1230, 0.1020, 0.0960, 0.0823],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,680][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0188, 0.0978, 0.1234, 0.1313, 0.1373, 0.1205, 0.1230, 0.1186, 0.1292],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,683][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0030, 0.0895, 0.5613, 0.1017, 0.0888, 0.0224, 0.0355, 0.0273, 0.0705],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,687][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2052, 0.0844, 0.0886, 0.0735, 0.2104, 0.1405, 0.0498, 0.0378, 0.1098],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,690][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0098, 0.0283, 0.0821, 0.0274, 0.1074, 0.0029, 0.0372, 0.7041, 0.0008],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,694][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1172, 0.0339, 0.2157, 0.1374, 0.1914, 0.1476, 0.0842, 0.0552, 0.0174],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,696][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.7028, 0.0142, 0.0568, 0.0447, 0.0335, 0.0333, 0.0298, 0.0359, 0.0489],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,697][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0035, 0.0643, 0.1166, 0.1108, 0.1275, 0.1681, 0.1655, 0.1163, 0.1274],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,698][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0604, 0.0360, 0.4637, 0.0258, 0.1633, 0.0375, 0.0242, 0.0927, 0.0962],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,699][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.6308, 0.0431, 0.0288, 0.0450, 0.0494, 0.0473, 0.0675, 0.0446, 0.0435],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,700][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([3.7341e-10, 2.6472e-07, 9.9972e-01, 3.3295e-07, 2.5443e-04, 1.1439e-08,
        3.6169e-09, 2.8066e-06, 1.9204e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:29,703][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0202, 0.0855, 0.1879, 0.0871, 0.1642, 0.0835, 0.0616, 0.0938, 0.0986,
        0.1175], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,708][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0194, 0.0968, 0.1360, 0.1285, 0.1309, 0.1032, 0.0931, 0.0909, 0.0753,
        0.1258], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,712][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0189, 0.0888, 0.1094, 0.1154, 0.1203, 0.1054, 0.1083, 0.1051, 0.1147,
        0.1136], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,714][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.3220e-04, 5.1376e-02, 4.3133e-01, 4.8964e-02, 7.9812e-02, 3.8867e-02,
        2.9750e-02, 6.5646e-02, 2.2078e-01, 3.3241e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,717][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1751, 0.1168, 0.0771, 0.1267, 0.0863, 0.1421, 0.0356, 0.0618, 0.0591,
        0.1196], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,717][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0217, 0.0140, 0.0600, 0.0663, 0.1843, 0.0036, 0.1766, 0.4606, 0.0052,
        0.0078], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,718][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1125, 0.0265, 0.2250, 0.1010, 0.1544, 0.0982, 0.0816, 0.0636, 0.0456,
        0.0916], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,719][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4363, 0.0201, 0.0750, 0.0630, 0.0453, 0.0519, 0.0465, 0.0527, 0.0806,
        0.1287], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,721][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0038, 0.0654, 0.1122, 0.0940, 0.1152, 0.1346, 0.1218, 0.0939, 0.1068,
        0.1522], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,725][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0188, 0.0229, 0.4513, 0.0210, 0.1924, 0.0253, 0.0163, 0.0616, 0.1029,
        0.0876], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,728][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5847, 0.0564, 0.0249, 0.0399, 0.0374, 0.0434, 0.0583, 0.0328, 0.0310,
        0.0913], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,730][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9464e-17, 2.1698e-10, 9.9978e-01, 2.6415e-09, 9.6448e-05, 1.9178e-10,
        1.3518e-11, 5.0883e-07, 1.1355e-04, 5.5003e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:29,734][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0172, 0.1019, 0.1433, 0.0788, 0.1297, 0.0912, 0.0632, 0.0790, 0.0809,
        0.1451, 0.0700], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,737][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0196, 0.0827, 0.1192, 0.1118, 0.1159, 0.0914, 0.0813, 0.0796, 0.0669,
        0.1085, 0.1230], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,737][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0174, 0.0797, 0.0979, 0.1039, 0.1081, 0.0953, 0.0973, 0.0940, 0.1028,
        0.1018, 0.1018], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,738][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([8.5465e-05, 5.1502e-02, 4.3353e-01, 3.8741e-02, 9.1196e-02, 3.8904e-02,
        2.4312e-02, 7.5178e-02, 1.9727e-01, 3.3483e-02, 1.5802e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,739][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1631, 0.1067, 0.0597, 0.1217, 0.0787, 0.1008, 0.0361, 0.0521, 0.0459,
        0.1186, 0.1166], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,741][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0198, 0.0516, 0.0417, 0.0133, 0.0927, 0.0048, 0.3385, 0.3884, 0.0074,
        0.0317, 0.0100], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,744][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1248, 0.0300, 0.2164, 0.0587, 0.1138, 0.0913, 0.0788, 0.0546, 0.0408,
        0.1055, 0.0852], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,748][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3522, 0.0177, 0.0664, 0.0607, 0.0420, 0.0485, 0.0437, 0.0486, 0.0718,
        0.1199, 0.1284], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,752][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0058, 0.0638, 0.1142, 0.0843, 0.1086, 0.1174, 0.1032, 0.0816, 0.0932,
        0.1297, 0.0982], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,757][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0224, 0.0223, 0.4342, 0.0154, 0.1869, 0.0234, 0.0141, 0.0560, 0.0814,
        0.1110, 0.0328], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,757][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5177, 0.0554, 0.0266, 0.0439, 0.0399, 0.0396, 0.0585, 0.0313, 0.0273,
        0.0998, 0.0600], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,758][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([4.0992e-18, 4.6172e-11, 9.9987e-01, 8.2164e-10, 6.0665e-05, 2.0991e-11,
        1.6680e-12, 1.2074e-07, 5.6841e-05, 1.0886e-05, 7.4156e-08],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:29,759][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0039, 0.0987, 0.0732, 0.1661, 0.0831, 0.1177, 0.0480, 0.0264, 0.0159,
        0.2014, 0.1264, 0.0392], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,761][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0132, 0.0726, 0.1059, 0.1025, 0.1040, 0.0816, 0.0746, 0.0737, 0.0606,
        0.1033, 0.1166, 0.0913], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,765][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0147, 0.0716, 0.0892, 0.0951, 0.0985, 0.0867, 0.0881, 0.0856, 0.0946,
        0.0933, 0.0928, 0.0898], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,767][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.9553e-04, 5.6112e-02, 5.2085e-01, 6.4640e-02, 7.0920e-02, 1.9320e-02,
        2.3733e-02, 4.5162e-02, 1.3709e-01, 3.3443e-02, 1.6879e-02, 1.1652e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,770][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.2306, 0.1140, 0.0560, 0.1045, 0.0408, 0.1184, 0.0164, 0.0397, 0.0334,
        0.1230, 0.0953, 0.0279], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,774][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0027, 0.0545, 0.0901, 0.0856, 0.0588, 0.0075, 0.3056, 0.2693, 0.0072,
        0.0337, 0.0731, 0.0118], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,776][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1278, 0.0263, 0.1808, 0.0778, 0.0843, 0.0819, 0.0685, 0.0371, 0.0388,
        0.1059, 0.1123, 0.0587], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,777][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.4347, 0.0152, 0.0577, 0.0450, 0.0340, 0.0355, 0.0316, 0.0368, 0.0511,
        0.0889, 0.0914, 0.0781], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,778][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0025, 0.0439, 0.0724, 0.0738, 0.0767, 0.1100, 0.1161, 0.0944, 0.0980,
        0.1267, 0.0988, 0.0867], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,779][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0271, 0.0208, 0.4009, 0.0156, 0.1260, 0.0286, 0.0190, 0.0462, 0.0987,
        0.1232, 0.0397, 0.0541], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,781][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.4762, 0.0459, 0.0297, 0.0403, 0.0434, 0.0343, 0.0530, 0.0365, 0.0304,
        0.1130, 0.0615, 0.0358], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,783][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([2.0389e-13, 6.8038e-08, 9.9872e-01, 1.9743e-07, 2.9226e-04, 6.8209e-09,
        4.6203e-10, 1.8404e-06, 4.4280e-04, 5.1650e-04, 2.7622e-05, 6.4917e-07],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:29,787][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0033, 0.1086, 0.0630, 0.1749, 0.0340, 0.0736, 0.0545, 0.0265, 0.0158,
        0.2151, 0.1423, 0.0558, 0.0327], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,790][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0095, 0.0573, 0.1088, 0.1016, 0.1103, 0.0780, 0.0674, 0.0648, 0.0529,
        0.0962, 0.1149, 0.0857, 0.0526], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,794][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0138, 0.0649, 0.0821, 0.0870, 0.0913, 0.0799, 0.0811, 0.0784, 0.0864,
        0.0847, 0.0842, 0.0823, 0.0839], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,797][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0013, 0.0800, 0.3727, 0.0910, 0.0607, 0.0295, 0.0430, 0.0606, 0.1246,
        0.0597, 0.0318, 0.0271, 0.0180], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,798][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0668, 0.0820, 0.0808, 0.0679, 0.1409, 0.0668, 0.0130, 0.0363, 0.0460,
        0.0826, 0.0653, 0.0174, 0.2343], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,798][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0225, 0.0581, 0.2024, 0.0232, 0.0353, 0.0140, 0.0718, 0.4327, 0.0043,
        0.0285, 0.0222, 0.0461, 0.0391], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,800][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0934, 0.0264, 0.1950, 0.0734, 0.0521, 0.1027, 0.0743, 0.0276, 0.0309,
        0.0914, 0.0982, 0.0826, 0.0521], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,803][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.3654, 0.0142, 0.0642, 0.0426, 0.0362, 0.0359, 0.0311, 0.0379, 0.0535,
        0.0908, 0.0904, 0.0808, 0.0571], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,807][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0012, 0.0256, 0.0530, 0.0663, 0.0711, 0.1084, 0.1282, 0.0923, 0.0968,
        0.1219, 0.0895, 0.0900, 0.0557], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,811][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0403, 0.0312, 0.3374, 0.0214, 0.1153, 0.0339, 0.0204, 0.0619, 0.0818,
        0.0908, 0.0408, 0.0738, 0.0510], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,815][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.4142, 0.0409, 0.0275, 0.0423, 0.0423, 0.0373, 0.0553, 0.0400, 0.0347,
        0.1046, 0.0675, 0.0375, 0.0558], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,816][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([1.3293e-10, 3.1795e-06, 9.9267e-01, 1.3698e-05, 2.6139e-04, 2.0376e-07,
        3.2221e-08, 4.1491e-05, 5.6784e-04, 5.9809e-03, 4.2072e-04, 3.6728e-05,
        1.0417e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:29,817][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0020, 0.0625, 0.1410, 0.0854, 0.0915, 0.0622, 0.0397, 0.0854, 0.0264,
        0.1333, 0.0796, 0.0754, 0.0895, 0.0260], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,818][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0107, 0.0600, 0.0978, 0.0966, 0.1023, 0.0729, 0.0644, 0.0599, 0.0466,
        0.0939, 0.1115, 0.0793, 0.0499, 0.0544], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,819][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0130, 0.0605, 0.0750, 0.0795, 0.0835, 0.0735, 0.0750, 0.0726, 0.0791,
        0.0782, 0.0780, 0.0760, 0.0768, 0.0793], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,820][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([3.1870e-04, 5.1658e-02, 5.3588e-01, 5.1545e-02, 7.2432e-02, 2.0104e-02,
        2.1087e-02, 3.2146e-02, 1.1123e-01, 2.6611e-02, 1.3542e-02, 1.3858e-02,
        1.8612e-02, 3.0972e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,823][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0700, 0.0452, 0.0541, 0.0291, 0.0576, 0.0667, 0.0154, 0.0178, 0.0502,
        0.0403, 0.0249, 0.0090, 0.0848, 0.4348], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,827][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0110, 0.0520, 0.0364, 0.0778, 0.1136, 0.0023, 0.1942, 0.1704, 0.0053,
        0.0311, 0.0868, 0.1050, 0.1126, 0.0015], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,832][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0671, 0.0207, 0.1457, 0.0605, 0.0968, 0.0543, 0.0432, 0.0422, 0.0185,
        0.0821, 0.0896, 0.1566, 0.0896, 0.0330], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,835][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.4232, 0.0137, 0.0542, 0.0410, 0.0322, 0.0311, 0.0278, 0.0331, 0.0438,
        0.0768, 0.0793, 0.0692, 0.0445, 0.0302], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,837][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0026, 0.0420, 0.0701, 0.0684, 0.0760, 0.1016, 0.1002, 0.0773, 0.0779,
        0.1051, 0.0793, 0.0791, 0.0457, 0.0747], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,838][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0339, 0.0198, 0.3759, 0.0102, 0.1215, 0.0167, 0.0106, 0.0370, 0.1124,
        0.0854, 0.0218, 0.0710, 0.0547, 0.0291], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,838][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.4340, 0.0491, 0.0233, 0.0437, 0.0338, 0.0364, 0.0604, 0.0372, 0.0297,
        0.0933, 0.0646, 0.0281, 0.0426, 0.0238], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,840][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([5.4642e-14, 3.2807e-09, 9.9972e-01, 1.6753e-08, 1.9849e-04, 7.6879e-11,
        1.5961e-11, 1.3255e-07, 5.7081e-05, 1.4725e-05, 4.9363e-07, 2.0321e-06,
        6.6091e-07, 3.8917e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:29,843][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0077, 0.0636, 0.0981, 0.0700, 0.0985, 0.0692, 0.0440, 0.0578, 0.0597,
        0.0949, 0.0591, 0.0836, 0.0976, 0.0669, 0.0293], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,847][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0106, 0.0592, 0.0966, 0.0893, 0.0966, 0.0687, 0.0581, 0.0547, 0.0479,
        0.0868, 0.1014, 0.0788, 0.0483, 0.0503, 0.0525], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,850][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0131, 0.0562, 0.0698, 0.0735, 0.0770, 0.0681, 0.0692, 0.0667, 0.0731,
        0.0721, 0.0720, 0.0703, 0.0715, 0.0734, 0.0739], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,852][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.5053e-04, 4.6752e-02, 3.9104e-01, 4.9415e-02, 7.9882e-02, 3.2769e-02,
        2.8843e-02, 5.5218e-02, 1.2517e-01, 3.8329e-02, 2.0722e-02, 3.0742e-02,
        2.3651e-02, 6.8267e-02, 8.8528e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,856][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1409, 0.0717, 0.0467, 0.0704, 0.0774, 0.0618, 0.0305, 0.0316, 0.0480,
        0.0829, 0.0638, 0.0116, 0.1084, 0.1435, 0.0108], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,857][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0125, 0.0163, 0.1895, 0.0381, 0.0804, 0.0011, 0.1763, 0.2886, 0.0155,
        0.0094, 0.0308, 0.0656, 0.0722, 0.0032, 0.0005], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,858][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0656, 0.0201, 0.1108, 0.0727, 0.0720, 0.0661, 0.0426, 0.0322, 0.0214,
        0.0756, 0.1046, 0.1256, 0.0687, 0.0739, 0.0479], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,859][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3476, 0.0144, 0.0542, 0.0429, 0.0339, 0.0332, 0.0304, 0.0356, 0.0475,
        0.0837, 0.0867, 0.0704, 0.0488, 0.0326, 0.0380], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,861][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0028, 0.0361, 0.0760, 0.0660, 0.0833, 0.0916, 0.0874, 0.0754, 0.0715,
        0.0934, 0.0711, 0.0760, 0.0436, 0.0702, 0.0554], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,864][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0251, 0.0235, 0.2914, 0.0172, 0.1491, 0.0212, 0.0152, 0.0455, 0.0753,
        0.0912, 0.0337, 0.0526, 0.0563, 0.0836, 0.0190], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,868][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3824, 0.0582, 0.0253, 0.0421, 0.0379, 0.0378, 0.0560, 0.0332, 0.0309,
        0.0896, 0.0596, 0.0287, 0.0478, 0.0266, 0.0439], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,870][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.8851e-14, 1.1877e-09, 9.9964e-01, 7.2371e-09, 2.4550e-04, 1.6102e-10,
        4.4814e-11, 2.6604e-07, 7.2176e-05, 1.1915e-05, 3.5205e-07, 3.0911e-06,
        6.4780e-07, 2.3525e-05, 3.0242e-09], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:29,916][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:29,920][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,921][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,922][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,922][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,923][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,924][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,924][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,925][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,926][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,926][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,927][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,928][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:29,928][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8683, 0.1317], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,929][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2409, 0.7591], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,930][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7922, 0.2078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,930][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2019, 0.7981], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,934][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2493, 0.7507], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,938][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4990, 0.5010], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,940][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4294, 0.5706], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,941][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7252, 0.2748], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,941][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8135, 0.1865], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,942][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5511, 0.4489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,943][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9446, 0.0554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,944][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([3.8789e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:29,947][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.7329, 0.1041, 0.1630], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,951][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.1420, 0.4211, 0.4369], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,954][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.6999, 0.0420, 0.2581], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,958][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.0392, 0.0458, 0.9150], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,960][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.0412, 0.1390, 0.8198], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,961][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.2341, 0.1866, 0.5793], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,962][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.2594, 0.3525, 0.3880], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,962][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.3661, 0.4495, 0.1843], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,963][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.8680, 0.0969, 0.0350], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,965][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.3879, 0.0893, 0.5228], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,969][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.9227, 0.0547, 0.0226], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,971][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([8.0094e-06, 8.2006e-04, 9.9917e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:29,974][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7110, 0.1215, 0.1278, 0.0398], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,978][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0968, 0.2915, 0.3153, 0.2964], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,980][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3588, 0.0474, 0.3997, 0.1941], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,981][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0016, 0.0111, 0.9694, 0.0179], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,982][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1440, 0.2294, 0.1929, 0.4337], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,983][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1161, 0.1483, 0.5693, 0.1664], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,983][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1863, 0.2602, 0.2945, 0.2590], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,986][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2243, 0.2584, 0.0717, 0.4456], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,989][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8274, 0.1080, 0.0287, 0.0359], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,992][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0845, 0.0547, 0.8228, 0.0379], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,996][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9275, 0.0435, 0.0156, 0.0134], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:29,999][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.2752e-15, 2.5184e-09, 1.0000e+00, 1.4731e-08], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,001][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.6141, 0.0931, 0.1457, 0.0316, 0.1155], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,002][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0782, 0.2179, 0.2460, 0.2333, 0.2246], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,002][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.3230, 0.0312, 0.3987, 0.1258, 0.1213], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,003][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0122, 0.0251, 0.8286, 0.0352, 0.0988], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,005][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0275, 0.0794, 0.1677, 0.1026, 0.6228], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,008][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.1290, 0.0959, 0.3891, 0.1155, 0.2706], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,012][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.1446, 0.1962, 0.2189, 0.1914, 0.2489], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,016][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1935, 0.5018, 0.0803, 0.1497, 0.0747], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,019][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.7055, 0.1133, 0.0894, 0.0522, 0.0395], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,021][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.1445, 0.0643, 0.5854, 0.0402, 0.1656], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,022][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.8430, 0.0723, 0.0331, 0.0291, 0.0225], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,023][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([2.4520e-09, 1.1195e-05, 9.9984e-01, 1.5893e-05, 1.3278e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,024][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.5682, 0.1066, 0.1300, 0.0354, 0.1072, 0.0527], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,025][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0521, 0.1757, 0.2024, 0.1917, 0.1883, 0.1898], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,028][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2311, 0.0315, 0.3113, 0.1357, 0.1381, 0.1523], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,030][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([7.5250e-04, 1.1529e-02, 8.1829e-01, 2.9359e-02, 1.2991e-01, 1.0161e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,034][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0624, 0.0857, 0.1238, 0.0905, 0.1808, 0.4567], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,037][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0740, 0.0933, 0.3301, 0.1105, 0.2823, 0.1098], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,041][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1289, 0.1607, 0.1792, 0.1641, 0.2113, 0.1559], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,042][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1320, 0.3478, 0.0568, 0.2784, 0.0662, 0.1188], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,043][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5162, 0.1847, 0.0584, 0.0978, 0.0516, 0.0913], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,044][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0352, 0.0528, 0.5673, 0.0329, 0.2698, 0.0420], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,045][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7844, 0.0731, 0.0308, 0.0327, 0.0309, 0.0480], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,046][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([3.5617e-14, 2.9761e-08, 9.9899e-01, 4.3810e-07, 1.0123e-03, 1.5306e-09],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,049][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5062, 0.1000, 0.1283, 0.0372, 0.0956, 0.0519, 0.0809],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,053][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0370, 0.1518, 0.1718, 0.1647, 0.1628, 0.1699, 0.1420],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,057][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1938, 0.0252, 0.2660, 0.0972, 0.1165, 0.1104, 0.1910],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,060][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0023, 0.0205, 0.7791, 0.0436, 0.1300, 0.0125, 0.0120],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,062][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0344, 0.0713, 0.1330, 0.0958, 0.3257, 0.1421, 0.1977],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,063][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0720, 0.0859, 0.3075, 0.0989, 0.2421, 0.1035, 0.0901],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,064][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1132, 0.1417, 0.1541, 0.1418, 0.1794, 0.1360, 0.1338],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,065][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1457, 0.1107, 0.0629, 0.0611, 0.0739, 0.0239, 0.5218],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,066][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6136, 0.1277, 0.0357, 0.0612, 0.0314, 0.0564, 0.0740],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,069][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0480, 0.0566, 0.5112, 0.0347, 0.2706, 0.0540, 0.0250],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,073][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7906, 0.0684, 0.0335, 0.0244, 0.0249, 0.0341, 0.0239],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,076][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.0931e-14, 2.3377e-08, 9.9951e-01, 6.9247e-07, 4.9280e-04, 8.3726e-09,
        1.6104e-10], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,080][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.3941, 0.0820, 0.1171, 0.0454, 0.1003, 0.0609, 0.0851, 0.1150],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,082][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0504, 0.1329, 0.1510, 0.1429, 0.1411, 0.1443, 0.1232, 0.1143],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,083][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1208, 0.0242, 0.1646, 0.0829, 0.0880, 0.0989, 0.1819, 0.2386],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,084][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0052, 0.0173, 0.7589, 0.0320, 0.1302, 0.0102, 0.0125, 0.0338],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,085][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0424, 0.0555, 0.0610, 0.0743, 0.0811, 0.1699, 0.0711, 0.4447],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,087][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0741, 0.0698, 0.2673, 0.0823, 0.1899, 0.0926, 0.0829, 0.1410],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,090][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0933, 0.1203, 0.1346, 0.1231, 0.1557, 0.1196, 0.1184, 0.1350],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,094][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0961, 0.1552, 0.0242, 0.1023, 0.0361, 0.0780, 0.4164, 0.0917],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,098][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.6000, 0.1009, 0.0312, 0.0412, 0.0270, 0.0555, 0.0760, 0.0682],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,101][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0741, 0.0583, 0.4713, 0.0283, 0.1961, 0.0516, 0.0281, 0.0921],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,103][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.8277, 0.0540, 0.0247, 0.0173, 0.0200, 0.0262, 0.0196, 0.0104],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,104][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([3.5074e-12, 6.4744e-08, 9.9944e-01, 3.7713e-07, 5.6302e-04, 1.3106e-08,
        2.5579e-09, 3.7425e-07], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,105][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3802, 0.0720, 0.0898, 0.0436, 0.0836, 0.0566, 0.0835, 0.1046, 0.0861],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,105][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0456, 0.1163, 0.1361, 0.1258, 0.1259, 0.1268, 0.1093, 0.1023, 0.1118],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,107][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1218, 0.0154, 0.1039, 0.0532, 0.0422, 0.1136, 0.1775, 0.2176, 0.1549],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,110][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0040, 0.0075, 0.7454, 0.0144, 0.1024, 0.0055, 0.0063, 0.0182, 0.0962],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,114][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0335, 0.0383, 0.1157, 0.0606, 0.3743, 0.0779, 0.0845, 0.0568, 0.1583],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,118][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0611, 0.0616, 0.2275, 0.0706, 0.1530, 0.0742, 0.0707, 0.1197, 0.1616],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,122][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0856, 0.1038, 0.1164, 0.1048, 0.1355, 0.1042, 0.1029, 0.1186, 0.1282],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,124][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.2786, 0.1857, 0.0502, 0.0713, 0.0446, 0.0410, 0.0806, 0.0540, 0.1940],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,124][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.5081, 0.1151, 0.0305, 0.0489, 0.0277, 0.0475, 0.0604, 0.0780, 0.0838],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,125][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0604, 0.0360, 0.4637, 0.0258, 0.1633, 0.0375, 0.0242, 0.0927, 0.0962],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,126][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.7813, 0.0674, 0.0254, 0.0236, 0.0224, 0.0184, 0.0294, 0.0100, 0.0221],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,127][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([3.7341e-10, 2.6472e-07, 9.9972e-01, 3.3295e-07, 2.5443e-04, 1.1439e-08,
        3.6169e-09, 2.8066e-06, 1.9204e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,130][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5348, 0.0643, 0.0596, 0.0179, 0.0431, 0.0314, 0.0522, 0.0772, 0.0588,
        0.0607], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,135][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0339, 0.1076, 0.1127, 0.1058, 0.1008, 0.1126, 0.1033, 0.0986, 0.0987,
        0.1261], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,139][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0491, 0.0148, 0.1265, 0.0585, 0.0574, 0.0752, 0.1294, 0.2054, 0.1606,
        0.1231], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,141][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([6.1043e-04, 4.6504e-03, 6.1059e-01, 9.3300e-03, 6.5901e-02, 5.0682e-03,
        4.9865e-03, 2.4071e-02, 2.3979e-01, 3.5006e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,144][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0385, 0.0942, 0.0924, 0.1449, 0.1702, 0.1100, 0.0653, 0.1504, 0.0551,
        0.0790], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,145][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0324, 0.0473, 0.2085, 0.0606, 0.1658, 0.0643, 0.0564, 0.1072, 0.1525,
        0.1050], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,145][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0692, 0.0927, 0.1065, 0.0936, 0.1246, 0.0947, 0.0946, 0.1063, 0.1134,
        0.1045], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,146][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1649, 0.1713, 0.0284, 0.1977, 0.0250, 0.0102, 0.1601, 0.0298, 0.0577,
        0.1548], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,148][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4182, 0.1141, 0.0286, 0.0451, 0.0250, 0.0375, 0.0461, 0.0651, 0.0888,
        0.1315], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,151][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0188, 0.0229, 0.4513, 0.0210, 0.1924, 0.0253, 0.0163, 0.0616, 0.1029,
        0.0876], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,155][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7203, 0.0579, 0.0228, 0.0229, 0.0130, 0.0260, 0.0243, 0.0163, 0.0283,
        0.0682], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,157][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9464e-17, 2.1698e-10, 9.9978e-01, 2.6415e-09, 9.6448e-05, 1.9178e-10,
        1.3518e-11, 5.0883e-07, 1.1355e-04, 5.5003e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,162][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4871, 0.0635, 0.0561, 0.0179, 0.0416, 0.0285, 0.0491, 0.0831, 0.0623,
        0.0584, 0.0525], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,164][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0279, 0.0954, 0.1011, 0.0953, 0.0915, 0.1006, 0.0897, 0.0864, 0.0893,
        0.1127, 0.1102], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,165][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0594, 0.0152, 0.1259, 0.0518, 0.0561, 0.0467, 0.0907, 0.1546, 0.1409,
        0.1023, 0.1565], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,166][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.7724e-04, 4.0713e-03, 5.8295e-01, 7.9530e-03, 6.5116e-02, 4.9210e-03,
        4.1924e-03, 2.3537e-02, 2.2771e-01, 4.5918e-02, 3.3346e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,167][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0396, 0.0808, 0.0657, 0.1438, 0.1671, 0.0726, 0.0686, 0.1275, 0.0405,
        0.0702, 0.1236], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,169][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0271, 0.0419, 0.2027, 0.0465, 0.1525, 0.0589, 0.0513, 0.0923, 0.1411,
        0.1039, 0.0819], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,171][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0630, 0.0828, 0.0957, 0.0839, 0.1117, 0.0858, 0.0858, 0.0956, 0.1013,
        0.0940, 0.1005], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,175][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1075, 0.1277, 0.0275, 0.1961, 0.0357, 0.0108, 0.1746, 0.0415, 0.0265,
        0.0899, 0.1621], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,179][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4586, 0.0961, 0.0282, 0.0341, 0.0213, 0.0394, 0.0415, 0.0470, 0.0808,
        0.1079, 0.0451], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,183][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0224, 0.0223, 0.4342, 0.0154, 0.1869, 0.0234, 0.0141, 0.0560, 0.0814,
        0.1110, 0.0328], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,184][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7184, 0.0552, 0.0179, 0.0214, 0.0103, 0.0221, 0.0195, 0.0113, 0.0176,
        0.0659, 0.0405], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,185][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.0992e-18, 4.6172e-11, 9.9987e-01, 8.2164e-10, 6.0665e-05, 2.0991e-11,
        1.6680e-12, 1.2074e-07, 5.6841e-05, 1.0886e-05, 7.4156e-08],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,186][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2963, 0.0518, 0.0560, 0.0251, 0.0566, 0.0402, 0.0635, 0.0977, 0.0764,
        0.0829, 0.0788, 0.0746], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,187][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0332, 0.0836, 0.0930, 0.0872, 0.0839, 0.0907, 0.0803, 0.0750, 0.0783,
        0.1017, 0.0992, 0.0939], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,189][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0471, 0.0096, 0.0790, 0.0385, 0.0347, 0.0658, 0.1023, 0.1367, 0.1079,
        0.0930, 0.1559, 0.1295], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,192][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0011, 0.0037, 0.6356, 0.0102, 0.0637, 0.0042, 0.0051, 0.0237, 0.1720,
        0.0335, 0.0277, 0.0193], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,196][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0359, 0.0833, 0.0600, 0.1406, 0.0351, 0.0923, 0.0356, 0.1385, 0.0294,
        0.0997, 0.1404, 0.1093], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,200][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0322, 0.0358, 0.1754, 0.0454, 0.1243, 0.0531, 0.0445, 0.0797, 0.1229,
        0.0969, 0.0844, 0.1055], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,204][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0635, 0.0720, 0.0829, 0.0750, 0.0975, 0.0746, 0.0733, 0.0853, 0.0911,
        0.0873, 0.0947, 0.1027], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,205][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0782, 0.1831, 0.0247, 0.1147, 0.0364, 0.0581, 0.1903, 0.0491, 0.0289,
        0.1256, 0.0983, 0.0128], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,206][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.3867, 0.1072, 0.0218, 0.0380, 0.0135, 0.0378, 0.0491, 0.0618, 0.0874,
        0.1028, 0.0511, 0.0427], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,207][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0271, 0.0208, 0.4009, 0.0156, 0.1260, 0.0286, 0.0190, 0.0462, 0.0987,
        0.1232, 0.0397, 0.0541], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,208][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.8138, 0.0416, 0.0118, 0.0150, 0.0115, 0.0146, 0.0143, 0.0062, 0.0122,
        0.0352, 0.0186, 0.0052], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,209][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.0389e-13, 6.8038e-08, 9.9872e-01, 1.9743e-07, 2.9226e-04, 6.8209e-09,
        4.6203e-10, 1.8404e-06, 4.4280e-04, 5.1650e-04, 2.7622e-05, 6.4917e-07],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,212][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.1976, 0.0431, 0.0834, 0.0218, 0.0727, 0.0341, 0.0496, 0.0645, 0.0539,
        0.0669, 0.0607, 0.0503, 0.2014], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,216][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0210, 0.0738, 0.0870, 0.0838, 0.0815, 0.0841, 0.0719, 0.0683, 0.0734,
        0.0961, 0.0951, 0.0923, 0.0718], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,220][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0455, 0.0065, 0.0768, 0.0299, 0.0236, 0.0987, 0.1048, 0.1214, 0.0988,
        0.0841, 0.1421, 0.1364, 0.0313], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,224][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0025, 0.0118, 0.4731, 0.0218, 0.0664, 0.0080, 0.0123, 0.0435, 0.1418,
        0.0716, 0.0605, 0.0617, 0.0249], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,225][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0117, 0.0426, 0.0892, 0.0555, 0.2905, 0.0279, 0.0175, 0.0554, 0.0243,
        0.0382, 0.0477, 0.0427, 0.2567], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,226][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0355, 0.0377, 0.1430, 0.0454, 0.1072, 0.0436, 0.0482, 0.0702, 0.1043,
        0.0820, 0.0752, 0.1181, 0.0895], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,227][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0573, 0.0646, 0.0745, 0.0659, 0.0857, 0.0666, 0.0656, 0.0767, 0.0831,
        0.0785, 0.0852, 0.0958, 0.1006], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,229][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0969, 0.2737, 0.0423, 0.0845, 0.0408, 0.0192, 0.1376, 0.0211, 0.0450,
        0.1171, 0.0691, 0.0207, 0.0319], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,232][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.2706, 0.0828, 0.0612, 0.0446, 0.0320, 0.0562, 0.0614, 0.0664, 0.0816,
        0.0982, 0.0492, 0.0478, 0.0480], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,236][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0403, 0.0312, 0.3374, 0.0214, 0.1153, 0.0339, 0.0204, 0.0619, 0.0818,
        0.0908, 0.0408, 0.0738, 0.0510], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,240][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.5658, 0.0670, 0.0371, 0.0362, 0.0248, 0.0330, 0.0306, 0.0182, 0.0345,
        0.0645, 0.0469, 0.0102, 0.0313], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,242][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([1.3293e-10, 3.1795e-06, 9.9267e-01, 1.3698e-05, 2.6139e-04, 2.0376e-07,
        3.2221e-08, 4.1491e-05, 5.6784e-04, 5.9809e-03, 4.2072e-04, 3.6728e-05,
        1.0417e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,245][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3159, 0.0509, 0.0510, 0.0190, 0.0442, 0.0281, 0.0435, 0.0654, 0.0483,
        0.0528, 0.0500, 0.0502, 0.1185, 0.0621], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,246][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0207, 0.0714, 0.0810, 0.0767, 0.0755, 0.0773, 0.0683, 0.0650, 0.0686,
        0.0869, 0.0868, 0.0838, 0.0678, 0.0702], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,247][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0416, 0.0132, 0.0951, 0.0478, 0.0404, 0.0447, 0.0824, 0.1038, 0.0817,
        0.0857, 0.1342, 0.1066, 0.0431, 0.0797], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,248][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0007, 0.0044, 0.6233, 0.0095, 0.0693, 0.0033, 0.0035, 0.0152, 0.1396,
        0.0261, 0.0224, 0.0199, 0.0235, 0.0393], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,250][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0141, 0.0283, 0.0748, 0.0302, 0.1228, 0.0732, 0.0489, 0.0455, 0.0699,
        0.0301, 0.0284, 0.0280, 0.0997, 0.3060], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,252][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0283, 0.0348, 0.1457, 0.0428, 0.1046, 0.0389, 0.0381, 0.0629, 0.1038,
        0.0747, 0.0694, 0.0898, 0.0825, 0.0838], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,256][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0525, 0.0583, 0.0691, 0.0626, 0.0812, 0.0621, 0.0616, 0.0718, 0.0764,
        0.0725, 0.0784, 0.0865, 0.0911, 0.0760], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,260][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0461, 0.1466, 0.0304, 0.0396, 0.0273, 0.0587, 0.1873, 0.0222, 0.0835,
        0.1339, 0.0450, 0.0223, 0.0260, 0.1310], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,264][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.3974, 0.0754, 0.0257, 0.0460, 0.0202, 0.0425, 0.0425, 0.0469, 0.0589,
        0.0828, 0.0526, 0.0391, 0.0209, 0.0493], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,265][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0339, 0.0198, 0.3759, 0.0102, 0.1215, 0.0167, 0.0106, 0.0370, 0.1124,
        0.0854, 0.0218, 0.0710, 0.0547, 0.0291], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,266][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.8063, 0.0387, 0.0134, 0.0134, 0.0121, 0.0132, 0.0134, 0.0065, 0.0126,
        0.0272, 0.0145, 0.0045, 0.0183, 0.0060], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,267][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([5.4642e-14, 3.2807e-09, 9.9972e-01, 1.6753e-08, 1.9849e-04, 7.6879e-11,
        1.5961e-11, 1.3255e-07, 5.7081e-05, 1.4725e-05, 4.9363e-07, 2.0321e-06,
        6.6091e-07, 3.8917e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,268][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2328, 0.0472, 0.0518, 0.0206, 0.0437, 0.0314, 0.0446, 0.0601, 0.0463,
        0.0550, 0.0532, 0.0480, 0.1300, 0.0709, 0.0646], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,270][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0174, 0.0673, 0.0755, 0.0713, 0.0697, 0.0744, 0.0630, 0.0587, 0.0638,
        0.0832, 0.0831, 0.0778, 0.0630, 0.0664, 0.0655], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,274][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0470, 0.0097, 0.0819, 0.0307, 0.0332, 0.0350, 0.0655, 0.1107, 0.1026,
        0.0646, 0.0919, 0.1212, 0.0386, 0.0839, 0.0834], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,277][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0013, 0.0064, 0.4634, 0.0116, 0.0641, 0.0055, 0.0064, 0.0249, 0.1687,
        0.0459, 0.0344, 0.0403, 0.0193, 0.1006, 0.0072], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,281][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0248, 0.0524, 0.0418, 0.0989, 0.1642, 0.0439, 0.0703, 0.0890, 0.0371,
        0.0542, 0.0854, 0.0412, 0.1296, 0.0429, 0.0243], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,285][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0216, 0.0311, 0.1310, 0.0381, 0.0999, 0.0415, 0.0369, 0.0611, 0.0915,
        0.0737, 0.0641, 0.0955, 0.0818, 0.0851, 0.0472], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,286][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0546, 0.0487, 0.0620, 0.0547, 0.0734, 0.0583, 0.0574, 0.0678, 0.0708,
        0.0656, 0.0711, 0.0802, 0.0822, 0.0723, 0.0808], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,287][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0902, 0.0758, 0.0283, 0.1188, 0.0322, 0.0096, 0.1451, 0.0453, 0.0723,
        0.0563, 0.0914, 0.0735, 0.0277, 0.0213, 0.1125], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,288][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3609, 0.0816, 0.0263, 0.0374, 0.0202, 0.0312, 0.0368, 0.0468, 0.0609,
        0.0835, 0.0462, 0.0334, 0.0272, 0.0472, 0.0604], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,290][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0251, 0.0235, 0.2914, 0.0172, 0.1491, 0.0212, 0.0152, 0.0455, 0.0753,
        0.0912, 0.0337, 0.0526, 0.0563, 0.0836, 0.0190], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,293][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5996, 0.0561, 0.0246, 0.0208, 0.0171, 0.0217, 0.0265, 0.0167, 0.0273,
        0.0475, 0.0322, 0.0088, 0.0335, 0.0101, 0.0577], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,295][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.8851e-14, 1.1877e-09, 9.9964e-01, 7.2371e-09, 2.4550e-04, 1.6102e-10,
        4.4814e-11, 2.6604e-07, 7.2176e-05, 1.1915e-05, 3.5205e-07, 3.0911e-06,
        6.4780e-07, 2.3525e-05, 3.0242e-09], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,299][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:30,301][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21598],
        [14801],
        [ 9752],
        [14289],
        [27561],
        [25363],
        [19559],
        [23246],
        [25184],
        [14857],
        [12310],
        [40403],
        [37876],
        [20314],
        [15693]], device='cuda:0')
[2024-07-24 10:25:30,303][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21702],
        [10816],
        [ 7682],
        [13493],
        [23313],
        [24592],
        [16616],
        [16605],
        [19138],
        [14576],
        [11968],
        [36185],
        [34816],
        [20358],
        [12473]], device='cuda:0')
[2024-07-24 10:25:30,306][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22027],
        [34225],
        [31904],
        [30997],
        [33444],
        [33207],
        [32426],
        [32766],
        [30836],
        [30573],
        [30714],
        [31850],
        [31696],
        [31102],
        [31673]], device='cuda:0')
[2024-07-24 10:25:30,309][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12395],
        [ 6422],
        [ 8023],
        [ 8313],
        [ 8148],
        [ 8137],
        [ 8594],
        [ 8864],
        [ 8985],
        [ 8274],
        [ 7779],
        [ 7649],
        [ 7525],
        [ 7587],
        [ 7699]], device='cuda:0')
[2024-07-24 10:25:30,310][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19728],
        [18808],
        [17852],
        [17799],
        [17852],
        [16982],
        [16565],
        [16496],
        [16366],
        [16379],
        [16276],
        [16244],
        [16319],
        [16366],
        [16276]], device='cuda:0')
[2024-07-24 10:25:30,311][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1392],
        [ 8239],
        [42732],
        [42454],
        [36375],
        [39026],
        [33792],
        [29619],
        [33658],
        [24429],
        [24467],
        [30251],
        [20073],
        [31559],
        [21599]], device='cuda:0')
[2024-07-24 10:25:30,313][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15148],
        [28936],
        [ 6993],
        [26121],
        [24417],
        [25992],
        [26010],
        [29205],
        [28386],
        [30659],
        [32116],
        [31000],
        [30897],
        [24636],
        [29822]], device='cuda:0')
[2024-07-24 10:25:30,316][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 2390],
        [16076],
        [ 3741],
        [16895],
        [ 9213],
        [21001],
        [13312],
        [32016],
        [27251],
        [33623],
        [39112],
        [39520],
        [23532],
        [35743],
        [26247]], device='cuda:0')
[2024-07-24 10:25:30,318][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41503],
        [40929],
        [28163],
        [17710],
        [14785],
        [13117],
        [17093],
        [17536],
        [18585],
        [18889],
        [21178],
        [22835],
        [21022],
        [16703],
        [18386]], device='cuda:0')
[2024-07-24 10:25:30,321][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42826],
        [42399],
        [39420],
        [34586],
        [34947],
        [35012],
        [34068],
        [34767],
        [35268],
        [28772],
        [27306],
        [28674],
        [27023],
        [28177],
        [26656]], device='cuda:0')
[2024-07-24 10:25:30,324][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[45476],
        [35338],
        [32227],
        [33410],
        [30883],
        [31757],
        [31929],
        [32296],
        [31941],
        [31609],
        [31821],
        [32076],
        [31986],
        [32599],
        [32784]], device='cuda:0')
[2024-07-24 10:25:30,326][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34608],
        [25132],
        [34298],
        [34027],
        [33552],
        [33619],
        [33359],
        [30948],
        [29161],
        [28573],
        [28476],
        [26125],
        [25554],
        [26266],
        [25625]], device='cuda:0')
[2024-07-24 10:25:30,329][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13782],
        [13061],
        [12943],
        [12445],
        [12486],
        [11100],
        [11337],
        [11312],
        [10884],
        [10981],
        [10868],
        [10787],
        [10506],
        [10323],
        [10183]], device='cuda:0')
[2024-07-24 10:25:30,332][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18057],
        [15271],
        [40427],
        [40435],
        [40435],
        [40441],
        [40438],
        [40438],
        [40435],
        [40435],
        [40435],
        [40423],
        [40298],
        [40435],
        [40435]], device='cuda:0')
[2024-07-24 10:25:30,333][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5913],
        [ 7178],
        [ 8407],
        [11366],
        [16848],
        [ 9524],
        [12779],
        [14652],
        [11981],
        [ 8933],
        [11009],
        [14614],
        [18965],
        [ 8767],
        [13142]], device='cuda:0')
[2024-07-24 10:25:30,334][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[5236],
        [5660],
        [5952],
        [6250],
        [6927],
        [7427],
        [7815],
        [8590],
        [8697],
        [7619],
        [7798],
        [9271],
        [8842],
        [8242],
        [8555]], device='cuda:0')
[2024-07-24 10:25:30,336][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9014],
        [19740],
        [17445],
        [17422],
        [15977],
        [16882],
        [17977],
        [18685],
        [18239],
        [18188],
        [18299],
        [17788],
        [17314],
        [17652],
        [18293]], device='cuda:0')
[2024-07-24 10:25:30,339][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[2422],
        [1029],
        [1853],
        [1691],
        [2011],
        [1840],
        [1652],
        [1766],
        [1830],
        [1824],
        [1655],
        [1563],
        [1564],
        [1606],
        [1679]], device='cuda:0')
[2024-07-24 10:25:30,341][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[9126],
        [1173],
        [ 674],
        [ 695],
        [ 661],
        [ 670],
        [ 623],
        [ 563],
        [ 629],
        [ 643],
        [ 662],
        [ 592],
        [ 579],
        [ 599],
        [ 621]], device='cuda:0')
[2024-07-24 10:25:30,344][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[2744],
        [1211],
        [2343],
        [1189],
        [5928],
        [2516],
        [3521],
        [2064],
        [4986],
        [2304],
        [2032],
        [1600],
        [5951],
        [4731],
        [3189]], device='cuda:0')
[2024-07-24 10:25:30,347][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4882],
        [ 4378],
        [ 5547],
        [ 5955],
        [ 6073],
        [ 6363],
        [ 6344],
        [ 6178],
        [ 6383],
        [ 8354],
        [ 9655],
        [ 9389],
        [ 9723],
        [ 9970],
        [10268]], device='cuda:0')
[2024-07-24 10:25:30,349][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[2456],
        [1271],
        [1009],
        [ 969],
        [ 974],
        [1020],
        [1048],
        [1024],
        [1005],
        [1007],
        [1010],
        [1008],
        [ 989],
        [ 999],
        [1004]], device='cuda:0')
[2024-07-24 10:25:30,352][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35879],
        [27665],
        [17812],
        [18087],
        [15041],
        [18819],
        [20473],
        [19366],
        [16946],
        [14999],
        [17545],
        [16870],
        [14933],
        [16096],
        [17748]], device='cuda:0')
[2024-07-24 10:25:30,354][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[2650],
        [1249],
        [1592],
        [1598],
        [2734],
        [3147],
        [2654],
        [2846],
        [3831],
        [3732],
        [3821],
        [4014],
        [5425],
        [4965],
        [4908]], device='cuda:0')
[2024-07-24 10:25:30,356][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24497],
        [13321],
        [29489],
        [28540],
        [25434],
        [23118],
        [22164],
        [22259],
        [20141],
        [19620],
        [20302],
        [19874],
        [18978],
        [18545],
        [17199]], device='cuda:0')
[2024-07-24 10:25:30,357][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7886],
        [ 8978],
        [ 9687],
        [ 9231],
        [10900],
        [10280],
        [10916],
        [10361],
        [11703],
        [11889],
        [11818],
        [10734],
        [12871],
        [10904],
        [13699]], device='cuda:0')
[2024-07-24 10:25:30,359][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[45717],
        [34341],
        [31438],
        [31444],
        [31444],
        [31442],
        [31443],
        [31443],
        [31444],
        [31443],
        [31444],
        [31441],
        [31455],
        [31443],
        [31443]], device='cuda:0')
[2024-07-24 10:25:30,361][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[49009],
        [49828],
        [49530],
        [49574],
        [49069],
        [49306],
        [49209],
        [49367],
        [49000],
        [49281],
        [49263],
        [49245],
        [48809],
        [48856],
        [49057]], device='cuda:0')
[2024-07-24 10:25:30,364][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[45052],
        [49217],
        [48168],
        [49319],
        [47722],
        [48814],
        [48436],
        [48390],
        [48264],
        [49294],
        [49252],
        [49074],
        [48367],
        [48739],
        [49008]], device='cuda:0')
[2024-07-24 10:25:30,367][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936],
        [4936]], device='cuda:0')
[2024-07-24 10:25:30,427][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:30,427][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,428][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,428][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,428][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,429][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,429][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,429][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,430][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,431][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,431][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,431][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,432][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,432][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3592, 0.6408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,432][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,433][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9369, 0.0631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,433][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5741, 0.4259], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,433][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8125, 0.1875], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,434][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,434][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6084, 0.3916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,434][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0852, 0.9148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,435][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1248, 0.8752], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,435][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6089, 0.3911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,435][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6783, 0.3217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,436][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2858, 0.7142], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,438][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.0752, 0.5870, 0.3378], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,440][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([3.4762e-06, 1.7583e-01, 8.2417e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,445][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.8504, 0.0562, 0.0934], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,449][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.2954, 0.2959, 0.4086], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,451][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.4933, 0.2025, 0.3041], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,451][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.0072, 0.6673, 0.3255], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,452][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.3142, 0.3179, 0.3680], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,452][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.0488, 0.4341, 0.5171], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,452][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.0717, 0.4439, 0.4844], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,453][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.4641, 0.3597, 0.1762], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,453][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.7743, 0.0567, 0.1690], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,453][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.6463, 0.1898, 0.1639], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,453][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0910, 0.1098, 0.2145, 0.5847], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,454][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([5.1488e-08, 1.5715e-03, 9.9260e-02, 8.9917e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,454][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7533, 0.0548, 0.1318, 0.0601], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,457][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2561, 0.2168, 0.3214, 0.2058], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,461][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2495, 0.1193, 0.4043, 0.2269], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,467][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0017, 0.3791, 0.3055, 0.3137], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,469][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1866, 0.1736, 0.3817, 0.2581], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,470][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0331, 0.2579, 0.2976, 0.4114], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,470][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0439, 0.2887, 0.3357, 0.3318], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,470][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2770, 0.2737, 0.1505, 0.2988], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,470][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3172, 0.1257, 0.4163, 0.1409], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,471][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3271, 0.4107, 0.1187, 0.1436], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,471][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0331, 0.1463, 0.1098, 0.5204, 0.1904], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,471][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([5.6434e-08, 1.2484e-02, 1.5340e-02, 7.3854e-01, 2.3363e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,472][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.6822, 0.0570, 0.1092, 0.0614, 0.0903], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,472][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.1556, 0.1794, 0.2655, 0.1868, 0.2127], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,475][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.2443, 0.1060, 0.2570, 0.3027, 0.0901], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,480][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0029, 0.3122, 0.2334, 0.3079, 0.1436], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,485][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0948, 0.1856, 0.2353, 0.3050, 0.1792], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,487][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0230, 0.1910, 0.2203, 0.3076, 0.2582], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,488][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0368, 0.2164, 0.2468, 0.2493, 0.2508], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,488][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0945, 0.1347, 0.5397, 0.1841, 0.0470], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,488][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.5461, 0.1707, 0.1311, 0.0790, 0.0731], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,489][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.4014, 0.2287, 0.1541, 0.1247, 0.0910], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,489][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0566, 0.1228, 0.1191, 0.3131, 0.1895, 0.1990], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,489][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([9.5285e-08, 3.1437e-03, 5.7619e-03, 3.0631e-01, 1.0111e-01, 5.8368e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,490][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.6038, 0.0580, 0.1139, 0.0678, 0.1059, 0.0506], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,490][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1198, 0.1353, 0.1888, 0.1298, 0.1647, 0.2617], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,490][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2605, 0.1086, 0.2271, 0.2499, 0.0868, 0.0671], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,491][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.9840e-04, 2.6721e-01, 1.3026e-01, 2.7626e-01, 1.4053e-01, 1.8554e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,496][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1211, 0.1267, 0.2049, 0.1931, 0.2165, 0.1377], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,501][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0188, 0.1539, 0.1814, 0.2540, 0.2131, 0.1788], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,506][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0265, 0.1733, 0.1993, 0.1989, 0.2032, 0.1988], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,506][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1144, 0.2907, 0.0954, 0.1651, 0.2696, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,506][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1998, 0.0859, 0.3199, 0.0965, 0.1034, 0.1945], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,506][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2225, 0.2395, 0.1476, 0.1186, 0.0808, 0.1911], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,507][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0382, 0.1127, 0.0725, 0.2150, 0.1477, 0.1778, 0.2361],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,507][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.4154e-07, 1.0594e-03, 4.9935e-03, 2.3556e-01, 8.5128e-02, 4.3649e-01,
        2.3677e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,507][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.6079, 0.0477, 0.1041, 0.0564, 0.0955, 0.0458, 0.0427],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,508][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1113, 0.1101, 0.1595, 0.1134, 0.1446, 0.2396, 0.1216],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,508][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2264, 0.0973, 0.2065, 0.2104, 0.0975, 0.0837, 0.0782],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,508][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0005, 0.2130, 0.1312, 0.2236, 0.1181, 0.1674, 0.1463],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,511][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0972, 0.0978, 0.1931, 0.1601, 0.2044, 0.1299, 0.1175],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,516][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0162, 0.1253, 0.1485, 0.2072, 0.1739, 0.1480, 0.1808],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,522][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0212, 0.1459, 0.1650, 0.1661, 0.1684, 0.1674, 0.1660],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,524][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0506, 0.1707, 0.0740, 0.1738, 0.1280, 0.0810, 0.3219],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,524][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3104, 0.1122, 0.1625, 0.0813, 0.0484, 0.1510, 0.1343],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,524][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2951, 0.2108, 0.1388, 0.0721, 0.0694, 0.1107, 0.1031],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,525][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0271, 0.0631, 0.0655, 0.2423, 0.1202, 0.1486, 0.1749, 0.1584],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,525][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([3.9614e-08, 3.6185e-03, 4.0707e-03, 2.4351e-01, 5.9375e-02, 2.5865e-01,
        1.7932e-01, 2.5146e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,525][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.4678, 0.0569, 0.1075, 0.0675, 0.0996, 0.0534, 0.0543, 0.0930],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,526][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0923, 0.0941, 0.1468, 0.0982, 0.1304, 0.2016, 0.1113, 0.1253],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,526][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1468, 0.0925, 0.1647, 0.2485, 0.0860, 0.0760, 0.1419, 0.0437],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,526][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0004, 0.1911, 0.0936, 0.1994, 0.1210, 0.1458, 0.1497, 0.0990],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,527][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0707, 0.0932, 0.1592, 0.1489, 0.1585, 0.1288, 0.1323, 0.1084],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,532][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0144, 0.1044, 0.1282, 0.1811, 0.1529, 0.1259, 0.1542, 0.1389],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,538][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0187, 0.1265, 0.1408, 0.1429, 0.1435, 0.1430, 0.1429, 0.1416],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,542][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0783, 0.1900, 0.0421, 0.1997, 0.0941, 0.1036, 0.2489, 0.0434],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,544][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1855, 0.0626, 0.1647, 0.0737, 0.0681, 0.1464, 0.1070, 0.1920],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,544][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.2971, 0.1882, 0.0979, 0.0760, 0.0641, 0.0867, 0.0879, 0.1021],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,544][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0138, 0.0371, 0.0422, 0.2033, 0.0969, 0.1467, 0.1758, 0.1195, 0.1647],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,545][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.4072e-07, 5.9082e-04, 4.7093e-03, 2.4556e-01, 6.6348e-02, 3.5880e-01,
        1.2948e-01, 1.4529e-01, 4.9229e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,545][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.4738, 0.0459, 0.0914, 0.0535, 0.0794, 0.0465, 0.0465, 0.0881, 0.0750],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,545][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0718, 0.0765, 0.1174, 0.0846, 0.1206, 0.1762, 0.1017, 0.1239, 0.1274],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,546][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1350, 0.0821, 0.1531, 0.2353, 0.0707, 0.0655, 0.1379, 0.0580, 0.0624],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,546][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([8.2796e-05, 1.4736e-01, 9.4048e-02, 1.4979e-01, 8.4835e-02, 1.3589e-01,
        1.3650e-01, 1.5777e-01, 9.3731e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,546][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0669, 0.0875, 0.1265, 0.1367, 0.1412, 0.0962, 0.1200, 0.1116, 0.1134],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,550][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0109, 0.0947, 0.1123, 0.1616, 0.1331, 0.1120, 0.1365, 0.1247, 0.1142],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,554][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0167, 0.1115, 0.1228, 0.1245, 0.1247, 0.1243, 0.1246, 0.1250, 0.1260],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,560][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0884, 0.1271, 0.0377, 0.0694, 0.3296, 0.0817, 0.0763, 0.1861, 0.0036],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,562][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2251, 0.0478, 0.2089, 0.0592, 0.0705, 0.1062, 0.0676, 0.0761, 0.1385],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,562][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.2311, 0.1940, 0.1245, 0.0806, 0.0546, 0.0827, 0.0784, 0.0597, 0.0944],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,563][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0161, 0.0302, 0.0374, 0.2459, 0.0657, 0.0605, 0.0559, 0.0687, 0.0725,
        0.3471], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,563][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.5034e-08, 8.2930e-04, 8.1636e-03, 2.2102e-01, 1.1759e-01, 3.1633e-01,
        1.0519e-01, 1.2631e-01, 4.0254e-02, 6.4309e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,563][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3915, 0.0413, 0.1029, 0.0554, 0.0976, 0.0498, 0.0473, 0.0920, 0.0835,
        0.0387], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,564][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0715, 0.0707, 0.1136, 0.0715, 0.0978, 0.1691, 0.0902, 0.1060, 0.1282,
        0.0813], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,564][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1733, 0.0507, 0.1785, 0.1181, 0.0737, 0.0649, 0.1220, 0.0613, 0.0940,
        0.0635], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,564][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0005, 0.0988, 0.0898, 0.1307, 0.0874, 0.1198, 0.1192, 0.1222, 0.1117,
        0.1199], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,568][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0667, 0.0595, 0.1365, 0.0918, 0.1554, 0.0880, 0.0997, 0.1060, 0.1282,
        0.0681], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,573][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0112, 0.0830, 0.0973, 0.1361, 0.1140, 0.0970, 0.1187, 0.1073, 0.0966,
        0.1388], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,578][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0150, 0.0952, 0.1074, 0.1099, 0.1107, 0.1103, 0.1116, 0.1113, 0.1113,
        0.1173], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,580][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0809, 0.0931, 0.0618, 0.0836, 0.1389, 0.0410, 0.1678, 0.2135, 0.0576,
        0.0618], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,580][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0584, 0.0208, 0.2473, 0.0417, 0.0802, 0.0883, 0.0578, 0.0861, 0.2359,
        0.0834], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,581][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1362, 0.2741, 0.0694, 0.0758, 0.0279, 0.0591, 0.0576, 0.0427, 0.0597,
        0.1976], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,581][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0097, 0.0182, 0.0279, 0.1399, 0.0547, 0.0488, 0.0475, 0.0598, 0.0743,
        0.1936, 0.3256], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,581][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.9721e-08, 7.9182e-04, 6.0434e-03, 1.7266e-01, 7.8733e-02, 3.1016e-01,
        7.9026e-02, 1.1156e-01, 4.1965e-02, 6.6537e-02, 1.3253e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,582][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3040, 0.0420, 0.1134, 0.0549, 0.1131, 0.0518, 0.0482, 0.0983, 0.0928,
        0.0430, 0.0385], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,582][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0618, 0.0701, 0.1060, 0.0659, 0.0962, 0.1502, 0.0832, 0.0952, 0.1145,
        0.0830, 0.0739], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,582][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0923, 0.0466, 0.1790, 0.0891, 0.0769, 0.0634, 0.1143, 0.0652, 0.1088,
        0.0739, 0.0906], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,583][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0006, 0.1037, 0.0847, 0.0855, 0.0755, 0.1134, 0.1041, 0.1120, 0.1068,
        0.1205, 0.0931], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,586][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0520, 0.0568, 0.1290, 0.0807, 0.1370, 0.0926, 0.0874, 0.0966, 0.1219,
        0.0674, 0.0786], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,590][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0106, 0.0732, 0.0847, 0.1190, 0.0990, 0.0850, 0.1036, 0.0940, 0.0844,
        0.1209, 0.1256], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,596][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0135, 0.0861, 0.0965, 0.0977, 0.0987, 0.0986, 0.0998, 0.0990, 0.0995,
        0.1056, 0.1051], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,598][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0760, 0.0740, 0.0544, 0.0785, 0.1599, 0.0622, 0.1201, 0.1903, 0.0641,
        0.0537, 0.0667], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,599][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0378, 0.0260, 0.3385, 0.0475, 0.1094, 0.0630, 0.0345, 0.0570, 0.1547,
        0.0611, 0.0705], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,599][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1282, 0.2600, 0.0598, 0.0726, 0.0272, 0.0465, 0.0483, 0.0323, 0.0492,
        0.1635, 0.1123], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,600][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0131, 0.0311, 0.0241, 0.1088, 0.0577, 0.0672, 0.0711, 0.0607, 0.0599,
        0.1302, 0.2370, 0.1391], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,600][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([3.6112e-09, 9.3333e-04, 8.1075e-04, 1.7557e-01, 2.0831e-02, 1.3944e-01,
        5.3708e-02, 5.0408e-02, 2.9039e-02, 3.2851e-02, 1.4478e-01, 3.5163e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,600][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.3225, 0.0384, 0.1131, 0.0543, 0.0983, 0.0487, 0.0478, 0.0901, 0.0841,
        0.0358, 0.0339, 0.0330], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,601][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0433, 0.0632, 0.0908, 0.0612, 0.0803, 0.1402, 0.0794, 0.0947, 0.1030,
        0.0767, 0.0717, 0.0956], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,601][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0375, 0.0588, 0.1444, 0.1493, 0.0495, 0.0567, 0.0915, 0.0440, 0.0590,
        0.0943, 0.1581, 0.0569], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,604][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0005, 0.0978, 0.0560, 0.0982, 0.0593, 0.0997, 0.1031, 0.0854, 0.0912,
        0.1293, 0.1158, 0.0638], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,610][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0305, 0.0633, 0.1038, 0.1091, 0.1009, 0.0836, 0.1006, 0.0781, 0.0828,
        0.0788, 0.1039, 0.0647], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,615][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0094, 0.0660, 0.0782, 0.1098, 0.0921, 0.0763, 0.0943, 0.0854, 0.0776,
        0.1115, 0.1149, 0.0844], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,617][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0114, 0.0788, 0.0884, 0.0890, 0.0894, 0.0890, 0.0891, 0.0892, 0.0902,
        0.0967, 0.0962, 0.0925], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,617][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0543, 0.0693, 0.0711, 0.0803, 0.0753, 0.0687, 0.1335, 0.2056, 0.0829,
        0.0504, 0.0763, 0.0325], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,617][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1786, 0.0331, 0.1482, 0.0593, 0.0704, 0.0883, 0.0866, 0.0605, 0.1066,
        0.0646, 0.0625, 0.0412], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,618][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1471, 0.1594, 0.0616, 0.0510, 0.0310, 0.0581, 0.0594, 0.0508, 0.0682,
        0.1365, 0.0796, 0.0973], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,618][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0096, 0.0473, 0.0299, 0.1305, 0.0535, 0.0761, 0.0782, 0.0655, 0.0790,
        0.1220, 0.1582, 0.0947, 0.0555], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,618][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([2.2026e-07, 2.3929e-03, 1.9050e-03, 2.4343e-01, 5.2743e-02, 2.2677e-01,
        4.4005e-02, 2.6439e-02, 1.9206e-02, 5.3245e-02, 1.7765e-01, 1.3274e-01,
        1.9473e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,619][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.4197, 0.0402, 0.0827, 0.0464, 0.0710, 0.0357, 0.0367, 0.0734, 0.0685,
        0.0330, 0.0300, 0.0315, 0.0311], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,619][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0367, 0.0541, 0.0850, 0.0571, 0.0676, 0.1293, 0.0718, 0.0869, 0.1001,
        0.0700, 0.0667, 0.0984, 0.0763], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,619][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.1014, 0.0408, 0.1380, 0.1368, 0.0429, 0.0349, 0.0772, 0.0567, 0.0510,
        0.0597, 0.1340, 0.0926, 0.0340], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,623][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0009, 0.0866, 0.0619, 0.0865, 0.0368, 0.1094, 0.0941, 0.1023, 0.0857,
        0.1175, 0.1004, 0.0844, 0.0335], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,629][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0274, 0.0696, 0.0895, 0.1097, 0.0663, 0.0743, 0.0819, 0.0722, 0.0858,
        0.0853, 0.1078, 0.0717, 0.0585], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,633][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0071, 0.0611, 0.0709, 0.1005, 0.0841, 0.0700, 0.0854, 0.0791, 0.0722,
        0.1022, 0.1075, 0.0778, 0.0821], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,635][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0103, 0.0721, 0.0798, 0.0824, 0.0812, 0.0829, 0.0829, 0.0829, 0.0839,
        0.0894, 0.0889, 0.0869, 0.0763], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,635][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0277, 0.0456, 0.1547, 0.0530, 0.0121, 0.1127, 0.1393, 0.1304, 0.1648,
        0.0433, 0.0602, 0.0427, 0.0134], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,636][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.1107, 0.0809, 0.0923, 0.0513, 0.0546, 0.0900, 0.0550, 0.0766, 0.0926,
        0.1262, 0.0856, 0.0361, 0.0481], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,636][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.1395, 0.1197, 0.0676, 0.0604, 0.0389, 0.0779, 0.0904, 0.0551, 0.0758,
        0.1059, 0.0741, 0.0509, 0.0436], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,636][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0114, 0.0192, 0.0230, 0.0643, 0.0557, 0.0615, 0.0655, 0.0580, 0.0638,
        0.1234, 0.1444, 0.0675, 0.0685, 0.1739], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,637][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.1978e-08, 4.3878e-04, 1.7696e-03, 6.1953e-02, 2.4357e-02, 9.8434e-02,
        9.7942e-02, 7.2252e-02, 1.9950e-02, 2.1001e-02, 6.1698e-02, 2.3720e-01,
        1.7886e-02, 2.8512e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,637][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.3008, 0.0370, 0.0907, 0.0490, 0.0864, 0.0414, 0.0419, 0.0801, 0.0735,
        0.0346, 0.0335, 0.0363, 0.0402, 0.0544], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,641][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0505, 0.0488, 0.0722, 0.0494, 0.0669, 0.1157, 0.0623, 0.0742, 0.0810,
        0.0606, 0.0584, 0.0878, 0.0770, 0.0952], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,647][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0912, 0.0531, 0.1002, 0.1339, 0.0466, 0.0382, 0.0644, 0.0411, 0.0579,
        0.0753, 0.1557, 0.0588, 0.0482, 0.0353], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,649][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.0005e-04, 8.8884e-02, 5.1864e-02, 8.9921e-02, 4.7031e-02, 7.6018e-02,
        7.2930e-02, 8.7271e-02, 7.0480e-02, 1.1688e-01, 1.0689e-01, 9.0382e-02,
        4.3315e-02, 5.8029e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,653][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0441, 0.0541, 0.0875, 0.0874, 0.0913, 0.0581, 0.0668, 0.0681, 0.0807,
        0.0648, 0.0846, 0.0712, 0.0840, 0.0573], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,653][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0074, 0.0556, 0.0661, 0.0930, 0.0786, 0.0658, 0.0799, 0.0739, 0.0665,
        0.0952, 0.0986, 0.0735, 0.0764, 0.0695], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,654][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0098, 0.0664, 0.0749, 0.0761, 0.0764, 0.0761, 0.0766, 0.0763, 0.0761,
        0.0821, 0.0820, 0.0800, 0.0720, 0.0752], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,654][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0270, 0.0948, 0.0325, 0.0385, 0.1188, 0.0695, 0.0843, 0.0678, 0.1357,
        0.0457, 0.0332, 0.0455, 0.1056, 0.1009], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,654][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0738, 0.0451, 0.1597, 0.0488, 0.0691, 0.0651, 0.0408, 0.0446, 0.1340,
        0.0977, 0.0753, 0.0337, 0.0468, 0.0654], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,655][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.1419, 0.1482, 0.0584, 0.0556, 0.0326, 0.0629, 0.0616, 0.0487, 0.0612,
        0.1072, 0.0745, 0.0514, 0.0357, 0.0600], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,655][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0179, 0.0421, 0.0299, 0.0963, 0.0542, 0.0601, 0.0627, 0.0592, 0.0580,
        0.1314, 0.1134, 0.0338, 0.0424, 0.1110, 0.0875], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,656][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.7537e-08, 3.4447e-04, 1.6842e-03, 1.0963e-01, 3.5213e-02, 1.3816e-01,
        4.8551e-02, 3.6668e-02, 8.7913e-03, 3.4071e-02, 7.9960e-02, 1.6212e-01,
        1.8316e-02, 1.2068e-01, 2.0581e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,656][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3010, 0.0334, 0.0930, 0.0434, 0.0906, 0.0389, 0.0382, 0.0798, 0.0734,
        0.0326, 0.0294, 0.0356, 0.0375, 0.0548, 0.0185], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,659][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0421, 0.0474, 0.0728, 0.0463, 0.0631, 0.1064, 0.0572, 0.0671, 0.0803,
        0.0573, 0.0523, 0.0802, 0.0706, 0.0935, 0.0635], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,664][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0677, 0.0426, 0.1466, 0.0965, 0.0554, 0.0429, 0.0746, 0.0410, 0.0668,
        0.0579, 0.0955, 0.0748, 0.0502, 0.0535, 0.0340], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,669][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0002, 0.0838, 0.0507, 0.0773, 0.0515, 0.0767, 0.0775, 0.0776, 0.0769,
        0.0965, 0.0869, 0.0664, 0.0448, 0.0815, 0.0517], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,672][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0412, 0.0415, 0.0915, 0.0668, 0.0947, 0.0622, 0.0690, 0.0724, 0.0843,
        0.0531, 0.0670, 0.0710, 0.0954, 0.0627, 0.0273], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,672][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0075, 0.0524, 0.0622, 0.0857, 0.0728, 0.0608, 0.0740, 0.0680, 0.0617,
        0.0873, 0.0908, 0.0672, 0.0707, 0.0637, 0.0753], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,672][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0091, 0.0621, 0.0697, 0.0701, 0.0706, 0.0704, 0.0709, 0.0707, 0.0717,
        0.0764, 0.0762, 0.0744, 0.0682, 0.0703, 0.0692], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,673][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0438, 0.0924, 0.0390, 0.0610, 0.0750, 0.0413, 0.1444, 0.0792, 0.0496,
        0.0575, 0.0615, 0.0450, 0.0936, 0.0693, 0.0472], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,673][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0922, 0.0759, 0.1583, 0.0569, 0.0383, 0.0612, 0.0389, 0.0617, 0.0849,
        0.1273, 0.0988, 0.0306, 0.0302, 0.0254, 0.0194], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,674][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1474, 0.1575, 0.0595, 0.0511, 0.0280, 0.0455, 0.0437, 0.0358, 0.0501,
        0.1210, 0.0773, 0.0484, 0.0284, 0.0472, 0.0592], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,708][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:30,712][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,712][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,713][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,713][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,713][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,714][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,714][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,714][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,715][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,716][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,718][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,720][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:30,724][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5897, 0.4103], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,728][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1840, 0.8160], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,728][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0649, 0.9351], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,729][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6068, 0.3932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,729][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3458, 0.6542], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,733][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4778, 0.5222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,734][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4412, 0.5588], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,734][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1385, 0.8615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,734][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1870, 0.8130], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,735][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9164, 0.0836], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,735][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7634, 0.2366], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,735][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2858, 0.7142], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:30,736][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.5747, 0.3154, 0.1099], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,736][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.5125, 0.3785, 0.1090], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,736][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.1081, 0.4688, 0.4232], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,738][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.3499, 0.1293, 0.5208], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,744][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.1350, 0.2051, 0.6599], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,748][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.6694, 0.2464, 0.0842], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,752][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.2599, 0.1814, 0.5587], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,752][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.2007, 0.3995, 0.3998], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,753][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.3408, 0.3909, 0.2683], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,753][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.8676, 0.0402, 0.0922], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,753][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.8761, 0.0418, 0.0821], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,754][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.6463, 0.1898, 0.1639], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:30,754][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5979, 0.1413, 0.1329, 0.1279], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,754][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2357, 0.3041, 0.1874, 0.2729], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,755][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0106, 0.2245, 0.6461, 0.1188], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,758][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1039, 0.1125, 0.7061, 0.0775], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,764][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0317, 0.0869, 0.8233, 0.0581], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,768][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3756, 0.2461, 0.2453, 0.1331], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,770][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0448, 0.1006, 0.7297, 0.1250], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,770][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0671, 0.3672, 0.3730, 0.1927], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,771][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0676, 0.1977, 0.5826, 0.1521], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,771][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8612, 0.0452, 0.0763, 0.0173], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,771][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7666, 0.0712, 0.1463, 0.0159], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,772][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3271, 0.4107, 0.1187, 0.1436], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:30,772][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.4974, 0.2260, 0.1066, 0.1109, 0.0591], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,772][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.3693, 0.2308, 0.1386, 0.1261, 0.1352], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,773][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0362, 0.2563, 0.4530, 0.1401, 0.1144], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,773][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.1068, 0.0928, 0.4914, 0.0815, 0.2276], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,776][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0281, 0.0920, 0.5831, 0.1046, 0.1922], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,781][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.5840, 0.1366, 0.1127, 0.0733, 0.0935], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,786][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.1064, 0.1328, 0.5028, 0.1531, 0.1048], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,788][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1414, 0.2504, 0.3383, 0.1568, 0.1130], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,789][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.1399, 0.2227, 0.3531, 0.1369, 0.1474], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,789][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.7299, 0.0481, 0.1546, 0.0220, 0.0453], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,789][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.8060, 0.0758, 0.0754, 0.0168, 0.0260], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,790][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.4014, 0.2287, 0.1541, 0.1247, 0.0910], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:30,790][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2805, 0.2612, 0.1542, 0.1469, 0.0716, 0.0856], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,790][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0432, 0.2918, 0.1569, 0.2237, 0.1593, 0.1251], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,791][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0093, 0.2038, 0.4638, 0.1310, 0.1336, 0.0585], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,794][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0392, 0.0685, 0.4955, 0.0681, 0.2599, 0.0687], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,800][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0192, 0.0568, 0.6070, 0.0519, 0.2206, 0.0444], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,805][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0746, 0.2833, 0.1278, 0.2763, 0.1525, 0.0855], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,806][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0514, 0.1092, 0.4941, 0.1207, 0.1555, 0.0691], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,807][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0525, 0.2737, 0.2958, 0.1832, 0.1157, 0.0790], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,807][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0382, 0.1958, 0.3441, 0.1612, 0.1815, 0.0792], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,807][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.5221, 0.0904, 0.1705, 0.0587, 0.0890, 0.0693], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,808][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.4676, 0.1025, 0.2637, 0.0427, 0.0544, 0.0690], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,808][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2225, 0.2395, 0.1476, 0.1186, 0.0808, 0.1911], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:30,808][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4942, 0.1518, 0.1000, 0.1012, 0.0441, 0.0635, 0.0453],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,809][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1310, 0.1389, 0.1251, 0.2016, 0.1205, 0.1530, 0.1299],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,809][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0116, 0.1777, 0.4321, 0.1465, 0.1167, 0.0651, 0.0503],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,811][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0495, 0.0880, 0.4185, 0.0746, 0.2433, 0.0868, 0.0393],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,817][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0170, 0.0678, 0.5507, 0.0628, 0.2146, 0.0571, 0.0299],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,821][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2350, 0.1437, 0.1740, 0.1304, 0.1423, 0.0906, 0.0841],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,825][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0392, 0.1066, 0.4766, 0.1245, 0.1325, 0.0953, 0.0252],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,825][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0555, 0.2155, 0.2611, 0.1518, 0.0991, 0.1029, 0.1141],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,826][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0477, 0.1649, 0.2914, 0.1536, 0.1547, 0.1052, 0.0825],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,826][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.6802, 0.0594, 0.0958, 0.0299, 0.0491, 0.0467, 0.0390],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,826][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7250, 0.0674, 0.1160, 0.0156, 0.0213, 0.0291, 0.0256],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,827][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2951, 0.2108, 0.1388, 0.0721, 0.0694, 0.1107, 0.1031],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:30,827][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.3604, 0.1706, 0.1237, 0.1289, 0.0572, 0.0646, 0.0546, 0.0400],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,827][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0662, 0.1712, 0.0757, 0.2282, 0.1062, 0.1171, 0.1672, 0.0682],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,831][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0126, 0.1900, 0.3871, 0.1105, 0.1011, 0.0585, 0.0624, 0.0780],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,835][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0437, 0.0759, 0.3976, 0.0634, 0.2033, 0.0666, 0.0362, 0.1133],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,841][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0255, 0.0678, 0.5348, 0.0460, 0.1970, 0.0495, 0.0376, 0.0418],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,843][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1222, 0.1550, 0.1427, 0.1707, 0.1486, 0.1040, 0.1059, 0.0508],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,843][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0476, 0.1004, 0.4218, 0.0998, 0.1251, 0.0909, 0.0416, 0.0728],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,844][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0647, 0.1809, 0.2815, 0.1071, 0.0885, 0.0646, 0.0834, 0.1293],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,844][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0463, 0.1548, 0.2706, 0.1295, 0.1535, 0.0908, 0.0834, 0.0711],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,844][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.5785, 0.0598, 0.1185, 0.0372, 0.0575, 0.0526, 0.0494, 0.0465],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,845][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.5957, 0.0659, 0.1522, 0.0228, 0.0351, 0.0440, 0.0333, 0.0510],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,845][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.2971, 0.1882, 0.0979, 0.0760, 0.0641, 0.0867, 0.0879, 0.1021],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:30,846][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3017, 0.2544, 0.0819, 0.1053, 0.0410, 0.0553, 0.0495, 0.0515, 0.0593],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,846][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0491, 0.1733, 0.0795, 0.1720, 0.0861, 0.1004, 0.1420, 0.1108, 0.0867],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,849][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0189, 0.1574, 0.3347, 0.0860, 0.0824, 0.0515, 0.0600, 0.0897, 0.1193],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,854][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0484, 0.0564, 0.3566, 0.0467, 0.1810, 0.0550, 0.0321, 0.0924, 0.1313],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,859][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0306, 0.0645, 0.4571, 0.0432, 0.1565, 0.0418, 0.0413, 0.0484, 0.1167],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,862][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1696, 0.1619, 0.1276, 0.0911, 0.1250, 0.0615, 0.0794, 0.0948, 0.0888],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,862][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0875, 0.0661, 0.3611, 0.0549, 0.0948, 0.0562, 0.0226, 0.0530, 0.2038],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,862][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0610, 0.1293, 0.2371, 0.1035, 0.0712, 0.0555, 0.0890, 0.1208, 0.1326],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,863][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0573, 0.1605, 0.2407, 0.0879, 0.1098, 0.0720, 0.0866, 0.1188, 0.0663],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,863][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.5652, 0.0472, 0.1040, 0.0305, 0.0591, 0.0447, 0.0389, 0.0514, 0.0590],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,863][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6585, 0.0414, 0.1246, 0.0153, 0.0258, 0.0332, 0.0242, 0.0265, 0.0506],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,864][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2311, 0.1940, 0.1245, 0.0806, 0.0546, 0.0827, 0.0784, 0.0597, 0.0944],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:30,867][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3013, 0.1084, 0.0920, 0.1069, 0.0526, 0.0611, 0.0624, 0.0537, 0.0705,
        0.0911], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,871][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0320, 0.1202, 0.0677, 0.2043, 0.0907, 0.0886, 0.1221, 0.0630, 0.0764,
        0.1351], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,877][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0028, 0.0914, 0.3217, 0.0740, 0.0674, 0.0351, 0.0354, 0.0743, 0.1151,
        0.1829], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,879][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0179, 0.0482, 0.3346, 0.0432, 0.1323, 0.0475, 0.0241, 0.0915, 0.1685,
        0.0922], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,880][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0077, 0.0468, 0.3743, 0.0427, 0.1242, 0.0460, 0.0302, 0.0407, 0.1367,
        0.1507], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,880][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0674, 0.0957, 0.0732, 0.1258, 0.0909, 0.0859, 0.0847, 0.0914, 0.1668,
        0.1182], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,880][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0311, 0.0507, 0.3213, 0.0518, 0.0673, 0.0627, 0.0198, 0.0724, 0.2435,
        0.0795], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,881][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0145, 0.1245, 0.2047, 0.0911, 0.0538, 0.0433, 0.0713, 0.1003, 0.0872,
        0.2093], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,881][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0155, 0.0699, 0.2093, 0.1067, 0.0930, 0.0750, 0.0802, 0.1087, 0.1063,
        0.1354], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,882][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5572, 0.0557, 0.0765, 0.0263, 0.0361, 0.0397, 0.0395, 0.0541, 0.0771,
        0.0377], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,882][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3202, 0.0607, 0.2303, 0.0283, 0.0364, 0.0450, 0.0316, 0.0480, 0.1049,
        0.0945], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,882][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1362, 0.2741, 0.0694, 0.0758, 0.0279, 0.0591, 0.0576, 0.0427, 0.0597,
        0.1976], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:30,885][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2917, 0.1322, 0.0679, 0.0935, 0.0328, 0.0409, 0.0453, 0.0345, 0.0500,
        0.1047, 0.1065], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,890][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0425, 0.1488, 0.0525, 0.1347, 0.0579, 0.0577, 0.1029, 0.0477, 0.0577,
        0.1228, 0.1748], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,896][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0019, 0.0823, 0.2935, 0.0558, 0.0622, 0.0296, 0.0269, 0.0563, 0.1210,
        0.2145, 0.0561], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,898][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0117, 0.0432, 0.3216, 0.0380, 0.1344, 0.0439, 0.0200, 0.0835, 0.1506,
        0.0958, 0.0572], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,898][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0053, 0.0371, 0.3732, 0.0296, 0.1242, 0.0356, 0.0247, 0.0333, 0.1375,
        0.1532, 0.0462], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,899][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0585, 0.1021, 0.0675, 0.0721, 0.0757, 0.0692, 0.0841, 0.0828, 0.1779,
        0.1152, 0.0949], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,899][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0093, 0.0479, 0.2586, 0.0589, 0.0490, 0.0445, 0.0135, 0.0693, 0.2627,
        0.1097, 0.0766], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,899][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0091, 0.1198, 0.1429, 0.0881, 0.0376, 0.0316, 0.0624, 0.0988, 0.0807,
        0.2525, 0.0765], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,900][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0144, 0.0790, 0.1978, 0.0600, 0.0743, 0.0682, 0.0777, 0.0894, 0.1023,
        0.1601, 0.0767], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,900][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5766, 0.0493, 0.0809, 0.0228, 0.0361, 0.0316, 0.0348, 0.0484, 0.0658,
        0.0325, 0.0213], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,904][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2673, 0.0555, 0.2807, 0.0274, 0.0473, 0.0389, 0.0244, 0.0393, 0.0818,
        0.0837, 0.0537], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,909][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1282, 0.2600, 0.0598, 0.0726, 0.0272, 0.0465, 0.0483, 0.0323, 0.0492,
        0.1635, 0.1123], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:30,914][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2560, 0.1617, 0.0738, 0.0874, 0.0416, 0.0538, 0.0439, 0.0245, 0.0275,
        0.1177, 0.0907, 0.0214], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,916][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0815, 0.1754, 0.0341, 0.1138, 0.0416, 0.0655, 0.0729, 0.0450, 0.0296,
        0.1205, 0.1784, 0.0415], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,916][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0040, 0.0668, 0.3097, 0.0615, 0.0685, 0.0345, 0.0377, 0.0591, 0.1090,
        0.1482, 0.0692, 0.0319], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,917][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0109, 0.0379, 0.2604, 0.0451, 0.1198, 0.0413, 0.0285, 0.0683, 0.1250,
        0.1032, 0.0713, 0.0883], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,917][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0049, 0.0403, 0.3465, 0.0369, 0.1145, 0.0302, 0.0206, 0.0332, 0.0983,
        0.1692, 0.0634, 0.0418], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,917][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1165, 0.1432, 0.0703, 0.1108, 0.0716, 0.0602, 0.0685, 0.0502, 0.0851,
        0.0929, 0.0931, 0.0377], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,918][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0163, 0.0553, 0.2586, 0.0496, 0.0699, 0.0510, 0.0148, 0.0576, 0.1912,
        0.1213, 0.0718, 0.0427], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,918][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0165, 0.0931, 0.1799, 0.0645, 0.0504, 0.0388, 0.0539, 0.0786, 0.1164,
        0.1974, 0.0776, 0.0331], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,919][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0199, 0.0974, 0.1912, 0.0900, 0.0900, 0.0598, 0.0618, 0.0606, 0.0581,
        0.1335, 0.1111, 0.0265], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,922][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.5199, 0.0610, 0.0792, 0.0306, 0.0357, 0.0385, 0.0452, 0.0460, 0.0590,
        0.0375, 0.0246, 0.0229], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,926][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.5346, 0.0510, 0.0840, 0.0211, 0.0203, 0.0354, 0.0398, 0.0322, 0.0539,
        0.0582, 0.0407, 0.0288], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,932][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1471, 0.1594, 0.0616, 0.0510, 0.0310, 0.0581, 0.0594, 0.0508, 0.0682,
        0.1365, 0.0796, 0.0973], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:30,934][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.1954, 0.1671, 0.0596, 0.0832, 0.0354, 0.0432, 0.0494, 0.0803, 0.0625,
        0.0668, 0.0777, 0.0463, 0.0331], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,935][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0589, 0.1013, 0.0577, 0.0795, 0.0593, 0.0752, 0.0870, 0.0703, 0.0721,
        0.0707, 0.1005, 0.1093, 0.0583], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,935][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0062, 0.0932, 0.2035, 0.0738, 0.0550, 0.0376, 0.0404, 0.0678, 0.1062,
        0.1682, 0.0826, 0.0512, 0.0143], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,935][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0146, 0.0403, 0.2256, 0.0457, 0.1075, 0.0435, 0.0275, 0.0729, 0.1182,
        0.0867, 0.0640, 0.1129, 0.0405], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,936][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0040, 0.0338, 0.2536, 0.0501, 0.0942, 0.0349, 0.0228, 0.0576, 0.1181,
        0.1616, 0.0793, 0.0678, 0.0221], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,936][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.1569, 0.0974, 0.0638, 0.0721, 0.0633, 0.0477, 0.0695, 0.0775, 0.0875,
        0.0523, 0.0662, 0.0965, 0.0493], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,937][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0219, 0.0549, 0.1925, 0.0793, 0.0454, 0.0499, 0.0225, 0.0699, 0.1801,
        0.1186, 0.0937, 0.0543, 0.0171], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,940][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0256, 0.1048, 0.1384, 0.0790, 0.0513, 0.0420, 0.0523, 0.1178, 0.0974,
        0.1451, 0.0707, 0.0519, 0.0237], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,946][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0256, 0.1156, 0.1213, 0.0784, 0.0607, 0.0688, 0.0620, 0.0954, 0.0775,
        0.1145, 0.0912, 0.0666, 0.0224], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,950][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.3965, 0.0485, 0.1521, 0.0283, 0.0476, 0.0377, 0.0392, 0.0479, 0.0676,
        0.0325, 0.0275, 0.0344, 0.0402], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,952][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.3774, 0.0759, 0.1003, 0.0230, 0.0351, 0.0466, 0.0323, 0.0439, 0.0638,
        0.0828, 0.0495, 0.0363, 0.0331], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,953][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.1395, 0.1197, 0.0676, 0.0604, 0.0389, 0.0779, 0.0904, 0.0551, 0.0758,
        0.1059, 0.0741, 0.0509, 0.0436], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:30,953][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.2646, 0.1493, 0.0759, 0.0817, 0.0331, 0.0411, 0.0363, 0.0402, 0.0325,
        0.0771, 0.0712, 0.0241, 0.0433, 0.0295], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,953][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0370, 0.1010, 0.0745, 0.1124, 0.0633, 0.0745, 0.0751, 0.0683, 0.0343,
        0.0539, 0.1064, 0.0713, 0.0643, 0.0638], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,954][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0055, 0.0882, 0.2660, 0.0522, 0.0584, 0.0276, 0.0311, 0.0562, 0.0968,
        0.1515, 0.0472, 0.0319, 0.0149, 0.0724], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,954][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0153, 0.0412, 0.2743, 0.0345, 0.1087, 0.0335, 0.0190, 0.0605, 0.1132,
        0.0728, 0.0573, 0.0784, 0.0411, 0.0502], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,955][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0114, 0.0342, 0.3872, 0.0240, 0.1081, 0.0232, 0.0215, 0.0304, 0.0918,
        0.1001, 0.0338, 0.0452, 0.0244, 0.0649], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,955][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0767, 0.1060, 0.0568, 0.0846, 0.0519, 0.0478, 0.0620, 0.0548, 0.0617,
        0.0846, 0.1028, 0.0851, 0.0521, 0.0732], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,958][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0198, 0.0718, 0.2415, 0.0544, 0.0578, 0.0347, 0.0149, 0.0436, 0.1795,
        0.0998, 0.0568, 0.0443, 0.0211, 0.0600], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,964][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0305, 0.1025, 0.1370, 0.0730, 0.0471, 0.0397, 0.0416, 0.1007, 0.0963,
        0.1455, 0.0530, 0.0494, 0.0187, 0.0649], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,969][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0388, 0.0792, 0.1786, 0.0602, 0.0792, 0.0489, 0.0524, 0.0822, 0.0490,
        0.1029, 0.0791, 0.0592, 0.0319, 0.0585], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,970][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.4971, 0.0400, 0.0790, 0.0217, 0.0440, 0.0390, 0.0329, 0.0405, 0.0625,
        0.0290, 0.0206, 0.0335, 0.0338, 0.0266], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,971][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.4009, 0.0532, 0.1672, 0.0220, 0.0378, 0.0291, 0.0213, 0.0278, 0.0673,
        0.0623, 0.0369, 0.0272, 0.0261, 0.0209], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,971][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.1419, 0.1482, 0.0584, 0.0556, 0.0326, 0.0629, 0.0616, 0.0487, 0.0612,
        0.1072, 0.0745, 0.0514, 0.0357, 0.0600], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:30,971][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2636, 0.1009, 0.0504, 0.0773, 0.0268, 0.0417, 0.0369, 0.0313, 0.0412,
        0.0858, 0.0840, 0.0202, 0.0408, 0.0348, 0.0643], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,972][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0167, 0.0830, 0.0248, 0.1205, 0.0334, 0.0485, 0.0685, 0.0403, 0.0350,
        0.1019, 0.1698, 0.0484, 0.0449, 0.0754, 0.0890], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,972][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0051, 0.0766, 0.2440, 0.0517, 0.0657, 0.0258, 0.0313, 0.0543, 0.0791,
        0.1486, 0.0478, 0.0442, 0.0159, 0.0902, 0.0197], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,975][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0158, 0.0373, 0.2169, 0.0354, 0.1084, 0.0359, 0.0192, 0.0648, 0.1097,
        0.0729, 0.0527, 0.0976, 0.0454, 0.0577, 0.0303], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,980][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0122, 0.0289, 0.3159, 0.0252, 0.1345, 0.0266, 0.0222, 0.0251, 0.0752,
        0.0961, 0.0365, 0.0449, 0.0371, 0.0858, 0.0339], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,985][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0541, 0.0807, 0.0436, 0.0808, 0.0561, 0.0438, 0.0565, 0.0504, 0.0776,
        0.0919, 0.0948, 0.0673, 0.0520, 0.0880, 0.0625], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,987][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0237, 0.0317, 0.2736, 0.0363, 0.0693, 0.0392, 0.0135, 0.0427, 0.1548,
        0.0636, 0.0480, 0.0592, 0.0257, 0.0815, 0.0372], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,988][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0193, 0.0572, 0.1944, 0.0575, 0.0677, 0.0342, 0.0591, 0.0742, 0.0729,
        0.1174, 0.0533, 0.0328, 0.0314, 0.0862, 0.0424], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,988][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0220, 0.0640, 0.1450, 0.0648, 0.0746, 0.0435, 0.0549, 0.0646, 0.0606,
        0.1134, 0.0877, 0.0509, 0.0324, 0.0790, 0.0426], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,989][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4261, 0.0455, 0.0685, 0.0217, 0.0386, 0.0370, 0.0317, 0.0440, 0.0628,
        0.0348, 0.0252, 0.0431, 0.0370, 0.0377, 0.0464], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,989][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4172, 0.0662, 0.1127, 0.0195, 0.0191, 0.0297, 0.0250, 0.0318, 0.0484,
        0.0806, 0.0509, 0.0281, 0.0179, 0.0209, 0.0320], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,990][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1474, 0.1575, 0.0595, 0.0511, 0.0280, 0.0455, 0.0437, 0.0358, 0.0501,
        0.1210, 0.0773, 0.0484, 0.0284, 0.0472, 0.0592], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:30,991][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:30,992][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[20192],
        [13398],
        [26297],
        [15593],
        [33148],
        [26650],
        [19879],
        [22669],
        [20918],
        [14603],
        [ 8715],
        [36147],
        [36087],
        [18694],
        [15036]], device='cuda:0')
[2024-07-24 10:25:30,993][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21327],
        [11926],
        [25502],
        [13834],
        [33543],
        [27874],
        [20808],
        [23904],
        [24963],
        [17107],
        [10237],
        [40066],
        [40758],
        [21308],
        [17495]], device='cuda:0')
[2024-07-24 10:25:30,995][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2949],
        [2326],
        [2388],
        [1998],
        [2436],
        [1844],
        [1259],
        [1088],
        [ 953],
        [1130],
        [ 783],
        [ 660],
        [ 752],
        [ 695],
        [ 728]], device='cuda:0')
[2024-07-24 10:25:30,998][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13527],
        [26187],
        [28847],
        [12881],
        [13171],
        [12439],
        [13413],
        [14971],
        [14397],
        [14600],
        [15041],
        [18849],
        [15872],
        [20586],
        [18352]], device='cuda:0')
[2024-07-24 10:25:31,000][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19097],
        [17835],
        [16898],
        [15999],
        [15736],
        [15483],
        [15439],
        [14771],
        [14658],
        [14338],
        [14082],
        [14129],
        [14240],
        [13897],
        [13990]], device='cuda:0')
[2024-07-24 10:25:31,003][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15706],
        [13538],
        [ 6827],
        [ 7314],
        [ 7224],
        [ 7168],
        [ 6989],
        [ 7047],
        [ 7376],
        [ 7546],
        [ 7687],
        [ 7982],
        [ 7948],
        [ 8023],
        [ 8141]], device='cuda:0')
[2024-07-24 10:25:31,005][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4793],
        [ 7665],
        [12321],
        [15795],
        [16434],
        [16829],
        [18338],
        [20502],
        [21612],
        [21564],
        [22732],
        [23379],
        [22379],
        [22494],
        [22923]], device='cuda:0')
[2024-07-24 10:25:31,008][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[2151],
        [3251],
        [5475],
        [6414],
        [6341],
        [4775],
        [5000],
        [4743],
        [4761],
        [5036],
        [5171],
        [5062],
        [4981],
        [5367],
        [5484]], device='cuda:0')
[2024-07-24 10:25:31,010][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[22058],
        [27750],
        [30097],
        [31926],
        [32736],
        [32857],
        [33745],
        [34360],
        [33738],
        [33400],
        [33499],
        [34173],
        [34021],
        [33826],
        [33669]], device='cuda:0')
[2024-07-24 10:25:31,011][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15195],
        [21722],
        [27674],
        [28520],
        [29205],
        [28002],
        [27445],
        [27019],
        [26860],
        [26830],
        [27148],
        [26931],
        [26382],
        [25724],
        [25180]], device='cuda:0')
[2024-07-24 10:25:31,012][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[6510],
        [2011],
        [2214],
        [2451],
        [2437],
        [2586],
        [2780],
        [2936],
        [3052],
        [3044],
        [3070],
        [3012],
        [3000],
        [3054],
        [3026]], device='cuda:0')
[2024-07-24 10:25:31,013][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39777],
        [42288],
        [44798],
        [47186],
        [48705],
        [47245],
        [46057],
        [45505],
        [44252],
        [43398],
        [44393],
        [43589],
        [44204],
        [45550],
        [45395]], device='cuda:0')
[2024-07-24 10:25:31,015][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3925],
        [ 5045],
        [16951],
        [26604],
        [12495],
        [25489],
        [16628],
        [21182],
        [23830],
        [24752],
        [25844],
        [16637],
        [12024],
        [15522],
        [13449]], device='cuda:0')
[2024-07-24 10:25:31,017][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13052],
        [34111],
        [ 7819],
        [22389],
        [12302],
        [15171],
        [14157],
        [15591],
        [14476],
        [22102],
        [22526],
        [19166],
        [17579],
        [19115],
        [19722]], device='cuda:0')
[2024-07-24 10:25:31,020][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[41978],
        [48553],
        [48206],
        [49013],
        [48430],
        [47888],
        [48372],
        [48510],
        [48260],
        [48526],
        [48613],
        [48385],
        [48084],
        [48886],
        [48999]], device='cuda:0')
[2024-07-24 10:25:31,022][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[40215],
        [ 9529],
        [ 9925],
        [ 9647],
        [ 6170],
        [ 2875],
        [ 5567],
        [ 3333],
        [ 2784],
        [ 2836],
        [ 2562],
        [ 2325],
        [ 2083],
        [ 2526],
        [ 2227]], device='cuda:0')
[2024-07-24 10:25:31,025][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17869],
        [31800],
        [29350],
        [34296],
        [33261],
        [34368],
        [34009],
        [33700],
        [33442],
        [31530],
        [31235],
        [30225],
        [31072],
        [31243],
        [29212]], device='cuda:0')
[2024-07-24 10:25:31,027][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23343],
        [31595],
        [29688],
        [23797],
        [26481],
        [24095],
        [24143],
        [25605],
        [26739],
        [27243],
        [28474],
        [27234],
        [29510],
        [28189],
        [27836]], device='cuda:0')
[2024-07-24 10:25:31,030][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 4399],
        [14874],
        [ 9775],
        [11827],
        [16550],
        [17794],
        [18778],
        [17777],
        [16567],
        [17493],
        [17609],
        [19543],
        [20431],
        [19658],
        [20810]], device='cuda:0')
[2024-07-24 10:25:31,032][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16348],
        [10093],
        [12827],
        [13062],
        [12693],
        [11623],
        [12343],
        [12163],
        [13460],
        [13610],
        [13220],
        [12956],
        [12812],
        [12597],
        [11726]], device='cuda:0')
[2024-07-24 10:25:31,033][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28806],
        [17386],
        [22349],
        [18953],
        [20041],
        [20708],
        [19591],
        [19563],
        [18281],
        [17803],
        [17596],
        [17997],
        [16622],
        [16817],
        [16472]], device='cuda:0')
[2024-07-24 10:25:31,034][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38959],
        [19480],
        [ 3816],
        [ 2913],
        [ 3162],
        [ 3114],
        [ 3567],
        [ 4905],
        [ 5171],
        [ 6350],
        [ 7762],
        [ 8022],
        [10230],
        [ 8269],
        [ 7969]], device='cuda:0')
[2024-07-24 10:25:31,035][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[28089],
        [17270],
        [27274],
        [23296],
        [26286],
        [25484],
        [23205],
        [23207],
        [22864],
        [19375],
        [18189],
        [20611],
        [20022],
        [20370],
        [22927]], device='cuda:0')
[2024-07-24 10:25:31,038][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34754],
        [ 5418],
        [11714],
        [10101],
        [11439],
        [10679],
        [11122],
        [11345],
        [11057],
        [11275],
        [10772],
        [10381],
        [10124],
        [10716],
        [10870]], device='cuda:0')
[2024-07-24 10:25:31,040][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 3557],
        [ 4084],
        [ 4927],
        [ 4870],
        [ 7538],
        [10644],
        [ 7338],
        [ 8914],
        [ 9481],
        [ 9040],
        [ 8686],
        [ 8704],
        [10569],
        [ 9470],
        [ 9114]], device='cuda:0')
[2024-07-24 10:25:31,043][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38749],
        [37744],
        [35282],
        [31981],
        [34734],
        [17493],
        [31588],
        [24935],
        [26091],
        [14070],
        [13287],
        [24951],
        [19027],
        [16506],
        [20708]], device='cuda:0')
[2024-07-24 10:25:31,045][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21131],
        [ 3037],
        [ 8776],
        [ 4889],
        [ 7069],
        [ 5830],
        [ 6741],
        [ 7199],
        [ 5894],
        [ 4213],
        [ 4216],
        [ 5041],
        [ 5710],
        [ 4692],
        [ 4768]], device='cuda:0')
[2024-07-24 10:25:31,048][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25429],
        [42431],
        [42271],
        [43844],
        [42064],
        [44423],
        [42752],
        [43071],
        [43750],
        [44773],
        [44985],
        [44080],
        [43930],
        [44451],
        [44488]], device='cuda:0')
[2024-07-24 10:25:31,050][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7348],
        [ 8477],
        [10887],
        [12367],
        [10874],
        [13658],
        [10943],
        [10762],
        [ 9800],
        [12474],
        [12962],
        [10675],
        [ 9569],
        [ 9666],
        [ 8308]], device='cuda:0')
[2024-07-24 10:25:31,053][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677],
        [30677]], device='cuda:0')
[2024-07-24 10:25:31,090][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:31,090][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,090][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,091][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,091][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,091][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,092][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,092][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,092][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,093][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,093][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,093][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,094][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,094][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,094][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2117, 0.7883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,095][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3278, 0.6722], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,097][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6728, 0.3272], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,100][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8994, 0.1006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,104][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4397, 0.5603], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,110][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2981, 0.7019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,112][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1361, 0.8639], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,112][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1303, 0.8697], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,112][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3412, 0.6588], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,113][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4365, 0.5635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,113][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0458, 0.9542], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,113][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([9.9851e-01, 1.2375e-03, 2.5319e-04], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,114][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.0453, 0.5832, 0.3714], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,114][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.1648, 0.4390, 0.3962], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,114][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.5985, 0.1016, 0.2998], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,114][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.9314, 0.0245, 0.0442], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,115][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.3170, 0.0436, 0.6394], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,118][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.4807, 0.0687, 0.4507], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,122][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.2711, 0.2621, 0.4668], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,128][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.1807, 0.3607, 0.4586], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,130][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.0705, 0.8448, 0.0847], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,130][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.2562, 0.3289, 0.4149], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,130][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.0403, 0.3379, 0.6218], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,131][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9837, 0.0014, 0.0016, 0.0133], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,131][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0532, 0.5457, 0.3155, 0.0856], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,131][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1490, 0.2780, 0.2731, 0.2998], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,132][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3685, 0.1137, 0.4323, 0.0855], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,132][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9261, 0.0270, 0.0363, 0.0107], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,132][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0744, 0.0335, 0.7831, 0.1089], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,133][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2265, 0.1718, 0.0923, 0.5094], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,133][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0634, 0.2646, 0.5086, 0.1634], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,136][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0213, 0.2784, 0.5251, 0.1752], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,140][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3165, 0.2378, 0.2968, 0.1490], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,146][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1375, 0.2194, 0.2835, 0.3596], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,148][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0069, 0.2643, 0.5739, 0.1549], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,148][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.9578, 0.0020, 0.0042, 0.0347, 0.0013], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,149][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0443, 0.4611, 0.2800, 0.0842, 0.1304], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,149][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0902, 0.2376, 0.2152, 0.2519, 0.2052], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,149][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.2871, 0.1136, 0.3585, 0.0873, 0.1534], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,149][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.8784, 0.0316, 0.0525, 0.0099, 0.0276], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,150][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.1355, 0.0261, 0.5176, 0.0830, 0.2378], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,150][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.4579, 0.0872, 0.1807, 0.1414, 0.1328], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,150][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.1095, 0.1578, 0.4755, 0.1261, 0.1311], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,151][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0428, 0.2383, 0.4955, 0.1395, 0.0838], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,152][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0225, 0.3561, 0.0971, 0.4013, 0.1230], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,158][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0957, 0.1562, 0.1990, 0.2733, 0.2758], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,162][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0094, 0.1777, 0.5137, 0.1567, 0.1425], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,166][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.9063, 0.0032, 0.0020, 0.0818, 0.0010, 0.0058], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,166][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0400, 0.3951, 0.2973, 0.0742, 0.1489, 0.0445], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,167][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0796, 0.1964, 0.1756, 0.2065, 0.1690, 0.1730], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,167][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1220, 0.1214, 0.4011, 0.0984, 0.1721, 0.0849], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,167][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.8844, 0.0247, 0.0291, 0.0112, 0.0201, 0.0305], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,168][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0480, 0.0189, 0.5208, 0.0722, 0.2321, 0.1079], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,168][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2578, 0.1261, 0.0670, 0.0789, 0.0574, 0.4129], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,168][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0301, 0.1842, 0.4308, 0.1423, 0.1457, 0.0670], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,169][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0218, 0.2396, 0.4323, 0.1562, 0.0965, 0.0535], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,169][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0006, 0.3968, 0.0596, 0.3313, 0.1613, 0.0505], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,170][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0706, 0.1437, 0.1873, 0.2397, 0.2144, 0.1443], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,174][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0058, 0.1660, 0.4807, 0.1408, 0.1403, 0.0663], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,177][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.6967e-01, 1.0867e-03, 1.1245e-03, 2.2458e-02, 3.7826e-04, 2.1140e-03,
        3.1652e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,183][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0375, 0.3948, 0.2586, 0.0661, 0.1264, 0.0441, 0.0725],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,185][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0716, 0.1565, 0.1464, 0.1656, 0.1404, 0.1447, 0.1747],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,185][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1648, 0.1027, 0.3413, 0.0878, 0.1585, 0.0830, 0.0619],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,185][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8893, 0.0215, 0.0279, 0.0062, 0.0100, 0.0288, 0.0163],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,186][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0336, 0.0164, 0.4768, 0.0635, 0.2134, 0.1052, 0.0911],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,186][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2314, 0.0859, 0.0978, 0.0841, 0.0333, 0.1343, 0.3331],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,186][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0371, 0.1748, 0.3758, 0.1566, 0.1172, 0.0700, 0.0686],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,187][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0269, 0.2113, 0.3871, 0.1422, 0.0836, 0.0728, 0.0762],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,187][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0029, 0.2015, 0.0772, 0.3421, 0.1097, 0.0857, 0.1809],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,187][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0516, 0.1059, 0.1442, 0.1913, 0.1576, 0.1186, 0.2307],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,188][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0046, 0.1624, 0.4328, 0.1445, 0.1122, 0.0797, 0.0639],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,189][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.8605e-01, 3.6116e-04, 2.8033e-04, 9.8501e-03, 8.7533e-05, 7.4633e-04,
        1.6233e-03, 1.0055e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,193][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0374, 0.3883, 0.2363, 0.0578, 0.1120, 0.0352, 0.0632, 0.0699],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,199][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0596, 0.1443, 0.1280, 0.1487, 0.1219, 0.1311, 0.1518, 0.1146],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,203][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1461, 0.0913, 0.3261, 0.0808, 0.1349, 0.0723, 0.0641, 0.0845],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,204][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.7074, 0.0371, 0.0520, 0.0237, 0.0282, 0.0396, 0.0680, 0.0440],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,204][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0527, 0.0204, 0.3787, 0.0750, 0.1903, 0.1158, 0.0976, 0.0695],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,204][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2312, 0.0624, 0.0694, 0.1773, 0.0326, 0.0944, 0.1380, 0.1946],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,205][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0396, 0.1606, 0.3319, 0.1193, 0.1113, 0.0633, 0.0607, 0.1134],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,205][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0194, 0.1953, 0.3141, 0.1218, 0.0637, 0.0626, 0.0885, 0.1345],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,205][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0015, 0.1196, 0.0401, 0.3047, 0.1093, 0.0549, 0.3341, 0.0358],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,206][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0495, 0.0906, 0.1300, 0.1623, 0.1466, 0.1038, 0.1932, 0.1241],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,206][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0053, 0.1385, 0.4141, 0.1025, 0.1117, 0.0593, 0.0581, 0.1105],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,206][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([9.8282e-01, 3.6131e-04, 7.7382e-05, 1.3523e-02, 3.3016e-05, 5.7955e-04,
        1.3316e-03, 9.2526e-04, 3.5153e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,209][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0485, 0.3191, 0.2333, 0.0549, 0.1118, 0.0314, 0.0551, 0.0613, 0.0847],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,214][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0502, 0.1246, 0.1153, 0.1335, 0.1119, 0.1169, 0.1374, 0.1032, 0.1070],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,220][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1646, 0.0826, 0.2824, 0.0593, 0.1085, 0.0579, 0.0499, 0.0726, 0.1220],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,222][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.5398, 0.0360, 0.0754, 0.0164, 0.0538, 0.0761, 0.0619, 0.0651, 0.0756],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,222][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0419, 0.0191, 0.3706, 0.0679, 0.1908, 0.1052, 0.0927, 0.0637, 0.0481],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,223][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.2324, 0.0568, 0.1719, 0.1090, 0.0483, 0.0658, 0.0772, 0.0321, 0.2065],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,223][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0411, 0.1415, 0.2768, 0.1048, 0.0846, 0.0574, 0.0627, 0.0937, 0.1376],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,223][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0350, 0.1622, 0.2809, 0.0908, 0.0518, 0.0470, 0.0746, 0.1252, 0.1325],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,224][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0028, 0.1570, 0.0700, 0.1739, 0.1165, 0.0411, 0.2129, 0.0644, 0.1614],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,224][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0416, 0.0774, 0.1003, 0.1352, 0.1189, 0.0860, 0.1798, 0.1045, 0.1564],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,224][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0061, 0.1102, 0.3289, 0.0772, 0.0779, 0.0463, 0.0505, 0.1020, 0.2008],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,225][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.7652e-01, 5.2050e-04, 2.4938e-04, 8.4171e-03, 8.8166e-05, 6.3377e-04,
        1.4698e-03, 1.2722e-03, 7.5492e-04, 1.0073e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,225][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0298, 0.2637, 0.2203, 0.0506, 0.1124, 0.0331, 0.0582, 0.0692, 0.0956,
        0.0669], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,228][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0539, 0.1087, 0.1010, 0.1178, 0.0982, 0.1011, 0.1203, 0.0903, 0.0951,
        0.1136], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,233][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0819, 0.0729, 0.2632, 0.0647, 0.1086, 0.0592, 0.0507, 0.0716, 0.1244,
        0.1028], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,239][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5886, 0.0458, 0.0507, 0.0217, 0.0395, 0.0492, 0.0547, 0.0453, 0.0428,
        0.0616], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,241][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0377, 0.0123, 0.3851, 0.0448, 0.1619, 0.0764, 0.0620, 0.0510, 0.0374,
        0.1314], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,241][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0943, 0.1454, 0.0776, 0.2161, 0.0324, 0.0471, 0.0708, 0.0142, 0.0257,
        0.2765], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,241][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0115, 0.1297, 0.2332, 0.1009, 0.0647, 0.0396, 0.0442, 0.0863, 0.1141,
        0.1758], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,242][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0052, 0.1316, 0.2206, 0.1006, 0.0378, 0.0353, 0.0518, 0.1281, 0.1501,
        0.1389], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,242][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0054, 0.0512, 0.0497, 0.0801, 0.0802, 0.0560, 0.1396, 0.0548, 0.2637,
        0.2194], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,242][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0334, 0.0922, 0.1128, 0.1165, 0.1251, 0.0691, 0.1467, 0.0858, 0.1309,
        0.0874], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,243][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0015, 0.1027, 0.2535, 0.0720, 0.0626, 0.0373, 0.0346, 0.0840, 0.1873,
        0.1645], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,243][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.2954e-01, 1.0992e-03, 5.2837e-04, 1.0088e-02, 1.7581e-04, 1.0391e-03,
        2.0973e-03, 2.0130e-03, 1.2017e-03, 1.2039e-02, 4.0181e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,243][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0255, 0.2592, 0.2210, 0.0444, 0.1089, 0.0302, 0.0547, 0.0658, 0.0918,
        0.0606, 0.0379], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,244][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0505, 0.0984, 0.0937, 0.1056, 0.0888, 0.0900, 0.1082, 0.0823, 0.0857,
        0.1004, 0.0964], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,247][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1006, 0.0549, 0.2675, 0.0519, 0.1071, 0.0501, 0.0438, 0.0688, 0.1194,
        0.0897, 0.0462], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,251][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6499, 0.0370, 0.0413, 0.0173, 0.0342, 0.0424, 0.0381, 0.0410, 0.0315,
        0.0443, 0.0229], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,257][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0309, 0.0113, 0.3645, 0.0389, 0.1490, 0.0734, 0.0576, 0.0469, 0.0365,
        0.1254, 0.0658], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,259][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1433, 0.0884, 0.0495, 0.2577, 0.0228, 0.0503, 0.0563, 0.0192, 0.0230,
        0.1151, 0.1743], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,260][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0082, 0.1250, 0.1951, 0.0868, 0.0522, 0.0330, 0.0356, 0.0756, 0.1008,
        0.1795, 0.1082], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,260][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0030, 0.1080, 0.2000, 0.0807, 0.0316, 0.0305, 0.0466, 0.1115, 0.1538,
        0.1522, 0.0822], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,260][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0111, 0.0688, 0.0624, 0.0612, 0.0806, 0.0532, 0.1220, 0.0441, 0.2027,
        0.2090, 0.0849], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,261][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0285, 0.0864, 0.0981, 0.1014, 0.1140, 0.0668, 0.1276, 0.0795, 0.1254,
        0.0816, 0.0907], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,261][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0008, 0.0898, 0.2620, 0.0547, 0.0598, 0.0286, 0.0267, 0.0734, 0.1832,
        0.1365, 0.0844], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,261][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([8.2783e-01, 4.4504e-04, 2.4370e-04, 1.5620e-02, 7.8816e-05, 9.0341e-04,
        2.8790e-03, 1.8399e-03, 1.0459e-03, 2.1469e-02, 1.2678e-01, 8.6308e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,262][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0249, 0.2116, 0.2337, 0.0507, 0.1107, 0.0271, 0.0510, 0.0590, 0.0759,
        0.0580, 0.0372, 0.0601], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,262][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0363, 0.0910, 0.0836, 0.1005, 0.0832, 0.0871, 0.0998, 0.0769, 0.0788,
        0.0979, 0.0939, 0.0709], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,265][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0749, 0.0639, 0.2586, 0.0501, 0.0942, 0.0498, 0.0467, 0.0659, 0.1073,
        0.0901, 0.0564, 0.0421], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,270][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.5869, 0.0345, 0.0470, 0.0132, 0.0227, 0.0511, 0.0607, 0.0465, 0.0312,
        0.0616, 0.0220, 0.0228], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,276][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0703, 0.0135, 0.2744, 0.0435, 0.1271, 0.0661, 0.0568, 0.0467, 0.0310,
        0.1254, 0.0674, 0.0778], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,278][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.3336, 0.0710, 0.0896, 0.1006, 0.0212, 0.0335, 0.0398, 0.0522, 0.0676,
        0.0728, 0.0571, 0.0609], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,278][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0128, 0.0817, 0.1972, 0.0813, 0.0592, 0.0383, 0.0387, 0.0761, 0.1356,
        0.1472, 0.1024, 0.0294], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,279][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0053, 0.1004, 0.2186, 0.0786, 0.0400, 0.0346, 0.0476, 0.0889, 0.1259,
        0.1406, 0.0826, 0.0369], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,279][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0012, 0.0663, 0.0168, 0.1399, 0.0252, 0.0216, 0.0998, 0.0178, 0.0708,
        0.2962, 0.2298, 0.0147], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,279][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0341, 0.0703, 0.0752, 0.0887, 0.0902, 0.0572, 0.1130, 0.0666, 0.1033,
        0.0864, 0.1016, 0.1136], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,280][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0014, 0.0491, 0.2289, 0.0471, 0.0628, 0.0381, 0.0362, 0.0750, 0.1635,
        0.1495, 0.0991, 0.0492], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,280][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.3504, 0.0018, 0.0036, 0.0545, 0.0012, 0.0051, 0.0079, 0.0239, 0.0096,
        0.0994, 0.4323, 0.0093, 0.0009], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,280][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0235, 0.1920, 0.2099, 0.0501, 0.1055, 0.0271, 0.0493, 0.0537, 0.0724,
        0.0617, 0.0385, 0.0645, 0.0518], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,281][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0277, 0.0865, 0.0762, 0.0930, 0.0742, 0.0805, 0.0930, 0.0698, 0.0708,
        0.0961, 0.0911, 0.0696, 0.0715], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,284][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0724, 0.0569, 0.2020, 0.0524, 0.0888, 0.0549, 0.0485, 0.0723, 0.1036,
        0.0985, 0.0610, 0.0573, 0.0315], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,289][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.5837, 0.0312, 0.0525, 0.0111, 0.0244, 0.0391, 0.0299, 0.0558, 0.0377,
        0.0547, 0.0186, 0.0311, 0.0303], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,294][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0238, 0.0108, 0.2830, 0.0400, 0.1252, 0.0690, 0.0574, 0.0414, 0.0290,
        0.1276, 0.0713, 0.0910, 0.0303], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,297][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.2471, 0.0540, 0.0841, 0.0864, 0.0604, 0.0843, 0.0817, 0.0277, 0.0221,
        0.0969, 0.0826, 0.0120, 0.0606], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,297][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0166, 0.0623, 0.1978, 0.0641, 0.0668, 0.0404, 0.0390, 0.0786, 0.1123,
        0.1428, 0.1084, 0.0451, 0.0255], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,297][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0051, 0.0903, 0.2153, 0.0735, 0.0428, 0.0308, 0.0413, 0.0909, 0.1217,
        0.1455, 0.0852, 0.0510, 0.0065], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,298][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0002, 0.0870, 0.0127, 0.1295, 0.0170, 0.0283, 0.1214, 0.0578, 0.1394,
        0.1502, 0.1553, 0.0882, 0.0130], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,298][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0258, 0.0595, 0.0559, 0.0704, 0.0720, 0.0473, 0.0942, 0.0597, 0.0964,
        0.0742, 0.0865, 0.1180, 0.1400], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,298][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0009, 0.0475, 0.1905, 0.0518, 0.0636, 0.0337, 0.0266, 0.0678, 0.1596,
        0.1525, 0.1107, 0.0817, 0.0131], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,299][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([9.0355e-01, 5.1442e-04, 1.5787e-04, 9.4201e-03, 4.7406e-05, 5.1430e-04,
        1.2881e-03, 1.0960e-03, 6.8674e-04, 1.1456e-02, 5.7445e-02, 6.6253e-04,
        4.0013e-05, 1.3125e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,299][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0221, 0.1894, 0.2051, 0.0425, 0.0948, 0.0275, 0.0444, 0.0532, 0.0743,
        0.0546, 0.0351, 0.0654, 0.0522, 0.0394], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,299][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0325, 0.0790, 0.0738, 0.0835, 0.0716, 0.0761, 0.0868, 0.0642, 0.0671,
        0.0837, 0.0784, 0.0643, 0.0668, 0.0721], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,303][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0921, 0.0507, 0.2304, 0.0471, 0.0949, 0.0436, 0.0366, 0.0556, 0.1067,
        0.0769, 0.0460, 0.0436, 0.0300, 0.0458], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,307][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.3673, 0.0321, 0.0497, 0.0111, 0.0332, 0.0642, 0.0410, 0.0467, 0.0396,
        0.0406, 0.0149, 0.0332, 0.0322, 0.1941], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,313][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0400, 0.0111, 0.2753, 0.0387, 0.1192, 0.0615, 0.0549, 0.0404, 0.0294,
        0.1174, 0.0635, 0.0838, 0.0301, 0.0348], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,315][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1000, 0.0399, 0.0829, 0.0405, 0.0445, 0.0324, 0.0367, 0.0079, 0.0432,
        0.1011, 0.0338, 0.0091, 0.0446, 0.3835], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,316][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0177, 0.0935, 0.1707, 0.0778, 0.0633, 0.0380, 0.0412, 0.0652, 0.0985,
        0.1336, 0.0920, 0.0310, 0.0221, 0.0553], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,316][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0100, 0.1202, 0.2019, 0.0747, 0.0393, 0.0269, 0.0477, 0.0827, 0.1063,
        0.1154, 0.0614, 0.0387, 0.0064, 0.0683], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,316][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0017, 0.1211, 0.0259, 0.0948, 0.0321, 0.0280, 0.0749, 0.0368, 0.0704,
        0.2095, 0.1636, 0.0701, 0.0471, 0.0240], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,317][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0217, 0.0514, 0.0543, 0.0750, 0.0679, 0.0522, 0.0976, 0.0590, 0.0849,
        0.0740, 0.0882, 0.0947, 0.1010, 0.0781], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,317][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0024, 0.0727, 0.1942, 0.0528, 0.0496, 0.0302, 0.0306, 0.0686, 0.1511,
        0.1244, 0.0837, 0.0554, 0.0094, 0.0748], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,317][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.4082e-01, 4.6396e-04, 1.7853e-04, 5.6849e-03, 5.1289e-05, 3.0772e-04,
        8.6548e-04, 6.8290e-04, 4.9053e-04, 6.5197e-03, 2.9939e-02, 4.8086e-04,
        3.9418e-05, 7.5571e-03, 5.9230e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,318][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0244, 0.1558, 0.2078, 0.0385, 0.1011, 0.0262, 0.0431, 0.0481, 0.0688,
        0.0508, 0.0340, 0.0666, 0.0533, 0.0417, 0.0397], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,318][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0326, 0.0730, 0.0681, 0.0792, 0.0666, 0.0678, 0.0794, 0.0604, 0.0621,
        0.0773, 0.0736, 0.0595, 0.0623, 0.0680, 0.0701], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,322][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1097, 0.0455, 0.2099, 0.0409, 0.1000, 0.0424, 0.0350, 0.0550, 0.0917,
        0.0656, 0.0422, 0.0486, 0.0334, 0.0467, 0.0333], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,327][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5604, 0.0284, 0.0336, 0.0111, 0.0210, 0.0368, 0.0276, 0.0283, 0.0242,
        0.0338, 0.0152, 0.0139, 0.0206, 0.1265, 0.0185], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,332][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0336, 0.0100, 0.2978, 0.0329, 0.1209, 0.0518, 0.0449, 0.0369, 0.0282,
        0.1067, 0.0539, 0.0731, 0.0286, 0.0326, 0.0479], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,334][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1571, 0.0543, 0.0925, 0.1134, 0.0312, 0.0440, 0.0442, 0.0053, 0.0244,
        0.0900, 0.0715, 0.0089, 0.0306, 0.0206, 0.2122], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,334][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0188, 0.0825, 0.1704, 0.0758, 0.0549, 0.0350, 0.0369, 0.0668, 0.0860,
        0.1319, 0.0956, 0.0295, 0.0218, 0.0514, 0.0427], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,335][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0119, 0.0846, 0.2104, 0.0623, 0.0407, 0.0245, 0.0418, 0.0770, 0.1014,
        0.1110, 0.0588, 0.0482, 0.0076, 0.0691, 0.0509], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,335][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0010, 0.0444, 0.0165, 0.0729, 0.0335, 0.0335, 0.1044, 0.0270, 0.1169,
        0.2233, 0.0993, 0.0376, 0.0399, 0.0490, 0.1008], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,335][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0189, 0.0567, 0.0655, 0.0653, 0.0693, 0.0429, 0.0851, 0.0500, 0.0775,
        0.0563, 0.0686, 0.0813, 0.0999, 0.0699, 0.0929], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,336][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0023, 0.0503, 0.2423, 0.0449, 0.0714, 0.0255, 0.0288, 0.0597, 0.1415,
        0.0957, 0.0687, 0.0525, 0.0132, 0.0686, 0.0345], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,371][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:31,374][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,376][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,380][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,383][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,385][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,385][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,386][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,386][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,386][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,386][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,387][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,387][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,387][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4131, 0.5869], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,388][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0556, 0.9444], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,389][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7344, 0.2656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,392][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6728, 0.3272], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,396][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9968, 0.0032], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,402][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2855, 0.7145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,404][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8538, 0.1462], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,404][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1361, 0.8639], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,405][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1303, 0.8697], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,405][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1136, 0.8864], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,405][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8907, 0.1093], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,405][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3263, 0.6737], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,406][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.1819, 0.2926, 0.5255], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,406][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.0260, 0.2514, 0.7226], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,406][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.4119, 0.2069, 0.3812], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,407][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.5985, 0.1016, 0.2998], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,407][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.9636, 0.0071, 0.0293], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,410][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.1110, 0.3068, 0.5822], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,415][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.8380, 0.0260, 0.1360], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,420][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.2711, 0.2621, 0.4668], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,422][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.1807, 0.3607, 0.4586], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,423][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.0493, 0.7473, 0.2034], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,423][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.8681, 0.0658, 0.0661], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,423][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.3534, 0.3361, 0.3105], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,423][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0974, 0.1998, 0.5836, 0.1192], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,424][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0039, 0.1811, 0.7136, 0.1014], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,424][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5358, 0.0976, 0.2757, 0.0909], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,424][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3685, 0.1137, 0.4323, 0.0855], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,425][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9137e-01, 2.9677e-04, 8.2544e-03, 7.5405e-05], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,425][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0741, 0.2326, 0.5490, 0.1443], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,425][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8702, 0.0350, 0.0686, 0.0262], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,428][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0634, 0.2646, 0.5086, 0.1634], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,429][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0213, 0.2784, 0.5251, 0.1752], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,429][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0702, 0.2632, 0.3486, 0.3180], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,429][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9255, 0.0280, 0.0241, 0.0224], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,429][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1609, 0.2839, 0.3010, 0.2541], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,434][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0662, 0.1507, 0.5124, 0.1203, 0.1504], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,439][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0111, 0.1242, 0.5978, 0.1231, 0.1438], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,442][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.2392, 0.1344, 0.2898, 0.1536, 0.1830], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,442][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.2871, 0.1136, 0.3585, 0.0873, 0.1534], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,443][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.9545, 0.0053, 0.0322, 0.0018, 0.0062], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,443][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0352, 0.1883, 0.4688, 0.1593, 0.1484], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,443][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.7422, 0.0266, 0.1238, 0.0260, 0.0814], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,444][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1095, 0.1578, 0.4755, 0.1261, 0.1311], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,444][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0428, 0.2383, 0.4955, 0.1395, 0.0838], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,444][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0245, 0.2716, 0.1531, 0.3665, 0.1842], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,445][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.8130, 0.0426, 0.0609, 0.0460, 0.0376], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,445][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.1545, 0.2121, 0.2391, 0.1937, 0.2007], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,446][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0292, 0.1727, 0.4408, 0.1247, 0.1443, 0.0883], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,450][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0036, 0.1667, 0.4551, 0.1431, 0.1438, 0.0877], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,455][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1708, 0.1031, 0.2662, 0.1234, 0.1951, 0.1415], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,460][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1220, 0.1214, 0.4011, 0.0984, 0.1721, 0.0849], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,461][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9435, 0.0025, 0.0447, 0.0010, 0.0062, 0.0021], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,461][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0340, 0.1776, 0.4053, 0.1369, 0.1622, 0.0840], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,461][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.6537, 0.0370, 0.1171, 0.0281, 0.0757, 0.0886], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,462][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0301, 0.1842, 0.4308, 0.1423, 0.1457, 0.0670], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,462][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0218, 0.2396, 0.4323, 0.1562, 0.0965, 0.0535], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,462][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0028, 0.2576, 0.1002, 0.3304, 0.1910, 0.1180], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,463][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8068, 0.0433, 0.0565, 0.0419, 0.0309, 0.0206], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,463][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1375, 0.1831, 0.1872, 0.1642, 0.1689, 0.1591], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,463][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0442, 0.1339, 0.4307, 0.1076, 0.1336, 0.0880, 0.0620],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,465][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0051, 0.1594, 0.3903, 0.1322, 0.1481, 0.0746, 0.0904],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,470][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2315, 0.0756, 0.2263, 0.0772, 0.1528, 0.1134, 0.1232],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,475][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1648, 0.1027, 0.3413, 0.0878, 0.1585, 0.0830, 0.0619],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,479][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.8182e-01, 9.3330e-04, 1.3748e-02, 2.6674e-04, 1.5771e-03, 5.5409e-04,
        1.0984e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,479][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0402, 0.1534, 0.3662, 0.1190, 0.1477, 0.0807, 0.0927],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,479][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6286, 0.0344, 0.0962, 0.0309, 0.0616, 0.0670, 0.0814],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,480][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0371, 0.1748, 0.3758, 0.1566, 0.1172, 0.0700, 0.0686],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,480][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0269, 0.2113, 0.3871, 0.1422, 0.0836, 0.0728, 0.0762],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,480][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0065, 0.1606, 0.1124, 0.2920, 0.1367, 0.1465, 0.1453],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,481][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6576, 0.0667, 0.0860, 0.0630, 0.0403, 0.0292, 0.0571],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,481][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1132, 0.1505, 0.1570, 0.1381, 0.1397, 0.1360, 0.1655],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,481][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0486, 0.1224, 0.3880, 0.0946, 0.1051, 0.0745, 0.0678, 0.0991],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,482][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0042, 0.1407, 0.3945, 0.1013, 0.1279, 0.0626, 0.1018, 0.0669],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,485][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1681, 0.0767, 0.2194, 0.0819, 0.1636, 0.1048, 0.1178, 0.0677],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,489][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1461, 0.0913, 0.3261, 0.0808, 0.1349, 0.0723, 0.0641, 0.0845],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,495][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.9468, 0.0028, 0.0347, 0.0010, 0.0055, 0.0021, 0.0037, 0.0035],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,497][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0354, 0.1494, 0.3199, 0.1138, 0.1157, 0.0756, 0.0903, 0.0998],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,497][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.6134, 0.0365, 0.0800, 0.0297, 0.0536, 0.0615, 0.0748, 0.0505],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,498][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0396, 0.1606, 0.3319, 0.1193, 0.1113, 0.0633, 0.0607, 0.1134],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,498][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0194, 0.1953, 0.3141, 0.1218, 0.0637, 0.0626, 0.0885, 0.1345],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,498][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0024, 0.1140, 0.0642, 0.3256, 0.1175, 0.1075, 0.1850, 0.0837],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,499][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.7629, 0.0455, 0.0512, 0.0354, 0.0202, 0.0149, 0.0343, 0.0355],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,499][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1028, 0.1366, 0.1454, 0.1241, 0.1272, 0.1213, 0.1515, 0.0909],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,499][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0501, 0.1168, 0.2684, 0.0828, 0.0828, 0.0794, 0.0573, 0.1091, 0.1531],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,500][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0043, 0.0978, 0.3799, 0.0883, 0.1066, 0.0434, 0.0770, 0.0528, 0.1498],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,500][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1654, 0.0930, 0.1538, 0.0833, 0.1090, 0.0971, 0.1078, 0.0561, 0.1345],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,503][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1646, 0.0826, 0.2824, 0.0593, 0.1085, 0.0579, 0.0499, 0.0726, 0.1220],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,506][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([9.5852e-01, 2.1136e-03, 2.4148e-02, 7.5510e-04, 3.9183e-03, 1.2865e-03,
        2.8110e-03, 2.9081e-03, 3.5421e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,511][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0343, 0.1347, 0.3020, 0.0923, 0.0971, 0.0574, 0.0723, 0.0847, 0.1253],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,515][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.5205, 0.0372, 0.0978, 0.0299, 0.0594, 0.0622, 0.0765, 0.0451, 0.0715],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,516][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0411, 0.1415, 0.2768, 0.1048, 0.0846, 0.0574, 0.0627, 0.0937, 0.1376],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,516][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0350, 0.1622, 0.2809, 0.0908, 0.0518, 0.0470, 0.0746, 0.1252, 0.1325],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,516][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0022, 0.1305, 0.0754, 0.2242, 0.1127, 0.0819, 0.1297, 0.1034, 0.1400],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,517][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.8930, 0.0184, 0.0218, 0.0137, 0.0080, 0.0048, 0.0145, 0.0129, 0.0127],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,517][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0863, 0.1238, 0.1334, 0.1121, 0.1167, 0.1112, 0.1380, 0.0836, 0.0948],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,517][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0194, 0.0893, 0.2587, 0.0626, 0.0659, 0.0529, 0.0420, 0.0873, 0.1786,
        0.1432], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,518][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0013, 0.0783, 0.3149, 0.0644, 0.0928, 0.0444, 0.0711, 0.0639, 0.1366,
        0.1322], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,518][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2030, 0.0638, 0.1370, 0.0571, 0.0916, 0.0799, 0.0801, 0.0611, 0.1249,
        0.1014], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,520][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0819, 0.0729, 0.2632, 0.0647, 0.1086, 0.0592, 0.0507, 0.0716, 0.1244,
        0.1028], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,523][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.5412e-01, 1.4440e-03, 3.2283e-02, 5.3776e-04, 3.6483e-03, 7.5684e-04,
        1.4141e-03, 1.7307e-03, 2.4585e-03, 1.6033e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,528][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0195, 0.1010, 0.2666, 0.0715, 0.0737, 0.0528, 0.0562, 0.0809, 0.1335,
        0.1444], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,534][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5035, 0.0514, 0.0731, 0.0392, 0.0455, 0.0580, 0.0677, 0.0452, 0.0558,
        0.0607], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,534][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0115, 0.1297, 0.2332, 0.1009, 0.0647, 0.0396, 0.0442, 0.0863, 0.1141,
        0.1758], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,534][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0052, 0.1316, 0.2206, 0.1006, 0.0378, 0.0353, 0.0518, 0.1281, 0.1501,
        0.1389], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,535][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0035, 0.0637, 0.0688, 0.1344, 0.0964, 0.0940, 0.1136, 0.0976, 0.1971,
        0.1309], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,535][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7723, 0.0490, 0.0311, 0.0273, 0.0144, 0.0118, 0.0245, 0.0235, 0.0251,
        0.0210], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,535][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0707, 0.1127, 0.1179, 0.0999, 0.1034, 0.0991, 0.1223, 0.0757, 0.0864,
        0.1119], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,536][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0125, 0.0799, 0.2553, 0.0553, 0.0662, 0.0458, 0.0314, 0.0757, 0.1664,
        0.1370, 0.0745], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,536][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0007, 0.0726, 0.2899, 0.0456, 0.0779, 0.0398, 0.0677, 0.0593, 0.1369,
        0.1247, 0.0849], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,536][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2251, 0.0532, 0.1261, 0.0470, 0.0839, 0.0628, 0.0701, 0.0524, 0.1047,
        0.0942, 0.0803], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,538][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1006, 0.0549, 0.2675, 0.0519, 0.1071, 0.0501, 0.0438, 0.0688, 0.1194,
        0.0897, 0.0462], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,540][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.6453e-01, 1.0649e-03, 2.6347e-02, 3.4340e-04, 2.4624e-03, 4.2581e-04,
        8.0264e-04, 1.0280e-03, 1.5208e-03, 1.0077e-03, 4.6958e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,546][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0168, 0.0930, 0.2590, 0.0598, 0.0672, 0.0453, 0.0473, 0.0722, 0.1218,
        0.1433, 0.0745], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,550][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5775, 0.0437, 0.0608, 0.0313, 0.0351, 0.0446, 0.0508, 0.0347, 0.0465,
        0.0505, 0.0246], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,552][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0082, 0.1250, 0.1951, 0.0868, 0.0522, 0.0330, 0.0356, 0.0756, 0.1008,
        0.1795, 0.1082], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,552][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0030, 0.1080, 0.2000, 0.0807, 0.0316, 0.0305, 0.0466, 0.1115, 0.1538,
        0.1522, 0.0822], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,553][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0035, 0.0687, 0.0685, 0.1029, 0.0873, 0.0863, 0.1032, 0.0843, 0.1681,
        0.1198, 0.1073], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,553][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8384, 0.0317, 0.0198, 0.0167, 0.0082, 0.0078, 0.0170, 0.0169, 0.0158,
        0.0135, 0.0144], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,553][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0620, 0.1007, 0.1100, 0.0892, 0.0948, 0.0892, 0.1090, 0.0694, 0.0795,
        0.1001, 0.0961], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,554][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0082, 0.0560, 0.2079, 0.0629, 0.0633, 0.0490, 0.0446, 0.0773, 0.1540,
        0.1331, 0.1037, 0.0401], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,554][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0532, 0.2742, 0.0603, 0.0921, 0.0312, 0.0511, 0.0460, 0.1242,
        0.1284, 0.0949, 0.0437], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,554][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1135, 0.0533, 0.1122, 0.0662, 0.0880, 0.0706, 0.0812, 0.0533, 0.1152,
        0.0996, 0.0905, 0.0566], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,555][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0749, 0.0639, 0.2586, 0.0501, 0.0942, 0.0498, 0.0467, 0.0659, 0.1073,
        0.0901, 0.0564, 0.0421], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,558][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.9040, 0.0058, 0.0399, 0.0021, 0.0079, 0.0032, 0.0063, 0.0060, 0.0083,
        0.0063, 0.0031, 0.0071], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,564][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0103, 0.0951, 0.2088, 0.0744, 0.0739, 0.0458, 0.0565, 0.0778, 0.0895,
        0.1441, 0.0835, 0.0402], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,569][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.5074, 0.0349, 0.0791, 0.0259, 0.0461, 0.0524, 0.0577, 0.0370, 0.0566,
        0.0452, 0.0238, 0.0339], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,570][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0128, 0.0817, 0.1972, 0.0813, 0.0592, 0.0383, 0.0387, 0.0761, 0.1356,
        0.1472, 0.1024, 0.0294], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,571][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0053, 0.1004, 0.2186, 0.0786, 0.0400, 0.0346, 0.0476, 0.0889, 0.1259,
        0.1406, 0.0826, 0.0369], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,571][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0018, 0.0746, 0.0355, 0.1675, 0.0486, 0.0615, 0.0815, 0.0543, 0.0938,
        0.1416, 0.2017, 0.0376], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,571][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.7800, 0.0292, 0.0325, 0.0236, 0.0154, 0.0094, 0.0218, 0.0202, 0.0186,
        0.0155, 0.0159, 0.0179], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,572][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0654, 0.0914, 0.1046, 0.0822, 0.0901, 0.0844, 0.1043, 0.0621, 0.0726,
        0.0935, 0.0898, 0.0595], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,572][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0089, 0.0493, 0.2476, 0.0550, 0.0851, 0.0381, 0.0257, 0.0848, 0.1212,
        0.1248, 0.0896, 0.0481, 0.0218], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,572][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0015, 0.0387, 0.2859, 0.0572, 0.0836, 0.0304, 0.0458, 0.0371, 0.1050,
        0.1221, 0.1139, 0.0650, 0.0139], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,573][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0679, 0.0626, 0.1171, 0.0777, 0.0875, 0.0652, 0.0815, 0.0490, 0.0968,
        0.0980, 0.0846, 0.0568, 0.0553], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,573][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0724, 0.0569, 0.2020, 0.0524, 0.0888, 0.0549, 0.0485, 0.0723, 0.1036,
        0.0985, 0.0610, 0.0573, 0.0315], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,577][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.8418, 0.0087, 0.0552, 0.0034, 0.0124, 0.0060, 0.0093, 0.0107, 0.0137,
        0.0105, 0.0052, 0.0148, 0.0084], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,582][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0064, 0.0780, 0.2047, 0.0761, 0.0731, 0.0447, 0.0474, 0.0671, 0.0974,
        0.1417, 0.0924, 0.0527, 0.0183], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,587][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.4154, 0.0255, 0.0925, 0.0257, 0.0656, 0.0534, 0.0588, 0.0335, 0.0529,
        0.0486, 0.0296, 0.0321, 0.0664], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,589][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0166, 0.0623, 0.1978, 0.0641, 0.0668, 0.0404, 0.0390, 0.0786, 0.1123,
        0.1428, 0.1084, 0.0451, 0.0255], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,589][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0051, 0.0903, 0.2153, 0.0735, 0.0428, 0.0308, 0.0413, 0.0909, 0.1217,
        0.1455, 0.0852, 0.0510, 0.0065], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,589][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0012, 0.0905, 0.0328, 0.1398, 0.0414, 0.0584, 0.0855, 0.0784, 0.1099,
        0.0961, 0.1520, 0.0818, 0.0323], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,590][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.8347, 0.0122, 0.0210, 0.0140, 0.0124, 0.0087, 0.0189, 0.0180, 0.0146,
        0.0121, 0.0123, 0.0121, 0.0089], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,590][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0486, 0.0823, 0.1008, 0.0756, 0.0846, 0.0777, 0.0937, 0.0582, 0.0689,
        0.0875, 0.0834, 0.0589, 0.0799], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,591][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0100, 0.0642, 0.2053, 0.0539, 0.0628, 0.0391, 0.0325, 0.0679, 0.1474,
        0.1073, 0.0658, 0.0462, 0.0156, 0.0819], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,591][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0024, 0.0715, 0.2189, 0.0521, 0.0583, 0.0324, 0.0494, 0.0441, 0.0970,
        0.1259, 0.0935, 0.0627, 0.0120, 0.0798], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,591][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1305, 0.0543, 0.1043, 0.0509, 0.0727, 0.0603, 0.0652, 0.0429, 0.0930,
        0.0871, 0.0729, 0.0476, 0.0546, 0.0637], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,592][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0921, 0.0507, 0.2304, 0.0471, 0.0949, 0.0436, 0.0366, 0.0556, 0.1067,
        0.0769, 0.0460, 0.0436, 0.0300, 0.0458], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,595][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.9178, 0.0031, 0.0375, 0.0014, 0.0062, 0.0018, 0.0029, 0.0040, 0.0058,
        0.0045, 0.0025, 0.0062, 0.0032, 0.0033], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,599][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0169, 0.0894, 0.2144, 0.0614, 0.0639, 0.0404, 0.0503, 0.0568, 0.0923,
        0.1099, 0.0683, 0.0455, 0.0164, 0.0741], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,605][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.3588, 0.0335, 0.0872, 0.0333, 0.0588, 0.0529, 0.0665, 0.0373, 0.0524,
        0.0510, 0.0278, 0.0282, 0.0523, 0.0601], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,607][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0177, 0.0935, 0.1707, 0.0778, 0.0633, 0.0380, 0.0412, 0.0652, 0.0985,
        0.1336, 0.0920, 0.0310, 0.0221, 0.0553], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,608][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0100, 0.1202, 0.2019, 0.0747, 0.0393, 0.0269, 0.0477, 0.0827, 0.1063,
        0.1154, 0.0614, 0.0387, 0.0064, 0.0683], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,608][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0020, 0.0947, 0.0412, 0.1108, 0.0482, 0.0573, 0.0655, 0.0703, 0.0798,
        0.0993, 0.1426, 0.0751, 0.0568, 0.0564], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,609][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.8617, 0.0123, 0.0191, 0.0117, 0.0093, 0.0060, 0.0168, 0.0140, 0.0107,
        0.0090, 0.0091, 0.0088, 0.0055, 0.0062], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,609][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0529, 0.0813, 0.0871, 0.0719, 0.0759, 0.0705, 0.0859, 0.0536, 0.0610,
        0.0775, 0.0750, 0.0531, 0.0728, 0.0816], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,609][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0223, 0.0548, 0.2297, 0.0456, 0.0690, 0.0323, 0.0301, 0.0555, 0.1145,
        0.0953, 0.0585, 0.0471, 0.0183, 0.0905, 0.0365], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,610][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0015, 0.0490, 0.2448, 0.0421, 0.0846, 0.0317, 0.0507, 0.0379, 0.0921,
        0.0883, 0.0671, 0.0686, 0.0152, 0.0807, 0.0455], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,610][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1354, 0.0477, 0.0946, 0.0453, 0.0712, 0.0578, 0.0586, 0.0424, 0.0910,
        0.0739, 0.0653, 0.0515, 0.0548, 0.0633, 0.0473], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,610][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1097, 0.0455, 0.2099, 0.0409, 0.1000, 0.0424, 0.0350, 0.0550, 0.0917,
        0.0656, 0.0422, 0.0486, 0.0334, 0.0467, 0.0333], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,612][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.5961e-01, 1.4317e-03, 2.2415e-02, 4.3325e-04, 2.1623e-03, 6.1344e-04,
        1.4311e-03, 1.5389e-03, 2.1482e-03, 1.6174e-03, 7.5798e-04, 2.0306e-03,
        1.2092e-03, 1.0586e-03, 1.5432e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,617][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0206, 0.0769, 0.2180, 0.0547, 0.0656, 0.0360, 0.0410, 0.0510, 0.0802,
        0.1080, 0.0643, 0.0441, 0.0174, 0.0738, 0.0483], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,622][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3644, 0.0331, 0.0687, 0.0335, 0.0461, 0.0515, 0.0568, 0.0339, 0.0520,
        0.0493, 0.0289, 0.0284, 0.0438, 0.0448, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,626][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0188, 0.0825, 0.1704, 0.0758, 0.0549, 0.0350, 0.0369, 0.0668, 0.0860,
        0.1319, 0.0956, 0.0295, 0.0218, 0.0514, 0.0427], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,626][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0119, 0.0846, 0.2104, 0.0623, 0.0407, 0.0245, 0.0418, 0.0770, 0.1014,
        0.1110, 0.0588, 0.0482, 0.0076, 0.0691, 0.0509], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,627][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0014, 0.0562, 0.0287, 0.1074, 0.0451, 0.0595, 0.0715, 0.0551, 0.1003,
        0.1095, 0.1206, 0.0495, 0.0449, 0.0762, 0.0740], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,627][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8315, 0.0154, 0.0208, 0.0140, 0.0096, 0.0075, 0.0172, 0.0154, 0.0130,
        0.0106, 0.0110, 0.0098, 0.0057, 0.0051, 0.0133], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,627][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0458, 0.0706, 0.0782, 0.0655, 0.0704, 0.0642, 0.0798, 0.0504, 0.0576,
        0.0724, 0.0703, 0.0492, 0.0673, 0.0758, 0.0826], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,628][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:31,630][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[18737],
        [16065],
        [23500],
        [14433],
        [28848],
        [21000],
        [15926],
        [18084],
        [15509],
        [15302],
        [11191],
        [24981],
        [27115],
        [12600],
        [12191]], device='cuda:0')
[2024-07-24 10:25:31,631][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21556],
        [18602],
        [41956],
        [16237],
        [41355],
        [30937],
        [26247],
        [27245],
        [27114],
        [19560],
        [10247],
        [37075],
        [42371],
        [24682],
        [21216]], device='cuda:0')
[2024-07-24 10:25:31,633][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36896],
        [36756],
        [36763],
        [35717],
        [33898],
        [29911],
        [34482],
        [35734],
        [35488],
        [34551],
        [29431],
        [20634],
        [ 8637],
        [26749],
        [30398]], device='cuda:0')
[2024-07-24 10:25:31,636][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17100],
        [ 7782],
        [ 8459],
        [ 7942],
        [ 8578],
        [ 8785],
        [ 8532],
        [ 8442],
        [ 8670],
        [ 8881],
        [ 8855],
        [ 9195],
        [ 9558],
        [ 9551],
        [ 9700]], device='cuda:0')
[2024-07-24 10:25:31,639][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[24338],
        [17322],
        [17450],
        [17751],
        [17101],
        [16968],
        [16528],
        [16162],
        [16515],
        [16380],
        [16114],
        [15723],
        [15531],
        [15491],
        [15212]], device='cuda:0')
[2024-07-24 10:25:31,641][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[10338],
        [ 4126],
        [ 2842],
        [ 3079],
        [ 3049],
        [ 3611],
        [ 4011],
        [ 4123],
        [ 4925],
        [ 5241],
        [ 5118],
        [ 5144],
        [ 5311],
        [ 5259],
        [ 5445]], device='cuda:0')
[2024-07-24 10:25:31,644][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 5572],
        [ 5795],
        [ 3364],
        [ 3963],
        [ 3846],
        [ 5459],
        [ 5600],
        [ 9790],
        [11063],
        [11761],
        [11432],
        [12355],
        [11005],
        [13177],
        [12015]], device='cuda:0')
[2024-07-24 10:25:31,646][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31040],
        [38511],
        [39493],
        [39761],
        [40524],
        [40360],
        [40451],
        [40458],
        [40440],
        [40216],
        [40046],
        [40211],
        [40251],
        [40301],
        [40155]], device='cuda:0')
[2024-07-24 10:25:31,649][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[20649],
        [10434],
        [   19],
        [ 6574],
        [  450],
        [18729],
        [ 6566],
        [12208],
        [ 5670],
        [ 7288],
        [ 9958],
        [ 7620],
        [ 4785],
        [ 3402],
        [ 6117]], device='cuda:0')
[2024-07-24 10:25:31,650][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[  515],
        [42354],
        [42836],
        [45581],
        [45601],
        [46147],
        [45858],
        [45590],
        [45242],
        [45895],
        [45602],
        [45504],
        [45436],
        [45431],
        [45388]], device='cuda:0')
[2024-07-24 10:25:31,651][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14890],
        [14650],
        [20958],
        [23985],
        [24173],
        [23909],
        [23926],
        [22669],
        [23722],
        [24321],
        [24785],
        [24535],
        [24489],
        [23586],
        [23797]], device='cuda:0')
[2024-07-24 10:25:31,652][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31259],
        [35605],
        [41091],
        [49961],
        [48105],
        [47833],
        [48368],
        [47505],
        [47635],
        [47406],
        [48397],
        [47850],
        [46338],
        [48135],
        [47668]], device='cuda:0')
[2024-07-24 10:25:31,653][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8594],
        [ 6704],
        [ 7868],
        [ 9954],
        [10436],
        [10965],
        [11125],
        [11005],
        [10515],
        [10431],
        [10102],
        [ 9341],
        [ 8253],
        [ 8105],
        [ 7718]], device='cuda:0')
[2024-07-24 10:25:31,654][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27222],
        [29198],
        [37033],
        [36499],
        [35920],
        [34885],
        [33511],
        [33183],
        [31425],
        [30757],
        [30781],
        [30628],
        [30593],
        [28727],
        [29488]], device='cuda:0')
[2024-07-24 10:25:31,656][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13209],
        [18676],
        [ 8424],
        [14235],
        [ 9883],
        [ 9346],
        [ 8511],
        [ 9522],
        [ 8608],
        [14688],
        [15080],
        [10752],
        [ 9493],
        [ 8367],
        [12164]], device='cuda:0')
[2024-07-24 10:25:31,659][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23621],
        [12196],
        [ 7804],
        [ 7829],
        [ 8113],
        [ 8546],
        [ 8532],
        [ 7622],
        [ 6774],
        [ 6898],
        [ 7252],
        [ 6975],
        [ 6995],
        [ 7339],
        [ 7688]], device='cuda:0')
[2024-07-24 10:25:31,661][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34510],
        [23406],
        [40787],
        [40064],
        [39375],
        [37885],
        [36401],
        [36710],
        [35618],
        [35431],
        [35060],
        [34238],
        [34319],
        [34667],
        [35758]], device='cuda:0')
[2024-07-24 10:25:31,664][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 3407],
        [17766],
        [11556],
        [ 8859],
        [16358],
        [19634],
        [16108],
        [16658],
        [21204],
        [19766],
        [20820],
        [22699],
        [21632],
        [20908],
        [19545]], device='cuda:0')
[2024-07-24 10:25:31,667][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10100],
        [40590],
        [42128],
        [42887],
        [42187],
        [41314],
        [40450],
        [39636],
        [38199],
        [38282],
        [38387],
        [38697],
        [38319],
        [37632],
        [37260]], device='cuda:0')
[2024-07-24 10:25:31,669][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[41443],
        [41441],
        [39971],
        [41071],
        [39620],
        [38929],
        [40723],
        [39321],
        [39820],
        [39549],
        [39971],
        [37818],
        [33523],
        [38368],
        [40019]], device='cuda:0')
[2024-07-24 10:25:31,672][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 7802],
        [14346],
        [19043],
        [21474],
        [21244],
        [22519],
        [23074],
        [22751],
        [25315],
        [27639],
        [29034],
        [28319],
        [28967],
        [30552],
        [30965]], device='cuda:0')
[2024-07-24 10:25:31,674][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[46863],
        [39489],
        [44687],
        [44535],
        [36958],
        [26092],
        [22206],
        [18897],
        [11526],
        [11569],
        [15446],
        [11384],
        [ 9316],
        [ 7581],
        [ 8091]], device='cuda:0')
[2024-07-24 10:25:31,675][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[32887],
        [18269],
        [ 6072],
        [ 4314],
        [ 2807],
        [ 2704],
        [ 2888],
        [ 2337],
        [ 2581],
        [ 3658],
        [ 5319],
        [ 4510],
        [ 4211],
        [ 4350],
        [ 4587]], device='cuda:0')
[2024-07-24 10:25:31,676][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[35980],
        [27203],
        [23496],
        [20903],
        [20304],
        [20854],
        [21532],
        [22495],
        [23010],
        [23099],
        [23033],
        [23382],
        [23457],
        [24655],
        [25018]], device='cuda:0')
[2024-07-24 10:25:31,677][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[29514],
        [21875],
        [20472],
        [19676],
        [19798],
        [18988],
        [17654],
        [18480],
        [18748],
        [18465],
        [18028],
        [18811],
        [19037],
        [17855],
        [17414]], device='cuda:0')
[2024-07-24 10:25:31,678][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4386],
        [ 3791],
        [ 4570],
        [ 3763],
        [ 7853],
        [ 8310],
        [15195],
        [11735],
        [ 5910],
        [11573],
        [ 8523],
        [11504],
        [ 9268],
        [ 7807],
        [ 9248]], device='cuda:0')
[2024-07-24 10:25:31,679][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[2977],
        [4047],
        [3935],
        [2867],
        [2798],
        [2514],
        [2524],
        [2510],
        [2515],
        [2489],
        [2450],
        [2361],
        [2443],
        [2425],
        [2436]], device='cuda:0')
[2024-07-24 10:25:31,682][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[37237],
        [31253],
        [30486],
        [34074],
        [33220],
        [35395],
        [35090],
        [36436],
        [39377],
        [36323],
        [35317],
        [35130],
        [37299],
        [37368],
        [36101]], device='cuda:0')
[2024-07-24 10:25:31,684][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38920],
        [35302],
        [38601],
        [35177],
        [35292],
        [33666],
        [34836],
        [35103],
        [35854],
        [33364],
        [34276],
        [35071],
        [36333],
        [36995],
        [33796]], device='cuda:0')
[2024-07-24 10:25:31,687][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166],
        [15166]], device='cuda:0')
[2024-07-24 10:25:31,716][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:31,717][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,717][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,718][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,718][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,718][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,719][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,719][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,719][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,720][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,720][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,721][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,723][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:31,725][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([2.9440e-04, 9.9971e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,729][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0637, 0.9363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,739][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,739][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8139, 0.1861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,739][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0291, 0.9709], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,743][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6760, 0.3240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,749][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1057, 0.8943], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,753][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1128, 0.8872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,755][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0284, 0.9716], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,755][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0994, 0.9006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,755][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0190, 0.9810], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,756][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2914, 0.7086], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:31,756][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([3.3167e-04, 3.8519e-01, 6.1448e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,756][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.1192, 0.4414, 0.4394], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,757][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.0024, 0.6262, 0.3714], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,757][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.8086, 0.0037, 0.1877], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,757][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.0683, 0.2038, 0.7278], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,757][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.5818, 0.1083, 0.3098], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,758][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.1145, 0.3807, 0.5048], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,761][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.1434, 0.4917, 0.3649], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,765][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.0143, 0.2818, 0.7040], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,771][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.1270, 0.5060, 0.3671], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,773][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.0205, 0.6779, 0.3017], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,774][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.1552, 0.2754, 0.5694], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:31,774][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([6.9417e-06, 2.1693e-01, 3.8359e-01, 3.9947e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,774][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5793, 0.1605, 0.2391, 0.0211], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,774][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0021, 0.4781, 0.2689, 0.2510], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,775][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2095, 0.0123, 0.7379, 0.0403], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,775][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0709, 0.2123, 0.6238, 0.0930], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,775][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8228, 0.0487, 0.1205, 0.0079], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,776][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0500, 0.2626, 0.3810, 0.3064], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,777][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3130, 0.2887, 0.2314, 0.1669], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,783][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0035, 0.1576, 0.7734, 0.0656], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,787][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0587, 0.3434, 0.3407, 0.2571], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,791][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1403, 0.1502, 0.4192, 0.2903], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,791][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1175, 0.1273, 0.4476, 0.3077], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:31,792][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([1.7971e-05, 2.0069e-01, 4.1506e-01, 3.4048e-01, 4.3748e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,792][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.1915, 0.1821, 0.3166, 0.0911, 0.2188], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,792][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0024, 0.3928, 0.2134, 0.1817, 0.2096], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,793][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.5122, 0.0064, 0.3818, 0.0201, 0.0795], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,793][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0086, 0.0713, 0.7257, 0.0589, 0.1355], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,793][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.4860, 0.1036, 0.3226, 0.0317, 0.0561], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,793][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0362, 0.2565, 0.3291, 0.2365, 0.1417], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,794][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.1181, 0.2741, 0.2474, 0.1936, 0.1669], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,794][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0021, 0.0905, 0.6833, 0.0793, 0.1448], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,797][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0554, 0.2986, 0.2744, 0.2047, 0.1669], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,802][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0046, 0.1077, 0.1106, 0.5560, 0.2211], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,807][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0618, 0.1267, 0.2299, 0.2481, 0.3335], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:31,809][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([4.2515e-06, 1.6052e-01, 3.3948e-01, 4.2133e-01, 4.7523e-02, 3.1148e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,810][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1622, 0.2144, 0.3501, 0.0641, 0.1468, 0.0624], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,810][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0016, 0.3590, 0.1819, 0.1384, 0.1884, 0.1307], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,810][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1467, 0.0044, 0.6799, 0.0168, 0.0978, 0.0544], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,811][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0015, 0.0991, 0.5345, 0.1437, 0.1430, 0.0781], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,811][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.5155, 0.0852, 0.3108, 0.0242, 0.0487, 0.0157], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,811][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0223, 0.1765, 0.2465, 0.2834, 0.1797, 0.0916], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,812][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1159, 0.2214, 0.3084, 0.1466, 0.1485, 0.0591], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,812][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0016, 0.1109, 0.6054, 0.0727, 0.1447, 0.0646], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,815][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0353, 0.2436, 0.2324, 0.1699, 0.1529, 0.1660], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,821][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0012, 0.0705, 0.1300, 0.5061, 0.1841, 0.1081], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,826][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0854, 0.0724, 0.1770, 0.2394, 0.2662, 0.1596], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:31,827][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.2750e-05, 1.6826e-01, 2.7001e-01, 4.5599e-01, 4.3620e-02, 4.5889e-02,
        1.6220e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,828][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3000, 0.1571, 0.3314, 0.0402, 0.0797, 0.0437, 0.0478],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,828][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0008, 0.2569, 0.1358, 0.1334, 0.1472, 0.1346, 0.1912],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,828][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0898, 0.0060, 0.6592, 0.0245, 0.1168, 0.0748, 0.0289],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,829][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0102, 0.0966, 0.4753, 0.1087, 0.1091, 0.0980, 0.1021],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,829][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6222, 0.1030, 0.2002, 0.0201, 0.0287, 0.0136, 0.0122],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,829][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0153, 0.1625, 0.2143, 0.2082, 0.1309, 0.0920, 0.1768],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,829][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1623, 0.2367, 0.2092, 0.1505, 0.0965, 0.0672, 0.0776],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,830][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0037, 0.0974, 0.5956, 0.0554, 0.1329, 0.0711, 0.0438],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,830][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0359, 0.2184, 0.1812, 0.1550, 0.1204, 0.1552, 0.1340],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,833][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0061, 0.0591, 0.1646, 0.3264, 0.1414, 0.1452, 0.1571],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,838][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0306, 0.0877, 0.1423, 0.2608, 0.2460, 0.1413, 0.0913],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:31,841][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([8.1561e-06, 1.7080e-01, 2.9976e-01, 3.7708e-01, 4.1384e-02, 4.5736e-02,
        2.3576e-02, 4.1655e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,846][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1181, 0.2140, 0.2628, 0.0699, 0.1093, 0.0840, 0.0747, 0.0673],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,846][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0008, 0.2608, 0.1524, 0.1127, 0.1439, 0.1024, 0.1703, 0.0566],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,846][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1335, 0.0073, 0.5707, 0.0263, 0.1058, 0.0761, 0.0321, 0.0482],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,847][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0067, 0.0924, 0.3128, 0.0669, 0.0630, 0.0503, 0.0793, 0.3286],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,847][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.4500, 0.1213, 0.2723, 0.0315, 0.0467, 0.0219, 0.0228, 0.0336],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,847][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0160, 0.1223, 0.1859, 0.1647, 0.1571, 0.0785, 0.1822, 0.0932],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,848][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0893, 0.1606, 0.2568, 0.1287, 0.1333, 0.0638, 0.0975, 0.0700],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,848][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0026, 0.0927, 0.5281, 0.0497, 0.1130, 0.0520, 0.0484, 0.1135],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,851][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0307, 0.1827, 0.1612, 0.1291, 0.1062, 0.1333, 0.1243, 0.1326],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,853][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([3.3565e-04, 3.0754e-02, 5.0909e-02, 4.7793e-01, 7.4083e-02, 9.8602e-02,
        2.0016e-01, 6.7226e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,859][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0297, 0.0448, 0.1468, 0.1667, 0.2030, 0.1228, 0.1086, 0.1777],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:31,862][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([1.6653e-05, 1.7164e-01, 3.8569e-01, 2.7614e-01, 3.2867e-02, 2.3188e-02,
        1.4824e-02, 2.4670e-02, 7.0968e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,863][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0980, 0.1538, 0.2005, 0.0673, 0.0999, 0.0767, 0.0803, 0.0787, 0.1447],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,864][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0015, 0.2465, 0.1366, 0.0973, 0.1353, 0.1038, 0.1472, 0.0594, 0.0723],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,864][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1340, 0.0075, 0.5361, 0.0254, 0.1154, 0.0725, 0.0306, 0.0494, 0.0290],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,864][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0030, 0.0632, 0.2573, 0.0666, 0.0507, 0.0477, 0.0516, 0.2234, 0.2365],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,865][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.4780, 0.1002, 0.2365, 0.0261, 0.0398, 0.0173, 0.0202, 0.0324, 0.0496],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,865][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0200, 0.1001, 0.1572, 0.1566, 0.1133, 0.0725, 0.1734, 0.0999, 0.1071],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,865][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0758, 0.1508, 0.1844, 0.1032, 0.0888, 0.0652, 0.0786, 0.0814, 0.1718],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,866][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0047, 0.0760, 0.4273, 0.0325, 0.0740, 0.0339, 0.0334, 0.0831, 0.2352],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,866][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0263, 0.1680, 0.1491, 0.1087, 0.0939, 0.1115, 0.1084, 0.1210, 0.1132],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,867][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([3.7680e-04, 3.3442e-02, 7.4333e-02, 4.0459e-01, 1.1412e-01, 7.9959e-02,
        1.8200e-01, 5.9790e-02, 5.1383e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,872][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0165, 0.0415, 0.1681, 0.1024, 0.1597, 0.1185, 0.0676, 0.2096, 0.1159],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:31,875][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([4.5472e-06, 1.2117e-01, 2.0004e-01, 1.9479e-01, 1.9699e-02, 1.8278e-02,
        1.2960e-02, 3.1007e-02, 1.3620e-01, 2.6585e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,880][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3256, 0.1831, 0.1564, 0.0323, 0.0488, 0.0323, 0.0375, 0.0345, 0.0981,
        0.0514], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,882][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0004, 0.2425, 0.1111, 0.1018, 0.1371, 0.0999, 0.1521, 0.0576, 0.0683,
        0.0293], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,882][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0662, 0.0048, 0.5851, 0.0213, 0.1038, 0.0652, 0.0268, 0.0439, 0.0287,
        0.0542], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,882][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0115, 0.0747, 0.2388, 0.0443, 0.0427, 0.0395, 0.0549, 0.1589, 0.1889,
        0.1457], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,883][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4345, 0.1144, 0.2111, 0.0273, 0.0379, 0.0150, 0.0158, 0.0288, 0.0422,
        0.0731], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,883][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0142, 0.1066, 0.1387, 0.1291, 0.0865, 0.0438, 0.1534, 0.0905, 0.0985,
        0.1388], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,883][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0794, 0.1569, 0.1433, 0.1083, 0.0686, 0.0497, 0.0597, 0.0550, 0.1444,
        0.1347], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,884][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0008, 0.0627, 0.2858, 0.0317, 0.0523, 0.0343, 0.0287, 0.0810, 0.2553,
        0.1675], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,884][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0112, 0.1291, 0.1352, 0.0928, 0.0842, 0.1021, 0.0851, 0.1014, 0.1064,
        0.1524], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,887][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0047, 0.0391, 0.0950, 0.2096, 0.0786, 0.1012, 0.1082, 0.0799, 0.0708,
        0.2129], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,893][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0239, 0.0283, 0.1436, 0.0751, 0.1762, 0.0805, 0.0782, 0.1663, 0.1863,
        0.0416], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:31,896][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([7.8715e-07, 9.8262e-02, 1.2550e-01, 1.1429e-01, 1.3164e-02, 1.4933e-02,
        7.6500e-03, 2.2612e-02, 1.1926e-01, 2.5225e-01, 2.3207e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,899][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3294, 0.1185, 0.2028, 0.0257, 0.0625, 0.0340, 0.0300, 0.0344, 0.1014,
        0.0366, 0.0248], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,900][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0003, 0.2392, 0.0973, 0.0973, 0.1234, 0.0954, 0.1515, 0.0627, 0.0688,
        0.0270, 0.0372], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,900][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0427, 0.0045, 0.5964, 0.0191, 0.0977, 0.0666, 0.0239, 0.0417, 0.0286,
        0.0510, 0.0277], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,900][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0214, 0.0618, 0.2175, 0.0275, 0.0364, 0.0415, 0.0496, 0.1263, 0.2021,
        0.1188, 0.0973], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,901][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5051, 0.0840, 0.2249, 0.0171, 0.0330, 0.0095, 0.0090, 0.0181, 0.0288,
        0.0489, 0.0218], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,901][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0141, 0.0919, 0.1306, 0.1064, 0.0773, 0.0469, 0.1317, 0.0804, 0.0940,
        0.1170, 0.1097], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,902][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1013, 0.1550, 0.1209, 0.1001, 0.0492, 0.0384, 0.0456, 0.0450, 0.1224,
        0.1240, 0.0981], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,902][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0003, 0.0558, 0.2303, 0.0231, 0.0427, 0.0279, 0.0230, 0.0651, 0.2568,
        0.1689, 0.1060], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,902][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0102, 0.1119, 0.1222, 0.0836, 0.0777, 0.0880, 0.0753, 0.0918, 0.0949,
        0.1366, 0.1078], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,905][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0092, 0.0325, 0.0814, 0.1197, 0.0676, 0.1234, 0.0913, 0.0875, 0.0721,
        0.1647, 0.1507], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,910][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0203, 0.0295, 0.1166, 0.0733, 0.1772, 0.0903, 0.0745, 0.1175, 0.1669,
        0.0570, 0.0768], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:31,914][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([1.0512e-06, 7.2155e-02, 1.7793e-01, 1.0059e-01, 2.3032e-02, 1.7461e-02,
        7.0510e-03, 1.9120e-02, 9.8823e-02, 2.7510e-01, 2.0418e-01, 4.5605e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,918][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.1121, 0.1294, 0.1898, 0.0360, 0.0823, 0.0513, 0.0553, 0.0513, 0.1056,
        0.0636, 0.0454, 0.0778], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,918][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0005, 0.2115, 0.1151, 0.0905, 0.1107, 0.1099, 0.1335, 0.0561, 0.0583,
        0.0328, 0.0444, 0.0367], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,919][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1927, 0.0043, 0.4936, 0.0145, 0.0776, 0.0459, 0.0179, 0.0312, 0.0190,
        0.0420, 0.0216, 0.0396], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,919][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0020, 0.0188, 0.2447, 0.0223, 0.0408, 0.0264, 0.0303, 0.1216, 0.1481,
        0.1225, 0.1256, 0.0969], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,919][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.3375, 0.0968, 0.2535, 0.0263, 0.0449, 0.0150, 0.0192, 0.0247, 0.0432,
        0.0666, 0.0352, 0.0371], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,920][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0173, 0.0769, 0.1002, 0.1051, 0.0697, 0.0458, 0.1269, 0.0810, 0.1181,
        0.0959, 0.0968, 0.0663], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,920][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0484, 0.1023, 0.1379, 0.0608, 0.0805, 0.0488, 0.0543, 0.0578, 0.1362,
        0.1187, 0.0896, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,920][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0003, 0.0438, 0.2931, 0.0293, 0.0690, 0.0301, 0.0220, 0.0648, 0.2230,
        0.1179, 0.0850, 0.0217], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,924][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0101, 0.1027, 0.1282, 0.0667, 0.0706, 0.0780, 0.0659, 0.0779, 0.0804,
        0.1279, 0.0944, 0.0971], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,929][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0008, 0.0142, 0.0464, 0.1566, 0.0615, 0.0680, 0.0852, 0.0459, 0.0445,
        0.1716, 0.2212, 0.0841], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,934][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0111, 0.0384, 0.1055, 0.1067, 0.1322, 0.0877, 0.0607, 0.1326, 0.1019,
        0.0703, 0.0898, 0.0631], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:31,936][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([2.3327e-07, 4.2912e-02, 1.0874e-01, 9.6144e-02, 1.3400e-02, 1.1830e-02,
        4.2490e-03, 3.4527e-02, 7.9886e-02, 3.2785e-01, 2.7284e-01, 7.1900e-03,
        4.2725e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,936][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0495, 0.0916, 0.1378, 0.0670, 0.1094, 0.0490, 0.0465, 0.0497, 0.0790,
        0.0728, 0.0839, 0.0896, 0.0742], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,936][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0004, 0.2041, 0.0799, 0.0650, 0.0875, 0.0887, 0.1066, 0.0525, 0.0646,
        0.0304, 0.0402, 0.0487, 0.1312], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,937][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0833, 0.0041, 0.5025, 0.0193, 0.0988, 0.0661, 0.0230, 0.0360, 0.0195,
        0.0579, 0.0311, 0.0494, 0.0089], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,937][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0003, 0.0171, 0.1832, 0.0260, 0.0438, 0.0205, 0.0258, 0.1554, 0.1374,
        0.1425, 0.1325, 0.1093, 0.0062], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,937][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.1704, 0.0977, 0.2397, 0.0330, 0.0490, 0.0388, 0.0233, 0.0487, 0.0780,
        0.0843, 0.0489, 0.0674, 0.0208], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,938][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0091, 0.0864, 0.1134, 0.0838, 0.0525, 0.0566, 0.0779, 0.0791, 0.1161,
        0.0929, 0.0718, 0.1169, 0.0434], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,938][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0334, 0.0976, 0.0945, 0.0773, 0.0655, 0.0474, 0.0524, 0.0820, 0.1171,
        0.1080, 0.1132, 0.0540, 0.0575], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,939][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([1.7638e-04, 2.5818e-02, 2.9519e-01, 3.0894e-02, 7.7811e-02, 2.7404e-02,
        1.7880e-02, 7.6926e-02, 1.9664e-01, 1.1309e-01, 9.9091e-02, 2.8782e-02,
        1.0300e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,942][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0086, 0.0963, 0.1158, 0.0659, 0.0654, 0.0726, 0.0601, 0.0711, 0.0764,
        0.1284, 0.0971, 0.1025, 0.0397], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,944][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([1.3389e-04, 1.5919e-02, 2.6788e-02, 1.7183e-01, 4.8728e-02, 4.8809e-02,
        8.1714e-02, 3.9233e-02, 3.1241e-02, 1.7432e-01, 2.6808e-01, 7.2209e-02,
        2.0997e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,950][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0131, 0.0389, 0.0788, 0.0778, 0.1079, 0.0881, 0.0531, 0.1129, 0.1054,
        0.0649, 0.0667, 0.0820, 0.1104], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:31,952][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([7.8043e-06, 1.1026e-01, 1.8577e-01, 1.3247e-01, 1.6147e-02, 1.2967e-02,
        9.4883e-03, 2.1074e-02, 7.3843e-02, 2.0905e-01, 1.5449e-01, 5.9409e-03,
        5.5060e-04, 6.7937e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,954][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1579, 0.0678, 0.2632, 0.0213, 0.1106, 0.0270, 0.0288, 0.0360, 0.0726,
        0.0321, 0.0209, 0.0623, 0.0621, 0.0374], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,954][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0005, 0.2395, 0.0836, 0.0687, 0.0831, 0.0762, 0.0958, 0.0472, 0.0455,
        0.0240, 0.0330, 0.0387, 0.0979, 0.0663], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,955][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1132, 0.0047, 0.4992, 0.0167, 0.0844, 0.0535, 0.0194, 0.0378, 0.0215,
        0.0449, 0.0227, 0.0502, 0.0070, 0.0246], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,955][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0043, 0.0338, 0.1625, 0.0254, 0.0281, 0.0194, 0.0267, 0.1028, 0.1180,
        0.0955, 0.0871, 0.0712, 0.0050, 0.2202], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,956][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.3538, 0.0667, 0.2606, 0.0222, 0.0437, 0.0126, 0.0160, 0.0270, 0.0358,
        0.0556, 0.0290, 0.0366, 0.0164, 0.0242], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,956][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0167, 0.0607, 0.0684, 0.1069, 0.0557, 0.0459, 0.0930, 0.0711, 0.0785,
        0.0984, 0.1167, 0.0511, 0.0553, 0.0815], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,956][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0465, 0.1519, 0.1173, 0.0820, 0.0523, 0.0397, 0.0397, 0.0456, 0.0832,
        0.1147, 0.0859, 0.0476, 0.0415, 0.0521], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,960][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0013, 0.0577, 0.2369, 0.0267, 0.0458, 0.0232, 0.0238, 0.0698, 0.1683,
        0.1198, 0.0729, 0.0353, 0.0065, 0.1120], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,965][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0139, 0.1024, 0.1040, 0.0677, 0.0591, 0.0685, 0.0619, 0.0714, 0.0675,
        0.1102, 0.0853, 0.0785, 0.0387, 0.0708], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,970][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0009, 0.0209, 0.0434, 0.1186, 0.0473, 0.0435, 0.0585, 0.0419, 0.0335,
        0.1806, 0.2373, 0.0926, 0.0253, 0.0557], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,972][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0101, 0.0349, 0.1124, 0.0739, 0.1289, 0.0752, 0.0462, 0.1154, 0.0632,
        0.0468, 0.0662, 0.0669, 0.1180, 0.0420], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:31,972][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.0389e-06, 9.4654e-02, 1.5463e-01, 1.4820e-01, 1.4321e-02, 8.9703e-03,
        5.1555e-03, 1.2883e-02, 4.0714e-02, 1.7216e-01, 2.0275e-01, 5.0185e-03,
        5.7408e-04, 6.3393e-02, 7.6565e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,972][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3361, 0.0935, 0.1719, 0.0217, 0.0494, 0.0267, 0.0260, 0.0296, 0.0731,
        0.0275, 0.0195, 0.0500, 0.0311, 0.0260, 0.0180], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,973][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.0434e-04, 2.0703e-01, 7.3136e-02, 7.2282e-02, 8.6326e-02, 6.9121e-02,
        1.1648e-01, 4.2543e-02, 4.8447e-02, 2.2742e-02, 3.1813e-02, 2.4478e-02,
        9.0339e-02, 5.9585e-02, 5.5477e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,973][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0826, 0.0042, 0.5396, 0.0158, 0.0824, 0.0442, 0.0167, 0.0317, 0.0232,
        0.0418, 0.0219, 0.0485, 0.0072, 0.0232, 0.0170], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,973][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0173, 0.0396, 0.1902, 0.0198, 0.0237, 0.0158, 0.0231, 0.0733, 0.0975,
        0.0719, 0.0637, 0.0565, 0.0055, 0.1813, 0.1208], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,974][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.4139, 0.0844, 0.2009, 0.0196, 0.0290, 0.0129, 0.0127, 0.0184, 0.0346,
        0.0527, 0.0285, 0.0321, 0.0123, 0.0209, 0.0272], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,977][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0119, 0.0628, 0.0948, 0.0815, 0.0611, 0.0332, 0.0775, 0.0595, 0.0793,
        0.0944, 0.0852, 0.0643, 0.0569, 0.0580, 0.0794], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,983][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0605, 0.1046, 0.1021, 0.0745, 0.0489, 0.0314, 0.0393, 0.0345, 0.0925,
        0.1007, 0.0800, 0.0422, 0.0505, 0.0585, 0.0799], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,987][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0013, 0.0392, 0.2753, 0.0192, 0.0564, 0.0222, 0.0165, 0.0453, 0.1516,
        0.1013, 0.0754, 0.0350, 0.0096, 0.1112, 0.0404], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,989][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0137, 0.0932, 0.0805, 0.0678, 0.0515, 0.0660, 0.0590, 0.0661, 0.0658,
        0.1054, 0.0869, 0.0768, 0.0352, 0.0677, 0.0645], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,989][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0045, 0.0176, 0.0640, 0.0913, 0.0630, 0.0791, 0.0706, 0.0518, 0.0511,
        0.1151, 0.1078, 0.0806, 0.0251, 0.0750, 0.1035], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:31,990][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0141, 0.0227, 0.0877, 0.0625, 0.1123, 0.0560, 0.0565, 0.0878, 0.1104,
        0.0405, 0.0652, 0.0688, 0.1122, 0.0668, 0.0366], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,018][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:32,022][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,024][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,027][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,030][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,031][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,031][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,032][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,032][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,032][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,033][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,033][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,033][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,034][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0060, 0.9940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,037][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0505, 0.9495], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,039][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,044][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0299, 0.9701], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,050][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0146, 0.9854], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,050][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6760, 0.3240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,050][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1435, 0.8565], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,050][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1128, 0.8872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,051][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0284, 0.9716], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,051][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0230, 0.9770], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,051][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0079, 0.9921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,051][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0297, 0.9703], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,052][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.0042, 0.3417, 0.6541], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,052][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.1511, 0.3965, 0.4524], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,052][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.0027, 0.7538, 0.2435], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,054][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.0289, 0.2891, 0.6820], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,059][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.0145, 0.5217, 0.4638], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,064][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.5818, 0.1083, 0.3098], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,068][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.1442, 0.4268, 0.4290], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,068][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.1434, 0.4917, 0.3649], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,068][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.0143, 0.2818, 0.7040], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,068][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.0110, 0.4617, 0.5273], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,069][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.0143, 0.6565, 0.3292], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,069][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.0010, 0.1387, 0.8603], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,069][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([3.6210e-04, 2.5343e-01, 5.3995e-01, 2.0625e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,070][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2760, 0.2608, 0.2985, 0.1648], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,070][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0045, 0.3503, 0.1745, 0.4707], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,070][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0106, 0.2503, 0.6193, 0.1198], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,070][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0054, 0.3944, 0.3305, 0.2697], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,074][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8228, 0.0487, 0.1205, 0.0079], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,079][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0856, 0.2754, 0.3475, 0.2915], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,084][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3130, 0.2887, 0.2314, 0.1669], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,085][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0035, 0.1576, 0.7734, 0.0656], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,086][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0052, 0.2301, 0.5846, 0.1801], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,086][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0078, 0.1743, 0.3709, 0.4469], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,086][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0036, 0.1176, 0.7322, 0.1465], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,087][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0006, 0.1989, 0.5558, 0.1777, 0.0671], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,087][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.1967, 0.1566, 0.3031, 0.1381, 0.2055], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,087][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0011, 0.3224, 0.0894, 0.3919, 0.1952], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,088][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0056, 0.1399, 0.5380, 0.0819, 0.2345], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,088][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0022, 0.2588, 0.4226, 0.2183, 0.0980], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,088][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.4860, 0.1036, 0.3226, 0.0317, 0.0561], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,091][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0765, 0.2319, 0.2627, 0.2269, 0.2020], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,097][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1181, 0.2741, 0.2474, 0.1936, 0.1669], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,102][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0021, 0.0905, 0.6833, 0.0793, 0.1448], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,103][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0030, 0.2519, 0.4790, 0.1617, 0.1044], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,104][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0045, 0.1467, 0.2008, 0.3397, 0.3083], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,104][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0008, 0.0772, 0.2856, 0.1242, 0.5122], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,104][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([4.1316e-04, 1.6607e-01, 5.2096e-01, 1.7965e-01, 7.6683e-02, 5.6219e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,105][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0878, 0.2167, 0.3019, 0.1585, 0.1387, 0.0964], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,105][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0013, 0.2583, 0.0844, 0.2524, 0.1923, 0.2113], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,105][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0023, 0.0977, 0.5586, 0.0709, 0.2003, 0.0702], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,105][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0013, 0.2995, 0.2685, 0.2638, 0.0845, 0.0823], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,106][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.5155, 0.0852, 0.3108, 0.0242, 0.0487, 0.0157], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,109][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0438, 0.1712, 0.2402, 0.1845, 0.1907, 0.1696], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,115][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1159, 0.2214, 0.3084, 0.1466, 0.1485, 0.0591], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,119][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0016, 0.1109, 0.6054, 0.0727, 0.1447, 0.0646], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,121][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0014, 0.1669, 0.4538, 0.1526, 0.1218, 0.1035], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,121][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0009, 0.1172, 0.1804, 0.3048, 0.2497, 0.1470], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,121][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0027, 0.0541, 0.2033, 0.1570, 0.3210, 0.2619], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,122][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0006, 0.1923, 0.4162, 0.2084, 0.0665, 0.0689, 0.0471],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,122][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1543, 0.1665, 0.2955, 0.1364, 0.0858, 0.0794, 0.0820],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,122][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0010, 0.1758, 0.0594, 0.2511, 0.1081, 0.1706, 0.2339],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,123][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0055, 0.1513, 0.4427, 0.0860, 0.1630, 0.0726, 0.0788],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,123][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0034, 0.2244, 0.2550, 0.2416, 0.0772, 0.0949, 0.1034],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,126][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6222, 0.1030, 0.2002, 0.0201, 0.0287, 0.0136, 0.0122],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,132][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0497, 0.1429, 0.1937, 0.1505, 0.1495, 0.1444, 0.1694],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,137][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1623, 0.2367, 0.2092, 0.1505, 0.0965, 0.0672, 0.0776],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,138][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0037, 0.0974, 0.5956, 0.0554, 0.1329, 0.0711, 0.0438],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,138][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0031, 0.1793, 0.3797, 0.1545, 0.0870, 0.1120, 0.0844],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,139][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0010, 0.0765, 0.1533, 0.2598, 0.1720, 0.1729, 0.1644],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,139][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0006, 0.0411, 0.1787, 0.1364, 0.4329, 0.1682, 0.0420],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,139][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0005, 0.1537, 0.4215, 0.1516, 0.0588, 0.0609, 0.0567, 0.0964],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,140][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0680, 0.1803, 0.2170, 0.1441, 0.1002, 0.1059, 0.0852, 0.0994],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,140][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0005, 0.1228, 0.0552, 0.2140, 0.1232, 0.1352, 0.2502, 0.0989],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,141][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0042, 0.1477, 0.4170, 0.0646, 0.1278, 0.0694, 0.0721, 0.0971],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,141][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0021, 0.2811, 0.1840, 0.2129, 0.0487, 0.0591, 0.0881, 0.1240],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,144][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.4500, 0.1213, 0.2723, 0.0315, 0.0467, 0.0219, 0.0228, 0.0336],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,148][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0286, 0.1186, 0.1758, 0.1283, 0.1373, 0.1293, 0.1475, 0.1346],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,154][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0893, 0.1606, 0.2568, 0.1287, 0.1333, 0.0638, 0.0975, 0.0700],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,156][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0026, 0.0927, 0.5281, 0.0497, 0.1130, 0.0520, 0.0484, 0.1135],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,157][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0026, 0.1484, 0.3374, 0.1033, 0.0730, 0.1068, 0.0973, 0.1312],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,157][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([2.1918e-04, 5.2292e-02, 7.6850e-02, 2.7763e-01, 1.2417e-01, 1.7293e-01,
        1.9225e-01, 1.0366e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,157][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0008, 0.0310, 0.1825, 0.0912, 0.3444, 0.1511, 0.0808, 0.1182],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,157][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0009, 0.1283, 0.4453, 0.0969, 0.0482, 0.0358, 0.0385, 0.0619, 0.1442],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,158][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0976, 0.1392, 0.2008, 0.0987, 0.0872, 0.0841, 0.0804, 0.1060, 0.1060],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,158][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0006, 0.1195, 0.0512, 0.1631, 0.1178, 0.1338, 0.1856, 0.1014, 0.1270],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,158][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0048, 0.0893, 0.3816, 0.0461, 0.1205, 0.0547, 0.0600, 0.0738, 0.1692],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,159][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0029, 0.2354, 0.1897, 0.1446, 0.0416, 0.0552, 0.0690, 0.0920, 0.1695],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,160][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.4780, 0.1002, 0.2365, 0.0261, 0.0398, 0.0173, 0.0202, 0.0324, 0.0496],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,165][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0303, 0.1035, 0.1421, 0.1079, 0.1145, 0.1118, 0.1293, 0.1226, 0.1380],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,170][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0758, 0.1508, 0.1844, 0.1032, 0.0888, 0.0652, 0.0786, 0.0814, 0.1718],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,174][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0047, 0.0760, 0.4273, 0.0325, 0.0740, 0.0339, 0.0334, 0.0831, 0.2352],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,174][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0020, 0.1215, 0.2755, 0.0696, 0.0564, 0.0658, 0.0691, 0.1100, 0.2302],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,175][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0006, 0.0550, 0.1295, 0.1552, 0.1801, 0.1221, 0.1727, 0.0986, 0.0862],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,175][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0005, 0.0208, 0.2075, 0.0525, 0.2278, 0.1824, 0.0566, 0.2195, 0.0325],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,175][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.0754e-04, 1.0711e-01, 2.7700e-01, 8.4360e-02, 3.2323e-02, 3.2752e-02,
        3.4620e-02, 7.4902e-02, 2.1705e-01, 1.3968e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,176][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0530, 0.1784, 0.1343, 0.1260, 0.0559, 0.0651, 0.0703, 0.0646, 0.0957,
        0.1568], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,176][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0003, 0.0840, 0.0366, 0.1731, 0.0906, 0.1037, 0.1808, 0.0748, 0.1016,
        0.1543], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,177][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0017, 0.1082, 0.2422, 0.0527, 0.0878, 0.0448, 0.0551, 0.0702, 0.1757,
        0.1615], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,177][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0010, 0.1815, 0.1317, 0.1382, 0.0295, 0.0465, 0.0527, 0.0748, 0.1274,
        0.2167], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,180][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4345, 0.1144, 0.2111, 0.0273, 0.0379, 0.0150, 0.0158, 0.0288, 0.0422,
        0.0731], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,184][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0255, 0.1015, 0.1171, 0.0997, 0.0991, 0.0975, 0.1175, 0.1069, 0.1209,
        0.1143], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,190][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0794, 0.1569, 0.1433, 0.1083, 0.0686, 0.0497, 0.0597, 0.0550, 0.1444,
        0.1347], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,192][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0008, 0.0627, 0.2858, 0.0317, 0.0523, 0.0343, 0.0287, 0.0810, 0.2553,
        0.1675], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,192][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0008, 0.0908, 0.1802, 0.0608, 0.0429, 0.0588, 0.0538, 0.0910, 0.2154,
        0.2053], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,193][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0002, 0.0431, 0.0876, 0.1747, 0.1204, 0.1211, 0.1307, 0.1012, 0.0983,
        0.1226], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,193][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0006, 0.0191, 0.2620, 0.0325, 0.2391, 0.1195, 0.0767, 0.1548, 0.0772,
        0.0184], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,193][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([7.0866e-05, 9.6351e-02, 2.4605e-01, 6.1111e-02, 2.7238e-02, 2.9792e-02,
        2.7006e-02, 6.6393e-02, 2.2848e-01, 1.4478e-01, 7.2726e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,194][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0333, 0.1226, 0.1349, 0.1165, 0.0584, 0.0646, 0.0588, 0.0570, 0.0814,
        0.1287, 0.1437], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,194][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.2411e-04, 5.5134e-02, 2.2761e-02, 1.1607e-01, 5.4169e-02, 7.2712e-02,
        1.3372e-01, 5.5860e-02, 7.5743e-02, 1.2001e-01, 2.9360e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,194][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0013, 0.0927, 0.2535, 0.0443, 0.0796, 0.0382, 0.0422, 0.0647, 0.1580,
        0.1478, 0.0777], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,197][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0008, 0.1441, 0.1345, 0.0957, 0.0274, 0.0405, 0.0432, 0.0619, 0.1259,
        0.2028, 0.1231], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,203][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5051, 0.0840, 0.2249, 0.0171, 0.0330, 0.0095, 0.0090, 0.0181, 0.0288,
        0.0489, 0.0218], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,207][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0260, 0.0910, 0.1032, 0.0916, 0.0896, 0.0901, 0.1061, 0.0981, 0.1100,
        0.1049, 0.0894], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,211][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1013, 0.1550, 0.1209, 0.1001, 0.0492, 0.0384, 0.0456, 0.0450, 0.1224,
        0.1240, 0.0981], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,211][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0003, 0.0558, 0.2303, 0.0231, 0.0427, 0.0279, 0.0230, 0.0651, 0.2568,
        0.1689, 0.1060], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,212][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0005, 0.0737, 0.1881, 0.0558, 0.0418, 0.0475, 0.0419, 0.0885, 0.2096,
        0.1746, 0.0781], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,212][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0002, 0.0321, 0.0620, 0.1309, 0.0895, 0.1215, 0.1227, 0.0998, 0.0858,
        0.1093, 0.1463], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,212][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0010, 0.0253, 0.1724, 0.0303, 0.2642, 0.1623, 0.0743, 0.1287, 0.0784,
        0.0299, 0.0332], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,213][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([9.2867e-05, 7.0573e-02, 2.9340e-01, 5.7339e-02, 4.2077e-02, 2.9891e-02,
        2.2897e-02, 5.4913e-02, 1.7479e-01, 1.5659e-01, 7.8306e-02, 1.9137e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,213][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0396, 0.1093, 0.1353, 0.0726, 0.0649, 0.0688, 0.0677, 0.0722, 0.0847,
        0.1159, 0.1092, 0.0597], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,213][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0749, 0.0313, 0.1195, 0.0534, 0.0996, 0.1012, 0.0579, 0.0585,
        0.1149, 0.2448, 0.0440], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,214][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0571, 0.3241, 0.0318, 0.1083, 0.0381, 0.0344, 0.0586, 0.1302,
        0.1080, 0.0553, 0.0534], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,217][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.0838, 0.1757, 0.0805, 0.0375, 0.0358, 0.0401, 0.0681, 0.1166,
        0.1827, 0.1412, 0.0376], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,223][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.3375, 0.0968, 0.2535, 0.0263, 0.0449, 0.0150, 0.0192, 0.0247, 0.0432,
        0.0666, 0.0352, 0.0371], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,227][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0251, 0.0774, 0.1045, 0.0833, 0.0850, 0.0822, 0.0945, 0.0859, 0.1046,
        0.0951, 0.0793, 0.0831], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,229][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0484, 0.1023, 0.1379, 0.0608, 0.0805, 0.0488, 0.0543, 0.0578, 0.1362,
        0.1187, 0.0896, 0.0648], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,229][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0438, 0.2931, 0.0293, 0.0690, 0.0301, 0.0220, 0.0648, 0.2230,
        0.1179, 0.0850, 0.0217], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,229][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0577, 0.1957, 0.0460, 0.0528, 0.0510, 0.0420, 0.0768, 0.1774,
        0.1692, 0.0927, 0.0385], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,230][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0004, 0.0252, 0.0757, 0.1167, 0.1067, 0.1144, 0.1104, 0.0850, 0.0802,
        0.0986, 0.1201, 0.0665], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,230][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.3790e-04, 1.7657e-02, 1.2980e-01, 5.5909e-02, 2.4210e-01, 1.2947e-01,
        5.9135e-02, 1.5507e-01, 3.2970e-02, 5.0970e-02, 7.5346e-02, 5.1323e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,230][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([4.5181e-05, 5.5297e-02, 2.5586e-01, 6.5733e-02, 3.4932e-02, 2.5639e-02,
        1.8607e-02, 9.0076e-02, 1.5856e-01, 1.6984e-01, 9.5430e-02, 2.8191e-02,
        1.7881e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,231][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0328, 0.0756, 0.1293, 0.0860, 0.0967, 0.0544, 0.0478, 0.0598, 0.0683,
        0.0972, 0.1090, 0.0757, 0.0675], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,231][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([9.5631e-05, 6.8778e-02, 1.6098e-02, 1.1896e-01, 4.2358e-02, 8.6798e-02,
        8.7130e-02, 6.7949e-02, 6.5099e-02, 9.4482e-02, 2.3723e-01, 4.5069e-02,
        6.9954e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,234][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0005, 0.0441, 0.2476, 0.0371, 0.1355, 0.0394, 0.0385, 0.0664, 0.1113,
        0.1239, 0.0877, 0.0547, 0.0135], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,239][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0002, 0.0792, 0.1360, 0.0847, 0.0364, 0.0308, 0.0397, 0.0776, 0.1154,
        0.2018, 0.1454, 0.0470, 0.0059], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,244][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.1704, 0.0977, 0.2397, 0.0330, 0.0490, 0.0388, 0.0233, 0.0487, 0.0780,
        0.0843, 0.0489, 0.0674, 0.0208], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,246][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0203, 0.0738, 0.0903, 0.0759, 0.0728, 0.0790, 0.0889, 0.0838, 0.0908,
        0.0895, 0.0754, 0.0860, 0.0735], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,247][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0334, 0.0976, 0.0945, 0.0773, 0.0655, 0.0474, 0.0524, 0.0820, 0.1171,
        0.1080, 0.1132, 0.0540, 0.0575], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,247][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([1.7638e-04, 2.5818e-02, 2.9519e-01, 3.0894e-02, 7.7811e-02, 2.7404e-02,
        1.7880e-02, 7.6926e-02, 1.9664e-01, 1.1309e-01, 9.9091e-02, 2.8782e-02,
        1.0300e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,247][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0002, 0.0607, 0.1826, 0.0558, 0.0472, 0.0450, 0.0344, 0.0644, 0.1495,
        0.1874, 0.1172, 0.0483, 0.0073], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,248][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0002, 0.0351, 0.0655, 0.1101, 0.0993, 0.1026, 0.1006, 0.0854, 0.0815,
        0.0865, 0.1003, 0.0792, 0.0537], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,248][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0003, 0.0256, 0.0883, 0.0455, 0.1711, 0.1677, 0.0433, 0.1106, 0.0376,
        0.0364, 0.0397, 0.0471, 0.1868], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,249][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0003, 0.0930, 0.2617, 0.0620, 0.0293, 0.0263, 0.0292, 0.0600, 0.1565,
        0.1215, 0.0578, 0.0229, 0.0018, 0.0779], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,249][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0716, 0.0804, 0.2015, 0.0601, 0.0933, 0.0401, 0.0398, 0.0505, 0.0563,
        0.0755, 0.0660, 0.0669, 0.0565, 0.0415], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,252][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0004, 0.0880, 0.0233, 0.0948, 0.0457, 0.0746, 0.0826, 0.0652, 0.0521,
        0.0943, 0.1978, 0.0515, 0.0780, 0.0515], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,256][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0017, 0.0798, 0.2569, 0.0386, 0.0800, 0.0360, 0.0376, 0.0553, 0.1237,
        0.1185, 0.0589, 0.0573, 0.0087, 0.0470], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,262][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0010, 0.1251, 0.1280, 0.0915, 0.0301, 0.0308, 0.0394, 0.0576, 0.0958,
        0.1708, 0.1107, 0.0291, 0.0049, 0.0853], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,264][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.3538, 0.0667, 0.2606, 0.0222, 0.0437, 0.0126, 0.0160, 0.0270, 0.0358,
        0.0556, 0.0290, 0.0366, 0.0164, 0.0242], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,264][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0247, 0.0694, 0.0788, 0.0702, 0.0691, 0.0716, 0.0833, 0.0775, 0.0838,
        0.0805, 0.0701, 0.0705, 0.0712, 0.0793], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,265][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0465, 0.1519, 0.1173, 0.0820, 0.0523, 0.0397, 0.0397, 0.0456, 0.0832,
        0.1147, 0.0859, 0.0476, 0.0415, 0.0521], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,265][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0013, 0.0577, 0.2369, 0.0267, 0.0458, 0.0232, 0.0238, 0.0698, 0.1683,
        0.1198, 0.0729, 0.0353, 0.0065, 0.1120], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,266][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0008, 0.0810, 0.2161, 0.0508, 0.0403, 0.0402, 0.0350, 0.0645, 0.1242,
        0.1539, 0.0789, 0.0394, 0.0073, 0.0676], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,266][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0003, 0.0369, 0.0601, 0.0969, 0.0769, 0.0741, 0.0817, 0.0693, 0.0582,
        0.1064, 0.1460, 0.0809, 0.0541, 0.0582], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,266][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0004, 0.0208, 0.1379, 0.0411, 0.1892, 0.1222, 0.0394, 0.1182, 0.0182,
        0.0265, 0.0382, 0.0422, 0.1856, 0.0202], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,267][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0005, 0.0827, 0.2817, 0.0673, 0.0323, 0.0207, 0.0211, 0.0458, 0.1103,
        0.1050, 0.0606, 0.0228, 0.0021, 0.0722, 0.0748], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,270][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0646, 0.0885, 0.1199, 0.0869, 0.0484, 0.0485, 0.0486, 0.0528, 0.0614,
        0.0926, 0.1066, 0.0598, 0.0351, 0.0354, 0.0510], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,274][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0002, 0.0469, 0.0176, 0.0958, 0.0390, 0.0551, 0.0947, 0.0421, 0.0538,
        0.0850, 0.1984, 0.0286, 0.0628, 0.0460, 0.1340], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,280][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0034, 0.0733, 0.2333, 0.0394, 0.0744, 0.0315, 0.0387, 0.0446, 0.1122,
        0.1133, 0.0652, 0.0557, 0.0095, 0.0498, 0.0556], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,282][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0017, 0.1122, 0.1345, 0.0791, 0.0264, 0.0280, 0.0356, 0.0552, 0.0834,
        0.1576, 0.0994, 0.0304, 0.0050, 0.0884, 0.0631], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,282][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4139, 0.0844, 0.2009, 0.0196, 0.0290, 0.0129, 0.0127, 0.0184, 0.0346,
        0.0527, 0.0285, 0.0321, 0.0123, 0.0209, 0.0272], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,283][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0217, 0.0608, 0.0744, 0.0638, 0.0652, 0.0650, 0.0785, 0.0715, 0.0820,
        0.0747, 0.0633, 0.0650, 0.0662, 0.0723, 0.0755], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,283][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0605, 0.1046, 0.1021, 0.0745, 0.0489, 0.0314, 0.0393, 0.0345, 0.0925,
        0.1007, 0.0800, 0.0422, 0.0505, 0.0585, 0.0799], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,283][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0013, 0.0392, 0.2753, 0.0192, 0.0564, 0.0222, 0.0165, 0.0453, 0.1516,
        0.1013, 0.0754, 0.0350, 0.0096, 0.1112, 0.0404], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,284][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0019, 0.0642, 0.1870, 0.0520, 0.0373, 0.0412, 0.0400, 0.0598, 0.1365,
        0.1331, 0.0730, 0.0421, 0.0079, 0.0714, 0.0525], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,284][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0003, 0.0240, 0.0540, 0.1055, 0.0800, 0.0867, 0.0875, 0.0590, 0.0612,
        0.0876, 0.1097, 0.0596, 0.0418, 0.0604, 0.0827], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,285][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0006, 0.0192, 0.1067, 0.0360, 0.1585, 0.0847, 0.0665, 0.0790, 0.0463,
        0.0211, 0.0364, 0.0614, 0.1960, 0.0391, 0.0485], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,286][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:32,287][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[20576],
        [ 8079],
        [ 5529],
        [ 5374],
        [ 4299],
        [ 2853],
        [ 1419],
        [ 2288],
        [ 2692],
        [ 7518],
        [ 4827],
        [ 4693],
        [ 2514],
        [ 1282],
        [ 1059]], device='cuda:0')
[2024-07-24 10:25:32,289][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[19899],
        [16015],
        [20391],
        [13205],
        [29088],
        [22322],
        [16584],
        [18053],
        [16322],
        [16251],
        [10683],
        [24126],
        [25591],
        [13237],
        [13477]], device='cuda:0')
[2024-07-24 10:25:32,292][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[32468],
        [ 8973],
        [11908],
        [ 7129],
        [ 8174],
        [ 7167],
        [ 6530],
        [ 7325],
        [ 8749],
        [ 7051],
        [ 6016],
        [ 6316],
        [ 5522],
        [ 6481],
        [ 6032]], device='cuda:0')
[2024-07-24 10:25:32,294][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18083],
        [19597],
        [46274],
        [47031],
        [46620],
        [47069],
        [47851],
        [43687],
        [41084],
        [39802],
        [44163],
        [41009],
        [39192],
        [45883],
        [42543]], device='cuda:0')
[2024-07-24 10:25:32,297][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23737],
        [18420],
        [24491],
        [23539],
        [23724],
        [24072],
        [22734],
        [22784],
        [22108],
        [21753],
        [21500],
        [22029],
        [21494],
        [21368],
        [21129]], device='cuda:0')
[2024-07-24 10:25:32,299][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[4898],
        [ 898],
        [ 256],
        [ 131],
        [ 173],
        [ 180],
        [ 210],
        [ 231],
        [ 249],
        [ 235],
        [ 237],
        [ 223],
        [ 279],
        [ 252],
        [ 236]], device='cuda:0')
[2024-07-24 10:25:32,302][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[25289],
        [44455],
        [38342],
        [39027],
        [34911],
        [36098],
        [37432],
        [40744],
        [40058],
        [40559],
        [40737],
        [40766],
        [41250],
        [40031],
        [40467]], device='cuda:0')
[2024-07-24 10:25:32,304][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35288],
        [11439],
        [41343],
        [38876],
        [38119],
        [38778],
        [33931],
        [30397],
        [28317],
        [23315],
        [29490],
        [22825],
        [15250],
        [23932],
        [20739]], device='cuda:0')
[2024-07-24 10:25:32,305][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2473],
        [1993],
        [2002],
        [2299],
        [2711],
        [3508],
        [4129],
        [4913],
        [6184],
        [4995],
        [4898],
        [5504],
        [5522],
        [4501],
        [4416]], device='cuda:0')
[2024-07-24 10:25:32,306][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[29484],
        [35843],
        [41632],
        [36426],
        [38268],
        [40147],
        [37091],
        [37405],
        [34377],
        [32935],
        [31804],
        [32402],
        [31471],
        [32768],
        [32163]], device='cuda:0')
[2024-07-24 10:25:32,307][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3834],
        [23129],
        [38310],
        [39573],
        [37353],
        [35820],
        [35729],
        [34693],
        [36327],
        [35936],
        [35345],
        [35334],
        [34902],
        [36747],
        [37410]], device='cuda:0')
[2024-07-24 10:25:32,308][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25493],
        [17527],
        [ 6026],
        [ 6170],
        [ 6800],
        [ 7036],
        [ 7372],
        [ 7845],
        [10355],
        [ 9548],
        [ 9302],
        [ 9538],
        [ 9478],
        [10038],
        [10028]], device='cuda:0')
[2024-07-24 10:25:32,309][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29496],
        [16437],
        [35661],
        [42207],
        [19336],
        [23518],
        [31991],
        [16343],
        [21598],
        [28295],
        [26879],
        [16300],
        [13074],
        [15434],
        [22319]], device='cuda:0')
[2024-07-24 10:25:32,311][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[8856],
        [1527],
        [ 624],
        [ 985],
        [ 959],
        [1249],
        [1302],
        [1375],
        [1291],
        [1201],
        [1246],
        [1347],
        [1202],
        [1175],
        [1176]], device='cuda:0')
[2024-07-24 10:25:32,314][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26880],
        [ 8216],
        [ 3095],
        [ 6791],
        [ 2339],
        [ 2268],
        [ 2413],
        [ 2637],
        [ 2924],
        [ 7993],
        [ 9694],
        [ 2863],
        [ 1823],
        [ 2877],
        [ 2694]], device='cuda:0')
[2024-07-24 10:25:32,316][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15955],
        [43036],
        [46847],
        [45262],
        [45377],
        [44766],
        [44114],
        [44252],
        [45930],
        [45473],
        [45015],
        [44907],
        [44297],
        [45199],
        [45027]], device='cuda:0')
[2024-07-24 10:25:32,319][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[33580],
        [17203],
        [20607],
        [21054],
        [16189],
        [15674],
        [14117],
        [12434],
        [11806],
        [12265],
        [13610],
        [12793],
        [12355],
        [13545],
        [12410]], device='cuda:0')
[2024-07-24 10:25:32,321][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33455],
        [39381],
        [36853],
        [34351],
        [33495],
        [32717],
        [29720],
        [30140],
        [30909],
        [31016],
        [35114],
        [34802],
        [35201],
        [34590],
        [34674]], device='cuda:0')
[2024-07-24 10:25:32,324][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 4538],
        [14223],
        [ 3503],
        [ 4419],
        [ 5376],
        [ 5224],
        [ 6755],
        [ 7986],
        [ 8104],
        [ 9759],
        [ 9123],
        [ 8082],
        [ 9012],
        [ 8599],
        [ 8598]], device='cuda:0')
[2024-07-24 10:25:32,326][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27811],
        [  505],
        [ 1846],
        [ 1490],
        [ 2922],
        [ 1440],
        [ 1283],
        [  804],
        [  890],
        [  710],
        [  842],
        [ 1054],
        [  907],
        [  694],
        [  766]], device='cuda:0')
[2024-07-24 10:25:32,327][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32907],
        [48050],
        [45948],
        [42177],
        [43279],
        [43967],
        [46793],
        [40757],
        [42497],
        [40567],
        [44785],
        [33837],
        [20772],
        [34002],
        [39508]], device='cuda:0')
[2024-07-24 10:25:32,328][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18032],
        [18511],
        [13144],
        [12717],
        [11277],
        [11052],
        [11912],
        [11303],
        [11435],
        [10922],
        [10673],
        [ 9406],
        [ 9014],
        [ 9446],
        [ 9518]], device='cuda:0')
[2024-07-24 10:25:32,329][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[41049],
        [ 7945],
        [15934],
        [17136],
        [18506],
        [18422],
        [16710],
        [17005],
        [14400],
        [12931],
        [11320],
        [12983],
        [11955],
        [12546],
        [12294]], device='cuda:0')
[2024-07-24 10:25:32,330][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[45437],
        [26178],
        [20975],
        [18024],
        [15207],
        [15490],
        [14754],
        [15645],
        [19649],
        [24760],
        [26629],
        [24229],
        [23714],
        [26461],
        [24919]], device='cuda:0')
[2024-07-24 10:25:32,331][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[41814],
        [32960],
        [35471],
        [33693],
        [33418],
        [30973],
        [29564],
        [28686],
        [22955],
        [18725],
        [17851],
        [18306],
        [18486],
        [17747],
        [17358]], device='cuda:0')
[2024-07-24 10:25:32,333][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[27895],
        [18122],
        [17251],
        [14502],
        [10156],
        [11848],
        [14037],
        [16798],
        [15703],
        [17605],
        [18007],
        [17434],
        [16937],
        [17189],
        [18002]], device='cuda:0')
[2024-07-24 10:25:32,336][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[26329],
        [ 8127],
        [ 7284],
        [ 6740],
        [ 7449],
        [ 8487],
        [ 8490],
        [ 8188],
        [ 7621],
        [ 7535],
        [ 7980],
        [ 7423],
        [ 8124],
        [ 8055],
        [ 8067]], device='cuda:0')
[2024-07-24 10:25:32,338][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 8873],
        [28986],
        [27694],
        [33113],
        [32639],
        [33954],
        [33673],
        [35323],
        [35727],
        [35222],
        [33208],
        [36276],
        [38790],
        [35713],
        [35236]], device='cuda:0')
[2024-07-24 10:25:32,341][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21680],
        [47466],
        [48354],
        [47440],
        [48805],
        [48902],
        [48762],
        [48710],
        [48742],
        [47868],
        [47670],
        [48770],
        [49307],
        [48798],
        [48996]], device='cuda:0')
[2024-07-24 10:25:32,343][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776],
        [24776]], device='cuda:0')
[2024-07-24 10:25:32,383][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:32,386][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,388][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,388][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,389][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,389][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,389][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,390][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,390][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,390][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,391][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,391][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,392][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,394][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6915, 0.3085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,405][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7868, 0.2132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,407][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5260, 0.4740], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,407][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([4.0565e-04, 9.9959e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,408][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0800, 0.9200], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,408][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0954, 0.9046], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,408][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7719, 0.2281], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,408][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0063, 0.9937], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,409][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9864, 0.0136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,409][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7608, 0.2392], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,409][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5046, 0.4954], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,410][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0113, 0.9887], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,411][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.4687, 0.2867, 0.2446], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,416][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.1949, 0.3719, 0.4332], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,421][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.3831, 0.1788, 0.4381], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,424][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.0077, 0.6408, 0.3515], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,424][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.0021, 0.3955, 0.6024], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,425][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.0210, 0.7293, 0.2497], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,425][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.2973, 0.1141, 0.5886], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,425][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.0011, 0.6982, 0.3007], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,426][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([3.8335e-01, 5.7239e-04, 6.1608e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,426][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.5499, 0.0276, 0.4225], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,426][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.4368, 0.1263, 0.4370], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,426][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.0355, 0.7734, 0.1911], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,427][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5293, 0.1621, 0.1688, 0.1398], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,427][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3017, 0.1133, 0.4151, 0.1699], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,430][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3084, 0.1259, 0.4301, 0.1356], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,433][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([4.0911e-04, 2.7916e-01, 2.3317e-01, 4.8726e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,438][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0014, 0.0905, 0.8419, 0.0662], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,441][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0116, 0.5853, 0.2560, 0.1471], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,442][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6451, 0.0202, 0.3241, 0.0106], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,442][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0005, 0.4582, 0.4300, 0.1112], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,442][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([7.7924e-02, 1.9374e-04, 9.2167e-01, 2.0748e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,442][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6670, 0.0103, 0.3200, 0.0027], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,443][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4002, 0.1705, 0.3172, 0.1120], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,443][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0099, 0.4047, 0.2638, 0.3217], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,443][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.3425, 0.1686, 0.1602, 0.1524, 0.1762], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,444][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0945, 0.2009, 0.2505, 0.2017, 0.2524], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,444][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0724, 0.1072, 0.3587, 0.1421, 0.3196], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,445][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0016, 0.3395, 0.2222, 0.3110, 0.1258], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,449][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([2.3299e-04, 1.3999e-01, 6.6500e-01, 9.9145e-02, 9.5636e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,453][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0022, 0.5687, 0.2392, 0.1357, 0.0542], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,459][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.3981, 0.0524, 0.3729, 0.0319, 0.1447], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,459][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([1.3319e-04, 4.1755e-01, 3.7997e-01, 1.5736e-01, 4.4994e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,459][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([7.5047e-02, 4.0340e-04, 8.9754e-01, 6.5390e-04, 2.6360e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,460][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.3915, 0.0133, 0.3872, 0.0125, 0.1954], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,460][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.2534, 0.1061, 0.3490, 0.0912, 0.2003], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,460][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0058, 0.4285, 0.1118, 0.4050, 0.0489], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,460][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2923, 0.1454, 0.1362, 0.1310, 0.1492, 0.1459], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,461][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0775, 0.1479, 0.2258, 0.1567, 0.2211, 0.1711], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,461][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0474, 0.1296, 0.3127, 0.1300, 0.2239, 0.1564], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,461][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([1.6416e-04, 2.1482e-01, 2.1918e-01, 2.5028e-01, 1.6753e-01, 1.4802e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,463][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([2.3501e-04, 1.5774e-01, 5.1463e-01, 1.3667e-01, 9.2695e-02, 9.8031e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,468][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0033, 0.5188, 0.2349, 0.1291, 0.0551, 0.0588], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,472][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1720, 0.0606, 0.4682, 0.0506, 0.1935, 0.0551], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,476][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([1.3502e-04, 3.6802e-01, 3.8149e-01, 1.5169e-01, 5.0802e-02, 4.7865e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,476][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([1.4544e-02, 3.0961e-04, 9.4841e-01, 8.5647e-04, 2.9542e-02, 6.3376e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,476][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1838, 0.0246, 0.5215, 0.0254, 0.1973, 0.0474], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,477][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2579, 0.1178, 0.2947, 0.0922, 0.1461, 0.0913], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,477][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0017, 0.2562, 0.1157, 0.4076, 0.0760, 0.1430], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,477][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2275, 0.1086, 0.1032, 0.0980, 0.1118, 0.1116, 0.2393],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,478][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0698, 0.1222, 0.1891, 0.1301, 0.1814, 0.1382, 0.1691],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,478][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1049, 0.1054, 0.2420, 0.0935, 0.1815, 0.1361, 0.1366],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,478][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.7020e-04, 2.4824e-01, 1.2884e-01, 3.1020e-01, 9.4218e-02, 1.3910e-01,
        7.9234e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,481][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0006, 0.1576, 0.4562, 0.1225, 0.0874, 0.0947, 0.0810],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,486][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0097, 0.4789, 0.2142, 0.1256, 0.0502, 0.0532, 0.0683],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,491][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3152, 0.0565, 0.3576, 0.0378, 0.1035, 0.0484, 0.0810],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,493][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.7792e-04, 3.5825e-01, 2.9294e-01, 1.8618e-01, 4.1549e-02, 5.5991e-02,
        6.4912e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,493][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.5327e-02, 5.3626e-04, 9.4546e-01, 1.0420e-03, 2.7842e-02, 6.5823e-03,
        3.2111e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,494][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2852, 0.0229, 0.4477, 0.0189, 0.1597, 0.0359, 0.0297],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,494][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2423, 0.1272, 0.2016, 0.0974, 0.0991, 0.0818, 0.1505],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,494][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0046, 0.2469, 0.1041, 0.3123, 0.0570, 0.1239, 0.1512],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,495][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1832, 0.0927, 0.0872, 0.0841, 0.0952, 0.0940, 0.2076, 0.1559],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,495][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0520, 0.0910, 0.1602, 0.1013, 0.1508, 0.1145, 0.1400, 0.1900],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,495][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0431, 0.0884, 0.2093, 0.0979, 0.1742, 0.1440, 0.1422, 0.1008],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,496][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0002, 0.1497, 0.1774, 0.1621, 0.1468, 0.1767, 0.1050, 0.0822],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,498][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0005, 0.0957, 0.5054, 0.0703, 0.0679, 0.0885, 0.0799, 0.0919],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,503][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0045, 0.4808, 0.1936, 0.1194, 0.0399, 0.0460, 0.0680, 0.0479],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,507][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1722, 0.0626, 0.3415, 0.0405, 0.1116, 0.0678, 0.0960, 0.1078],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,510][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([9.4494e-05, 4.0512e-01, 2.1801e-01, 1.3972e-01, 2.7940e-02, 4.2427e-02,
        7.1564e-02, 9.5121e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,511][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([9.8881e-03, 6.7084e-04, 9.0685e-01, 1.8838e-03, 4.6082e-02, 1.5433e-02,
        6.6836e-03, 1.2512e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,511][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1343, 0.0293, 0.4618, 0.0365, 0.1572, 0.0538, 0.0457, 0.0814],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,511][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1441, 0.1166, 0.2276, 0.0843, 0.1064, 0.0663, 0.1264, 0.1283],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,512][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0019, 0.2210, 0.0847, 0.2897, 0.0530, 0.1366, 0.1362, 0.0768],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,512][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1549, 0.0824, 0.0759, 0.0751, 0.0841, 0.0831, 0.1897, 0.1367, 0.1183],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,512][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0441, 0.0718, 0.1349, 0.0780, 0.1315, 0.0965, 0.1180, 0.1654, 0.1598],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,513][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0705, 0.0877, 0.2056, 0.0871, 0.1421, 0.1162, 0.1211, 0.0833, 0.0864],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,513][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0002, 0.1587, 0.1085, 0.1925, 0.0913, 0.1711, 0.0901, 0.0474, 0.1401],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,516][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0007, 0.1699, 0.2826, 0.0899, 0.0434, 0.0727, 0.0855, 0.0829, 0.1723],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,522][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0080, 0.4494, 0.1754, 0.0966, 0.0365, 0.0426, 0.0622, 0.0495, 0.0798],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,526][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1231, 0.0482, 0.3203, 0.0347, 0.1238, 0.0567, 0.1034, 0.0972, 0.0925],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,528][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([2.9275e-04, 3.9386e-01, 2.2307e-01, 1.0192e-01, 2.6780e-02, 3.1739e-02,
        5.8761e-02, 8.3302e-02, 8.0274e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,528][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([1.6822e-02, 4.8715e-04, 9.1621e-01, 1.1299e-03, 3.7810e-02, 1.0806e-02,
        6.4246e-03, 7.5567e-03, 2.7500e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,528][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1859, 0.0286, 0.3770, 0.0302, 0.1331, 0.0415, 0.0321, 0.0539, 0.1176],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,529][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1013, 0.0845, 0.2293, 0.0651, 0.1034, 0.0574, 0.1006, 0.1023, 0.1560],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,529][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0017, 0.2267, 0.0535, 0.2702, 0.0323, 0.1090, 0.1193, 0.0568, 0.1306],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,529][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2147, 0.0637, 0.0693, 0.0557, 0.0734, 0.0717, 0.1495, 0.1174, 0.0997,
        0.0849], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,530][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0942, 0.0269, 0.1422, 0.0463, 0.1258, 0.0877, 0.1084, 0.1625, 0.1431,
        0.0630], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,530][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0454, 0.0500, 0.2136, 0.0724, 0.1526, 0.1106, 0.1193, 0.0817, 0.0820,
        0.0724], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,530][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([6.4260e-05, 1.1885e-01, 1.0824e-01, 1.8975e-01, 7.3621e-02, 7.6881e-02,
        5.0356e-02, 3.3389e-02, 9.0299e-02, 2.5855e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,535][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0007, 0.0691, 0.4427, 0.0463, 0.0661, 0.0413, 0.0382, 0.0458, 0.1678,
        0.0820], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,539][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0019, 0.3567, 0.1853, 0.0894, 0.0443, 0.0435, 0.0559, 0.0521, 0.1018,
        0.0690], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,545][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2996, 0.0254, 0.4144, 0.0150, 0.0899, 0.0186, 0.0429, 0.0485, 0.0331,
        0.0126], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,545][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0003, 0.2114, 0.2610, 0.0560, 0.0270, 0.0336, 0.0606, 0.0982, 0.1332,
        0.1188], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,545][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.5263e-02, 1.5058e-04, 9.5932e-01, 2.7215e-04, 1.8712e-02, 1.5037e-03,
        8.8226e-04, 2.4913e-03, 1.0392e-03, 3.6163e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,546][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4966, 0.0066, 0.3049, 0.0022, 0.0667, 0.0116, 0.0084, 0.0274, 0.0663,
        0.0095], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,546][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2375, 0.0917, 0.1776, 0.0595, 0.0805, 0.0434, 0.0905, 0.0643, 0.0878,
        0.0672], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,546][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0024, 0.1574, 0.0848, 0.1511, 0.0350, 0.0647, 0.0746, 0.0449, 0.1042,
        0.2810], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,547][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2158, 0.0577, 0.0644, 0.0498, 0.0674, 0.0656, 0.1362, 0.1089, 0.0924,
        0.0765, 0.0652], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,547][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1059, 0.0206, 0.1419, 0.0373, 0.1247, 0.0833, 0.1034, 0.1583, 0.1314,
        0.0477, 0.0456], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,550][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0512, 0.0477, 0.1940, 0.0618, 0.1366, 0.1066, 0.1114, 0.0762, 0.0825,
        0.0711, 0.0609], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,552][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([3.8619e-05, 7.8463e-02, 8.3140e-02, 1.7107e-01, 5.7165e-02, 5.7128e-02,
        3.9179e-02, 2.4920e-02, 6.7658e-02, 2.1852e-01, 2.0272e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,556][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([3.6118e-04, 5.1801e-02, 4.4934e-01, 3.5420e-02, 7.3223e-02, 4.0633e-02,
        3.5453e-02, 4.5733e-02, 1.7050e-01, 6.9448e-02, 2.8085e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,560][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0013, 0.3502, 0.1781, 0.0804, 0.0416, 0.0406, 0.0494, 0.0473, 0.0984,
        0.0668, 0.0461], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,562][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4107, 0.0174, 0.3796, 0.0092, 0.0630, 0.0134, 0.0305, 0.0374, 0.0276,
        0.0078, 0.0035], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,562][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.1677e-04, 1.6671e-01, 2.6620e-01, 4.6767e-02, 2.8841e-02, 3.5367e-02,
        5.4298e-02, 9.0793e-02, 1.5138e-01, 1.1095e-01, 4.8575e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,562][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([2.2114e-02, 1.4489e-04, 9.5344e-01, 2.5636e-04, 1.7758e-02, 1.4178e-03,
        7.9734e-04, 2.4385e-03, 1.1673e-03, 3.3573e-04, 1.2684e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,563][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5990, 0.0034, 0.2674, 0.0009, 0.0444, 0.0066, 0.0048, 0.0165, 0.0512,
        0.0040, 0.0018], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,563][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1765, 0.0969, 0.1544, 0.0579, 0.0813, 0.0490, 0.0872, 0.0711, 0.0868,
        0.0786, 0.0602], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,563][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0032, 0.1268, 0.0755, 0.1017, 0.0259, 0.0564, 0.0609, 0.0431, 0.1047,
        0.2128, 0.1891], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,564][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1216, 0.0605, 0.0581, 0.0557, 0.0639, 0.0631, 0.1369, 0.1015, 0.0895,
        0.0811, 0.0728, 0.0953], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,564][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0332, 0.0620, 0.0896, 0.0634, 0.0862, 0.0679, 0.0821, 0.1070, 0.1021,
        0.0972, 0.1043, 0.1050], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,567][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0127, 0.0595, 0.1865, 0.0743, 0.1244, 0.0958, 0.0884, 0.0652, 0.0696,
        0.0511, 0.0563, 0.1162], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,570][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.0284e-04, 7.3548e-02, 8.2806e-02, 1.1637e-01, 7.8342e-02, 7.9092e-02,
        3.9996e-02, 3.0835e-02, 7.5327e-02, 1.8892e-01, 1.7733e-01, 5.7327e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,573][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([9.5915e-05, 7.6496e-02, 2.9723e-01, 5.2184e-02, 5.2759e-02, 5.1462e-02,
        4.9364e-02, 7.3850e-02, 1.7409e-01, 9.6286e-02, 4.5729e-02, 3.0453e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,577][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0010, 0.3608, 0.1687, 0.0826, 0.0370, 0.0370, 0.0515, 0.0451, 0.0853,
        0.0658, 0.0456, 0.0196], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,579][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0644, 0.0354, 0.3501, 0.0277, 0.1285, 0.0526, 0.0824, 0.0810, 0.0844,
        0.0319, 0.0197, 0.0419], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,579][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([3.2548e-05, 1.7749e-01, 2.3540e-01, 7.0898e-02, 3.2882e-02, 3.0961e-02,
        4.2046e-02, 8.0370e-02, 8.8445e-02, 1.5168e-01, 7.2155e-02, 1.7632e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,580][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([6.3956e-03, 1.8889e-04, 9.2808e-01, 5.5883e-04, 3.3600e-02, 5.5474e-03,
        2.3400e-03, 4.8790e-03, 2.1844e-03, 8.5212e-04, 3.2497e-04, 1.5050e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,580][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.2054, 0.0067, 0.4115, 0.0063, 0.1267, 0.0186, 0.0169, 0.0453, 0.0885,
        0.0167, 0.0111, 0.0462], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,580][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0683, 0.0687, 0.1713, 0.0569, 0.0847, 0.0550, 0.0917, 0.1019, 0.1254,
        0.0727, 0.0581, 0.0454], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,581][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0009, 0.1206, 0.0379, 0.1143, 0.0197, 0.0454, 0.0524, 0.0325, 0.0698,
        0.2181, 0.2392, 0.0491], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,581][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.1063, 0.0547, 0.0535, 0.0511, 0.0598, 0.0572, 0.1303, 0.0968, 0.0831,
        0.0754, 0.0675, 0.0885, 0.0756], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,582][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0220, 0.0601, 0.0758, 0.0579, 0.0747, 0.0589, 0.0672, 0.0888, 0.0869,
        0.0915, 0.1021, 0.0956, 0.1184], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,585][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0173, 0.0417, 0.1528, 0.0567, 0.1258, 0.0884, 0.0803, 0.0651, 0.0693,
        0.0546, 0.0520, 0.1168, 0.0793], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,588][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([9.5249e-05, 9.5233e-02, 5.0333e-02, 1.2972e-01, 4.5969e-02, 7.2479e-02,
        3.1476e-02, 2.8475e-02, 6.0778e-02, 2.1961e-01, 1.9088e-01, 6.3331e-02,
        1.1624e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,591][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([1.4784e-05, 6.1328e-02, 3.1687e-01, 6.9357e-02, 7.7545e-02, 3.7413e-02,
        2.6389e-02, 8.1634e-02, 9.8370e-02, 1.1485e-01, 6.6741e-02, 4.7327e-02,
        2.1594e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,596][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0004, 0.3041, 0.1844, 0.0824, 0.0469, 0.0407, 0.0532, 0.0544, 0.0937,
        0.0644, 0.0460, 0.0236, 0.0058], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,596][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0915, 0.0367, 0.2392, 0.0282, 0.1167, 0.0521, 0.0856, 0.0869, 0.0824,
        0.0400, 0.0266, 0.0535, 0.0607], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,597][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([5.8913e-06, 9.8891e-02, 2.0223e-01, 8.0051e-02, 4.3838e-02, 2.6565e-02,
        2.8645e-02, 1.2793e-01, 8.5921e-02, 1.7405e-01, 9.6821e-02, 3.3945e-02,
        1.1087e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,597][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([6.9544e-03, 4.1482e-04, 8.9435e-01, 1.1079e-03, 3.5690e-02, 8.3087e-03,
        4.6025e-03, 7.9332e-03, 2.5236e-03, 2.2740e-03, 8.5562e-04, 3.1590e-02,
        3.3953e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,597][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.1312, 0.0118, 0.2730, 0.0144, 0.1661, 0.0257, 0.0226, 0.0442, 0.0907,
        0.0545, 0.0417, 0.0733, 0.0508], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,598][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0817, 0.0544, 0.2019, 0.0484, 0.1254, 0.0422, 0.0794, 0.0782, 0.1095,
        0.0497, 0.0402, 0.0328, 0.0562], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,598][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0005, 0.1063, 0.0215, 0.1358, 0.0127, 0.0373, 0.0443, 0.0231, 0.0418,
        0.2164, 0.3172, 0.0366, 0.0066], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,599][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0936, 0.0521, 0.0476, 0.0475, 0.0530, 0.0533, 0.1179, 0.0867, 0.0751,
        0.0700, 0.0627, 0.0805, 0.0683, 0.0917], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,599][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0212, 0.0528, 0.0704, 0.0530, 0.0696, 0.0550, 0.0644, 0.0868, 0.0813,
        0.0836, 0.0920, 0.0885, 0.1098, 0.0716], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,601][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0306, 0.0519, 0.1490, 0.0579, 0.1209, 0.0732, 0.0873, 0.0650, 0.0552,
        0.0542, 0.0571, 0.1012, 0.0651, 0.0314], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,604][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([5.8650e-05, 1.0542e-01, 7.3763e-02, 1.2418e-01, 4.5214e-02, 5.0738e-02,
        2.7249e-02, 1.6196e-02, 5.8638e-02, 1.9798e-01, 1.8032e-01, 4.2658e-02,
        9.5024e-03, 6.8085e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,608][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0004, 0.0900, 0.2634, 0.0622, 0.0478, 0.0555, 0.0491, 0.0519, 0.1046,
        0.0895, 0.0500, 0.0316, 0.0019, 0.1022], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,614][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0028, 0.3842, 0.1667, 0.0763, 0.0302, 0.0310, 0.0496, 0.0362, 0.0684,
        0.0534, 0.0359, 0.0161, 0.0041, 0.0452], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,614][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1002, 0.0401, 0.3399, 0.0309, 0.1055, 0.0376, 0.0610, 0.0751, 0.0541,
        0.0343, 0.0182, 0.0363, 0.0358, 0.0310], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,614][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([1.1377e-04, 2.3952e-01, 1.8379e-01, 6.5547e-02, 2.1732e-02, 2.8509e-02,
        4.5868e-02, 6.3616e-02, 6.8118e-02, 1.2883e-01, 6.1802e-02, 2.3044e-02,
        8.0755e-04, 6.8695e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,615][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([9.7041e-03, 2.0278e-04, 9.1751e-01, 7.3671e-04, 2.4018e-02, 4.9288e-03,
        2.9022e-03, 5.3257e-03, 1.3734e-03, 1.2405e-03, 5.7332e-04, 2.5097e-02,
        1.9306e-03, 4.4562e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,615][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.2308, 0.0130, 0.2730, 0.0100, 0.0963, 0.0226, 0.0183, 0.0381, 0.0772,
        0.0324, 0.0263, 0.0572, 0.0312, 0.0735], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,616][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0282, 0.0601, 0.1457, 0.0506, 0.0790, 0.0464, 0.0992, 0.0928, 0.1059,
        0.0580, 0.0509, 0.0305, 0.0383, 0.1144], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,616][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0011, 0.1116, 0.0374, 0.1101, 0.0161, 0.0400, 0.0529, 0.0279, 0.0654,
        0.1762, 0.1972, 0.0411, 0.0083, 0.1145], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,619][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1154, 0.0438, 0.0456, 0.0397, 0.0495, 0.0487, 0.1051, 0.0788, 0.0682,
        0.0589, 0.0518, 0.0738, 0.0641, 0.0839, 0.0727], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,623][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0234, 0.0383, 0.0694, 0.0435, 0.0702, 0.0535, 0.0639, 0.0873, 0.0818,
        0.0687, 0.0725, 0.0853, 0.1077, 0.0700, 0.0643], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,629][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0513, 0.0419, 0.1337, 0.0467, 0.1007, 0.0667, 0.0814, 0.0557, 0.0552,
        0.0516, 0.0482, 0.1086, 0.0690, 0.0320, 0.0571], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,631][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.9440e-05, 8.8529e-02, 3.3683e-02, 1.3840e-01, 2.7125e-02, 6.0520e-02,
        2.6825e-02, 1.8077e-02, 4.5339e-02, 2.2363e-01, 1.9639e-01, 3.6766e-02,
        7.3120e-03, 6.5832e-02, 3.1542e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,631][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0008, 0.0803, 0.2944, 0.0676, 0.0582, 0.0308, 0.0413, 0.0425, 0.0914,
        0.0718, 0.0408, 0.0316, 0.0025, 0.0754, 0.0706], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,631][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0110, 0.3120, 0.1625, 0.0710, 0.0307, 0.0249, 0.0435, 0.0313, 0.0485,
        0.0462, 0.0320, 0.0152, 0.0049, 0.0392, 0.1270], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,632][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1259, 0.0413, 0.3078, 0.0272, 0.0815, 0.0313, 0.0701, 0.0666, 0.0533,
        0.0317, 0.0183, 0.0296, 0.0324, 0.0345, 0.0484], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,632][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.7914e-04, 1.8065e-01, 1.8377e-01, 9.1034e-02, 2.2673e-02, 1.8426e-02,
        3.0881e-02, 4.6599e-02, 4.0872e-02, 1.1869e-01, 7.5209e-02, 1.8055e-02,
        9.6882e-04, 5.0393e-02, 1.2160e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,633][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.8641e-03, 2.3862e-04, 9.3192e-01, 7.0929e-04, 2.3307e-02, 3.4806e-03,
        1.8482e-03, 4.0765e-03, 1.4988e-03, 8.8567e-04, 3.1620e-04, 2.0223e-02,
        1.5748e-03, 3.0134e-03, 2.0466e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,633][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3863, 0.0086, 0.2305, 0.0047, 0.0658, 0.0140, 0.0129, 0.0279, 0.0710,
        0.0167, 0.0119, 0.0448, 0.0219, 0.0523, 0.0308], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,633][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0294, 0.0712, 0.1188, 0.0528, 0.0679, 0.0412, 0.0825, 0.0564, 0.0714,
        0.0645, 0.0537, 0.0297, 0.0346, 0.0723, 0.1536], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,637][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0017, 0.1011, 0.0403, 0.0927, 0.0172, 0.0427, 0.0517, 0.0266, 0.0619,
        0.1593, 0.1617, 0.0351, 0.0093, 0.1002, 0.0985], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,667][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:32,669][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,671][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,675][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,677][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,680][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,682][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,682][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,682][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,683][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,683][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,684][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,684][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:32,684][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9627, 0.0373], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,686][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0592, 0.9408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,688][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9318, 0.0682], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,691][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0656, 0.9344], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,694][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1073, 0.8927], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,698][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3827, 0.6173], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,701][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7719, 0.2281], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,701][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0063, 0.9937], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,702][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7795, 0.2205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,702][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7624, 0.2376], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,702][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2425, 0.7575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,703][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0160, 0.9840], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:32,703][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.8733, 0.0925, 0.0341], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,703][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.0204, 0.4538, 0.5258], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,704][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.6828, 0.0323, 0.2850], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,705][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.0913, 0.2836, 0.6251], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,709][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.0042, 0.2751, 0.7207], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,714][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.0717, 0.2868, 0.6415], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,718][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.2973, 0.1141, 0.5886], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,719][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.0011, 0.6982, 0.3007], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,719][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.2104, 0.0336, 0.7560], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,719][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([0.5321, 0.0479, 0.4201], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,720][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.0613, 0.0767, 0.8621], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,720][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.0264, 0.4262, 0.5474], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:32,720][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9796, 0.0090, 0.0070, 0.0045], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,721][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0470, 0.1361, 0.6692, 0.1477], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,721][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7964, 0.0043, 0.1968, 0.0025], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,722][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0722, 0.0984, 0.7020, 0.1274], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,728][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0027, 0.0602, 0.8847, 0.0524], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,732][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0284, 0.1158, 0.8216, 0.0342], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,736][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6451, 0.0202, 0.3241, 0.0106], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,736][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0005, 0.4582, 0.4300, 0.1112], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,736][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1439, 0.0073, 0.8464, 0.0024], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,737][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5352, 0.0420, 0.4068, 0.0160], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,737][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0950, 0.0533, 0.8112, 0.0405], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,737][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0047, 0.2021, 0.5681, 0.2251], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:32,738][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.8698, 0.0359, 0.0290, 0.0254, 0.0399], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,738][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0075, 0.1669, 0.2753, 0.2136, 0.3366], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,738][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.4892, 0.0214, 0.3619, 0.0153, 0.1122], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,740][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0321, 0.1734, 0.4489, 0.1472, 0.1984], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,743][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([5.7806e-04, 9.8262e-02, 7.1827e-01, 7.8335e-02, 1.0455e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,747][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0103, 0.1138, 0.7540, 0.0356, 0.0863], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,753][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.3981, 0.0524, 0.3729, 0.0319, 0.1447], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,755][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([1.3319e-04, 4.1755e-01, 3.7997e-01, 1.5736e-01, 4.4994e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,755][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0541, 0.0239, 0.8253, 0.0113, 0.0854], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,755][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.3467, 0.0340, 0.4480, 0.0216, 0.1497], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,756][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0257, 0.0403, 0.6561, 0.0339, 0.2439], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,756][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0040, 0.2424, 0.3558, 0.2573, 0.1405], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:32,756][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8247, 0.0590, 0.0311, 0.0363, 0.0405, 0.0083], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,757][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0027, 0.0906, 0.3327, 0.0842, 0.3822, 0.1076], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,760][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3645, 0.0281, 0.4432, 0.0161, 0.0947, 0.0534], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,764][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.1010, 0.4012, 0.1231, 0.2461, 0.1237], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,768][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([5.6367e-04, 1.0721e-01, 6.0360e-01, 1.0380e-01, 1.0473e-01, 8.0094e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,772][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0069, 0.1032, 0.6936, 0.0432, 0.1091, 0.0438], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,772][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1720, 0.0606, 0.4682, 0.0506, 0.1935, 0.0551], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,772][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([1.3502e-04, 3.6802e-01, 3.8149e-01, 1.5169e-01, 5.0802e-02, 4.7865e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,773][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0313, 0.0182, 0.8236, 0.0101, 0.0952, 0.0215], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,773][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1612, 0.0574, 0.5433, 0.0376, 0.1456, 0.0549], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,773][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0142, 0.0317, 0.5980, 0.0307, 0.2450, 0.0803], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,774][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0008, 0.1440, 0.3663, 0.2022, 0.2132, 0.0736], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:32,774][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6185, 0.0294, 0.0151, 0.0165, 0.0185, 0.0043, 0.2976],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,774][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0036, 0.1106, 0.2737, 0.1129, 0.2520, 0.1228, 0.1242],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,777][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.5910, 0.0134, 0.2693, 0.0077, 0.0508, 0.0281, 0.0396],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,782][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0050, 0.1260, 0.3038, 0.1695, 0.1673, 0.1098, 0.1186],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,787][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0013, 0.1060, 0.5420, 0.0972, 0.1009, 0.0796, 0.0730],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,789][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0178, 0.1079, 0.6385, 0.0457, 0.1015, 0.0424, 0.0462],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,790][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3152, 0.0565, 0.3576, 0.0378, 0.1035, 0.0484, 0.0810],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,790][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.7792e-04, 3.5825e-01, 2.9294e-01, 1.8618e-01, 4.1549e-02, 5.5991e-02,
        6.4912e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,790][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0447, 0.0224, 0.7958, 0.0095, 0.0834, 0.0204, 0.0238],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,791][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2207, 0.0568, 0.4515, 0.0392, 0.1271, 0.0479, 0.0568],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,791][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0212, 0.0388, 0.5274, 0.0378, 0.2180, 0.0741, 0.0828],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,791][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0016, 0.1407, 0.2717, 0.2122, 0.1566, 0.0759, 0.1413],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:32,794][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.4726, 0.0436, 0.0213, 0.0256, 0.0246, 0.0053, 0.3216, 0.0853],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,799][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0017, 0.0702, 0.2105, 0.1107, 0.2370, 0.0950, 0.1142, 0.1607],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,804][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3958, 0.0274, 0.3231, 0.0135, 0.0654, 0.0427, 0.0705, 0.0615],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,806][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0044, 0.0647, 0.3100, 0.0724, 0.1928, 0.1154, 0.1196, 0.1206],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,807][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0012, 0.0636, 0.5759, 0.0546, 0.0758, 0.0679, 0.0652, 0.0958],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,807][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0112, 0.1109, 0.5984, 0.0442, 0.0796, 0.0389, 0.0556, 0.0613],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,807][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1722, 0.0626, 0.3415, 0.0405, 0.1116, 0.0678, 0.0960, 0.1078],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,808][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([9.4494e-05, 4.0512e-01, 2.1801e-01, 1.3972e-01, 2.7940e-02, 4.2427e-02,
        7.1564e-02, 9.5121e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,808][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0273, 0.0210, 0.7602, 0.0124, 0.0804, 0.0202, 0.0231, 0.0555],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,808][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1186, 0.0549, 0.4798, 0.0407, 0.1152, 0.0533, 0.0646, 0.0729],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,809][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0142, 0.0373, 0.4400, 0.0371, 0.1960, 0.0830, 0.0810, 0.1113],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,810][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0008, 0.1017, 0.3058, 0.1395, 0.1598, 0.0658, 0.1054, 0.1212],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:32,814][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.5392, 0.0328, 0.0153, 0.0158, 0.0190, 0.0040, 0.2850, 0.0608, 0.0280],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,820][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0021, 0.0567, 0.1531, 0.0789, 0.2152, 0.0816, 0.1280, 0.1512, 0.1331],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,824][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.5697, 0.0154, 0.2007, 0.0066, 0.0389, 0.0282, 0.0343, 0.0339, 0.0724],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,824][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0045, 0.0885, 0.2202, 0.1148, 0.1330, 0.1073, 0.1075, 0.0773, 0.1469],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,825][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0016, 0.1170, 0.3767, 0.0718, 0.0562, 0.0619, 0.0745, 0.0956, 0.1448],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,825][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0158, 0.1045, 0.5171, 0.0360, 0.0756, 0.0366, 0.0471, 0.0702, 0.0971],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,825][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1231, 0.0482, 0.3203, 0.0347, 0.1238, 0.0567, 0.1034, 0.0972, 0.0925],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,826][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([2.9275e-04, 3.9386e-01, 2.2307e-01, 1.0192e-01, 2.6780e-02, 3.1739e-02,
        5.8761e-02, 8.3302e-02, 8.0274e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,826][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0398, 0.0205, 0.7314, 0.0088, 0.0738, 0.0153, 0.0225, 0.0447, 0.0433],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,828][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2062, 0.0498, 0.3914, 0.0291, 0.0930, 0.0413, 0.0439, 0.0485, 0.0968],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,833][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0145, 0.0306, 0.3972, 0.0302, 0.1709, 0.0693, 0.0742, 0.0794, 0.1337],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,837][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0024, 0.1216, 0.2483, 0.1307, 0.1244, 0.0588, 0.1094, 0.0937, 0.1107],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:32,841][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7349, 0.0115, 0.0106, 0.0056, 0.0116, 0.0018, 0.1316, 0.0526, 0.0119,
        0.0280], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,841][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0032, 0.0500, 0.2015, 0.0675, 0.1915, 0.0567, 0.0830, 0.1564, 0.1201,
        0.0703], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,842][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5244, 0.0115, 0.2395, 0.0073, 0.0443, 0.0235, 0.0373, 0.0309, 0.0662,
        0.0152], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,842][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0105, 0.0469, 0.3448, 0.0605, 0.1338, 0.0490, 0.0851, 0.0770, 0.1271,
        0.0655], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,842][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0013, 0.0488, 0.5086, 0.0393, 0.0749, 0.0360, 0.0355, 0.0544, 0.1343,
        0.0670], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,843][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0075, 0.0594, 0.5672, 0.0197, 0.0678, 0.0268, 0.0349, 0.0584, 0.1215,
        0.0368], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,843][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2996, 0.0254, 0.4144, 0.0150, 0.0899, 0.0186, 0.0429, 0.0485, 0.0331,
        0.0126], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,844][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0003, 0.2114, 0.2610, 0.0560, 0.0270, 0.0336, 0.0606, 0.0982, 0.1332,
        0.1188], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,847][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0444, 0.0065, 0.8063, 0.0029, 0.0584, 0.0067, 0.0103, 0.0291, 0.0305,
        0.0050], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,851][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2281, 0.0305, 0.4184, 0.0138, 0.0872, 0.0265, 0.0324, 0.0477, 0.0912,
        0.0242], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,857][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0203, 0.0280, 0.4453, 0.0217, 0.1508, 0.0429, 0.0575, 0.0769, 0.1153,
        0.0413], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,859][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0007, 0.0831, 0.2281, 0.1087, 0.1238, 0.0409, 0.0795, 0.0980, 0.0684,
        0.1686], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:32,859][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7787, 0.0083, 0.0085, 0.0038, 0.0088, 0.0012, 0.1074, 0.0411, 0.0096,
        0.0214, 0.0112], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,859][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0045, 0.0421, 0.2061, 0.0494, 0.1637, 0.0528, 0.0836, 0.1722, 0.1205,
        0.0592, 0.0460], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,860][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6204, 0.0063, 0.2073, 0.0037, 0.0326, 0.0163, 0.0267, 0.0222, 0.0523,
        0.0088, 0.0036], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,860][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0111, 0.0363, 0.3506, 0.0555, 0.1304, 0.0429, 0.0795, 0.0727, 0.1199,
        0.0572, 0.0438], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,861][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0008, 0.0367, 0.5201, 0.0304, 0.0803, 0.0340, 0.0323, 0.0524, 0.1328,
        0.0561, 0.0242], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,861][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0043, 0.0494, 0.6093, 0.0140, 0.0642, 0.0222, 0.0268, 0.0519, 0.1136,
        0.0313, 0.0130], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,864][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4107, 0.0174, 0.3796, 0.0092, 0.0630, 0.0134, 0.0305, 0.0374, 0.0276,
        0.0078, 0.0035], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,868][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.1677e-04, 1.6671e-01, 2.6620e-01, 4.6767e-02, 2.8841e-02, 3.5367e-02,
        5.4298e-02, 9.0793e-02, 1.5138e-01, 1.1095e-01, 4.8575e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,872][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0509, 0.0040, 0.8179, 0.0018, 0.0514, 0.0056, 0.0083, 0.0266, 0.0290,
        0.0036, 0.0010], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,876][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2572, 0.0236, 0.4359, 0.0104, 0.0761, 0.0203, 0.0265, 0.0381, 0.0839,
        0.0185, 0.0094], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,876][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0264, 0.0227, 0.4435, 0.0202, 0.1376, 0.0404, 0.0564, 0.0777, 0.1187,
        0.0388, 0.0177], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,876][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0008, 0.0679, 0.1846, 0.0874, 0.0947, 0.0388, 0.0731, 0.1034, 0.0694,
        0.1683, 0.1117], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:32,877][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.4065, 0.0273, 0.0146, 0.0151, 0.0205, 0.0045, 0.2840, 0.0635, 0.0344,
        0.0537, 0.0392, 0.0367], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,877][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0012, 0.0383, 0.1213, 0.0540, 0.1549, 0.0939, 0.0933, 0.1147, 0.1211,
        0.0824, 0.0835, 0.0412], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,878][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2990, 0.0232, 0.2268, 0.0130, 0.0582, 0.0345, 0.0497, 0.0458, 0.0947,
        0.0235, 0.0157, 0.1160], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,878][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0035, 0.0434, 0.2102, 0.0694, 0.1385, 0.0624, 0.0642, 0.0623, 0.0989,
        0.0867, 0.0707, 0.0896], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,878][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([2.5491e-04, 5.7070e-02, 3.7077e-01, 4.5450e-02, 6.3693e-02, 4.4853e-02,
        4.5332e-02, 8.1250e-02, 1.4181e-01, 7.8273e-02, 3.9583e-02, 3.1660e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,881][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0032, 0.0697, 0.5198, 0.0261, 0.0735, 0.0261, 0.0322, 0.0537, 0.0924,
        0.0501, 0.0233, 0.0299], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,886][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0644, 0.0354, 0.3501, 0.0277, 0.1285, 0.0526, 0.0824, 0.0810, 0.0844,
        0.0319, 0.0197, 0.0419], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,889][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([3.2548e-05, 1.7749e-01, 2.3540e-01, 7.0898e-02, 3.2882e-02, 3.0961e-02,
        4.2046e-02, 8.0370e-02, 8.8445e-02, 1.5168e-01, 7.2155e-02, 1.7632e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,893][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0149, 0.0131, 0.6933, 0.0086, 0.0894, 0.0173, 0.0190, 0.0449, 0.0488,
        0.0113, 0.0046, 0.0347], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,894][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1158, 0.0240, 0.4419, 0.0181, 0.1129, 0.0291, 0.0390, 0.0535, 0.0929,
        0.0221, 0.0126, 0.0380], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,894][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0089, 0.0233, 0.3732, 0.0250, 0.1648, 0.0537, 0.0544, 0.0688, 0.1096,
        0.0453, 0.0234, 0.0497], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,894][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0011, 0.0818, 0.1856, 0.0871, 0.0991, 0.0356, 0.0624, 0.0752, 0.0740,
        0.1510, 0.1063, 0.0408], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:32,895][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.3388, 0.0202, 0.0178, 0.0141, 0.0255, 0.0043, 0.3138, 0.0729, 0.0337,
        0.0541, 0.0361, 0.0376, 0.0310], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,895][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0005, 0.0462, 0.0847, 0.0750, 0.1355, 0.0710, 0.0816, 0.1358, 0.1055,
        0.0798, 0.0934, 0.0480, 0.0428], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,896][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.1828, 0.0178, 0.2484, 0.0121, 0.0801, 0.0440, 0.0558, 0.0552, 0.1116,
        0.0233, 0.0137, 0.1145, 0.0408], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,896][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0027, 0.0697, 0.1437, 0.0849, 0.0935, 0.0629, 0.0574, 0.0632, 0.0863,
        0.1120, 0.0868, 0.1058, 0.0312], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,897][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([4.8093e-05, 4.7893e-02, 3.7676e-01, 5.7333e-02, 8.6235e-02, 3.4450e-02,
        2.6921e-02, 8.7973e-02, 8.7881e-02, 9.0728e-02, 5.5217e-02, 4.5257e-02,
        3.3048e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,897][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0008, 0.0416, 0.5448, 0.0227, 0.0934, 0.0243, 0.0282, 0.0624, 0.0849,
        0.0417, 0.0193, 0.0313, 0.0045], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,898][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0915, 0.0367, 0.2392, 0.0282, 0.1167, 0.0521, 0.0856, 0.0869, 0.0824,
        0.0400, 0.0266, 0.0535, 0.0607], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,898][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([5.8913e-06, 9.8891e-02, 2.0223e-01, 8.0051e-02, 4.3838e-02, 2.6565e-02,
        2.8645e-02, 1.2793e-01, 8.5921e-02, 1.7405e-01, 9.6821e-02, 3.3945e-02,
        1.1087e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,901][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0079, 0.0213, 0.5839, 0.0139, 0.0946, 0.0226, 0.0249, 0.0660, 0.0606,
        0.0228, 0.0085, 0.0605, 0.0125], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,905][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([0.0927, 0.0311, 0.3448, 0.0232, 0.1353, 0.0362, 0.0420, 0.0522, 0.0975,
        0.0390, 0.0234, 0.0522, 0.0304], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,911][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([0.0049, 0.0207, 0.3556, 0.0239, 0.1806, 0.0481, 0.0458, 0.0613, 0.1018,
        0.0513, 0.0281, 0.0503, 0.0277], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,913][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0004, 0.0868, 0.1246, 0.1179, 0.0705, 0.0327, 0.0582, 0.0666, 0.0567,
        0.1770, 0.1642, 0.0349, 0.0093], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:32,913][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.4402, 0.0277, 0.0092, 0.0120, 0.0119, 0.0032, 0.2026, 0.0413, 0.0194,
        0.0498, 0.0321, 0.0265, 0.0175, 0.1066], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,913][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0010, 0.0727, 0.1326, 0.0611, 0.1320, 0.0670, 0.0793, 0.1262, 0.0867,
        0.0732, 0.0604, 0.0405, 0.0299, 0.0374], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,914][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.4037, 0.0171, 0.2020, 0.0080, 0.0456, 0.0201, 0.0399, 0.0393, 0.0732,
        0.0187, 0.0117, 0.0685, 0.0204, 0.0320], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,914][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0017, 0.0645, 0.1776, 0.0820, 0.0887, 0.0511, 0.0463, 0.0380, 0.0844,
        0.1032, 0.0814, 0.0753, 0.0242, 0.0816], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,915][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0008, 0.0647, 0.3344, 0.0524, 0.0579, 0.0475, 0.0453, 0.0606, 0.0933,
        0.0746, 0.0428, 0.0334, 0.0031, 0.0891], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,915][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0052, 0.0741, 0.5108, 0.0254, 0.0651, 0.0236, 0.0324, 0.0434, 0.0790,
        0.0441, 0.0204, 0.0273, 0.0044, 0.0447], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,915][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1002, 0.0401, 0.3399, 0.0309, 0.1055, 0.0376, 0.0610, 0.0751, 0.0541,
        0.0343, 0.0182, 0.0363, 0.0358, 0.0310], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,917][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([1.1377e-04, 2.3952e-01, 1.8379e-01, 6.5547e-02, 2.1732e-02, 2.8509e-02,
        4.5868e-02, 6.3616e-02, 6.8118e-02, 1.2883e-01, 6.1802e-02, 2.3044e-02,
        8.0755e-04, 6.8695e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,922][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0242, 0.0156, 0.6562, 0.0086, 0.0694, 0.0138, 0.0207, 0.0509, 0.0439,
        0.0122, 0.0048, 0.0472, 0.0085, 0.0239], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,927][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1293, 0.0405, 0.3338, 0.0243, 0.0940, 0.0329, 0.0399, 0.0457, 0.0802,
        0.0367, 0.0245, 0.0446, 0.0231, 0.0505], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,930][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0091, 0.0235, 0.3442, 0.0238, 0.1478, 0.0453, 0.0446, 0.0577, 0.0985,
        0.0416, 0.0230, 0.0467, 0.0247, 0.0695], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,931][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0009, 0.0726, 0.1743, 0.0937, 0.0832, 0.0316, 0.0662, 0.0664, 0.0696,
        0.1287, 0.0972, 0.0366, 0.0091, 0.0699], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:32,931][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4058, 0.0170, 0.0111, 0.0102, 0.0146, 0.0029, 0.1866, 0.0473, 0.0177,
        0.0336, 0.0215, 0.0249, 0.0195, 0.0801, 0.1072], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,931][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0015, 0.0410, 0.1321, 0.0470, 0.1443, 0.0611, 0.0804, 0.1135, 0.1021,
        0.0615, 0.0510, 0.0399, 0.0317, 0.0425, 0.0502], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,932][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.5767, 0.0081, 0.1564, 0.0032, 0.0269, 0.0114, 0.0241, 0.0223, 0.0516,
        0.0082, 0.0038, 0.0533, 0.0115, 0.0181, 0.0245], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,932][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0016, 0.0609, 0.1131, 0.0938, 0.0616, 0.0531, 0.0501, 0.0466, 0.0750,
        0.1147, 0.0874, 0.0697, 0.0204, 0.0825, 0.0696], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,933][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0014, 0.0558, 0.3637, 0.0538, 0.0674, 0.0284, 0.0382, 0.0507, 0.0804,
        0.0598, 0.0343, 0.0321, 0.0037, 0.0674, 0.0628], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,936][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0146, 0.0535, 0.5185, 0.0230, 0.0701, 0.0187, 0.0287, 0.0386, 0.0580,
        0.0305, 0.0161, 0.0256, 0.0056, 0.0427, 0.0558], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,941][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1259, 0.0413, 0.3078, 0.0272, 0.0815, 0.0313, 0.0701, 0.0666, 0.0533,
        0.0317, 0.0183, 0.0296, 0.0324, 0.0345, 0.0484], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,944][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.7914e-04, 1.8065e-01, 1.8377e-01, 9.1034e-02, 2.2673e-02, 1.8426e-02,
        3.0881e-02, 4.6599e-02, 4.0872e-02, 1.1869e-01, 7.5209e-02, 1.8055e-02,
        9.6882e-04, 5.0393e-02, 1.2160e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,947][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0278, 0.0112, 0.6969, 0.0060, 0.0581, 0.0119, 0.0163, 0.0439, 0.0389,
        0.0091, 0.0030, 0.0353, 0.0076, 0.0214, 0.0129], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,948][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1844, 0.0300, 0.3022, 0.0195, 0.0832, 0.0251, 0.0364, 0.0421, 0.0769,
        0.0297, 0.0199, 0.0422, 0.0193, 0.0437, 0.0453], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,948][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0104, 0.0260, 0.2964, 0.0265, 0.1235, 0.0416, 0.0520, 0.0590, 0.0949,
        0.0479, 0.0261, 0.0491, 0.0262, 0.0651, 0.0551], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,949][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0008, 0.0553, 0.1492, 0.0822, 0.0821, 0.0374, 0.0773, 0.0675, 0.0643,
        0.1310, 0.0964, 0.0303, 0.0098, 0.0644, 0.0520], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:32,950][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:32,951][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17867],
        [ 8146],
        [11150],
        [ 9576],
        [ 8555],
        [ 5320],
        [ 2649],
        [ 4165],
        [ 3564],
        [ 9085],
        [ 6309],
        [ 5747],
        [ 3882],
        [ 1887],
        [ 2275]], device='cuda:0')
[2024-07-24 10:25:32,952][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[22379],
        [ 9099],
        [ 9021],
        [ 5187],
        [ 5123],
        [ 2917],
        [ 1597],
        [ 2392],
        [ 3116],
        [ 7907],
        [ 4811],
        [ 4634],
        [ 3606],
        [ 1593],
        [ 1480]], device='cuda:0')
[2024-07-24 10:25:32,955][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15643],
        [23572],
        [26535],
        [25355],
        [27707],
        [28123],
        [27420],
        [28609],
        [27919],
        [26978],
        [26512],
        [26817],
        [26992],
        [26982],
        [26474]], device='cuda:0')
[2024-07-24 10:25:32,957][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[39342],
        [39569],
        [46882],
        [46688],
        [46264],
        [46509],
        [45959],
        [45753],
        [46159],
        [46057],
        [45781],
        [44187],
        [44381],
        [44689],
        [44957]], device='cuda:0')
[2024-07-24 10:25:32,960][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3197],
        [15778],
        [10482],
        [11709],
        [14637],
        [13701],
        [12167],
        [12057],
        [12512],
        [13564],
        [14776],
        [14192],
        [14912],
        [14865],
        [14850]], device='cuda:0')
[2024-07-24 10:25:32,962][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30508],
        [10098],
        [12777],
        [ 7844],
        [ 7848],
        [ 5602],
        [ 4905],
        [ 4194],
        [ 3432],
        [ 3353],
        [ 3359],
        [ 2806],
        [ 2748],
        [ 3331],
        [ 3155]], device='cuda:0')
[2024-07-24 10:25:32,964][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[47287],
        [ 4217],
        [11353],
        [21686],
        [17068],
        [11683],
        [10204],
        [12077],
        [ 7359],
        [11327],
        [11879],
        [ 7402],
        [ 7171],
        [ 6781],
        [ 7811]], device='cuda:0')
[2024-07-24 10:25:32,967][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[3240],
        [1224],
        [1026],
        [ 956],
        [ 904],
        [ 846],
        [ 793],
        [ 779],
        [ 763],
        [ 737],
        [ 778],
        [ 776],
        [ 723],
        [ 758],
        [ 712]], device='cuda:0')
[2024-07-24 10:25:32,969][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14492],
        [26177],
        [37683],
        [32882],
        [40402],
        [41250],
        [38132],
        [36136],
        [35786],
        [37322],
        [36367],
        [37142],
        [37599],
        [37714],
        [36319]], device='cuda:0')
[2024-07-24 10:25:32,970][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25189],
        [20880],
        [23186],
        [22772],
        [21907],
        [21626],
        [19412],
        [20705],
        [20853],
        [20420],
        [19347],
        [17796],
        [17171],
        [16746],
        [16208]], device='cuda:0')
[2024-07-24 10:25:32,971][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9272],
        [ 9040],
        [38736],
        [39942],
        [39496],
        [39401],
        [39338],
        [38340],
        [38705],
        [39652],
        [39647],
        [38999],
        [38445],
        [38930],
        [39114]], device='cuda:0')
[2024-07-24 10:25:32,972][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43760],
        [40227],
        [25620],
        [28113],
        [25691],
        [23614],
        [24903],
        [24626],
        [22308],
        [24326],
        [25993],
        [21857],
        [21735],
        [22782],
        [24213]], device='cuda:0')
[2024-07-24 10:25:32,974][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[26441],
        [19786],
        [45267],
        [40021],
        [40959],
        [38651],
        [33677],
        [34840],
        [33911],
        [31858],
        [28743],
        [29423],
        [32800],
        [30131],
        [26757]], device='cuda:0')
[2024-07-24 10:25:32,977][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7518],
        [ 6252],
        [14128],
        [12598],
        [ 5365],
        [ 4293],
        [ 3100],
        [ 2545],
        [ 1772],
        [ 3834],
        [ 3951],
        [ 3231],
        [ 3301],
        [ 2544],
        [ 2371]], device='cuda:0')
[2024-07-24 10:25:32,979][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5987],
        [31327],
        [26724],
        [31593],
        [35813],
        [37410],
        [39509],
        [41320],
        [37403],
        [30050],
        [30036],
        [42521],
        [34435],
        [33899],
        [39548]], device='cuda:0')
[2024-07-24 10:25:32,982][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16719],
        [17939],
        [12822],
        [16332],
        [10426],
        [ 9383],
        [ 7738],
        [ 5410],
        [ 6213],
        [ 8932],
        [10650],
        [ 5581],
        [ 4880],
        [ 6800],
        [ 7329]], device='cuda:0')
[2024-07-24 10:25:32,984][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14458],
        [ 9970],
        [20437],
        [24102],
        [16000],
        [18542],
        [19797],
        [16228],
        [14426],
        [14777],
        [14809],
        [15725],
        [13901],
        [14705],
        [15488]], device='cuda:0')
[2024-07-24 10:25:32,987][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7578],
        [10190],
        [ 6770],
        [ 9122],
        [ 3268],
        [ 3416],
        [ 3919],
        [ 2937],
        [ 3059],
        [ 2930],
        [ 3497],
        [ 2329],
        [ 1958],
        [ 2215],
        [ 2612]], device='cuda:0')
[2024-07-24 10:25:32,989][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[39169],
        [21778],
        [29978],
        [29860],
        [26119],
        [27280],
        [27425],
        [27937],
        [27663],
        [28568],
        [28380],
        [26420],
        [25932],
        [25910],
        [25548]], device='cuda:0')
[2024-07-24 10:25:32,990][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12281],
        [29013],
        [31798],
        [31579],
        [32555],
        [33600],
        [34180],
        [35585],
        [33043],
        [35127],
        [35142],
        [33721],
        [34012],
        [32991],
        [33721]], device='cuda:0')
[2024-07-24 10:25:32,991][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38643],
        [26821],
        [30744],
        [31563],
        [31724],
        [31495],
        [31137],
        [30931],
        [30233],
        [30031],
        [30216],
        [29185],
        [29929],
        [29240],
        [29784]], device='cuda:0')
[2024-07-24 10:25:32,992][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28695],
        [18494],
        [ 9406],
        [11499],
        [ 7697],
        [ 7148],
        [ 7724],
        [ 7433],
        [ 6943],
        [ 7120],
        [ 7647],
        [ 7436],
        [ 7226],
        [ 7338],
        [ 7541]], device='cuda:0')
[2024-07-24 10:25:32,993][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22520],
        [ 8940],
        [10020],
        [10418],
        [ 9570],
        [10423],
        [ 8400],
        [ 8151],
        [10380],
        [13394],
        [14139],
        [ 9812],
        [ 9551],
        [ 9679],
        [ 8661]], device='cuda:0')
[2024-07-24 10:25:32,995][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14601],
        [29921],
        [17036],
        [16281],
        [17652],
        [17238],
        [17352],
        [16707],
        [17296],
        [16788],
        [16664],
        [17521],
        [18484],
        [17870],
        [17647]], device='cuda:0')
[2024-07-24 10:25:32,998][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20552],
        [ 8108],
        [ 1048],
        [ 1070],
        [ 1163],
        [ 1066],
        [ 1093],
        [ 1104],
        [ 1089],
        [ 1088],
        [ 1045],
        [ 1073],
        [ 1147],
        [ 1076],
        [ 1034]], device='cuda:0')
[2024-07-24 10:25:33,000][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4330],
        [ 6444],
        [19747],
        [18896],
        [14054],
        [11845],
        [ 9940],
        [10454],
        [ 7665],
        [ 9205],
        [ 9245],
        [ 7396],
        [ 6653],
        [ 6222],
        [ 6011]], device='cuda:0')
[2024-07-24 10:25:33,003][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9800],
        [33262],
        [26603],
        [23066],
        [22751],
        [20126],
        [24437],
        [21833],
        [27920],
        [28786],
        [32545],
        [31491],
        [34257],
        [32557],
        [33667]], device='cuda:0')
[2024-07-24 10:25:33,005][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[33636],
        [42361],
        [45469],
        [44906],
        [47286],
        [46861],
        [47137],
        [47740],
        [47776],
        [47275],
        [46860],
        [47915],
        [47773],
        [48022],
        [47906]], device='cuda:0')
[2024-07-24 10:25:33,007][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[44581],
        [21617],
        [26737],
        [24422],
        [28412],
        [30119],
        [22592],
        [25678],
        [25099],
        [33420],
        [30840],
        [23347],
        [30304],
        [28702],
        [26456]], device='cuda:0')
[2024-07-24 10:25:33,010][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161],
        [17161]], device='cuda:0')
[2024-07-24 10:25:33,042][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:33,044][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,046][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,049][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,052][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,055][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,065][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,067][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,070][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,073][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,075][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,075][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,076][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,076][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9672, 0.0328], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,076][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2608, 0.7392], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,077][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0907, 0.9093], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,077][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9722, 0.0278], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,077][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2525, 0.7475], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,077][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8351, 0.1649], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,078][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,078][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0470, 0.9530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,081][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,084][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([7.8195e-05, 9.9992e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,089][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9490, 0.0510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,092][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0135, 0.9865], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,093][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.9271, 0.0091, 0.0638], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,093][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.0120, 0.1119, 0.8761], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,093][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.0174, 0.3294, 0.6532], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,093][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.2792, 0.3462, 0.3746], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,094][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.1367, 0.1777, 0.6856], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,094][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.3550, 0.1337, 0.5113], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,094][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.0013, 0.7763, 0.2224], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,095][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.0322, 0.2578, 0.7100], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,098][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.0108, 0.9348, 0.0545], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,101][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([2.9293e-05, 6.5193e-01, 3.4804e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,105][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.0144, 0.0140, 0.9717], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,109][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([0.0016, 0.9840, 0.0144], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,109][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9173, 0.0042, 0.0765, 0.0021], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,110][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0305, 0.0295, 0.9006, 0.0394], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,110][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0337, 0.1828, 0.3382, 0.4453], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,110][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4217, 0.0245, 0.5487, 0.0051], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,110][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2992, 0.1864, 0.4064, 0.1080], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,111][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8060, 0.0230, 0.1667, 0.0043], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,111][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0015, 0.3161, 0.1736, 0.5088], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,111][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0145, 0.1543, 0.6264, 0.2047], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,112][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0052, 0.5081, 0.2755, 0.2113], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,113][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0006, 0.1694, 0.4704, 0.3596], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,117][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.3833e-02, 6.8714e-04, 9.7513e-01, 3.4700e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,121][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0079, 0.4778, 0.0469, 0.4674], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,126][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.8539, 0.0096, 0.1150, 0.0038, 0.0177], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,127][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0071, 0.0453, 0.6094, 0.0510, 0.2873], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,127][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0253, 0.1227, 0.2664, 0.3648, 0.2208], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,127][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.1249, 0.0530, 0.7897, 0.0119, 0.0206], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,127][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0542, 0.1088, 0.3257, 0.2061, 0.3053], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,128][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.3701, 0.0598, 0.4426, 0.0177, 0.1098], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,128][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0006, 0.3056, 0.0981, 0.4406, 0.1552], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,128][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0211, 0.1509, 0.4831, 0.1402, 0.2048], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,130][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0059, 0.6190, 0.1284, 0.2166, 0.0302], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,133][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([4.7538e-06, 2.0208e-01, 7.6081e-02, 2.6683e-01, 4.5500e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,138][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([0.0041, 0.0018, 0.9505, 0.0016, 0.0420], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,143][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0012, 0.6139, 0.0118, 0.3323, 0.0407], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,143][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8123, 0.0071, 0.1539, 0.0045, 0.0087, 0.0135], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,144][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0070, 0.0586, 0.4721, 0.0791, 0.3192, 0.0639], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,144][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0039, 0.0950, 0.1483, 0.2972, 0.2062, 0.2495], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,144][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1934, 0.0531, 0.6900, 0.0139, 0.0265, 0.0232], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,144][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1203, 0.0953, 0.3400, 0.0533, 0.2133, 0.1778], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,145][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3312, 0.0830, 0.3427, 0.0194, 0.1151, 0.1087], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,145][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0004, 0.1951, 0.0904, 0.3296, 0.1615, 0.2230], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,145][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0034, 0.0806, 0.4722, 0.0973, 0.1932, 0.1534], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,146][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0012, 0.6667, 0.1094, 0.1528, 0.0310, 0.0389], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,147][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.3238e-06, 4.0942e-02, 6.4700e-02, 1.4317e-01, 4.8967e-01, 2.6152e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,152][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0033, 0.0040, 0.8983, 0.0053, 0.0587, 0.0305], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,157][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0012, 0.3249, 0.0205, 0.3164, 0.0793, 0.2577], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,160][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8375, 0.0093, 0.1281, 0.0047, 0.0050, 0.0105, 0.0049],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,160][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0130, 0.0551, 0.5133, 0.0674, 0.2277, 0.0511, 0.0724],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,161][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0033, 0.0829, 0.0718, 0.3477, 0.1277, 0.1786, 0.1880],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,161][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3319, 0.0489, 0.5437, 0.0124, 0.0201, 0.0233, 0.0196],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,161][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1118, 0.0799, 0.3277, 0.0499, 0.1654, 0.1146, 0.1508],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,162][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4324, 0.0578, 0.2925, 0.0168, 0.0785, 0.0714, 0.0506],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,162][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0005, 0.1517, 0.0804, 0.2635, 0.1252, 0.1746, 0.2041],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,162][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0032, 0.0798, 0.3399, 0.1075, 0.1581, 0.1580, 0.1536],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,165][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0023, 0.6444, 0.0864, 0.1712, 0.0237, 0.0304, 0.0415],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,168][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.4986e-05, 1.7683e-02, 1.2146e-01, 3.6221e-02, 3.8386e-01, 1.0662e-01,
        3.3414e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,173][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0185, 0.0034, 0.8900, 0.0029, 0.0431, 0.0212, 0.0210],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,177][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0020, 0.2249, 0.0150, 0.2384, 0.0521, 0.1863, 0.2813],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,177][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.6145, 0.0360, 0.2252, 0.0234, 0.0165, 0.0418, 0.0153, 0.0273],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,178][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0047, 0.0460, 0.4514, 0.0621, 0.2475, 0.0534, 0.0585, 0.0765],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,178][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0025, 0.0613, 0.0815, 0.2045, 0.1106, 0.2429, 0.1906, 0.1061],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,178][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1282, 0.0838, 0.6034, 0.0247, 0.0234, 0.0232, 0.0392, 0.0742],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,179][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0157, 0.0506, 0.1125, 0.0828, 0.1025, 0.1188, 0.3069, 0.2102],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,179][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1825, 0.0690, 0.2451, 0.0237, 0.0944, 0.0895, 0.0604, 0.2354],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,179][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0003, 0.1478, 0.0584, 0.2508, 0.0974, 0.1508, 0.1977, 0.0969],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,180][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0021, 0.0712, 0.3162, 0.0900, 0.1599, 0.1377, 0.1380, 0.0849],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,183][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0009, 0.7473, 0.0409, 0.1089, 0.0132, 0.0300, 0.0355, 0.0235],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,186][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.3956e-07, 1.9331e-02, 2.0010e-02, 7.3101e-02, 1.5105e-01, 8.7001e-02,
        3.8621e-01, 2.6330e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,191][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0044, 0.0033, 0.5449, 0.0043, 0.0276, 0.0166, 0.0285, 0.3704],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,194][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0010, 0.4023, 0.0069, 0.2145, 0.0243, 0.1061, 0.1763, 0.0687],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,195][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.4042, 0.0218, 0.3477, 0.0112, 0.0346, 0.0628, 0.0289, 0.0410, 0.0477],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,195][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0055, 0.0497, 0.3932, 0.0575, 0.2402, 0.0500, 0.0553, 0.0749, 0.0738],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,195][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0502, 0.0575, 0.1292, 0.1970, 0.0589, 0.1173, 0.2301, 0.1076, 0.0522],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,196][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2343, 0.0806, 0.4446, 0.0209, 0.0177, 0.0194, 0.0301, 0.0733, 0.0792],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,196][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0132, 0.0343, 0.1186, 0.0519, 0.0626, 0.1189, 0.3180, 0.1064, 0.1760],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,196][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1713, 0.0727, 0.1861, 0.0266, 0.0728, 0.0741, 0.0490, 0.1336, 0.2138],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,197][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0003, 0.1495, 0.0512, 0.2235, 0.0920, 0.1281, 0.1934, 0.0874, 0.0747],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,200][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0017, 0.0619, 0.2984, 0.0727, 0.1604, 0.1324, 0.1295, 0.0767, 0.0662],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,205][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0021, 0.5700, 0.0823, 0.1227, 0.0183, 0.0406, 0.0500, 0.0331, 0.0808],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,208][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([1.4254e-07, 1.6875e-02, 5.7508e-03, 8.0589e-02, 8.2443e-02, 8.6843e-02,
        4.8209e-01, 1.8994e-01, 5.5464e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,211][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0024, 0.0022, 0.3452, 0.0032, 0.0235, 0.0200, 0.0244, 0.3851, 0.1938],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,211][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0012, 0.3150, 0.0055, 0.1473, 0.0242, 0.1174, 0.2203, 0.0877, 0.0813],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,212][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7706, 0.0120, 0.1435, 0.0058, 0.0094, 0.0242, 0.0087, 0.0113, 0.0095,
        0.0051], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,212][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0113, 0.0315, 0.4561, 0.0385, 0.1610, 0.0350, 0.0467, 0.1007, 0.0632,
        0.0560], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,213][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0120, 0.0328, 0.1287, 0.1120, 0.1805, 0.0901, 0.0953, 0.0613, 0.0647,
        0.2226], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,213][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2416, 0.0126, 0.5205, 0.0023, 0.0143, 0.0131, 0.0192, 0.0627, 0.1045,
        0.0091], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,213][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0963, 0.0747, 0.1896, 0.0267, 0.1060, 0.0487, 0.0962, 0.1707, 0.1334,
        0.0578], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,214][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4852, 0.0475, 0.1665, 0.0085, 0.0411, 0.0268, 0.0202, 0.0772, 0.1131,
        0.0140], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,214][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0003, 0.0971, 0.0617, 0.1594, 0.0887, 0.1034, 0.1290, 0.0809, 0.0847,
        0.1947], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,217][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0036, 0.0562, 0.3156, 0.0718, 0.1397, 0.1146, 0.1108, 0.0697, 0.0485,
        0.0694], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,221][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0021, 0.3409, 0.0954, 0.1164, 0.0394, 0.0370, 0.0414, 0.0297, 0.0819,
        0.2159], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,225][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.6529e-05, 1.9604e-02, 2.3611e-02, 6.1839e-02, 1.1348e-01, 7.2021e-02,
        2.0757e-01, 1.4950e-01, 7.8025e-02, 2.7434e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,227][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([3.1269e-02, 6.7452e-04, 7.2141e-01, 3.0587e-04, 1.4276e-02, 5.4952e-03,
        4.1291e-03, 1.1944e-01, 1.0057e-01, 2.4265e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,229][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0016, 0.1598, 0.0100, 0.1178, 0.0257, 0.0900, 0.1410, 0.0939, 0.0699,
        0.2903], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,229][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7175, 0.0127, 0.1782, 0.0066, 0.0128, 0.0287, 0.0114, 0.0125, 0.0105,
        0.0063, 0.0027], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,229][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0203, 0.0181, 0.5004, 0.0230, 0.1462, 0.0287, 0.0373, 0.0961, 0.0630,
        0.0397, 0.0272], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,230][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0091, 0.0335, 0.1111, 0.0825, 0.1572, 0.0801, 0.0727, 0.0620, 0.0811,
        0.1654, 0.1453], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,230][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1528, 0.0089, 0.6072, 0.0020, 0.0156, 0.0130, 0.0178, 0.0615, 0.1108,
        0.0087, 0.0017], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,230][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1012, 0.0646, 0.1844, 0.0212, 0.1345, 0.0433, 0.0854, 0.1721, 0.1216,
        0.0521, 0.0197], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,231][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5927, 0.0303, 0.1501, 0.0051, 0.0328, 0.0174, 0.0131, 0.0562, 0.0901,
        0.0094, 0.0028], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,234][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0004, 0.0814, 0.0516, 0.1283, 0.0709, 0.0907, 0.1041, 0.0686, 0.0784,
        0.1519, 0.1737], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,239][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0033, 0.0471, 0.3009, 0.0641, 0.1371, 0.1131, 0.1038, 0.0652, 0.0497,
        0.0663, 0.0494], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,244][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0021, 0.2203, 0.1026, 0.0888, 0.0357, 0.0257, 0.0297, 0.0269, 0.0820,
        0.1795, 0.2066], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,245][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.7667e-05, 1.7868e-02, 2.7207e-02, 4.5121e-02, 1.0910e-01, 7.3585e-02,
        1.6393e-01, 1.3312e-01, 8.6500e-02, 1.9970e-01, 1.4382e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,246][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([5.3896e-02, 5.3610e-04, 7.3436e-01, 1.6065e-04, 1.0995e-02, 4.3794e-03,
        2.9229e-03, 9.4132e-02, 9.6451e-02, 1.4712e-03, 6.9243e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,246][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0018, 0.1135, 0.0081, 0.0755, 0.0165, 0.0683, 0.1117, 0.0801, 0.0603,
        0.1868, 0.2773], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,246][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.4985, 0.0433, 0.2086, 0.0249, 0.0332, 0.0354, 0.0273, 0.0458, 0.0220,
        0.0252, 0.0122, 0.0236], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,247][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0039, 0.0439, 0.3124, 0.0546, 0.1688, 0.0408, 0.0477, 0.0662, 0.0528,
        0.0850, 0.0709, 0.0529], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,247][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0037, 0.0281, 0.0331, 0.0926, 0.0418, 0.0559, 0.0685, 0.0352, 0.0365,
        0.2507, 0.2300, 0.1238], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,248][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0268, 0.0370, 0.6591, 0.0106, 0.0207, 0.0150, 0.0185, 0.0630, 0.0933,
        0.0331, 0.0091, 0.0140], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,248][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0162, 0.0438, 0.0766, 0.0425, 0.0500, 0.0742, 0.1411, 0.1179, 0.0765,
        0.0705, 0.0521, 0.2386], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,251][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1437, 0.0631, 0.2125, 0.0210, 0.0652, 0.0616, 0.0436, 0.1065, 0.1666,
        0.0339, 0.0147, 0.0676], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,253][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([1.0183e-04, 8.0111e-02, 2.9974e-02, 1.1956e-01, 5.0518e-02, 8.0024e-02,
        1.1137e-01, 5.1678e-02, 5.1325e-02, 1.7799e-01, 1.8361e-01, 6.3728e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,259][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0021, 0.0570, 0.2760, 0.0634, 0.1165, 0.0976, 0.0953, 0.0559, 0.0439,
        0.0702, 0.0516, 0.0706], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,263][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0007, 0.2280, 0.0239, 0.0679, 0.0083, 0.0223, 0.0240, 0.0147, 0.0349,
        0.2210, 0.3057, 0.0486], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,263][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([4.1153e-07, 1.2366e-02, 5.8666e-03, 3.5969e-02, 6.6533e-02, 7.4467e-02,
        2.3813e-01, 8.0558e-02, 3.4715e-02, 2.3406e-01, 1.4402e-01, 7.3310e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,263][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0066, 0.0023, 0.3933, 0.0017, 0.0170, 0.0111, 0.0128, 0.1813, 0.1446,
        0.0105, 0.0083, 0.2107], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,264][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0004, 0.1971, 0.0054, 0.0935, 0.0174, 0.0554, 0.0696, 0.0389, 0.0319,
        0.1536, 0.3074, 0.0295], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,264][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.3899, 0.0243, 0.2938, 0.0110, 0.0378, 0.0576, 0.0265, 0.0741, 0.0349,
        0.0168, 0.0068, 0.0218, 0.0047], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,264][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0022, 0.0277, 0.3461, 0.0407, 0.1927, 0.0364, 0.0408, 0.0713, 0.0611,
        0.0464, 0.0397, 0.0604, 0.0346], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,265][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0031, 0.0217, 0.0868, 0.0750, 0.0791, 0.0446, 0.0738, 0.0688, 0.0572,
        0.1573, 0.1514, 0.1268, 0.0543], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,265][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([6.9602e-03, 1.0060e-02, 7.4149e-01, 6.8247e-03, 2.8700e-02, 9.7858e-03,
        9.2950e-03, 6.0166e-02, 5.9220e-02, 2.7012e-02, 7.5168e-03, 3.2306e-02,
        6.6096e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,268][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0098, 0.0340, 0.1100, 0.0416, 0.0894, 0.0515, 0.2234, 0.0831, 0.0906,
        0.0478, 0.0447, 0.1054, 0.0686], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,274][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0822, 0.0528, 0.2019, 0.0190, 0.0801, 0.0702, 0.0446, 0.1164, 0.1871,
        0.0317, 0.0142, 0.0756, 0.0243], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,276][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([1.2211e-04, 7.9123e-02, 2.9073e-02, 1.1686e-01, 4.6237e-02, 7.3444e-02,
        9.8363e-02, 5.0032e-02, 4.7898e-02, 1.6867e-01, 1.8232e-01, 5.9551e-02,
        4.8300e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,281][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.0008, 0.0404, 0.2854, 0.0575, 0.1311, 0.0904, 0.0806, 0.0507, 0.0401,
        0.0699, 0.0501, 0.0843, 0.0187], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,282][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0007, 0.1644, 0.0408, 0.0593, 0.0141, 0.0167, 0.0325, 0.0178, 0.0428,
        0.2395, 0.3057, 0.0530, 0.0128], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,282][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([5.3202e-08, 1.2112e-02, 9.2263e-03, 3.1843e-02, 8.7406e-02, 3.6779e-02,
        1.4720e-01, 7.1415e-02, 3.0104e-02, 2.4099e-01, 1.6214e-01, 7.8137e-02,
        9.2646e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,282][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([1.6568e-04, 7.8535e-04, 4.2121e-01, 1.2414e-03, 3.0590e-02, 7.9124e-03,
        7.8828e-03, 2.0361e-01, 9.9777e-02, 6.7202e-03, 5.1526e-03, 2.1391e-01,
        1.0469e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,283][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([0.0006, 0.2047, 0.0058, 0.0968, 0.0179, 0.0432, 0.0810, 0.0344, 0.0406,
        0.1588, 0.2574, 0.0347, 0.0240], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,283][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.6244, 0.0115, 0.2536, 0.0055, 0.0161, 0.0136, 0.0098, 0.0154, 0.0095,
        0.0067, 0.0029, 0.0085, 0.0017, 0.0208], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,284][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0080, 0.0421, 0.3523, 0.0399, 0.1443, 0.0243, 0.0371, 0.0602, 0.0547,
        0.0595, 0.0428, 0.0798, 0.0283, 0.0268], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,284][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0026, 0.0236, 0.0443, 0.0698, 0.0429, 0.0450, 0.0377, 0.0433, 0.0386,
        0.2206, 0.1917, 0.1546, 0.0262, 0.0592], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,287][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1725, 0.0575, 0.4830, 0.0124, 0.0156, 0.0146, 0.0221, 0.0428, 0.0570,
        0.0406, 0.0129, 0.0266, 0.0008, 0.0415], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,291][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0153, 0.0299, 0.0765, 0.0198, 0.0557, 0.0583, 0.1210, 0.0930, 0.1603,
        0.0349, 0.0222, 0.1348, 0.0447, 0.1335], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,297][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1390, 0.0506, 0.1827, 0.0167, 0.0656, 0.0528, 0.0366, 0.1130, 0.1481,
        0.0256, 0.0104, 0.0507, 0.0170, 0.0913], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,299][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0002, 0.0652, 0.0309, 0.1065, 0.0500, 0.0703, 0.0930, 0.0497, 0.0473,
        0.1343, 0.1579, 0.0612, 0.0491, 0.0843], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,299][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0010, 0.0377, 0.2837, 0.0505, 0.1064, 0.0846, 0.0871, 0.0482, 0.0402,
        0.0564, 0.0416, 0.0738, 0.0152, 0.0736], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,299][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0010, 0.2591, 0.0345, 0.0668, 0.0079, 0.0116, 0.0161, 0.0125, 0.0260,
        0.2015, 0.2922, 0.0341, 0.0060, 0.0306], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,300][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([9.6999e-07, 6.7564e-03, 1.4620e-02, 2.1152e-02, 9.2631e-02, 4.0590e-02,
        1.4211e-01, 8.6989e-02, 5.1925e-02, 1.5595e-01, 9.6742e-02, 7.3354e-02,
        6.8567e-02, 1.4862e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,300][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0132, 0.0033, 0.2830, 0.0019, 0.0135, 0.0106, 0.0124, 0.1276, 0.0979,
        0.0104, 0.0081, 0.1847, 0.0011, 0.2324], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,300][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0010, 0.1605, 0.0047, 0.0818, 0.0178, 0.0583, 0.1006, 0.0467, 0.0346,
        0.1633, 0.2440, 0.0292, 0.0228, 0.0346], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,301][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.6408, 0.0050, 0.2168, 0.0054, 0.0210, 0.0291, 0.0112, 0.0165, 0.0118,
        0.0035, 0.0023, 0.0138, 0.0020, 0.0179, 0.0028], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,301][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0115, 0.0301, 0.3485, 0.0357, 0.1306, 0.0279, 0.0435, 0.0591, 0.0549,
        0.0571, 0.0401, 0.0609, 0.0271, 0.0287, 0.0443], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,305][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0055, 0.0227, 0.0413, 0.0735, 0.0577, 0.0369, 0.0578, 0.0374, 0.0394,
        0.1718, 0.1613, 0.1071, 0.0338, 0.0573, 0.0965], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,310][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3609, 0.0230, 0.4556, 0.0064, 0.0125, 0.0061, 0.0107, 0.0247, 0.0261,
        0.0145, 0.0047, 0.0155, 0.0008, 0.0229, 0.0156], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,314][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0368, 0.0349, 0.0917, 0.0245, 0.0555, 0.0326, 0.0768, 0.0967, 0.0831,
        0.0391, 0.0260, 0.2170, 0.0516, 0.0507, 0.0830], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,316][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2929, 0.0437, 0.1641, 0.0117, 0.0449, 0.0345, 0.0238, 0.0873, 0.1195,
        0.0173, 0.0063, 0.0504, 0.0115, 0.0595, 0.0325], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,316][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0003, 0.0564, 0.0306, 0.0927, 0.0479, 0.0660, 0.0809, 0.0433, 0.0466,
        0.1165, 0.1358, 0.0562, 0.0482, 0.0810, 0.0977], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,317][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0017, 0.0430, 0.2053, 0.0574, 0.0882, 0.0839, 0.0840, 0.0496, 0.0377,
        0.0623, 0.0468, 0.0657, 0.0144, 0.0706, 0.0894], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,317][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0009, 0.2840, 0.0361, 0.0583, 0.0082, 0.0100, 0.0197, 0.0146, 0.0394,
        0.1779, 0.2289, 0.0386, 0.0080, 0.0325, 0.0428], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,317][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.8932e-05, 7.4570e-03, 2.9276e-02, 1.4324e-02, 1.2426e-01, 4.5204e-02,
        1.0311e-01, 8.3347e-02, 7.2301e-02, 8.1993e-02, 4.6414e-02, 6.6211e-02,
        7.5925e-02, 1.1181e-01, 1.3835e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,318][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1069, 0.0033, 0.3905, 0.0012, 0.0120, 0.0042, 0.0063, 0.0804, 0.0561,
        0.0061, 0.0049, 0.1107, 0.0010, 0.1547, 0.0616], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,318][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0017, 0.1276, 0.0041, 0.0659, 0.0134, 0.0547, 0.0929, 0.0478, 0.0339,
        0.1452, 0.2598, 0.0342, 0.0202, 0.0280, 0.0708], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,359][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:33,359][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,359][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,360][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,360][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,360][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,361][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,361][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,361][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,362][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,362][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,362][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,363][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,363][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9722, 0.0278], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,363][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2608, 0.7392], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,364][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9591, 0.0409], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,364][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9416, 0.0584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,364][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9387, 0.0613], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,365][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8351, 0.1649], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,365][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0015, 0.9985], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,365][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0808, 0.9192], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,366][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6878, 0.3122], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,366][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.0760e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,366][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1838, 0.8162], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,367][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1060, 0.8940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,367][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.6940, 0.0087, 0.2973], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,367][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([0.0120, 0.1119, 0.8761], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,368][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.4181, 0.0163, 0.5656], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,368][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.1308, 0.5716, 0.2977], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,368][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.2495, 0.0565, 0.6940], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,370][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.3550, 0.1337, 0.5113], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,370][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([4.2375e-04, 5.1642e-01, 4.8316e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,370][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.0119, 0.1745, 0.8135], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,371][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.4219, 0.1696, 0.4085], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,371][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([8.8836e-05, 7.6594e-01, 2.3398e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,371][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.0031, 0.4119, 0.5850], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,372][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.0128, 0.8754, 0.1118], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,372][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([8.0890e-01, 2.0711e-03, 1.8834e-01, 6.9135e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,373][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0305, 0.0295, 0.9006, 0.0394], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,375][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3078, 0.0020, 0.6894, 0.0008], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,376][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1854, 0.1208, 0.6871, 0.0067], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,377][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.3201e-01, 7.7029e-04, 6.6895e-02, 3.2035e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,378][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8060, 0.0230, 0.1667, 0.0043], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,379][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([4.6725e-04, 7.3246e-02, 7.5285e-01, 1.7344e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,380][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0048, 0.0484, 0.9314, 0.0154], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,381][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2351, 0.0382, 0.7123, 0.0143], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,382][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.4661e-05, 3.2064e-01, 2.0288e-01, 4.7647e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,383][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0018, 0.0487, 0.9375, 0.0119], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,385][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0589, 0.2898, 0.2029, 0.4485], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,386][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.5296, 0.0041, 0.4190, 0.0014, 0.0459], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,387][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0071, 0.0453, 0.6094, 0.0510, 0.2873], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,388][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.2709, 0.0074, 0.6946, 0.0017, 0.0255], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,390][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0325, 0.1695, 0.7790, 0.0107, 0.0083], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,391][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.3530, 0.0120, 0.4806, 0.0072, 0.1472], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,392][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.3701, 0.0598, 0.4426, 0.0177, 0.1098], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,393][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([1.4124e-04, 1.2935e-01, 2.9416e-01, 2.2711e-01, 3.4924e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,394][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.0013, 0.0770, 0.7940, 0.0219, 0.1058], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,395][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.2280, 0.0831, 0.5416, 0.0384, 0.1089], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,396][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([2.1394e-05, 3.0366e-01, 1.4520e-01, 2.9834e-01, 2.5278e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,397][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([2.9133e-04, 8.9164e-02, 8.6522e-01, 1.8082e-02, 2.7245e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,398][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0084, 0.3812, 0.0788, 0.3847, 0.1468], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,399][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3454, 0.0026, 0.5987, 0.0010, 0.0499, 0.0023], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,401][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0070, 0.0586, 0.4721, 0.0791, 0.3192, 0.0639], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,401][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([7.9798e-02, 3.0219e-03, 8.9167e-01, 8.5154e-04, 2.2750e-02, 1.9108e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,403][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0623, 0.1736, 0.7272, 0.0116, 0.0103, 0.0150], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,404][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3003, 0.0048, 0.5209, 0.0044, 0.0983, 0.0714], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,405][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3312, 0.0830, 0.3427, 0.0194, 0.1151, 0.1087], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,406][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([4.4029e-05, 4.5984e-02, 2.9509e-01, 1.3993e-01, 4.2367e-01, 9.5277e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,407][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([4.9039e-04, 4.5645e-02, 7.8140e-01, 2.0123e-02, 1.2817e-01, 2.4165e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,408][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0788, 0.0508, 0.6947, 0.0223, 0.1323, 0.0211], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,409][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([3.5078e-06, 1.2514e-01, 1.4273e-01, 2.5624e-01, 3.4048e-01, 1.3540e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,410][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([4.2360e-04, 1.0081e-01, 8.2061e-01, 2.5423e-02, 3.4093e-02, 1.8640e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,410][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0066, 0.1457, 0.0892, 0.2581, 0.1750, 0.3254], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,410][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5604, 0.0028, 0.3979, 0.0011, 0.0340, 0.0014, 0.0023],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,411][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0130, 0.0551, 0.5133, 0.0674, 0.2277, 0.0511, 0.0724],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,411][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1204, 0.0036, 0.8525, 0.0011, 0.0185, 0.0014, 0.0025],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,411][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2212, 0.1609, 0.5601, 0.0108, 0.0077, 0.0148, 0.0244],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,412][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4037, 0.0050, 0.4395, 0.0048, 0.0623, 0.0408, 0.0440],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,412][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4324, 0.0578, 0.2925, 0.0168, 0.0785, 0.0714, 0.0506],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,412][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([6.0791e-05, 4.9061e-02, 3.0597e-01, 1.6430e-01, 3.1507e-01, 8.6125e-02,
        7.9412e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,412][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0015, 0.0811, 0.7065, 0.0359, 0.1177, 0.0297, 0.0275],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,413][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2097, 0.0603, 0.5576, 0.0250, 0.1062, 0.0161, 0.0252],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,414][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0130e-06, 1.6107e-01, 1.6807e-01, 2.5283e-01, 2.5585e-01, 8.0526e-02,
        8.1664e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,415][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0017, 0.0977, 0.7822, 0.0266, 0.0354, 0.0218, 0.0346],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,416][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0103, 0.1132, 0.0637, 0.1982, 0.1142, 0.2242, 0.2761],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,418][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1847, 0.0050, 0.6675, 0.0030, 0.1069, 0.0053, 0.0098, 0.0177],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,419][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0047, 0.0460, 0.4514, 0.0621, 0.2475, 0.0534, 0.0585, 0.0765],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,420][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0319, 0.0067, 0.9094, 0.0022, 0.0307, 0.0041, 0.0055, 0.0096],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,421][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0418, 0.2503, 0.5684, 0.0179, 0.0079, 0.0131, 0.0425, 0.0582],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,422][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1544, 0.0065, 0.4182, 0.0078, 0.1346, 0.0916, 0.0814, 0.1056],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,424][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1825, 0.0690, 0.2451, 0.0237, 0.0944, 0.0895, 0.0604, 0.2354],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,424][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([2.4450e-05, 4.3393e-02, 2.2456e-01, 1.7462e-01, 3.2936e-01, 8.2536e-02,
        6.4551e-02, 8.0963e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,425][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([4.9027e-04, 8.4709e-02, 6.5572e-01, 2.8487e-02, 1.1566e-01, 2.5073e-02,
        3.0302e-02, 5.9561e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,426][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0837, 0.0827, 0.5624, 0.0268, 0.1237, 0.0272, 0.0397, 0.0538],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,427][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.1751e-06, 9.7579e-02, 9.9033e-02, 2.5677e-01, 2.2528e-01, 9.9341e-02,
        6.8702e-02, 1.5330e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,428][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([5.7604e-04, 9.0312e-02, 7.3770e-01, 2.4852e-02, 2.6341e-02, 1.8572e-02,
        4.4235e-02, 5.7413e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,429][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0060, 0.1741, 0.0384, 0.1938, 0.0699, 0.1658, 0.2158, 0.1363],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,431][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.2791, 0.0045, 0.5665, 0.0019, 0.0857, 0.0055, 0.0091, 0.0162, 0.0316],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,432][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0055, 0.0497, 0.3932, 0.0575, 0.2402, 0.0500, 0.0553, 0.0749, 0.0738],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,433][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1093, 0.0081, 0.8132, 0.0021, 0.0275, 0.0037, 0.0060, 0.0093, 0.0208],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,434][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0911, 0.2373, 0.4728, 0.0161, 0.0067, 0.0127, 0.0354, 0.0649, 0.0629],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,435][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0603, 0.0094, 0.2682, 0.0108, 0.0798, 0.1149, 0.0926, 0.0857, 0.2783],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,437][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1713, 0.0727, 0.1861, 0.0266, 0.0728, 0.0741, 0.0490, 0.1336, 0.2138],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,437][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([3.9308e-05, 3.7870e-02, 1.6894e-01, 1.3803e-01, 3.0963e-01, 8.1761e-02,
        7.8909e-02, 8.2884e-02, 1.0194e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,439][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0007, 0.0651, 0.6104, 0.0227, 0.1067, 0.0307, 0.0337, 0.0537, 0.0763],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,440][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2097, 0.0453, 0.4885, 0.0160, 0.0783, 0.0157, 0.0239, 0.0361, 0.0865],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,441][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.7376e-06, 1.1179e-01, 9.5803e-02, 1.6821e-01, 2.2340e-01, 8.9323e-02,
        8.8624e-02, 1.3285e-01, 8.9987e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,442][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0012, 0.1224, 0.6164, 0.0255, 0.0231, 0.0209, 0.0443, 0.0628, 0.0833],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,443][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0061, 0.1338, 0.0282, 0.1310, 0.0607, 0.1534, 0.2213, 0.1389, 0.1266],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,444][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4409, 0.0053, 0.4714, 0.0020, 0.0336, 0.0023, 0.0036, 0.0083, 0.0294,
        0.0034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,446][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0113, 0.0315, 0.4561, 0.0385, 0.1610, 0.0350, 0.0467, 0.1007, 0.0632,
        0.0560], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,447][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([7.7340e-02, 2.2914e-03, 8.9096e-01, 8.4178e-04, 1.8307e-02, 9.5363e-04,
        1.2164e-03, 2.4510e-03, 5.1026e-03, 5.3392e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,448][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0870, 0.0674, 0.6069, 0.0036, 0.0075, 0.0115, 0.0333, 0.0703, 0.0997,
        0.0128], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,449][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6888, 0.0028, 0.1813, 0.0015, 0.0117, 0.0092, 0.0091, 0.0261, 0.0664,
        0.0032], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,450][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4852, 0.0475, 0.1665, 0.0085, 0.0411, 0.0268, 0.0202, 0.0772, 0.1131,
        0.0140], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,451][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([6.5681e-05, 4.3739e-02, 3.1565e-01, 1.2148e-01, 2.3688e-01, 4.0538e-02,
        3.0731e-02, 6.1869e-02, 8.5136e-02, 6.3917e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,452][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0008, 0.0302, 0.6727, 0.0138, 0.1281, 0.0169, 0.0182, 0.0597, 0.0486,
        0.0111], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,452][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0861, 0.0381, 0.5175, 0.0163, 0.1362, 0.0185, 0.0254, 0.0384, 0.0969,
        0.0267], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,452][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.4993e-06, 1.3349e-01, 8.3416e-02, 2.1819e-01, 1.7165e-01, 6.2308e-02,
        6.6501e-02, 1.2705e-01, 6.6940e-02, 7.0457e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,453][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([7.0272e-04, 2.8631e-02, 8.2459e-01, 6.6283e-03, 1.7543e-02, 8.5622e-03,
        1.3292e-02, 2.8246e-02, 5.7792e-02, 1.4011e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,453][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0074, 0.0824, 0.0388, 0.1128, 0.0595, 0.1183, 0.1509, 0.1318, 0.1015,
        0.1964], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,453][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5101, 0.0038, 0.4130, 0.0015, 0.0301, 0.0018, 0.0028, 0.0067, 0.0266,
        0.0026, 0.0010], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,454][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0203, 0.0181, 0.5004, 0.0230, 0.1462, 0.0287, 0.0373, 0.0961, 0.0630,
        0.0397, 0.0272], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,454][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([7.5071e-02, 1.4027e-03, 8.9647e-01, 5.4915e-04, 1.7846e-02, 6.9514e-04,
        9.4439e-04, 2.0554e-03, 4.5119e-03, 3.3858e-04, 1.1633e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,454][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0419, 0.0516, 0.6624, 0.0032, 0.0078, 0.0113, 0.0310, 0.0694, 0.1066,
        0.0124, 0.0023], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,455][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([8.4022e-01, 7.3875e-04, 1.0676e-01, 4.2094e-04, 5.3062e-03, 3.3315e-03,
        3.3401e-03, 9.9044e-03, 2.8534e-02, 9.6004e-04, 4.9025e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,456][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5927, 0.0303, 0.1501, 0.0051, 0.0328, 0.0174, 0.0131, 0.0562, 0.0901,
        0.0094, 0.0028], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,457][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9456e-05, 2.6485e-02, 3.7162e-01, 8.2307e-02, 2.2824e-01, 3.7239e-02,
        2.5866e-02, 5.9920e-02, 8.5006e-02, 4.1817e-02, 4.1397e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,458][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0008, 0.0181, 0.7135, 0.0089, 0.1290, 0.0131, 0.0137, 0.0499, 0.0421,
        0.0081, 0.0029], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,460][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1399, 0.0272, 0.5223, 0.0116, 0.1201, 0.0131, 0.0174, 0.0300, 0.0868,
        0.0219, 0.0096], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,460][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.5998e-06, 9.9387e-02, 8.3439e-02, 1.7788e-01, 1.8230e-01, 6.6289e-02,
        6.6321e-02, 1.2264e-01, 7.1142e-02, 5.9657e-02, 7.0934e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,461][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.1471e-04, 1.8854e-02, 8.4979e-01, 4.5203e-03, 1.6210e-02, 6.9240e-03,
        9.9627e-03, 2.5801e-02, 5.2430e-02, 1.1678e-02, 3.4151e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,462][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0101, 0.0660, 0.0339, 0.0814, 0.0431, 0.0968, 0.1275, 0.1162, 0.0906,
        0.1454, 0.1891], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,464][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1701, 0.0098, 0.5685, 0.0064, 0.1134, 0.0067, 0.0094, 0.0210, 0.0380,
        0.0104, 0.0059, 0.0403], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,465][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0039, 0.0439, 0.3124, 0.0546, 0.1688, 0.0408, 0.0477, 0.0662, 0.0528,
        0.0850, 0.0709, 0.0529], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,466][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0576, 0.0133, 0.7823, 0.0045, 0.0535, 0.0053, 0.0083, 0.0136, 0.0245,
        0.0054, 0.0020, 0.0297], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,467][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0069, 0.1243, 0.6356, 0.0094, 0.0082, 0.0109, 0.0244, 0.0610, 0.0786,
        0.0264, 0.0060, 0.0082], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,469][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0422, 0.0050, 0.1966, 0.0090, 0.0995, 0.0848, 0.0812, 0.0786, 0.1461,
        0.0174, 0.0117, 0.2279], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,470][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1437, 0.0631, 0.2125, 0.0210, 0.0652, 0.0616, 0.0436, 0.1065, 0.1666,
        0.0339, 0.0147, 0.0676], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,471][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([2.5532e-05, 4.7146e-02, 1.1340e-01, 1.2170e-01, 2.1579e-01, 6.4227e-02,
        5.5521e-02, 6.2860e-02, 6.6018e-02, 9.4389e-02, 1.1819e-01, 4.0736e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,472][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([6.2461e-04, 4.7108e-02, 6.5315e-01, 2.1054e-02, 8.4968e-02, 1.6635e-02,
        1.8848e-02, 4.0105e-02, 4.5708e-02, 1.7081e-02, 8.5961e-03, 4.6117e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,473][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0778, 0.0615, 0.3436, 0.0287, 0.0964, 0.0290, 0.0368, 0.0509, 0.1058,
        0.0538, 0.0308, 0.0849], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,474][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.8530e-06, 8.6267e-02, 6.9628e-02, 1.9121e-01, 1.5519e-01, 7.7863e-02,
        6.8976e-02, 8.3057e-02, 5.8542e-02, 8.0707e-02, 1.0208e-01, 2.6478e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,475][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.4534e-04, 6.1162e-02, 7.1162e-01, 1.4900e-02, 2.1838e-02, 1.3118e-02,
        2.0226e-02, 3.8819e-02, 7.1852e-02, 2.2937e-02, 9.2953e-03, 1.4089e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,476][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0021, 0.0918, 0.0247, 0.0944, 0.0445, 0.0835, 0.0915, 0.0742, 0.0626,
        0.1257, 0.2140, 0.0911], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,477][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.1157, 0.0057, 0.6782, 0.0028, 0.0977, 0.0035, 0.0059, 0.0148, 0.0271,
        0.0053, 0.0025, 0.0320, 0.0087], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,478][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([0.0022, 0.0277, 0.3461, 0.0407, 0.1927, 0.0364, 0.0408, 0.0713, 0.0611,
        0.0464, 0.0397, 0.0604, 0.0346], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,480][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0324, 0.0082, 0.8395, 0.0024, 0.0377, 0.0037, 0.0067, 0.0118, 0.0247,
        0.0037, 0.0012, 0.0246, 0.0034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,481][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([1.1454e-03, 4.0252e-02, 7.5270e-01, 7.3931e-03, 1.2944e-02, 7.8379e-03,
        1.2789e-02, 6.3634e-02, 5.3229e-02, 2.4048e-02, 5.7749e-03, 1.8084e-02,
        1.6297e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,482][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0485, 0.0087, 0.2048, 0.0076, 0.0786, 0.0535, 0.0500, 0.0595, 0.1332,
        0.0168, 0.0116, 0.2489, 0.0783], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,483][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([0.0822, 0.0528, 0.2019, 0.0190, 0.0801, 0.0702, 0.0446, 0.1164, 0.1871,
        0.0317, 0.0142, 0.0756, 0.0243], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,484][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([2.2391e-05, 4.2823e-02, 1.4988e-01, 1.1622e-01, 2.2663e-01, 4.6877e-02,
        4.2806e-02, 5.6889e-02, 6.0727e-02, 7.5273e-02, 1.0443e-01, 3.9575e-02,
        3.7842e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,485][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([1.2934e-04, 4.1339e-02, 5.5856e-01, 2.3183e-02, 1.2667e-01, 2.0025e-02,
        1.5882e-02, 5.0624e-02, 5.9828e-02, 2.3493e-02, 1.0893e-02, 6.5471e-02,
        3.9078e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,486][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0506, 0.0464, 0.3865, 0.0267, 0.1166, 0.0191, 0.0362, 0.0502, 0.0971,
        0.0457, 0.0262, 0.0671, 0.0316], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,487][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([1.6306e-06, 1.0959e-01, 8.6811e-02, 1.6965e-01, 1.8868e-01, 6.2932e-02,
        4.3395e-02, 8.3450e-02, 6.1714e-02, 5.7452e-02, 7.9840e-02, 2.7187e-02,
        2.9301e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,488][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([1.1250e-05, 3.0793e-02, 7.5391e-01, 1.3243e-02, 4.0276e-02, 9.2262e-03,
        1.3426e-02, 4.2832e-02, 4.7142e-02, 2.0384e-02, 8.5715e-03, 1.9911e-02,
        2.7257e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,489][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0027, 0.1004, 0.0255, 0.0986, 0.0443, 0.0671, 0.0999, 0.0626, 0.0685,
        0.1199, 0.1735, 0.0914, 0.0454], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,490][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.2311, 0.0046, 0.5285, 0.0023, 0.0840, 0.0048, 0.0080, 0.0193, 0.0346,
        0.0046, 0.0020, 0.0398, 0.0089, 0.0274], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,492][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0080, 0.0421, 0.3523, 0.0399, 0.1443, 0.0243, 0.0371, 0.0602, 0.0547,
        0.0595, 0.0428, 0.0798, 0.0283, 0.0268], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,493][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([7.4546e-02, 6.5737e-03, 8.2671e-01, 1.7203e-03, 2.7120e-02, 2.3702e-03,
        4.1244e-03, 8.8638e-03, 1.7109e-02, 2.2767e-03, 7.4397e-04, 1.8644e-02,
        2.0885e-03, 7.1088e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,494][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([7.6280e-02, 1.7772e-01, 5.0343e-01, 1.0872e-02, 6.2725e-03, 1.0309e-02,
        2.8316e-02, 4.0679e-02, 4.8143e-02, 3.3917e-02, 8.8923e-03, 1.5508e-02,
        2.0609e-04, 3.9456e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,494][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.1106, 0.0048, 0.2760, 0.0051, 0.0666, 0.0518, 0.0397, 0.0465, 0.1353,
        0.0096, 0.0055, 0.1496, 0.0518, 0.0471], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,494][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1390, 0.0506, 0.1827, 0.0167, 0.0656, 0.0528, 0.0366, 0.1130, 0.1481,
        0.0256, 0.0104, 0.0507, 0.0170, 0.0913], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,495][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([4.1398e-05, 4.5758e-02, 1.5860e-01, 1.1402e-01, 2.0075e-01, 4.8164e-02,
        4.0755e-02, 4.7944e-02, 6.0045e-02, 7.3778e-02, 9.5785e-02, 4.4415e-02,
        2.8693e-02, 4.1254e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,495][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0008, 0.0527, 0.6180, 0.0209, 0.0746, 0.0154, 0.0196, 0.0369, 0.0503,
        0.0165, 0.0082, 0.0562, 0.0027, 0.0271], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,495][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1366, 0.0494, 0.4057, 0.0209, 0.0742, 0.0128, 0.0216, 0.0348, 0.0715,
        0.0344, 0.0197, 0.0513, 0.0176, 0.0493], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,496][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.4704e-06, 8.9099e-02, 8.1784e-02, 1.6228e-01, 1.7894e-01, 5.7667e-02,
        5.7797e-02, 8.1646e-02, 6.4494e-02, 6.2707e-02, 7.8655e-02, 3.2685e-02,
        2.6669e-02, 2.5577e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,496][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([7.1605e-04, 9.6291e-02, 5.6864e-01, 2.3086e-02, 2.1718e-02, 1.5361e-02,
        3.1961e-02, 3.8363e-02, 6.0446e-02, 2.9691e-02, 1.1722e-02, 1.8559e-02,
        3.4625e-04, 8.3101e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,496][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0040, 0.0749, 0.0197, 0.0793, 0.0417, 0.0786, 0.1097, 0.0746, 0.0581,
        0.1189, 0.1612, 0.0782, 0.0423, 0.0587], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,497][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4126, 0.0043, 0.4361, 0.0018, 0.0425, 0.0026, 0.0051, 0.0103, 0.0271,
        0.0037, 0.0014, 0.0234, 0.0040, 0.0182, 0.0069], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,498][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0115, 0.0301, 0.3485, 0.0357, 0.1306, 0.0279, 0.0435, 0.0591, 0.0549,
        0.0571, 0.0401, 0.0609, 0.0271, 0.0287, 0.0443], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,499][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.1377e-01, 3.5078e-03, 8.2092e-01, 1.0374e-03, 1.9610e-02, 1.3854e-03,
        2.7638e-03, 4.8108e-03, 1.1181e-02, 1.1705e-03, 3.4282e-04, 1.2833e-02,
        1.2411e-03, 3.6163e-03, 1.8071e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,500][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.4330e-01, 7.9482e-02, 4.2371e-01, 5.8074e-03, 4.1830e-03, 3.8097e-03,
        1.3212e-02, 2.0748e-02, 1.9566e-02, 1.2782e-02, 3.3827e-03, 7.8435e-03,
        1.5542e-04, 2.1717e-02, 4.0306e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,501][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2905, 0.0030, 0.2730, 0.0030, 0.0340, 0.0231, 0.0234, 0.0295, 0.1010,
        0.0062, 0.0034, 0.1274, 0.0288, 0.0328, 0.0210], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,502][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2929, 0.0437, 0.1641, 0.0117, 0.0449, 0.0345, 0.0238, 0.0873, 0.1195,
        0.0173, 0.0063, 0.0504, 0.0115, 0.0595, 0.0325], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,503][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.0437e-05, 3.3169e-02, 1.6652e-01, 1.0194e-01, 2.1007e-01, 4.2808e-02,
        4.1151e-02, 4.6739e-02, 6.2295e-02, 6.5882e-02, 7.8967e-02, 3.9838e-02,
        2.8061e-02, 3.7275e-02, 4.5251e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,504][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0013, 0.0646, 0.5556, 0.0218, 0.0796, 0.0191, 0.0203, 0.0388, 0.0521,
        0.0182, 0.0079, 0.0664, 0.0033, 0.0267, 0.0242], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,506][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2313, 0.0428, 0.3588, 0.0142, 0.0623, 0.0088, 0.0177, 0.0279, 0.0714,
        0.0266, 0.0127, 0.0463, 0.0148, 0.0355, 0.0291], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,507][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.1341e-06, 1.0461e-01, 8.7270e-02, 1.6469e-01, 1.6114e-01, 5.7980e-02,
        5.7982e-02, 7.1373e-02, 5.8010e-02, 6.3357e-02, 7.3188e-02, 2.4250e-02,
        1.9386e-02, 2.0646e-02, 3.6104e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,507][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.9679e-03, 5.2494e-02, 7.0328e-01, 1.2135e-02, 2.1391e-02, 6.4233e-03,
        1.6749e-02, 2.2532e-02, 2.9036e-02, 1.5681e-02, 6.7491e-03, 1.1052e-02,
        3.7343e-04, 5.2303e-02, 4.6830e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,509][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0075, 0.0576, 0.0190, 0.0637, 0.0347, 0.0724, 0.0984, 0.0721, 0.0546,
        0.1029, 0.1545, 0.0882, 0.0378, 0.0482, 0.0884], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,510][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:33,511][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[19862],
        [ 1354],
        [11946],
        [ 4837],
        [ 2583],
        [ 1186],
        [  425],
        [  584],
        [  759],
        [ 3460],
        [ 2227],
        [ 1140],
        [  977],
        [  313],
        [  417]], device='cuda:0')
[2024-07-24 10:25:33,512][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17882],
        [ 5359],
        [ 7585],
        [ 2929],
        [ 3468],
        [ 1904],
        [  965],
        [ 1892],
        [ 2086],
        [ 5038],
        [ 3097],
        [ 3377],
        [ 2841],
        [ 1119],
        [ 1486]], device='cuda:0')
[2024-07-24 10:25:33,513][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[9877],
        [6611],
        [ 577],
        [ 384],
        [ 156],
        [ 106],
        [ 145],
        [ 172],
        [ 180],
        [ 193],
        [ 163],
        [ 409],
        [ 300],
        [ 117],
        [ 180]], device='cuda:0')
[2024-07-24 10:25:33,515][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[14776],
        [11174],
        [19981],
        [21326],
        [32019],
        [32694],
        [29714],
        [31191],
        [30992],
        [28265],
        [27933],
        [28040],
        [31080],
        [28634],
        [27819]], device='cuda:0')
[2024-07-24 10:25:33,516][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7196],
        [ 1451],
        [50224],
        [49537],
        [47362],
        [30262],
        [15289],
        [16081],
        [33022],
        [35837],
        [33798],
        [14421],
        [26116],
        [16633],
        [17050]], device='cuda:0')
[2024-07-24 10:25:33,517][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25796],
        [25843],
        [34909],
        [40276],
        [42788],
        [42127],
        [40705],
        [41035],
        [39086],
        [40447],
        [41381],
        [41667],
        [42458],
        [40071],
        [39864]], device='cuda:0')
[2024-07-24 10:25:33,519][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4262],
        [ 7619],
        [34193],
        [23440],
        [13955],
        [14476],
        [13019],
        [ 6460],
        [ 6469],
        [ 8890],
        [ 8675],
        [ 7836],
        [ 6894],
        [ 7750],
        [ 8924]], device='cuda:0')
[2024-07-24 10:25:33,520][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38200],
        [33259],
        [10271],
        [18597],
        [11295],
        [16660],
        [18463],
        [26351],
        [29754],
        [27396],
        [27224],
        [28363],
        [28853],
        [28122],
        [28504]], device='cuda:0')
[2024-07-24 10:25:33,521][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26964],
        [40385],
        [50136],
        [47633],
        [37622],
        [34057],
        [25929],
        [20825],
        [21939],
        [30550],
        [26140],
        [21030],
        [19639],
        [20813],
        [20748]], device='cuda:0')
[2024-07-24 10:25:33,522][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 6392],
        [ 2526],
        [13178],
        [12317],
        [11582],
        [11413],
        [ 8791],
        [ 8586],
        [ 8490],
        [ 8263],
        [ 7818],
        [ 7427],
        [ 7855],
        [ 7198],
        [ 5646]], device='cuda:0')
[2024-07-24 10:25:33,524][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[4972],
        [ 807],
        [ 979],
        [2934],
        [1257],
        [1136],
        [ 928],
        [ 754],
        [ 844],
        [ 978],
        [1223],
        [ 855],
        [ 960],
        [ 872],
        [ 803]], device='cuda:0')
[2024-07-24 10:25:33,525][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 6476],
        [ 2923],
        [36136],
        [47700],
        [25010],
        [29228],
        [29355],
        [14445],
        [10886],
        [11861],
        [11718],
        [ 6990],
        [ 7307],
        [ 7395],
        [ 8809]], device='cuda:0')
[2024-07-24 10:25:33,527][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25258],
        [24068],
        [ 9800],
        [ 9775],
        [ 9808],
        [ 9820],
        [ 9841],
        [12271],
        [13337],
        [10696],
        [10553],
        [12317],
        [12248],
        [12796],
        [12128]], device='cuda:0')
[2024-07-24 10:25:33,528][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22395],
        [39324],
        [39667],
        [39334],
        [39990],
        [42575],
        [42355],
        [42291],
        [43383],
        [42105],
        [38725],
        [37335],
        [38575],
        [39002],
        [38469]], device='cuda:0')
[2024-07-24 10:25:33,529][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18071],
        [14103],
        [13158],
        [13385],
        [13350],
        [13596],
        [14233],
        [14427],
        [16373],
        [15114],
        [15196],
        [16285],
        [14838],
        [15360],
        [15232]], device='cuda:0')
[2024-07-24 10:25:33,530][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 7020],
        [ 6374],
        [ 5639],
        [ 4039],
        [ 7674],
        [ 9117],
        [ 7349],
        [10039],
        [10009],
        [ 8838],
        [ 8164],
        [10526],
        [10440],
        [10233],
        [ 8989]], device='cuda:0')
[2024-07-24 10:25:33,532][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34793],
        [ 2826],
        [ 3179],
        [ 3511],
        [ 3270],
        [ 2709],
        [ 2521],
        [ 2538],
        [ 2672],
        [ 2373],
        [ 2459],
        [ 1392],
        [ 1930],
        [ 1631],
        [ 1583]], device='cuda:0')
[2024-07-24 10:25:33,533][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3652],
        [2725],
        [1339],
        [1377],
        [1505],
        [1569],
        [1562],
        [1693],
        [1736],
        [1595],
        [1581],
        [2194],
        [2017],
        [1898],
        [1734]], device='cuda:0')
[2024-07-24 10:25:33,534][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12508],
        [15446],
        [27392],
        [18063],
        [19490],
        [19291],
        [18438],
        [20880],
        [19608],
        [14647],
        [14549],
        [17035],
        [15240],
        [17606],
        [14629]], device='cuda:0')
[2024-07-24 10:25:33,536][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23118],
        [29391],
        [18812],
        [22497],
        [16416],
        [17553],
        [18644],
        [18765],
        [20949],
        [21821],
        [22186],
        [21581],
        [20401],
        [20116],
        [21337]], device='cuda:0')
[2024-07-24 10:25:33,537][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18588],
        [15645],
        [23599],
        [29724],
        [24570],
        [21359],
        [21121],
        [19885],
        [17115],
        [17664],
        [18398],
        [16652],
        [17014],
        [15662],
        [15053]], device='cuda:0')
[2024-07-24 10:25:33,538][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8940],
        [11398],
        [ 4979],
        [ 4926],
        [ 8458],
        [ 7476],
        [ 7216],
        [ 7402],
        [ 7566],
        [ 6616],
        [ 6235],
        [11449],
        [10530],
        [10712],
        [10223]], device='cuda:0')
[2024-07-24 10:25:33,539][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3293],
        [45658],
        [38714],
        [36025],
        [40663],
        [40944],
        [41957],
        [41610],
        [41243],
        [40933],
        [40582],
        [40636],
        [41810],
        [40594],
        [40990]], device='cuda:0')
[2024-07-24 10:25:33,540][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[37632],
        [45032],
        [25772],
        [12701],
        [13267],
        [10227],
        [11926],
        [11471],
        [11891],
        [10194],
        [10362],
        [13358],
        [11303],
        [13513],
        [14936]], device='cuda:0')
[2024-07-24 10:25:33,541][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39724],
        [38132],
        [36121],
        [37690],
        [37486],
        [36640],
        [37487],
        [36873],
        [36885],
        [38800],
        [38500],
        [40144],
        [38741],
        [39034],
        [39004]], device='cuda:0')
[2024-07-24 10:25:33,542][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[33223],
        [35627],
        [41826],
        [45161],
        [45063],
        [44817],
        [44704],
        [45117],
        [45304],
        [45825],
        [45789],
        [45875],
        [45870],
        [44958],
        [45253]], device='cuda:0')
[2024-07-24 10:25:33,543][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8919],
        [24718],
        [24380],
        [20475],
        [20932],
        [14395],
        [14139],
        [15542],
        [14770],
        [16882],
        [18306],
        [19933],
        [19073],
        [18457],
        [18304]], device='cuda:0')
[2024-07-24 10:25:33,544][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[42074],
        [31044],
        [38044],
        [38413],
        [38680],
        [40487],
        [40643],
        [40423],
        [41231],
        [39571],
        [39144],
        [40045],
        [41025],
        [41095],
        [41294]], device='cuda:0')
[2024-07-24 10:25:33,546][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[36383],
        [32805],
        [38470],
        [43410],
        [40111],
        [41075],
        [40434],
        [39026],
        [36246],
        [42018],
        [43075],
        [35244],
        [36471],
        [36648],
        [37802]], device='cuda:0')
[2024-07-24 10:25:33,547][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154],
        [19154]], device='cuda:0')
[2024-07-24 10:25:33,592][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:33,593][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,593][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,594][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,594][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,594][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,595][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,596][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,597][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,598][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,599][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,600][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,601][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,602][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0209, 0.9791], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,603][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0068, 0.9932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,605][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0079, 0.9921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,606][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4383, 0.5617], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,607][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2655, 0.7345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,609][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5341, 0.4659], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,610][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2320, 0.7680], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,611][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9871, 0.0129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,613][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8388, 0.1612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,614][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0622, 0.9378], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,615][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1199, 0.8801], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,616][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.9079e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,618][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.0119, 0.5121, 0.4760], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,619][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.0019, 0.9940, 0.0041], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,620][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.0153, 0.9061, 0.0786], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,622][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.1452, 0.3307, 0.5241], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,623][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([0.3848, 0.1265, 0.4886], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,624][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([1.7176e-02, 2.1633e-05, 9.8280e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,625][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.5464, 0.1496, 0.3040], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,626][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.7452, 0.0042, 0.2506], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,628][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.1217, 0.1036, 0.7747], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,629][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([5.0264e-04, 7.3580e-01, 2.6370e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,630][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.0054, 0.0030, 0.9916], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,631][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([4.5091e-07, 9.9995e-01, 5.1776e-05], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,632][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0096, 0.4057, 0.2932, 0.2914], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,633][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0121, 0.2185, 0.0192, 0.7503], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,633][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0172, 0.4546, 0.0746, 0.4536], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,634][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1750, 0.0779, 0.7013, 0.0458], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,634][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0802, 0.0721, 0.8039, 0.0438], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,634][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([4.4532e-05, 2.3732e-06, 9.9994e-01, 1.1796e-05], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,635][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1975, 0.2121, 0.5197, 0.0706], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,635][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.7137e-01, 2.7851e-03, 2.5149e-02, 7.0057e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,635][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4180, 0.0283, 0.5473, 0.0064], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,636][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.7214e-04, 1.4398e-01, 8.5225e-01, 3.4978e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,636][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0012, 0.0014, 0.9963, 0.0011], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,637][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([6.0013e-06, 4.6209e-01, 2.9407e-03, 5.3496e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,639][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0047, 0.2808, 0.2542, 0.1827, 0.2775], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,639][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([2.5547e-04, 1.3026e-01, 1.0509e-03, 8.5965e-01, 8.7827e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,641][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0126, 0.4369, 0.0740, 0.3716, 0.1048], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,642][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0378, 0.2260, 0.4593, 0.1078, 0.1691], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,643][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0665, 0.1519, 0.6604, 0.0319, 0.0893], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,643][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([3.0841e-04, 2.3409e-06, 9.7870e-01, 9.5135e-06, 2.0982e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,645][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.2824, 0.1211, 0.5046, 0.0306, 0.0612], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,646][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.6948, 0.0031, 0.2803, 0.0008, 0.0209], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,648][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0634, 0.0604, 0.6432, 0.0171, 0.2160], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,648][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([2.8849e-05, 1.8489e-01, 8.0864e-01, 3.3763e-03, 3.0689e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,649][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([1.2678e-03, 9.5733e-04, 9.3323e-01, 9.1149e-04, 6.3634e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,650][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([7.2207e-08, 1.4613e-01, 3.9287e-05, 8.5362e-01, 2.0827e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,651][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0050, 0.2379, 0.1969, 0.1570, 0.2201, 0.1832], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,652][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([9.5088e-05, 1.0011e-01, 1.0342e-03, 8.7400e-01, 9.9587e-03, 1.4801e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,653][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0043, 0.2765, 0.0451, 0.3956, 0.0936, 0.1848], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,655][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0128, 0.1527, 0.4650, 0.0795, 0.1925, 0.0976], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,656][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0191, 0.1629, 0.6104, 0.0803, 0.0957, 0.0317], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,657][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.4930e-05, 1.6188e-06, 9.5658e-01, 8.8009e-06, 4.3345e-02, 4.5848e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,658][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2881, 0.1761, 0.3899, 0.0438, 0.0305, 0.0716], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,660][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.5642, 0.0145, 0.3461, 0.0040, 0.0346, 0.0366], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,661][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1073, 0.0384, 0.5717, 0.0100, 0.2270, 0.0455], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,662][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([4.0122e-05, 1.0961e-01, 8.7298e-01, 4.7065e-03, 8.2454e-03, 4.4169e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,663][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.7422e-04, 6.3690e-04, 9.1723e-01, 8.5855e-04, 8.0274e-02, 8.2662e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,664][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([4.6263e-09, 1.0590e-01, 5.9303e-06, 8.9370e-01, 6.9306e-05, 3.2638e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,665][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0073, 0.2132, 0.1683, 0.1368, 0.1708, 0.1623, 0.1413],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,666][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.9442e-04, 1.0519e-01, 1.9382e-03, 8.2708e-01, 1.4360e-02, 1.6880e-02,
        3.4154e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,667][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0046, 0.2662, 0.0447, 0.3431, 0.0743, 0.1194, 0.1477],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,669][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0375, 0.1472, 0.4242, 0.0713, 0.1472, 0.0768, 0.0958],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,670][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0453, 0.1818, 0.5810, 0.0610, 0.0685, 0.0266, 0.0359],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,671][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.5348e-05, 5.0098e-06, 9.3690e-01, 3.0748e-05, 6.2878e-02, 1.2514e-04,
        3.5425e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,672][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2813, 0.1451, 0.4647, 0.0235, 0.0260, 0.0375, 0.0220],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,674][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7233, 0.0147, 0.2119, 0.0042, 0.0183, 0.0155, 0.0120],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,675][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0847, 0.0443, 0.6251, 0.0122, 0.1575, 0.0321, 0.0441],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,675][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.6119e-04, 1.3411e-01, 8.3716e-01, 5.9413e-03, 1.0244e-02, 5.7954e-03,
        6.3857e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,676][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.8419e-04, 7.8682e-04, 9.2258e-01, 1.0643e-03, 7.3060e-02, 8.7908e-04,
        1.3449e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,676][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.6769e-09, 1.5012e-01, 1.0533e-05, 8.4901e-01, 7.2584e-05, 2.9152e-04,
        4.9506e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,676][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0029, 0.1775, 0.1411, 0.1211, 0.1447, 0.1277, 0.1223, 0.1627],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,677][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([4.9167e-05, 8.4460e-02, 7.6430e-04, 8.5350e-01, 8.5504e-03, 1.6474e-02,
        3.4647e-02, 1.5509e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,677][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0022, 0.2272, 0.0340, 0.2839, 0.0682, 0.1276, 0.1492, 0.1077],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,677][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0110, 0.1396, 0.3922, 0.0542, 0.1326, 0.0743, 0.0725, 0.1237],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,678][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0135, 0.0678, 0.6221, 0.0413, 0.0935, 0.0362, 0.0447, 0.0809],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,678][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([3.4823e-05, 3.1163e-06, 9.4637e-01, 1.5165e-05, 5.3319e-02, 8.7454e-05,
        2.9112e-05, 1.4056e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,679][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0882, 0.2104, 0.4409, 0.0545, 0.0294, 0.0825, 0.0321, 0.0621],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,681][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.3796, 0.0239, 0.4338, 0.0088, 0.0425, 0.0492, 0.0249, 0.0372],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,682][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0321, 0.0638, 0.4298, 0.0325, 0.2253, 0.0531, 0.0572, 0.1063],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,683][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([9.1439e-05, 2.9974e-01, 6.4984e-01, 7.9069e-03, 5.8410e-03, 6.1684e-03,
        1.2138e-02, 1.8267e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,684][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([1.2235e-04, 6.3855e-04, 8.9235e-01, 1.3874e-03, 9.7915e-02, 1.1267e-03,
        1.4756e-03, 4.9853e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,685][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([1.9412e-10, 5.7759e-02, 5.2917e-07, 9.4194e-01, 1.1783e-05, 1.0898e-04,
        1.7251e-04, 6.8423e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,686][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0014, 0.1189, 0.1346, 0.0830, 0.1312, 0.1107, 0.0891, 0.1265, 0.2046],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,687][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([7.0766e-05, 8.6797e-02, 7.0293e-04, 8.5469e-01, 7.5612e-03, 1.2866e-02,
        3.3955e-02, 1.2638e-03, 2.0890e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,688][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0053, 0.2266, 0.0231, 0.2779, 0.0558, 0.1221, 0.1509, 0.0991, 0.0391],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,690][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0142, 0.1350, 0.2757, 0.0618, 0.0993, 0.0741, 0.0842, 0.1097, 0.1461],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,691][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0275, 0.1972, 0.3240, 0.0630, 0.0768, 0.0248, 0.0320, 0.0849, 0.1699],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,692][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.4740e-05, 5.3843e-06, 9.5027e-01, 2.1061e-05, 4.8939e-02, 1.0241e-04,
        5.6967e-05, 2.2479e-04, 2.8502e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,693][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0669, 0.1070, 0.3785, 0.0345, 0.0346, 0.1112, 0.0454, 0.0831, 0.1388],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,695][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.2992, 0.0251, 0.4117, 0.0084, 0.0472, 0.0411, 0.0241, 0.0245, 0.1186],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,696][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0359, 0.0629, 0.3864, 0.0263, 0.2046, 0.0487, 0.0673, 0.0738, 0.0940],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,697][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([1.2093e-04, 3.4340e-01, 5.5843e-01, 9.8767e-03, 5.9539e-03, 6.3575e-03,
        1.4028e-02, 2.4837e-02, 3.6999e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,698][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([3.6553e-04, 1.2947e-03, 8.7769e-01, 1.9326e-03, 9.9834e-02, 1.4922e-03,
        2.7943e-03, 5.4674e-03, 9.1290e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,699][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.1138e-09, 9.6428e-02, 2.1396e-06, 9.0306e-01, 2.8980e-05, 1.8473e-04,
        2.7920e-04, 9.6957e-06, 3.3415e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,700][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0023, 0.1379, 0.0944, 0.0944, 0.0968, 0.1099, 0.0982, 0.1078, 0.1448,
        0.1135], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,702][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0007, 0.0775, 0.0036, 0.2777, 0.0132, 0.0115, 0.0217, 0.0026, 0.0036,
        0.5879], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,703][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0031, 0.2049, 0.0303, 0.2369, 0.0451, 0.0695, 0.0888, 0.0743, 0.0343,
        0.2129], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,704][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0263, 0.0924, 0.4039, 0.0437, 0.1211, 0.0433, 0.0544, 0.0722, 0.0995,
        0.0432], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,706][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0073, 0.0309, 0.6863, 0.0233, 0.0488, 0.0188, 0.0198, 0.0391, 0.0941,
        0.0316], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,707][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([5.4046e-05, 5.0916e-06, 9.4819e-01, 1.8714e-05, 5.0797e-02, 1.0405e-04,
        3.3532e-05, 1.7280e-04, 3.6466e-04, 2.6252e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,708][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1127, 0.1696, 0.3537, 0.0430, 0.0260, 0.0763, 0.0455, 0.0573, 0.0744,
        0.0416], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,709][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7789, 0.0125, 0.1329, 0.0031, 0.0110, 0.0089, 0.0076, 0.0101, 0.0298,
        0.0052], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,711][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1502, 0.0634, 0.4926, 0.0128, 0.1185, 0.0179, 0.0240, 0.0406, 0.0534,
        0.0268], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,712][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.1396e-05, 6.7558e-02, 8.6379e-01, 2.2040e-03, 6.7427e-03, 3.6657e-03,
        5.7447e-03, 1.3407e-02, 3.3142e-02, 3.6512e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,713][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.5193e-04, 2.6445e-03, 9.2208e-01, 2.3124e-03, 5.8439e-02, 1.0765e-03,
        1.4395e-03, 4.1245e-03, 6.5607e-03, 1.0743e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,714][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.0191e-06, 3.5170e-01, 2.0441e-03, 5.5763e-01, 2.9210e-03, 6.4370e-03,
        9.9057e-03, 1.1444e-03, 7.0533e-04, 6.7514e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,715][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0019, 0.1326, 0.0783, 0.0919, 0.0833, 0.1047, 0.0878, 0.0974, 0.1131,
        0.1127, 0.0964], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,716][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0010, 0.0441, 0.0047, 0.1484, 0.0139, 0.0112, 0.0174, 0.0028, 0.0038,
        0.2827, 0.4699], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,717][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0027, 0.1411, 0.0221, 0.1798, 0.0355, 0.0557, 0.0729, 0.0632, 0.0314,
        0.1592, 0.2362], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,717][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0346, 0.0641, 0.4505, 0.0326, 0.1211, 0.0381, 0.0470, 0.0710, 0.0930,
        0.0308, 0.0173], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,718][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0070, 0.0242, 0.6592, 0.0223, 0.0462, 0.0171, 0.0181, 0.0442, 0.1119,
        0.0296, 0.0203], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,718][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([2.2340e-05, 3.5910e-06, 9.4104e-01, 1.7757e-05, 5.7921e-02, 1.1504e-04,
        3.0565e-05, 1.7132e-04, 3.6102e-04, 2.7294e-04, 3.9725e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,719][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0380, 0.1896, 0.3104, 0.0662, 0.0293, 0.0837, 0.0635, 0.0586, 0.0592,
        0.0656, 0.0359], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,719][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8687, 0.0077, 0.0749, 0.0019, 0.0058, 0.0046, 0.0050, 0.0069, 0.0193,
        0.0037, 0.0016], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,719][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2266, 0.0285, 0.4911, 0.0063, 0.1007, 0.0153, 0.0184, 0.0344, 0.0556,
        0.0140, 0.0091], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,720][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.5538e-05, 4.4985e-02, 8.8837e-01, 1.4795e-03, 6.6324e-03, 3.3445e-03,
        4.0202e-03, 1.1261e-02, 3.6121e-02, 2.8224e-03, 9.2249e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,721][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.1420e-04, 1.8999e-03, 9.3161e-01, 1.6888e-03, 5.0041e-02, 1.0900e-03,
        1.1637e-03, 3.9685e-03, 6.7162e-03, 7.9098e-04, 7.2027e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,721][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.6733e-06, 3.0762e-01, 6.5797e-03, 4.8006e-01, 5.1947e-03, 1.4521e-02,
        2.0890e-02, 2.7538e-03, 2.4622e-03, 7.6797e-02, 8.3124e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,723][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0012, 0.0971, 0.0807, 0.0591, 0.1081, 0.0932, 0.0692, 0.0975, 0.1417,
        0.0757, 0.0605, 0.1160], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,724][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.6086e-05, 1.1690e-02, 8.9882e-05, 1.1109e-01, 9.1162e-04, 1.7015e-03,
        3.0829e-03, 1.4152e-04, 1.9005e-04, 2.2428e-01, 6.4615e-01, 6.6223e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,725][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0014, 0.1218, 0.0117, 0.1544, 0.0275, 0.0555, 0.0667, 0.0449, 0.0169,
        0.1819, 0.2926, 0.0247], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,726][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0139, 0.1027, 0.2938, 0.0505, 0.0773, 0.0608, 0.0565, 0.1023, 0.0846,
        0.0704, 0.0502, 0.0370], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,728][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0196, 0.1393, 0.2927, 0.0521, 0.0491, 0.0162, 0.0188, 0.0355, 0.0802,
        0.1464, 0.1089, 0.0412], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,729][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([4.1983e-05, 3.1926e-06, 9.5363e-01, 1.9346e-05, 4.4360e-02, 9.1910e-05,
        2.8879e-05, 1.4172e-04, 2.8132e-04, 2.5982e-04, 3.9305e-05, 1.1070e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,730][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0461, 0.1452, 0.3752, 0.0324, 0.0465, 0.0930, 0.0302, 0.0516, 0.0992,
        0.0364, 0.0179, 0.0263], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,732][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1865, 0.0398, 0.4003, 0.0127, 0.0550, 0.0499, 0.0288, 0.0426, 0.0845,
        0.0136, 0.0075, 0.0789], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,733][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0330, 0.0351, 0.3225, 0.0144, 0.1401, 0.0410, 0.0427, 0.0506, 0.0606,
        0.0293, 0.0278, 0.2030], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,734][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([5.8505e-06, 1.6198e-01, 7.6680e-01, 5.7944e-03, 6.2405e-03, 4.3852e-03,
        5.1167e-03, 1.2755e-02, 2.6255e-02, 6.0631e-03, 1.8861e-03, 2.7200e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,735][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([2.5147e-04, 1.4733e-03, 8.6090e-01, 2.4204e-03, 1.1091e-01, 1.8564e-03,
        2.7099e-03, 7.2391e-03, 8.7224e-03, 1.0691e-03, 1.1707e-03, 1.2701e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,736][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([1.0207e-09, 5.9322e-02, 1.6534e-06, 6.3424e-01, 2.3340e-05, 1.3934e-04,
        1.2564e-04, 4.4199e-06, 2.4262e-06, 6.4484e-02, 2.4165e-01, 5.2230e-07],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,737][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0008, 0.1042, 0.0835, 0.0609, 0.0975, 0.0810, 0.0704, 0.0907, 0.1311,
        0.0723, 0.0596, 0.0910, 0.0572], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,738][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([3.6445e-06, 1.0959e-02, 6.9717e-05, 9.9240e-02, 8.1871e-04, 8.1311e-04,
        2.0574e-03, 8.1487e-05, 9.8597e-05, 2.1041e-01, 6.7450e-01, 4.4127e-04,
        5.0705e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,740][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0015, 0.1324, 0.0179, 0.1432, 0.0314, 0.0633, 0.0658, 0.0500, 0.0214,
        0.1636, 0.2589, 0.0304, 0.0201], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,741][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([0.0037, 0.1379, 0.2359, 0.0634, 0.0891, 0.0557, 0.0578, 0.0739, 0.0844,
        0.0676, 0.0550, 0.0638, 0.0117], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,743][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([0.0043, 0.1224, 0.4052, 0.0398, 0.0863, 0.0158, 0.0193, 0.0346, 0.0932,
        0.0739, 0.0605, 0.0360, 0.0087], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,743][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([2.0197e-06, 1.6162e-06, 9.4590e-01, 1.2330e-05, 5.2609e-02, 4.5731e-05,
        1.1924e-05, 1.1683e-04, 1.2796e-04, 1.5796e-04, 2.4196e-05, 9.6564e-04,
        2.6225e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,745][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0739, 0.0993, 0.3417, 0.0278, 0.0399, 0.0951, 0.0496, 0.0693, 0.1258,
        0.0247, 0.0162, 0.0267, 0.0099], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,746][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([0.1881, 0.0117, 0.5686, 0.0036, 0.0577, 0.0287, 0.0163, 0.0161, 0.0521,
        0.0052, 0.0027, 0.0285, 0.0208], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,748][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([0.0152, 0.0548, 0.3679, 0.0165, 0.1510, 0.0280, 0.0403, 0.0502, 0.0641,
        0.0262, 0.0246, 0.1324, 0.0289], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,749][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([2.4052e-07, 2.0646e-02, 9.4566e-01, 1.8386e-03, 7.0821e-03, 1.1552e-03,
        8.8742e-04, 8.6117e-03, 9.9982e-03, 1.6415e-03, 4.9332e-04, 1.9812e-03,
        2.9437e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,750][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([1.4541e-04, 1.1355e-03, 9.0710e-01, 1.3143e-03, 7.7866e-02, 7.7947e-04,
        1.2198e-03, 3.4522e-03, 4.3773e-03, 5.8406e-04, 6.0922e-04, 6.4729e-04,
        7.6501e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,751][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([1.8038e-09, 7.1102e-02, 4.1492e-06, 7.0462e-01, 4.6464e-05, 1.2743e-04,
        1.2927e-04, 8.8993e-06, 2.7362e-06, 5.0394e-02, 1.7356e-01, 8.0615e-07,
        1.1073e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,752][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0018, 0.0841, 0.0855, 0.0551, 0.0812, 0.0723, 0.0665, 0.0725, 0.1128,
        0.0648, 0.0551, 0.0869, 0.0523, 0.1091], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,753][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([2.8129e-05, 2.2272e-02, 2.9534e-04, 1.3996e-01, 2.6573e-03, 2.9551e-03,
        6.3055e-03, 3.6022e-04, 5.2667e-04, 2.3957e-01, 5.7831e-01, 1.5827e-03,
        1.3463e-03, 3.8383e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,754][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0023, 0.1108, 0.0158, 0.1380, 0.0379, 0.0614, 0.0740, 0.0508, 0.0234,
        0.1432, 0.2418, 0.0307, 0.0201, 0.0498], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,756][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0164, 0.0911, 0.3141, 0.0388, 0.0878, 0.0403, 0.0500, 0.0882, 0.0850,
        0.0343, 0.0258, 0.0509, 0.0078, 0.0695], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,757][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0238, 0.0765, 0.4119, 0.0399, 0.0567, 0.0186, 0.0225, 0.0337, 0.0805,
        0.0720, 0.0575, 0.0445, 0.0061, 0.0558], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,758][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([3.8035e-05, 4.6388e-06, 9.4721e-01, 1.6154e-05, 5.0456e-02, 7.4336e-05,
        2.8772e-05, 1.4919e-04, 2.1691e-04, 2.4128e-04, 3.9415e-05, 1.2741e-03,
        5.8918e-05, 1.9579e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,759][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1043, 0.1029, 0.3771, 0.0257, 0.0195, 0.0515, 0.0230, 0.0446, 0.0584,
        0.0162, 0.0113, 0.0259, 0.0038, 0.1359], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,759][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.3256, 0.0199, 0.4016, 0.0049, 0.0366, 0.0232, 0.0154, 0.0176, 0.0578,
        0.0058, 0.0031, 0.0304, 0.0136, 0.0445], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,760][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0572, 0.0408, 0.2723, 0.0125, 0.1369, 0.0314, 0.0429, 0.0474, 0.0559,
        0.0233, 0.0217, 0.1733, 0.0307, 0.0536], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,760][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.2879e-04, 2.1135e-01, 7.0760e-01, 6.8877e-03, 5.1217e-03, 4.0691e-03,
        7.6035e-03, 1.1162e-02, 1.4537e-02, 4.9419e-03, 1.9168e-03, 2.5799e-03,
        1.0108e-05, 2.2092e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,761][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([3.4094e-04, 1.3102e-03, 8.8039e-01, 1.4636e-03, 9.8995e-02, 1.0439e-03,
        1.9212e-03, 3.7274e-03, 5.9986e-03, 6.3830e-04, 6.7810e-04, 7.4195e-04,
        1.0221e-03, 1.7244e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,761][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.8056e-09, 9.0087e-02, 2.0139e-06, 6.2061e-01, 2.3401e-05, 2.2846e-04,
        2.9431e-04, 1.0778e-05, 4.9851e-06, 5.9903e-02, 2.2875e-01, 2.2111e-06,
        1.4040e-06, 9.1089e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,761][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0022, 0.0825, 0.0730, 0.0555, 0.0749, 0.0716, 0.0612, 0.0719, 0.1078,
        0.0618, 0.0543, 0.0815, 0.0552, 0.0878, 0.0587], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,762][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5467e-04, 2.7381e-02, 5.4898e-04, 1.3094e-01, 3.3529e-03, 3.8454e-03,
        7.6029e-03, 4.9040e-04, 7.5767e-04, 2.4501e-01, 5.5076e-01, 2.3570e-03,
        1.6605e-03, 4.0603e-03, 2.1071e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,763][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0020, 0.1180, 0.0136, 0.1536, 0.0270, 0.0485, 0.0583, 0.0450, 0.0192,
        0.1421, 0.2335, 0.0228, 0.0140, 0.0420, 0.0604], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,765][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0347, 0.0998, 0.2965, 0.0362, 0.0772, 0.0381, 0.0530, 0.0598, 0.0838,
        0.0378, 0.0256, 0.0362, 0.0080, 0.0778, 0.0354], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,766][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0306, 0.1382, 0.3680, 0.0437, 0.0306, 0.0136, 0.0184, 0.0283, 0.0783,
        0.0796, 0.0541, 0.0286, 0.0030, 0.0491, 0.0359], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,767][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.1598e-05, 4.0033e-06, 9.3793e-01, 1.9321e-05, 5.9232e-02, 7.8365e-05,
        3.0867e-05, 1.6113e-04, 2.5146e-04, 2.0909e-04, 3.5130e-05, 1.5559e-03,
        1.0224e-04, 2.5883e-04, 7.8838e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,769][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0435, 0.1539, 0.4267, 0.0348, 0.0328, 0.0561, 0.0292, 0.0356, 0.0586,
        0.0243, 0.0130, 0.0161, 0.0055, 0.0531, 0.0168], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,770][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6196, 0.0245, 0.1994, 0.0049, 0.0175, 0.0111, 0.0092, 0.0094, 0.0311,
        0.0067, 0.0036, 0.0169, 0.0072, 0.0185, 0.0206], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,771][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0716, 0.0285, 0.3783, 0.0071, 0.1329, 0.0183, 0.0273, 0.0377, 0.0440,
        0.0140, 0.0113, 0.1466, 0.0222, 0.0375, 0.0226], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,772][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.2802e-03, 1.7854e-01, 7.3061e-01, 5.4759e-03, 6.5565e-03, 1.9740e-03,
        5.0206e-03, 4.6395e-03, 6.2084e-03, 2.7359e-03, 1.3359e-03, 2.2690e-03,
        1.7662e-05, 1.3747e-02, 3.9593e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,773][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.9659e-04, 1.2614e-03, 9.1462e-01, 1.2168e-03, 6.9380e-02, 8.1621e-04,
        1.2880e-03, 2.9307e-03, 4.7066e-03, 5.5030e-04, 5.1641e-04, 5.5258e-04,
        5.5524e-04, 9.3583e-04, 2.7690e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,774][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.5468e-09, 1.1968e-01, 4.6913e-06, 6.7030e-01, 3.2067e-05, 1.5581e-04,
        2.4922e-04, 1.2708e-05, 4.5462e-06, 5.3900e-02, 1.5543e-01, 2.3105e-06,
        1.1341e-06, 5.2763e-05, 1.7978e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:33,835][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:33,836][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,837][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,839][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,840][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,841][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,842][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,844][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,844][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,845][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,845][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,845][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,846][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:33,846][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0085, 0.9915], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,846][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([7.2388e-04, 9.9928e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,847][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1860, 0.8140], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,847][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4383, 0.5617], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,848][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6415, 0.3585], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,849][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2311, 0.7689], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,850][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0123, 0.9877], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,852][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9871, 0.0129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,853][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8388, 0.1612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,854][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0622, 0.9378], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,855][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1199, 0.8801], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,856][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2812, 0.7188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:33,858][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.0180, 0.2631, 0.7189], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,859][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([1.4353e-04, 1.9472e-01, 8.0514e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,860][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.0877, 0.3679, 0.5444], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,861][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.1452, 0.3307, 0.5241], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,863][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([0.4429, 0.0453, 0.5118], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,864][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.0025, 0.8914, 0.1061], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,866][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([0.0067, 0.3294, 0.6638], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,867][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.7452, 0.0042, 0.2506], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,868][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.1217, 0.1036, 0.7747], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,869][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([5.0264e-04, 7.3580e-01, 2.6370e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,871][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.0054, 0.0030, 0.9916], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,872][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([0.0042, 0.2910, 0.7047], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:33,874][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0015, 0.1093, 0.8341, 0.0550], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,874][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.1061e-05, 4.2070e-02, 8.9977e-01, 5.8069e-02], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,876][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3215, 0.1252, 0.4926, 0.0607], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,877][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1750, 0.0779, 0.7013, 0.0458], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,879][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1469, 0.0256, 0.8084, 0.0192], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,880][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0077, 0.4650, 0.5208, 0.0065], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,881][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0045, 0.1163, 0.6934, 0.1859], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,882][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.7137e-01, 2.7851e-03, 2.5149e-02, 7.0057e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,884][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4180, 0.0283, 0.5473, 0.0064], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,885][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.7214e-04, 1.4398e-01, 8.5225e-01, 3.4978e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,886][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0012, 0.0014, 0.9963, 0.0011], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,886][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0875, 0.0931, 0.7882, 0.0312], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:33,887][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0016, 0.1573, 0.6800, 0.0379, 0.1232], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,887][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([4.9885e-05, 5.3318e-02, 6.6237e-01, 6.5873e-02, 2.1839e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,887][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0729, 0.1216, 0.5857, 0.0479, 0.1719], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,888][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0378, 0.2260, 0.4593, 0.1078, 0.1691], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,888][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.1306, 0.0593, 0.7025, 0.0169, 0.0908], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,888][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([2.1206e-04, 4.4264e-01, 5.4553e-01, 7.0194e-03, 4.6007e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,889][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([0.0022, 0.1283, 0.6154, 0.1311, 0.1230], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,889][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.6948, 0.0031, 0.2803, 0.0008, 0.0209], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,890][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0634, 0.0604, 0.6432, 0.0171, 0.2160], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,891][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([2.8849e-05, 1.8489e-01, 8.0864e-01, 3.3763e-03, 3.0689e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,892][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([1.2678e-03, 9.5733e-04, 9.3323e-01, 9.1149e-04, 6.3634e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,893][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0191, 0.0681, 0.6981, 0.0365, 0.1782], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:33,894][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([2.4745e-04, 5.5502e-02, 7.6037e-01, 2.4838e-02, 1.4169e-01, 1.7351e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,895][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.4162e-05, 5.8956e-02, 5.7190e-01, 9.6037e-02, 2.4690e-01, 2.6193e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,897][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0327, 0.1052, 0.3992, 0.1037, 0.2740, 0.0851], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,898][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0128, 0.1527, 0.4650, 0.0795, 0.1925, 0.0976], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,899][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0443, 0.0688, 0.7154, 0.0410, 0.1030, 0.0276], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,900][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([5.2890e-04, 3.8476e-01, 5.9114e-01, 1.1637e-02, 7.4165e-03, 4.5134e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,901][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([5.7862e-04, 5.7818e-02, 6.7045e-01, 9.3788e-02, 1.5021e-01, 2.7158e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,903][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.5642, 0.0145, 0.3461, 0.0040, 0.0346, 0.0366], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,904][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1073, 0.0384, 0.5717, 0.0100, 0.2270, 0.0455], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,905][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([4.0122e-05, 1.0961e-01, 8.7298e-01, 4.7065e-03, 8.2454e-03, 4.4169e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,906][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.7422e-04, 6.3690e-04, 9.1723e-01, 8.5855e-04, 8.0274e-02, 8.2662e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,907][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0044, 0.0995, 0.5011, 0.0695, 0.2111, 0.1143], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:33,908][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([4.1201e-04, 6.2863e-02, 6.9556e-01, 2.9144e-02, 1.6440e-01, 1.7513e-02,
        3.0101e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,909][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.1912e-05, 4.7211e-02, 6.2038e-01, 6.7354e-02, 2.1711e-01, 1.6595e-02,
        3.1331e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,911][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0549, 0.1238, 0.4297, 0.1007, 0.1844, 0.0424, 0.0642],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,912][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0375, 0.1472, 0.4242, 0.0713, 0.1472, 0.0768, 0.0958],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,913][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1029, 0.0697, 0.6684, 0.0310, 0.0775, 0.0235, 0.0270],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,915][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0050, 0.4616, 0.5046, 0.0120, 0.0060, 0.0041, 0.0067],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,916][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0017, 0.0720, 0.6525, 0.1053, 0.1168, 0.0205, 0.0312],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,918][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.7233, 0.0147, 0.2119, 0.0042, 0.0183, 0.0155, 0.0120],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,919][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0847, 0.0443, 0.6251, 0.0122, 0.1575, 0.0321, 0.0441],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,920][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.6119e-04, 1.3411e-01, 8.3716e-01, 5.9413e-03, 1.0244e-02, 5.7954e-03,
        6.3857e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,921][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.8419e-04, 7.8682e-04, 9.2258e-01, 1.0643e-03, 7.3060e-02, 8.7908e-04,
        1.3449e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,923][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0265, 0.1061, 0.5726, 0.0534, 0.1313, 0.0554, 0.0547],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:33,923][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([1.5037e-04, 6.2077e-02, 5.4546e-01, 3.9095e-02, 2.0014e-01, 3.2720e-02,
        4.3429e-02, 7.6934e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,924][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([1.0053e-05, 4.1091e-02, 5.0811e-01, 8.6647e-02, 2.5196e-01, 3.2893e-02,
        5.1950e-02, 2.7339e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,926][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0134, 0.1347, 0.3414, 0.1027, 0.1879, 0.0529, 0.0539, 0.1132],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,927][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0110, 0.1396, 0.3922, 0.0542, 0.1326, 0.0743, 0.0725, 0.1237],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,928][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0373, 0.0267, 0.7027, 0.0193, 0.0931, 0.0273, 0.0292, 0.0644],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,928][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0010, 0.5486, 0.4159, 0.0091, 0.0035, 0.0025, 0.0054, 0.0141],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,929][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([3.5298e-04, 8.6011e-02, 4.1458e-01, 1.8007e-01, 1.5273e-01, 4.3309e-02,
        5.4933e-02, 6.8015e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,929][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.3796, 0.0239, 0.4338, 0.0088, 0.0425, 0.0492, 0.0249, 0.0372],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,929][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0321, 0.0638, 0.4298, 0.0325, 0.2253, 0.0531, 0.0572, 0.1063],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,930][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([9.1439e-05, 2.9974e-01, 6.4984e-01, 7.9069e-03, 5.8410e-03, 6.1684e-03,
        1.2138e-02, 1.8267e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,930][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([1.2235e-04, 6.3855e-04, 8.9235e-01, 1.3874e-03, 9.7915e-02, 1.1267e-03,
        1.4756e-03, 4.9853e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,930][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0007, 0.1384, 0.2141, 0.1422, 0.1308, 0.1078, 0.1024, 0.1636],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:33,931][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0006, 0.0659, 0.5623, 0.0301, 0.1429, 0.0255, 0.0394, 0.0584, 0.0748],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,932][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.7815e-05, 5.1154e-02, 4.8240e-01, 8.1124e-02, 2.2182e-01, 2.4643e-02,
        5.4314e-02, 2.2440e-02, 6.2084e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,932][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0253, 0.1441, 0.2197, 0.1152, 0.1846, 0.0609, 0.0690, 0.1152, 0.0660],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,934][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0142, 0.1350, 0.2757, 0.0618, 0.0993, 0.0741, 0.0842, 0.1097, 0.1461],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,935][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0795, 0.0764, 0.4522, 0.0318, 0.0909, 0.0227, 0.0253, 0.0775, 0.1437],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,937][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0012, 0.5988, 0.3449, 0.0107, 0.0034, 0.0025, 0.0071, 0.0158, 0.0155],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,938][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0008, 0.0757, 0.4799, 0.1278, 0.1438, 0.0300, 0.0438, 0.0525, 0.0456],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,939][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.2992, 0.0251, 0.4117, 0.0084, 0.0472, 0.0411, 0.0241, 0.0245, 0.1186],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,940][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0359, 0.0629, 0.3864, 0.0263, 0.2046, 0.0487, 0.0673, 0.0738, 0.0940],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,941][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.2093e-04, 3.4340e-01, 5.5843e-01, 9.8767e-03, 5.9539e-03, 6.3575e-03,
        1.4028e-02, 2.4837e-02, 3.6999e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,942][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([3.6553e-04, 1.2947e-03, 8.7769e-01, 1.9326e-03, 9.9834e-02, 1.4922e-03,
        2.7943e-03, 5.4674e-03, 9.1290e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,944][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0016, 0.1213, 0.3146, 0.0817, 0.1432, 0.0908, 0.0888, 0.1130, 0.0449],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:33,945][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.1573e-04, 9.5109e-02, 5.9395e-01, 3.5232e-02, 1.3022e-01, 1.9580e-02,
        2.3292e-02, 4.8182e-02, 3.8188e-02, 1.6036e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,946][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.0665e-05, 5.6096e-02, 6.0843e-01, 6.5903e-02, 1.4278e-01, 1.2735e-02,
        2.3340e-02, 2.0148e-02, 4.0233e-02, 3.0314e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,947][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0499, 0.1353, 0.3531, 0.0825, 0.1045, 0.0268, 0.0385, 0.0917, 0.0592,
        0.0586], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,949][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0263, 0.0924, 0.4039, 0.0437, 0.1211, 0.0433, 0.0544, 0.0722, 0.0995,
        0.0432], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,950][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0199, 0.0132, 0.7500, 0.0120, 0.0525, 0.0157, 0.0145, 0.0339, 0.0749,
        0.0135], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,951][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0022, 0.4090, 0.5045, 0.0065, 0.0041, 0.0033, 0.0051, 0.0212, 0.0307,
        0.0133], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,953][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0009, 0.1284, 0.4074, 0.1720, 0.0907, 0.0230, 0.0261, 0.0450, 0.0427,
        0.0638], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,954][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7789, 0.0125, 0.1329, 0.0031, 0.0110, 0.0089, 0.0076, 0.0101, 0.0298,
        0.0052], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,956][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1502, 0.0634, 0.4926, 0.0128, 0.1185, 0.0179, 0.0240, 0.0406, 0.0534,
        0.0268], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,957][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.1396e-05, 6.7558e-02, 8.6379e-01, 2.2040e-03, 6.7427e-03, 3.6657e-03,
        5.7447e-03, 1.3407e-02, 3.3142e-02, 3.6512e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,958][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.5193e-04, 2.6445e-03, 9.2208e-01, 2.3124e-03, 5.8439e-02, 1.0765e-03,
        1.4395e-03, 4.1245e-03, 6.5607e-03, 1.0743e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,959][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0392, 0.0735, 0.6054, 0.0253, 0.0793, 0.0386, 0.0324, 0.0602, 0.0366,
        0.0096], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:33,960][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.2620e-04, 7.7268e-02, 5.9492e-01, 3.3094e-02, 1.2049e-01, 2.2123e-02,
        2.4603e-02, 5.3561e-02, 4.7622e-02, 1.4830e-02, 1.1258e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,961][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3622e-05, 3.2961e-02, 6.4682e-01, 4.4149e-02, 1.4841e-01, 1.3815e-02,
        2.0547e-02, 2.0171e-02, 3.9258e-02, 1.8985e-02, 1.4859e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,962][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0809, 0.0986, 0.3224, 0.0642, 0.0963, 0.0254, 0.0407, 0.1095, 0.0737,
        0.0475, 0.0409], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,964][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0346, 0.0641, 0.4505, 0.0326, 0.1211, 0.0381, 0.0470, 0.0710, 0.0930,
        0.0308, 0.0173], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,965][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0197, 0.0102, 0.7373, 0.0112, 0.0502, 0.0143, 0.0131, 0.0371, 0.0868,
        0.0123, 0.0079], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,967][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0014, 0.3182, 0.5977, 0.0055, 0.0047, 0.0029, 0.0041, 0.0193, 0.0308,
        0.0122, 0.0033], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,968][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0012, 0.0891, 0.4322, 0.1401, 0.0938, 0.0237, 0.0253, 0.0427, 0.0408,
        0.0535, 0.0574], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,970][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8687, 0.0077, 0.0749, 0.0019, 0.0058, 0.0046, 0.0050, 0.0069, 0.0193,
        0.0037, 0.0016], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,970][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2266, 0.0285, 0.4911, 0.0063, 0.1007, 0.0153, 0.0184, 0.0344, 0.0556,
        0.0140, 0.0091], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,971][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.5538e-05, 4.4985e-02, 8.8837e-01, 1.4795e-03, 6.6324e-03, 3.3445e-03,
        4.0202e-03, 1.1261e-02, 3.6121e-02, 2.8224e-03, 9.2249e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,971][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.1420e-04, 1.8999e-03, 9.3161e-01, 1.6888e-03, 5.0041e-02, 1.0900e-03,
        1.1637e-03, 3.9685e-03, 6.7162e-03, 7.9098e-04, 7.2027e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,971][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0547, 0.0412, 0.6528, 0.0150, 0.0605, 0.0362, 0.0297, 0.0554, 0.0447,
        0.0068, 0.0031], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:33,972][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([2.6986e-04, 8.8584e-02, 4.7696e-01, 4.3127e-02, 1.6014e-01, 2.8122e-02,
        3.0564e-02, 4.3825e-02, 4.8302e-02, 2.7619e-02, 2.4280e-02, 2.8204e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,972][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.1004e-05, 4.5229e-02, 4.0818e-01, 8.7029e-02, 2.0017e-01, 2.8247e-02,
        3.5418e-02, 1.7971e-02, 3.4369e-02, 4.4210e-02, 4.5257e-02, 5.3917e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,973][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0090, 0.1053, 0.1800, 0.0965, 0.1399, 0.0440, 0.0530, 0.0938, 0.0391,
        0.0934, 0.1055, 0.0405], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,973][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0139, 0.1027, 0.2938, 0.0505, 0.0773, 0.0608, 0.0565, 0.1023, 0.0846,
        0.0704, 0.0502, 0.0370], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,974][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0600, 0.0660, 0.4536, 0.0311, 0.0692, 0.0175, 0.0180, 0.0397, 0.0847,
        0.0663, 0.0467, 0.0472], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,975][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([1.5454e-04, 3.5612e-01, 5.6111e-01, 9.0952e-03, 5.4841e-03, 2.8243e-03,
        4.7338e-03, 1.4480e-02, 2.2811e-02, 1.5016e-02, 5.2482e-03, 2.9157e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,977][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0873, 0.2333, 0.1803, 0.1113, 0.0319, 0.0339, 0.0483, 0.0306,
        0.0768, 0.0970, 0.0691], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,978][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1865, 0.0398, 0.4003, 0.0127, 0.0550, 0.0499, 0.0288, 0.0426, 0.0845,
        0.0136, 0.0075, 0.0789], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,980][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0330, 0.0351, 0.3225, 0.0144, 0.1401, 0.0410, 0.0427, 0.0506, 0.0606,
        0.0293, 0.0278, 0.2030], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,980][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([5.8505e-06, 1.6198e-01, 7.6680e-01, 5.7944e-03, 6.2405e-03, 4.3852e-03,
        5.1167e-03, 1.2755e-02, 2.6255e-02, 6.0631e-03, 1.8861e-03, 2.7200e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,981][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([2.5147e-04, 1.4733e-03, 8.6090e-01, 2.4204e-03, 1.1091e-01, 1.8564e-03,
        2.7099e-03, 7.2391e-03, 8.7224e-03, 1.0691e-03, 1.1707e-03, 1.2701e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,983][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.0887, 0.2648, 0.0652, 0.1563, 0.0934, 0.0697, 0.0882, 0.0486,
        0.0348, 0.0240, 0.0659], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:33,984][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([1.0641e-04, 7.6186e-02, 6.3353e-01, 2.4851e-02, 1.2908e-01, 1.2316e-02,
        1.9085e-02, 2.7216e-02, 3.6184e-02, 1.3292e-02, 1.0681e-02, 1.4706e-02,
        2.7710e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,985][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([6.5425e-06, 5.4731e-02, 4.7943e-01, 7.4655e-02, 2.0192e-01, 1.2485e-02,
        1.9555e-02, 1.2707e-02, 2.4258e-02, 3.3900e-02, 3.6743e-02, 4.1295e-02,
        8.3157e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,986][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([0.0114, 0.0933, 0.3403, 0.0575, 0.1455, 0.0383, 0.0371, 0.0757, 0.0432,
        0.0438, 0.0534, 0.0365, 0.0238], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,988][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([0.0037, 0.1379, 0.2359, 0.0634, 0.0891, 0.0557, 0.0578, 0.0739, 0.0844,
        0.0676, 0.0550, 0.0638, 0.0117], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,989][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([0.0133, 0.0533, 0.5396, 0.0229, 0.1025, 0.0160, 0.0171, 0.0363, 0.0894,
        0.0341, 0.0261, 0.0385, 0.0106], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,990][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([4.4573e-06, 1.0291e-01, 8.2970e-01, 6.0475e-03, 1.0694e-02, 1.5344e-03,
        1.8090e-03, 1.5248e-02, 1.4315e-02, 1.0336e-02, 3.6805e-03, 3.6970e-03,
        1.9888e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,991][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([2.5069e-04, 8.2191e-02, 4.7331e-01, 9.9588e-02, 1.0827e-01, 2.1397e-02,
        2.5989e-02, 2.6617e-02, 2.8142e-02, 3.6917e-02, 4.6039e-02, 4.3819e-02,
        7.4709e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,993][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([0.1881, 0.0117, 0.5686, 0.0036, 0.0577, 0.0287, 0.0163, 0.0161, 0.0521,
        0.0052, 0.0027, 0.0285, 0.0208], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,994][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0152, 0.0548, 0.3679, 0.0165, 0.1510, 0.0280, 0.0403, 0.0502, 0.0641,
        0.0262, 0.0246, 0.1324, 0.0289], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,995][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([2.4052e-07, 2.0646e-02, 9.4566e-01, 1.8386e-03, 7.0821e-03, 1.1552e-03,
        8.8742e-04, 8.6117e-03, 9.9982e-03, 1.6415e-03, 4.9332e-04, 1.9812e-03,
        2.9437e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,996][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([1.4541e-04, 1.1355e-03, 9.0710e-01, 1.3143e-03, 7.7866e-02, 7.7947e-04,
        1.2198e-03, 3.4522e-03, 4.3773e-03, 5.8406e-04, 6.0922e-04, 6.4729e-04,
        7.6501e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,997][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([0.0020, 0.0777, 0.3994, 0.0513, 0.1499, 0.0492, 0.0424, 0.0894, 0.0326,
        0.0193, 0.0123, 0.0565, 0.0179], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:33,998][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([3.1748e-04, 5.0945e-02, 5.8111e-01, 2.5764e-02, 1.4600e-01, 1.7369e-02,
        2.6075e-02, 4.1245e-02, 4.1972e-02, 1.3630e-02, 1.0378e-02, 2.0921e-02,
        4.0194e-03, 2.0251e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:33,999][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([2.0311e-05, 5.6276e-02, 4.7363e-01, 5.7886e-02, 1.9063e-01, 1.5728e-02,
        2.5780e-02, 1.5838e-02, 3.9407e-02, 2.5214e-02, 2.2695e-02, 5.6938e-02,
        8.0000e-03, 1.1964e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,001][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0344, 0.0840, 0.2376, 0.0591, 0.1844, 0.0389, 0.0493, 0.0679, 0.0521,
        0.0422, 0.0509, 0.0390, 0.0250, 0.0351], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,002][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0164, 0.0911, 0.3141, 0.0388, 0.0878, 0.0403, 0.0500, 0.0882, 0.0850,
        0.0343, 0.0258, 0.0509, 0.0078, 0.0695], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,004][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0553, 0.0356, 0.5230, 0.0222, 0.0683, 0.0174, 0.0185, 0.0329, 0.0732,
        0.0317, 0.0238, 0.0433, 0.0074, 0.0475], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,005][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2533e-03, 5.3194e-01, 4.0425e-01, 8.1650e-03, 3.1573e-03, 1.8734e-03,
        3.8334e-03, 7.9630e-03, 9.7031e-03, 1.0715e-02, 4.2684e-03, 1.8080e-03,
        1.6111e-05, 1.1060e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,006][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0007, 0.0455, 0.5137, 0.0640, 0.1472, 0.0190, 0.0214, 0.0266, 0.0288,
        0.0228, 0.0236, 0.0472, 0.0080, 0.0313], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,008][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.3256, 0.0199, 0.4016, 0.0049, 0.0366, 0.0232, 0.0154, 0.0176, 0.0578,
        0.0058, 0.0031, 0.0304, 0.0136, 0.0445], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,009][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0572, 0.0408, 0.2723, 0.0125, 0.1369, 0.0314, 0.0429, 0.0474, 0.0559,
        0.0233, 0.0217, 0.1733, 0.0307, 0.0536], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,010][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.2879e-04, 2.1135e-01, 7.0760e-01, 6.8877e-03, 5.1217e-03, 4.0691e-03,
        7.6035e-03, 1.1162e-02, 1.4537e-02, 4.9419e-03, 1.9168e-03, 2.5799e-03,
        1.0108e-05, 2.2092e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,011][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([3.4094e-04, 1.3102e-03, 8.8039e-01, 1.4636e-03, 9.8995e-02, 1.0439e-03,
        1.9212e-03, 3.7274e-03, 5.9986e-03, 6.3830e-04, 6.7810e-04, 7.4195e-04,
        1.0221e-03, 1.7244e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,012][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0038, 0.1065, 0.2499, 0.0615, 0.0953, 0.0781, 0.0704, 0.0914, 0.0492,
        0.0256, 0.0178, 0.1032, 0.0183, 0.0289], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,012][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.4253e-04, 6.4393e-02, 6.1138e-01, 2.3644e-02, 1.2081e-01, 1.4437e-02,
        2.4153e-02, 3.8649e-02, 3.4220e-02, 1.1278e-02, 7.7504e-03, 1.6472e-02,
        2.4852e-03, 1.4640e-02, 1.5148e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,013][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.6961e-05, 4.4274e-02, 5.4012e-01, 4.5554e-02, 1.6293e-01, 1.4110e-02,
        2.5630e-02, 1.1466e-02, 3.3326e-02, 2.1952e-02, 1.8421e-02, 5.4090e-02,
        5.7405e-03, 8.3505e-03, 1.4015e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,013][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0620, 0.1047, 0.2711, 0.0657, 0.1092, 0.0268, 0.0378, 0.0697, 0.0416,
        0.0471, 0.0494, 0.0351, 0.0143, 0.0282, 0.0375], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,014][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0347, 0.0998, 0.2965, 0.0362, 0.0772, 0.0381, 0.0530, 0.0598, 0.0838,
        0.0378, 0.0256, 0.0362, 0.0080, 0.0778, 0.0354], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,014][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0837, 0.0540, 0.4986, 0.0237, 0.0421, 0.0138, 0.0160, 0.0297, 0.0761,
        0.0343, 0.0220, 0.0308, 0.0041, 0.0439, 0.0271], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,015][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.9461e-02, 4.3478e-01, 4.7299e-01, 7.1839e-03, 3.6843e-03, 1.1306e-03,
        3.3539e-03, 6.0454e-03, 6.4769e-03, 7.9527e-03, 3.1569e-03, 2.3117e-03,
        2.6974e-05, 1.1986e-02, 1.9459e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,015][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0013, 0.0779, 0.4760, 0.1004, 0.0957, 0.0176, 0.0254, 0.0281, 0.0263,
        0.0310, 0.0289, 0.0471, 0.0047, 0.0236, 0.0160], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,017][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.6196, 0.0245, 0.1994, 0.0049, 0.0175, 0.0111, 0.0092, 0.0094, 0.0311,
        0.0067, 0.0036, 0.0169, 0.0072, 0.0185, 0.0206], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,018][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0716, 0.0285, 0.3783, 0.0071, 0.1329, 0.0183, 0.0273, 0.0377, 0.0440,
        0.0140, 0.0113, 0.1466, 0.0222, 0.0375, 0.0226], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,019][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.2802e-03, 1.7854e-01, 7.3061e-01, 5.4759e-03, 6.5565e-03, 1.9740e-03,
        5.0206e-03, 4.6395e-03, 6.2084e-03, 2.7359e-03, 1.3359e-03, 2.2690e-03,
        1.7662e-05, 1.3747e-02, 3.9593e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,020][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.9659e-04, 1.2614e-03, 9.1462e-01, 1.2168e-03, 6.9380e-02, 8.1621e-04,
        1.2880e-03, 2.9307e-03, 4.7066e-03, 5.5030e-04, 5.1641e-04, 5.5258e-04,
        5.5524e-04, 9.3583e-04, 2.7690e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,021][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0175, 0.0913, 0.4404, 0.0419, 0.0872, 0.0365, 0.0354, 0.0709, 0.0314,
        0.0158, 0.0088, 0.0808, 0.0109, 0.0122, 0.0191], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,023][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:34,024][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[22517],
        [  345],
        [ 6088],
        [  766],
        [  574],
        [  174],
        [  103],
        [  115],
        [  172],
        [  453],
        [  251],
        [  314],
        [  260],
        [   66],
        [  122]], device='cuda:0')
[2024-07-24 10:25:34,026][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17298],
        [ 1149],
        [ 6410],
        [  824],
        [  783],
        [  216],
        [  142],
        [  229],
        [  332],
        [  573],
        [  273],
        [  412],
        [  557],
        [  136],
        [  161]], device='cuda:0')
[2024-07-24 10:25:34,027][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[48011],
        [46686],
        [  750],
        [ 3884],
        [ 9139],
        [ 9388],
        [ 8300],
        [ 8028],
        [ 5772],
        [ 9514],
        [10472],
        [12182],
        [12767],
        [10987],
        [11589]], device='cuda:0')
[2024-07-24 10:25:34,029][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15282],
        [15298],
        [15391],
        [14161],
        [13645],
        [13542],
        [13534],
        [13520],
        [13525],
        [12970],
        [13561],
        [13738],
        [13777],
        [13654],
        [13732]], device='cuda:0')
[2024-07-24 10:25:34,030][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6077],
        [ 9940],
        [14286],
        [11199],
        [14933],
        [10882],
        [ 8427],
        [ 6349],
        [ 5419],
        [ 7079],
        [ 5910],
        [ 5369],
        [ 6011],
        [ 5284],
        [ 5302]], device='cuda:0')
[2024-07-24 10:25:34,032][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[20433],
        [23577],
        [35095],
        [38471],
        [33534],
        [32685],
        [30726],
        [29078],
        [24908],
        [29412],
        [30676],
        [25601],
        [23996],
        [25805],
        [25796]], device='cuda:0')
[2024-07-24 10:25:34,033][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 8754],
        [26762],
        [12030],
        [12201],
        [13364],
        [14402],
        [14616],
        [12464],
        [15083],
        [12144],
        [12517],
        [21385],
        [17261],
        [16743],
        [18128]], device='cuda:0')
[2024-07-24 10:25:34,035][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19070],
        [ 8587],
        [23445],
        [23477],
        [23232],
        [22985],
        [22770],
        [22868],
        [22902],
        [22879],
        [22806],
        [22921],
        [22854],
        [22857],
        [22761]], device='cuda:0')
[2024-07-24 10:25:34,036][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24988],
        [ 1667],
        [  517],
        [  411],
        [  407],
        [  519],
        [  437],
        [  503],
        [  519],
        [  527],
        [  615],
        [  526],
        [  542],
        [  472],
        [  472]], device='cuda:0')
[2024-07-24 10:25:34,037][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31935],
        [31284],
        [  737],
        [23909],
        [  603],
        [  517],
        [ 1632],
        [  556],
        [ 1814],
        [ 6774],
        [13846],
        [ 2709],
        [  512],
        [ 1423],
        [ 4664]], device='cuda:0')
[2024-07-24 10:25:34,039][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22188],
        [23219],
        [47075],
        [46795],
        [47019],
        [46945],
        [46933],
        [46712],
        [46921],
        [47137],
        [47295],
        [47148],
        [47045],
        [46794],
        [47200]], device='cuda:0')
[2024-07-24 10:25:34,040][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30491],
        [ 6332],
        [ 9270],
        [22242],
        [21271],
        [22650],
        [21924],
        [17533],
        [15251],
        [22419],
        [22966],
        [20142],
        [24223],
        [18872],
        [19442]], device='cuda:0')
[2024-07-24 10:25:34,042][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[45903],
        [12058],
        [50135],
        [50135],
        [50097],
        [50085],
        [50089],
        [50067],
        [50057],
        [50087],
        [50095],
        [50034],
        [50078],
        [50059],
        [50082]], device='cuda:0')
[2024-07-24 10:25:34,043][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30722],
        [14866],
        [14867],
        [10350],
        [ 8293],
        [ 8088],
        [ 8326],
        [ 7867],
        [ 8052],
        [ 9829],
        [ 9807],
        [ 8120],
        [ 8081],
        [ 8256],
        [ 8365]], device='cuda:0')
[2024-07-24 10:25:34,045][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[32719],
        [38584],
        [30016],
        [37560],
        [25522],
        [32518],
        [28396],
        [31511],
        [28251],
        [33066],
        [29487],
        [32572],
        [22355],
        [26162],
        [29919]], device='cuda:0')
[2024-07-24 10:25:34,046][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13459],
        [25426],
        [29694],
        [30014],
        [27846],
        [27869],
        [27497],
        [26659],
        [27233],
        [27584],
        [27715],
        [26188],
        [27525],
        [26905],
        [27696]], device='cuda:0')
[2024-07-24 10:25:34,047][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41702],
        [31288],
        [47153],
        [47590],
        [46090],
        [45366],
        [45622],
        [44049],
        [43360],
        [44992],
        [45299],
        [41888],
        [43397],
        [43116],
        [43990]], device='cuda:0')
[2024-07-24 10:25:34,049][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[41786],
        [40800],
        [30984],
        [29782],
        [30653],
        [31522],
        [31382],
        [32468],
        [32303],
        [31419],
        [31283],
        [30545],
        [31305],
        [31845],
        [31222]], device='cuda:0')
[2024-07-24 10:25:34,050][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[35374],
        [33952],
        [29797],
        [27881],
        [29229],
        [30225],
        [30836],
        [31326],
        [33201],
        [31598],
        [31050],
        [32814],
        [33094],
        [31996],
        [31990]], device='cuda:0')
[2024-07-24 10:25:34,052][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[35589],
        [19393],
        [43588],
        [43881],
        [42480],
        [41187],
        [41249],
        [41521],
        [35517],
        [42038],
        [41767],
        [32526],
        [36218],
        [36800],
        [36077]], device='cuda:0')
[2024-07-24 10:25:34,053][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[37503],
        [40281],
        [39026],
        [32678],
        [32171],
        [31154],
        [32631],
        [34286],
        [35256],
        [32078],
        [30347],
        [31020],
        [25630],
        [34220],
        [32791]], device='cuda:0')
[2024-07-24 10:25:34,054][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10705],
        [ 5472],
        [ 7886],
        [ 7312],
        [ 7676],
        [ 8958],
        [ 8300],
        [ 6671],
        [ 7046],
        [ 5603],
        [ 5696],
        [ 4888],
        [ 6425],
        [ 7546],
        [ 6375]], device='cuda:0')
[2024-07-24 10:25:34,056][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[29303],
        [29220],
        [36279],
        [30544],
        [37027],
        [35635],
        [35568],
        [33593],
        [32062],
        [33071],
        [31834],
        [31219],
        [33359],
        [33048],
        [33515]], device='cuda:0')
[2024-07-24 10:25:34,057][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[37227],
        [26474],
        [11089],
        [12904],
        [12977],
        [13757],
        [13283],
        [16125],
        [16703],
        [15056],
        [14956],
        [16756],
        [16378],
        [16885],
        [15593]], device='cuda:0')
[2024-07-24 10:25:34,058][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[41890],
        [26518],
        [28275],
        [33553],
        [33256],
        [33519],
        [33336],
        [32157],
        [31476],
        [33583],
        [33652],
        [32953],
        [33697],
        [32309],
        [31991]], device='cuda:0')
[2024-07-24 10:25:34,059][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38288],
        [15314],
        [39502],
        [39487],
        [39198],
        [39121],
        [39141],
        [39062],
        [39012],
        [39184],
        [39223],
        [38942],
        [39110],
        [39040],
        [39148]], device='cuda:0')
[2024-07-24 10:25:34,060][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22517],
        [32292],
        [30416],
        [28692],
        [28642],
        [29250],
        [29221],
        [34071],
        [32149],
        [29169],
        [28459],
        [32688],
        [30707],
        [33535],
        [30533]], device='cuda:0')
[2024-07-24 10:25:34,061][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6214],
        [11605],
        [ 5557],
        [ 6839],
        [ 6842],
        [ 7101],
        [ 6886],
        [ 6498],
        [ 7545],
        [ 7490],
        [ 7970],
        [ 9580],
        [ 9035],
        [ 7151],
        [ 8017]], device='cuda:0')
[2024-07-24 10:25:34,063][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12792],
        [ 7106],
        [ 6377],
        [ 3453],
        [ 8473],
        [ 6083],
        [ 8902],
        [ 6977],
        [ 4750],
        [ 4971],
        [ 6449],
        [ 4978],
        [ 5974],
        [ 5468],
        [ 6058]], device='cuda:0')
[2024-07-24 10:25:34,064][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775],
        [29775]], device='cuda:0')
[2024-07-24 10:25:34,128][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:34,129][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,131][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,132][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,133][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,134][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,135][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,136][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,137][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,139][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,140][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,141][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,141][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,142][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3528, 0.6472], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,142][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8182, 0.1818], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,142][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0092, 0.9908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,143][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,143][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([6.5896e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,143][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4776, 0.5224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,144][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0324, 0.9676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,144][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6939, 0.3061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,145][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,146][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9468, 0.0532], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,147][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.9912e-01, 8.7851e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,148][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9959e-01, 4.1068e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,149][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Christina] are: tensor([0.2358, 0.1117, 0.6525], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,150][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Christina] are: tensor([0.9314, 0.0051, 0.0634], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,152][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Christina] are: tensor([0.0123, 0.8136, 0.1740], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,153][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Christina] are: tensor([0.0020, 0.0068, 0.9912], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,154][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Christina] are: tensor([2.5983e-04, 3.5603e-01, 6.4371e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,155][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Christina] are: tensor([0.0106, 0.0106, 0.9788], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,157][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Christina] are: tensor([0.7729, 0.0155, 0.2115], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,158][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Christina] are: tensor([0.3181, 0.0016, 0.6803], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,159][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Christina] are: tensor([0.9684, 0.0016, 0.0300], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,161][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Christina] are: tensor([0.6692, 0.0085, 0.3223], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,162][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Christina] are: tensor([0.9691, 0.0025, 0.0284], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,163][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Christina] are: tensor([6.3498e-01, 5.4903e-04, 3.6447e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,164][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0461, 0.0582, 0.8859, 0.0097], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,166][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5123, 0.0111, 0.4729, 0.0037], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,167][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([6.3675e-04, 9.8779e-02, 8.2770e-03, 8.9231e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,168][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.1707e-04, 1.1517e-02, 9.8351e-01, 4.7535e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,168][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([4.5289e-05, 2.6004e-01, 4.7013e-01, 2.6978e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,169][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([4.5628e-03, 2.1790e-03, 9.9256e-01, 6.9875e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,171][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0284, 0.1106, 0.8260, 0.0349], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,172][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.1903e-02, 9.0455e-04, 9.0696e-01, 2.3140e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,173][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9622, 0.0030, 0.0323, 0.0026], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,174][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4707, 0.0018, 0.5267, 0.0008], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,175][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9281e-01, 1.9835e-04, 6.9845e-03, 5.9840e-06], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,176][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.7242e-01, 1.2372e-04, 7.2743e-01, 2.5317e-05], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,177][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0442, 0.0899, 0.7798, 0.0134, 0.0728], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,179][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.5579, 0.0267, 0.3328, 0.0050, 0.0776], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,180][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([0.0012, 0.1011, 0.0234, 0.8012, 0.0731], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,181][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([4.6742e-04, 8.8934e-03, 8.6773e-01, 3.4597e-03, 1.1944e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,182][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([1.0657e-05, 2.5630e-01, 4.3206e-01, 2.3509e-01, 7.6538e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,183][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([0.0015, 0.0092, 0.9278, 0.0038, 0.0576], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,183][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([0.0570, 0.0253, 0.8843, 0.0067, 0.0267], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,184][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([3.3729e-02, 1.4638e-03, 9.6157e-01, 2.3990e-04, 3.0009e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,184][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([9.8246e-01, 6.2887e-04, 7.6158e-03, 5.6682e-04, 8.7285e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,185][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.3354, 0.0080, 0.6182, 0.0017, 0.0367], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,185][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([8.3099e-01, 7.8288e-04, 1.6765e-01, 1.3348e-05, 5.6294e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,185][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([4.6241e-02, 2.2179e-04, 9.5243e-01, 7.0858e-05, 1.0395e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,186][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0126, 0.0626, 0.7970, 0.0094, 0.0927, 0.0257], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,186][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0594, 0.0134, 0.6935, 0.0051, 0.2076, 0.0211], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,186][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([5.9298e-04, 6.4359e-02, 2.3254e-02, 7.8197e-01, 9.3298e-02, 3.6529e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,187][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([5.2377e-05, 9.8990e-03, 8.5117e-01, 2.3962e-03, 1.3011e-01, 6.3692e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,188][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([6.3059e-06, 1.5103e-01, 4.5445e-01, 2.5322e-01, 1.1294e-01, 2.8357e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,189][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([5.1624e-04, 2.7738e-03, 9.1724e-01, 1.2574e-03, 6.9553e-02, 8.6587e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,190][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0330, 0.0508, 0.7999, 0.0196, 0.0442, 0.0526], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,191][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([5.2881e-03, 5.3388e-04, 9.8203e-01, 2.8229e-04, 8.9816e-03, 2.8793e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,192][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([9.6830e-01, 1.0399e-03, 1.4320e-02, 7.4387e-04, 1.4348e-02, 1.2448e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,193][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0579, 0.0029, 0.8750, 0.0011, 0.0505, 0.0125], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,194][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([3.9121e-01, 6.4899e-03, 5.9613e-01, 3.3897e-04, 5.0834e-03, 7.5440e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,195][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.0914e-02, 7.9446e-04, 9.8481e-01, 2.4340e-04, 2.9983e-03, 2.4157e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,196][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0439, 0.0692, 0.7044, 0.0114, 0.0761, 0.0179, 0.0772],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,198][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1337, 0.0144, 0.6548, 0.0049, 0.1585, 0.0165, 0.0172],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,198][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.9198e-04, 6.1549e-02, 1.6371e-02, 7.8126e-01, 7.1173e-02, 2.6413e-02,
        4.2847e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,199][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.5849e-04, 1.4720e-02, 8.2528e-01, 3.9391e-03, 1.3206e-01, 9.2670e-03,
        1.4575e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,200][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([7.2656e-06, 1.6739e-01, 4.6016e-01, 2.4828e-01, 7.9475e-02, 2.6665e-02,
        1.8022e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,202][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0026, 0.0057, 0.9152, 0.0020, 0.0607, 0.0080, 0.0058],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,203][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0117, 0.0414, 0.5563, 0.0255, 0.0707, 0.0696, 0.2247],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,204][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.5692e-03, 1.2497e-03, 9.7742e-01, 6.3364e-04, 7.4012e-03, 1.9712e-03,
        1.7514e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,205][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.9574e-01, 1.4491e-04, 1.5862e-03, 9.9570e-05, 1.8924e-03, 1.6697e-04,
        3.7124e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,206][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.3202e-02, 1.9480e-03, 8.5992e-01, 7.9437e-04, 3.1253e-02, 6.9826e-03,
        5.9047e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,207][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([8.5788e-01, 2.3283e-03, 1.3815e-01, 7.1445e-05, 7.7712e-04, 7.7980e-05,
        7.1758e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,208][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.0158e-02, 1.1793e-03, 9.6448e-01, 3.4476e-04, 3.0992e-03, 3.1551e-04,
        4.2410e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,209][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0329, 0.0931, 0.6506, 0.0236, 0.0879, 0.0159, 0.0545, 0.0415],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,210][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0805, 0.0126, 0.6095, 0.0053, 0.2086, 0.0202, 0.0237, 0.0396],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,211][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([3.9950e-04, 5.9351e-02, 1.8447e-02, 7.2950e-01, 8.1421e-02, 3.1487e-02,
        4.9606e-02, 2.9786e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,212][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([1.4517e-04, 1.8201e-02, 7.6438e-01, 3.1862e-03, 1.1678e-01, 1.1339e-02,
        2.2449e-02, 6.3520e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,213][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([5.5059e-06, 1.7544e-01, 2.5106e-01, 3.9035e-01, 6.8372e-02, 3.2173e-02,
        2.0369e-02, 6.2240e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,215][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0010, 0.0076, 0.8188, 0.0053, 0.1087, 0.0205, 0.0090, 0.0291],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,216][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0116, 0.0706, 0.5876, 0.0396, 0.0657, 0.0774, 0.1109, 0.0366],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,217][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0028, 0.0022, 0.9298, 0.0018, 0.0165, 0.0086, 0.0060, 0.0323],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,218][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([9.9262e-01, 2.2157e-04, 2.1303e-03, 1.4297e-04, 2.7493e-03, 2.2498e-04,
        5.2111e-04, 1.3934e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,220][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0337, 0.0043, 0.8391, 0.0022, 0.0631, 0.0154, 0.0105, 0.0316],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,221][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2805, 0.0176, 0.6794, 0.0010, 0.0101, 0.0014, 0.0086, 0.0015],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,222][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([8.8970e-03, 8.5022e-04, 9.8554e-01, 2.6725e-04, 2.4137e-03, 2.6802e-04,
        2.9711e-04, 1.4631e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,223][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0268, 0.0631, 0.6568, 0.0129, 0.0760, 0.0107, 0.0511, 0.0296, 0.0731],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,225][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0929, 0.0226, 0.5535, 0.0056, 0.1838, 0.0207, 0.0270, 0.0556, 0.0382],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,225][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([2.7476e-04, 5.0123e-02, 1.9456e-02, 7.0359e-01, 8.7801e-02, 3.5295e-02,
        5.2778e-02, 3.4099e-02, 1.6586e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,226][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.2279e-04, 2.2325e-02, 5.8918e-01, 2.8613e-03, 9.9462e-02, 9.1825e-03,
        1.8445e-02, 7.5238e-02, 1.8298e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,226][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([6.0794e-06, 1.7191e-01, 2.7406e-01, 3.3802e-01, 8.2735e-02, 4.0156e-02,
        2.2345e-02, 5.2665e-02, 1.8103e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,227][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([8.1335e-04, 2.5460e-03, 8.3689e-01, 2.3532e-03, 8.3853e-02, 1.4655e-02,
        6.1997e-03, 1.9981e-02, 3.2705e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,227][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0158, 0.0156, 0.6945, 0.0111, 0.0327, 0.0462, 0.1303, 0.0243, 0.0294],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,227][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([6.1505e-03, 1.1323e-03, 9.0615e-01, 8.5508e-04, 1.2962e-02, 6.9361e-03,
        3.8392e-03, 2.6737e-02, 3.5239e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,228][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([9.8803e-01, 2.3535e-04, 2.5203e-03, 1.5958e-04, 2.9917e-03, 2.4331e-04,
        5.6549e-04, 1.6350e-03, 3.6183e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,228][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1234, 0.0033, 0.7204, 0.0010, 0.0499, 0.0114, 0.0108, 0.0294, 0.0504],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,229][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([3.0136e-01, 1.8315e-02, 6.6519e-01, 6.6339e-04, 6.9883e-03, 7.0912e-04,
        4.0451e-03, 7.4367e-04, 1.9863e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,229][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.4443e-02, 1.9784e-03, 9.7322e-01, 5.7984e-04, 3.1459e-03, 6.1000e-04,
        5.5640e-04, 3.9276e-03, 1.5396e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,231][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0189, 0.0374, 0.6355, 0.0052, 0.0449, 0.0129, 0.0564, 0.0430, 0.1352,
        0.0107], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,232][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0891, 0.0092, 0.6845, 0.0032, 0.1255, 0.0109, 0.0103, 0.0276, 0.0236,
        0.0160], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,233][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.6343e-04, 3.3907e-02, 2.0699e-03, 3.5984e-01, 1.2857e-02, 5.1912e-03,
        1.0552e-02, 5.0784e-03, 2.7561e-03, 5.6759e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,234][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.7483e-04, 1.0494e-02, 5.4314e-01, 2.7767e-03, 7.8331e-02, 7.5282e-03,
        1.3756e-02, 5.1385e-02, 1.4069e-01, 1.5163e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,235][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([6.7137e-06, 2.2457e-01, 3.5392e-01, 2.3831e-01, 4.7919e-02, 1.8470e-02,
        1.2779e-02, 4.8968e-02, 1.2676e-02, 4.2382e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,235][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([7.5662e-04, 3.5319e-03, 8.8612e-01, 1.1439e-03, 4.5670e-02, 7.4266e-03,
        3.0005e-03, 1.5073e-02, 3.6574e-02, 7.0365e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,237][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0017, 0.0903, 0.4878, 0.0389, 0.0395, 0.0524, 0.1878, 0.0504, 0.0392,
        0.0120], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,237][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([1.0785e-02, 2.8894e-03, 9.6092e-01, 7.8952e-04, 4.5278e-03, 1.4742e-03,
        1.2356e-03, 8.1022e-03, 8.9847e-03, 2.9079e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,238][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.3522e-01, 1.0730e-03, 6.2343e-03, 7.4646e-04, 1.1435e-02, 1.0252e-03,
        2.1462e-03, 5.8744e-03, 1.7210e-02, 1.9035e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,239][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([3.7289e-02, 1.8861e-03, 8.7679e-01, 8.1943e-04, 2.6607e-02, 5.0167e-03,
        3.5386e-03, 1.0671e-02, 3.6116e-02, 1.2612e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,240][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.3158e-01, 1.2097e-03, 6.6416e-02, 3.6654e-05, 3.3947e-04, 2.7306e-05,
        1.9498e-04, 5.0712e-05, 1.2641e-04, 2.1509e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,241][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([7.5446e-02, 2.9774e-04, 9.2309e-01, 5.5137e-05, 5.0705e-04, 5.9254e-05,
        7.7435e-05, 2.9680e-04, 1.6156e-04, 4.9840e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,243][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0191, 0.0310, 0.6623, 0.0044, 0.0419, 0.0111, 0.0548, 0.0472, 0.1160,
        0.0088, 0.0034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,244][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1129, 0.0058, 0.6991, 0.0023, 0.1018, 0.0085, 0.0081, 0.0236, 0.0198,
        0.0123, 0.0058], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,245][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([6.2756e-05, 1.2525e-02, 5.4662e-04, 1.1846e-01, 3.6406e-03, 1.4383e-03,
        3.0894e-03, 1.4226e-03, 7.8128e-04, 1.9662e-01, 6.6142e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,246][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.7388e-04, 1.2350e-02, 4.5489e-01, 2.4988e-03, 7.0944e-02, 7.5205e-03,
        1.3098e-02, 4.4251e-02, 1.3175e-01, 1.5818e-01, 1.0425e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,247][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([8.9575e-06, 1.3484e-01, 4.2494e-01, 2.0634e-01, 5.4938e-02, 1.5536e-02,
        1.3163e-02, 5.3004e-02, 1.4669e-02, 3.0745e-02, 5.1816e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,248][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([6.7151e-04, 1.4921e-03, 9.1011e-01, 6.0749e-04, 4.1019e-02, 4.7044e-03,
        2.2385e-03, 1.2300e-02, 2.6404e-02, 3.0606e-04, 1.5150e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,249][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0015, 0.1149, 0.4348, 0.0498, 0.0504, 0.0497, 0.1945, 0.0508, 0.0302,
        0.0184, 0.0050], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,250][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.9408e-02, 1.1468e-03, 9.6162e-01, 3.2774e-04, 3.7221e-03, 8.6439e-04,
        8.7374e-04, 5.9442e-03, 5.9229e-03, 1.1628e-04, 5.3116e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,252][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8580, 0.0028, 0.0141, 0.0015, 0.0237, 0.0022, 0.0045, 0.0109, 0.0302,
        0.0319, 0.0202], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,253][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.9392e-02, 7.3200e-04, 8.7247e-01, 4.1862e-04, 2.2356e-02, 3.5232e-03,
        2.3231e-03, 7.8982e-03, 2.9981e-02, 6.0410e-04, 2.9984e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,254][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.4529e-01, 8.5065e-04, 5.3259e-02, 3.0682e-05, 2.5991e-04, 1.7285e-05,
        1.3719e-04, 4.2917e-05, 8.4949e-05, 1.8198e-05, 7.0810e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,255][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.0562e-01, 2.4504e-04, 8.9296e-01, 4.8857e-05, 5.1514e-04, 6.8591e-05,
        7.3158e-05, 2.7614e-04, 1.8489e-04, 3.8158e-06, 2.5226e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,256][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0312, 0.0550, 0.6274, 0.0077, 0.0698, 0.0101, 0.0326, 0.0257, 0.0936,
        0.0114, 0.0081, 0.0275], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,258][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0606, 0.0148, 0.5290, 0.0057, 0.1481, 0.0183, 0.0201, 0.0427, 0.0321,
        0.0249, 0.0124, 0.0914], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,259][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([1.3062e-04, 1.3523e-02, 3.0405e-03, 1.4715e-01, 1.3684e-02, 5.4344e-03,
        8.6099e-03, 5.4507e-03, 2.7283e-03, 2.2943e-01, 5.6311e-01, 7.7054e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,260][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.3621e-04, 1.0320e-02, 4.2211e-01, 2.1613e-03, 5.3505e-02, 5.8343e-03,
        1.2356e-02, 4.5935e-02, 1.4054e-01, 1.0185e-01, 6.9956e-02, 1.3531e-01],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,261][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([7.4056e-06, 1.5299e-01, 3.0381e-01, 2.5143e-01, 5.9817e-02, 2.4032e-02,
        1.3407e-02, 4.4877e-02, 1.0103e-02, 4.2785e-02, 8.4665e-02, 1.2072e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,262][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([6.6831e-04, 5.6516e-03, 7.9487e-01, 3.6949e-03, 6.4423e-02, 1.9178e-02,
        8.7080e-03, 2.4059e-02, 4.0822e-02, 2.5801e-03, 1.6785e-03, 3.3663e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,263][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0072, 0.0648, 0.4383, 0.0289, 0.0546, 0.0868, 0.2496, 0.0332, 0.0223,
        0.0073, 0.0025, 0.0046], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,264][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0043, 0.0077, 0.8795, 0.0023, 0.0148, 0.0053, 0.0039, 0.0316, 0.0235,
        0.0012, 0.0009, 0.0248], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,265][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([9.7823e-01, 2.9688e-04, 1.7701e-03, 1.2479e-04, 2.2994e-03, 1.7552e-04,
        4.3170e-04, 1.2581e-03, 3.0649e-03, 2.1878e-03, 1.6390e-03, 8.5245e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,267][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0442, 0.0042, 0.7281, 0.0017, 0.0674, 0.0137, 0.0115, 0.0330, 0.0537,
        0.0031, 0.0014, 0.0380], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,268][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.3865e-01, 3.7825e-02, 8.0747e-01, 8.9663e-04, 5.2896e-03, 6.9249e-04,
        3.0098e-03, 5.9710e-04, 1.3459e-03, 5.2058e-04, 2.3956e-04, 3.4560e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,268][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([2.0509e-03, 4.3917e-03, 9.7911e-01, 2.0494e-03, 4.9754e-03, 8.0444e-04,
        7.6806e-04, 3.7332e-03, 1.0571e-03, 3.4449e-04, 3.9928e-04, 3.1181e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,269][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Jesse] are: tensor([0.0053, 0.0600, 0.4756, 0.0084, 0.1156, 0.0168, 0.0823, 0.0454, 0.1207,
        0.0163, 0.0084, 0.0373, 0.0078], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,269][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Jesse] are: tensor([0.0482, 0.0214, 0.5085, 0.0047, 0.1308, 0.0143, 0.0155, 0.0359, 0.0255,
        0.0224, 0.0127, 0.1128, 0.0473], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,269][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Jesse] are: tensor([1.2194e-04, 1.3352e-02, 4.7262e-03, 1.5049e-01, 1.7016e-02, 5.4861e-03,
        7.5984e-03, 5.2126e-03, 2.4262e-03, 2.3495e-01, 5.4733e-01, 8.2941e-03,
        2.9965e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,270][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Jesse] are: tensor([7.5014e-05, 9.1992e-03, 4.1173e-01, 1.6481e-03, 5.3121e-02, 5.7173e-03,
        9.9427e-03, 3.8014e-02, 1.2062e-01, 1.0643e-01, 6.0291e-02, 1.4935e-01,
        3.3867e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,270][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Jesse] are: tensor([6.5467e-07, 1.3073e-01, 3.2814e-01, 2.5922e-01, 8.1795e-02, 2.7869e-02,
        1.6693e-02, 4.7027e-02, 1.0379e-02, 2.7869e-02, 5.6718e-02, 1.2999e-02,
        5.6378e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,271][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Jesse] are: tensor([2.4504e-04, 4.6974e-03, 8.5911e-01, 2.8191e-03, 6.7655e-02, 8.5879e-03,
        4.3874e-03, 1.2717e-02, 1.8702e-02, 9.7352e-04, 7.8308e-04, 1.7523e-02,
        1.7964e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,271][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Jesse] are: tensor([2.1967e-03, 2.9497e-02, 5.9921e-01, 9.7724e-03, 3.7108e-02, 7.2812e-02,
        1.8833e-01, 2.3523e-02, 2.5985e-02, 3.4594e-03, 9.8741e-04, 6.7513e-03,
        3.6532e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,272][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Jesse] are: tensor([1.5355e-03, 1.6581e-03, 9.7072e-01, 4.5334e-04, 6.2958e-03, 1.6137e-03,
        1.1674e-03, 5.5293e-03, 7.0632e-03, 1.5319e-04, 1.0356e-04, 3.6332e-03,
        7.8343e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,273][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Jesse] are: tensor([7.7480e-01, 9.0931e-04, 6.5216e-03, 4.8613e-04, 8.9174e-03, 7.8296e-04,
        2.0631e-03, 4.8913e-03, 1.2650e-02, 7.3767e-03, 5.9741e-03, 2.8528e-02,
        1.4610e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,275][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Jesse] are: tensor([0.0161, 0.0033, 0.8034, 0.0014, 0.0562, 0.0081, 0.0073, 0.0250, 0.0372,
        0.0025, 0.0013, 0.0312, 0.0070], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,276][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Jesse] are: tensor([5.5129e-02, 6.8084e-03, 9.2564e-01, 2.0082e-04, 5.7278e-03, 1.1169e-04,
        5.2225e-04, 2.3485e-04, 4.9660e-04, 1.3289e-04, 6.0276e-05, 4.8171e-03,
        1.1351e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,277][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Jesse] are: tensor([4.8705e-04, 9.5087e-04, 9.9164e-01, 4.2637e-04, 4.3166e-03, 1.2736e-04,
        1.0198e-04, 1.2875e-03, 3.0037e-04, 6.1032e-05, 6.1829e-05, 2.4046e-04,
        3.2701e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,278][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0530, 0.0552, 0.5792, 0.0065, 0.0659, 0.0139, 0.0463, 0.0270, 0.0662,
        0.0089, 0.0053, 0.0213, 0.0033, 0.0481], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,279][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0197, 0.0099, 0.5049, 0.0039, 0.1568, 0.0150, 0.0137, 0.0338, 0.0321,
        0.0187, 0.0098, 0.0969, 0.0521, 0.0327], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,280][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([4.7210e-05, 8.3661e-03, 2.1786e-03, 1.3526e-01, 1.2405e-02, 4.4901e-03,
        6.7008e-03, 4.3687e-03, 2.0614e-03, 2.2758e-01, 5.8442e-01, 6.0273e-03,
        3.0157e-03, 3.0717e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,281][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([8.8318e-05, 7.7282e-03, 3.8555e-01, 1.3075e-03, 5.0044e-02, 3.9756e-03,
        8.5454e-03, 2.9077e-02, 9.1271e-02, 7.8852e-02, 4.6901e-02, 1.0390e-01,
        3.1841e-02, 1.6092e-01], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,282][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([4.4234e-06, 1.7358e-01, 3.2070e-01, 2.6142e-01, 7.1993e-02, 2.4062e-02,
        1.3651e-02, 2.8520e-02, 7.3874e-03, 2.3791e-02, 5.2785e-02, 1.0809e-02,
        4.0473e-04, 1.0896e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,283][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([7.3130e-04, 1.4972e-03, 8.6540e-01, 9.5296e-04, 5.8058e-02, 6.8621e-03,
        2.8630e-03, 1.2087e-02, 1.9397e-02, 3.6756e-04, 2.6761e-04, 2.4003e-02,
        1.5169e-03, 5.9990e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,284][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([6.4726e-03, 1.7727e-02, 7.2535e-01, 6.7062e-03, 2.1466e-02, 3.9392e-02,
        1.1419e-01, 7.3785e-03, 1.5106e-02, 9.4915e-04, 2.7714e-04, 1.9609e-03,
        1.1419e-04, 4.2907e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,285][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([3.8527e-03, 5.8368e-04, 9.6413e-01, 1.8006e-04, 6.4197e-03, 1.8948e-03,
        1.0930e-03, 6.1325e-03, 7.6377e-03, 6.9991e-05, 4.2374e-05, 3.8756e-03,
        7.1532e-05, 4.0133e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,286][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.6297, 0.0015, 0.0194, 0.0010, 0.0201, 0.0013, 0.0031, 0.0072, 0.0221,
        0.0163, 0.0112, 0.0574, 0.1960, 0.0136], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,288][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([4.1817e-02, 1.7605e-03, 7.7440e-01, 8.1506e-04, 5.1020e-02, 8.1200e-03,
        6.6964e-03, 2.1522e-02, 3.7794e-02, 1.3740e-03, 6.1997e-04, 3.9196e-02,
        5.4142e-03, 9.4457e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,288][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([3.2680e-01, 1.7117e-02, 6.4431e-01, 2.5790e-04, 4.0244e-03, 2.5172e-04,
        1.5793e-03, 1.6331e-04, 4.2147e-04, 1.0605e-04, 3.8759e-05, 2.7326e-03,
        7.3379e-05, 2.1245e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,289][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.4249e-02, 5.0034e-03, 9.6032e-01, 9.6298e-04, 3.1114e-03, 4.5507e-04,
        4.7829e-04, 2.1060e-03, 5.2564e-04, 1.0957e-04, 1.2553e-04, 2.3640e-04,
        3.4636e-06, 2.3109e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,291][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0446, 0.0659, 0.5423, 0.0086, 0.0522, 0.0105, 0.0491, 0.0257, 0.0850,
        0.0118, 0.0065, 0.0170, 0.0034, 0.0402, 0.0369], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,292][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0616, 0.0095, 0.5076, 0.0032, 0.1280, 0.0124, 0.0131, 0.0302, 0.0251,
        0.0175, 0.0091, 0.0896, 0.0483, 0.0286, 0.0162], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,293][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([5.7308e-05, 1.1275e-02, 1.4530e-03, 1.4009e-01, 8.5653e-03, 3.5838e-03,
        6.0441e-03, 3.4136e-03, 1.7620e-03, 2.1707e-01, 5.9034e-01, 4.8058e-03,
        2.4658e-03, 2.5044e-03, 6.5725e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,294][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.2177e-04, 8.1207e-03, 2.9353e-01, 1.5859e-03, 4.9333e-02, 4.6979e-03,
        8.1329e-03, 3.2556e-02, 8.4446e-02, 8.5206e-02, 5.1867e-02, 1.2539e-01,
        3.1309e-02, 1.6846e-01, 5.5137e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,295][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([3.4638e-06, 2.3437e-01, 2.4691e-01, 3.1305e-01, 4.1005e-02, 1.6139e-02,
        1.3377e-02, 2.6625e-02, 5.8778e-03, 2.8977e-02, 5.1594e-02, 8.2275e-03,
        2.5247e-04, 5.7487e-03, 7.8411e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,296][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.7237e-03, 5.8557e-03, 8.6565e-01, 1.5272e-03, 5.7356e-02, 6.0682e-03,
        3.6925e-03, 8.5992e-03, 2.1296e-02, 7.7908e-04, 4.5480e-04, 1.6512e-02,
        1.8352e-03, 6.6249e-03, 2.0278e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,297][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([8.8196e-04, 9.9963e-02, 4.1549e-01, 2.6758e-02, 3.6781e-02, 5.9463e-02,
        2.3385e-01, 2.8953e-02, 2.7121e-02, 9.1195e-03, 1.6495e-03, 2.2615e-03,
        3.1600e-04, 4.7262e-02, 1.0132e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,298][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.9862e-02, 2.0821e-03, 9.4751e-01, 5.1965e-04, 5.1542e-03, 1.2796e-03,
        1.5078e-03, 6.6211e-03, 6.8620e-03, 1.5338e-04, 8.2820e-05, 4.1655e-03,
        5.2209e-05, 3.0326e-03, 1.1121e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,300][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6639, 0.0019, 0.0120, 0.0009, 0.0152, 0.0012, 0.0027, 0.0062, 0.0171,
        0.0138, 0.0090, 0.0452, 0.1476, 0.0123, 0.0511], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,301][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.9189e-02, 1.5698e-03, 7.8383e-01, 6.5067e-04, 3.5788e-02, 5.6288e-03,
        4.6387e-03, 1.1030e-02, 3.4086e-02, 1.2999e-03, 5.8149e-04, 2.7820e-02,
        4.0586e-03, 6.5319e-03, 3.2926e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,302][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.3005e-01, 1.2999e-02, 1.5315e-01, 1.5389e-04, 5.0959e-04, 4.5770e-05,
        4.1148e-04, 6.2646e-05, 1.3812e-04, 6.2970e-05, 3.0144e-05, 7.7700e-04,
        1.5975e-05, 5.8323e-04, 1.0116e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,303][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.6555e-02, 1.3226e-03, 9.5822e-01, 3.3673e-04, 1.7281e-03, 1.7472e-04,
        1.7187e-04, 6.1214e-04, 1.7882e-04, 2.2103e-05, 2.1151e-05, 9.7913e-05,
        1.0397e-06, 4.1240e-04, 1.4592e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,357][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:25:34,358][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,359][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,360][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,361][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,362][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,363][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,363][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,363][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,364][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,364][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,364][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,364][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:25:34,365][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3528, 0.6472], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,365][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4762, 0.5238], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,365][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,367][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9561, 0.0439], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,367][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.5896e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,369][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6013, 0.3987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,370][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0637, 0.9363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,371][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6939, 0.3061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,373][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9830, 0.0170], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,374][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7739, 0.2261], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,375][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9912e-01, 8.7851e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,376][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9959e-01, 4.1068e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:25:34,377][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Christina] are: tensor([0.2358, 0.1117, 0.6525], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,378][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Christina] are: tensor([6.9244e-01, 5.3389e-04, 3.0703e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,379][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Christina] are: tensor([0.0145, 0.0234, 0.9621], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,381][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Christina] are: tensor([0.1391, 0.0154, 0.8456], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,381][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Christina] are: tensor([2.5983e-04, 3.5603e-01, 6.4371e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,383][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Christina] are: tensor([0.0208, 0.0016, 0.9776], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,384][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Christina] are: tensor([8.2100e-03, 8.0628e-04, 9.9098e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,385][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Christina] are: tensor([0.3181, 0.0016, 0.6803], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,387][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Christina] are: tensor([0.5834, 0.2643, 0.1523], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,388][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Christina] are: tensor([6.8337e-03, 2.8728e-04, 9.9288e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,389][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Christina] are: tensor([0.9691, 0.0025, 0.0284], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,390][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Christina] are: tensor([6.3498e-01, 5.4903e-04, 3.6447e-01], device='cuda:0') for source tokens [Then, Christina]
[2024-07-24 10:25:34,391][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0461, 0.0582, 0.8859, 0.0097], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,392][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([3.0988e-03, 3.4952e-04, 9.9653e-01, 2.2453e-05], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,393][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.5665e-04, 8.0322e-03, 9.9003e-01, 1.6854e-03], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,394][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([3.3104e-03, 3.5161e-04, 9.9619e-01, 1.5278e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,395][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([4.5289e-05, 2.6004e-01, 4.7013e-01, 2.6978e-01], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,396][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([5.0769e-03, 3.9756e-04, 9.9445e-01, 7.1605e-05], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,396][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([3.6412e-04, 2.2078e-04, 9.9916e-01, 2.6012e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,397][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.1903e-02, 9.0455e-04, 9.0696e-01, 2.3140e-04], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,399][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5661, 0.2455, 0.1557, 0.0328], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,400][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.7224e-03, 3.1513e-05, 9.9524e-01, 9.2978e-06], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,401][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9281e-01, 1.9835e-04, 6.9845e-03, 5.9840e-06], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,401][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.7242e-01, 1.2372e-04, 7.2743e-01, 2.5317e-05], device='cuda:0') for source tokens [Then, Christina and]
[2024-07-24 10:25:34,403][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0442, 0.0899, 0.7798, 0.0134, 0.0728], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,404][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([1.0287e-02, 9.1810e-04, 9.7592e-01, 6.6588e-05, 1.2809e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,405][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([6.4075e-05, 3.3894e-03, 9.6507e-01, 5.9854e-04, 3.0880e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,405][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([1.2274e-03, 2.4278e-04, 9.9794e-01, 3.6836e-05, 5.5593e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,406][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([1.0657e-05, 2.5630e-01, 4.3206e-01, 2.3509e-01, 7.6538e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,406][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([2.3331e-03, 1.3186e-03, 9.8209e-01, 2.6218e-04, 1.4001e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,406][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([2.4484e-04, 2.0136e-04, 9.9092e-01, 2.4724e-04, 8.3900e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,407][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([3.3729e-02, 1.4638e-03, 9.6157e-01, 2.3990e-04, 3.0009e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,407][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.2538, 0.2241, 0.4678, 0.0258, 0.0285], device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,407][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([1.1200e-03, 5.3742e-05, 9.9651e-01, 9.1729e-06, 2.3060e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,408][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([8.3099e-01, 7.8288e-04, 1.6765e-01, 1.3348e-05, 5.6294e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,408][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([4.6241e-02, 2.2179e-04, 9.5243e-01, 7.0858e-05, 1.0395e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse]
[2024-07-24 10:25:34,409][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0126, 0.0626, 0.7970, 0.0094, 0.0927, 0.0257], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,410][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([2.8503e-04, 3.0860e-04, 9.7694e-01, 4.9175e-05, 2.2073e-02, 3.3927e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,411][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.4134e-05, 7.2229e-03, 8.0242e-01, 2.9184e-03, 1.8633e-01, 1.0862e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,412][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([5.2375e-04, 1.9165e-04, 9.9608e-01, 6.9210e-05, 3.0506e-03, 8.6140e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,413][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([6.3059e-06, 1.5103e-01, 4.5445e-01, 2.5322e-01, 1.1294e-01, 2.8357e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,413][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([2.1907e-04, 2.1630e-04, 9.7818e-01, 9.0207e-05, 2.0219e-02, 1.0748e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,414][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.5325e-05, 3.4590e-05, 9.8756e-01, 1.6405e-04, 1.2012e-02, 2.0963e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,415][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([5.2881e-03, 5.3388e-04, 9.8203e-01, 2.8229e-04, 8.9816e-03, 2.8793e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,417][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4508, 0.2532, 0.2117, 0.0349, 0.0178, 0.0316], device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,417][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.3334e-04, 1.4877e-05, 9.9691e-01, 4.8271e-06, 2.8278e-03, 1.1153e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,418][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([3.9121e-01, 6.4899e-03, 5.9613e-01, 3.3897e-04, 5.0834e-03, 7.5440e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,419][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.0914e-02, 7.9446e-04, 9.8481e-01, 2.4340e-04, 2.9983e-03, 2.4157e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had]
[2024-07-24 10:25:34,421][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0439, 0.0692, 0.7044, 0.0114, 0.0761, 0.0179, 0.0772],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,421][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.5254e-03, 9.0640e-04, 9.8509e-01, 8.5726e-05, 1.2047e-02, 2.6472e-04,
        8.1028e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,422][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.0986e-05, 6.5518e-03, 8.1775e-01, 2.9436e-03, 1.6949e-01, 8.6977e-04,
        2.3842e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,423][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.5635e-03, 7.1912e-04, 9.8831e-01, 2.7065e-04, 2.7677e-03, 1.3705e-04,
        2.3259e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,424][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([7.2656e-06, 1.6739e-01, 4.6016e-01, 2.4828e-01, 7.9475e-02, 2.6665e-02,
        1.8022e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,425][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.3031e-03, 7.3706e-04, 9.8237e-01, 1.6980e-04, 1.3887e-02, 8.4459e-04,
        6.8456e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,426][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.1485e-05, 5.3159e-05, 9.8929e-01, 2.0481e-04, 9.9632e-03, 1.9798e-04,
        2.6783e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,427][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([9.5692e-03, 1.2497e-03, 9.7742e-01, 6.3364e-04, 7.4012e-03, 1.9712e-03,
        1.7514e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,428][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8491, 0.0410, 0.0824, 0.0087, 0.0042, 0.0050, 0.0096],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,429][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.4883e-04, 1.2373e-05, 9.9828e-01, 3.4273e-06, 1.3756e-03, 4.9128e-05,
        2.6494e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,430][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([8.5788e-01, 2.3283e-03, 1.3815e-01, 7.1445e-05, 7.7712e-04, 7.7980e-05,
        7.1758e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,431][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.0158e-02, 1.1793e-03, 9.6448e-01, 3.4476e-04, 3.0992e-03, 3.1551e-04,
        4.2410e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a]
[2024-07-24 10:25:34,432][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0329, 0.0931, 0.6506, 0.0236, 0.0879, 0.0159, 0.0545, 0.0415],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,433][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([6.3592e-04, 5.5988e-04, 9.6400e-01, 2.0868e-04, 3.2538e-02, 8.2075e-04,
        2.4060e-04, 9.9607e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,434][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([1.9013e-05, 1.4878e-02, 6.0306e-01, 7.3484e-03, 3.6640e-01, 1.3870e-03,
        3.3999e-03, 3.5120e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,435][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([8.2418e-04, 6.1479e-04, 9.9123e-01, 3.3162e-04, 4.6296e-03, 2.7703e-04,
        8.1199e-04, 1.2850e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,436][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([5.5059e-06, 1.7544e-01, 2.5106e-01, 3.9035e-01, 6.8372e-02, 3.2173e-02,
        2.0369e-02, 6.2240e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,437][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([2.5047e-04, 9.9188e-04, 9.5592e-01, 5.1208e-04, 3.2195e-02, 2.8785e-03,
        1.0559e-03, 6.1913e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,438][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([9.8261e-06, 1.1697e-04, 9.4786e-01, 9.7235e-04, 3.4631e-02, 1.2063e-03,
        9.8720e-04, 1.4213e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,439][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0028, 0.0022, 0.9298, 0.0018, 0.0165, 0.0086, 0.0060, 0.0323],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,441][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.6088, 0.0320, 0.2690, 0.0148, 0.0195, 0.0150, 0.0267, 0.0142],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,442][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([5.2453e-05, 4.9711e-05, 9.8999e-01, 4.7070e-05, 7.9007e-03, 4.4981e-04,
        1.0775e-04, 1.4041e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,443][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2805, 0.0176, 0.6794, 0.0010, 0.0101, 0.0014, 0.0086, 0.0015],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,444][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([8.8970e-03, 8.5022e-04, 9.8554e-01, 2.6725e-04, 2.4137e-03, 2.6802e-04,
        2.9711e-04, 1.4631e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long]
[2024-07-24 10:25:34,446][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0268, 0.0631, 0.6568, 0.0129, 0.0760, 0.0107, 0.0511, 0.0296, 0.0731],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,447][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([6.7281e-04, 8.7366e-04, 9.6566e-01, 1.7233e-04, 2.9783e-02, 7.0234e-04,
        1.8988e-04, 1.1881e-03, 7.5376e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,447][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([2.3397e-05, 5.4999e-03, 6.9230e-01, 3.2240e-03, 2.8492e-01, 1.4034e-03,
        3.0783e-03, 4.1990e-03, 5.3473e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,448][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.7170e-03, 1.0446e-03, 9.8836e-01, 2.7550e-04, 4.0794e-03, 1.6539e-04,
        3.1949e-04, 1.2852e-03, 7.5156e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,449][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([6.0794e-06, 1.7191e-01, 2.7406e-01, 3.3802e-01, 8.2735e-02, 4.0156e-02,
        2.2345e-02, 5.2665e-02, 1.8103e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,450][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([2.4001e-04, 2.2091e-04, 9.6367e-01, 1.8937e-04, 2.2643e-02, 1.8809e-03,
        6.6542e-04, 3.5731e-03, 6.9128e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,451][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([2.4017e-05, 3.1430e-05, 9.7587e-01, 2.3870e-04, 1.7311e-02, 4.1477e-04,
        3.5635e-04, 4.4874e-03, 1.2704e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,452][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([6.1505e-03, 1.1323e-03, 9.0615e-01, 8.5508e-04, 1.2962e-02, 6.9361e-03,
        3.8392e-03, 2.6737e-02, 3.5239e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,452][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.5435, 0.0684, 0.2021, 0.0142, 0.0316, 0.0303, 0.0497, 0.0305, 0.0297],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,453][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.7898e-04, 1.7505e-05, 9.8890e-01, 8.8245e-06, 5.1102e-03, 2.5094e-04,
        8.1774e-05, 9.9980e-04, 4.2561e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,453][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([3.0136e-01, 1.8315e-02, 6.6519e-01, 6.6339e-04, 6.9883e-03, 7.0912e-04,
        4.0451e-03, 7.4367e-04, 1.9863e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,454][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([1.4443e-02, 1.9784e-03, 9.7322e-01, 5.7984e-04, 3.1459e-03, 6.1000e-04,
        5.5640e-04, 3.9276e-03, 1.5396e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument]
[2024-07-24 10:25:34,454][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0189, 0.0374, 0.6355, 0.0052, 0.0449, 0.0129, 0.0564, 0.0430, 0.1352,
        0.0107], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,454][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.5017e-04, 3.7965e-04, 9.9567e-01, 2.8141e-05, 3.4431e-03, 9.0695e-05,
        1.7073e-05, 1.1035e-04, 8.9940e-05, 2.3849e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,455][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.0983e-05, 6.7147e-03, 8.9921e-01, 1.4022e-03, 8.9523e-02, 3.2558e-04,
        6.9696e-04, 9.8636e-04, 9.6320e-04, 1.6307e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,456][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([4.5678e-04, 1.8705e-04, 9.9472e-01, 1.0040e-04, 2.8615e-03, 1.1927e-04,
        2.7978e-04, 6.3405e-04, 6.2225e-04, 1.8295e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,457][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.7137e-06, 2.2457e-01, 3.5392e-01, 2.3831e-01, 4.7919e-02, 1.8470e-02,
        1.2779e-02, 4.8968e-02, 1.2676e-02, 4.2382e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,458][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.7128e-04, 5.9962e-04, 9.7404e-01, 1.2034e-04, 1.0091e-02, 9.8738e-04,
        3.7682e-04, 3.0698e-03, 1.0169e-02, 7.9007e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,459][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.8411e-05, 2.8701e-04, 9.8758e-01, 4.0953e-04, 8.0908e-03, 2.7359e-04,
        2.2221e-04, 2.0829e-03, 9.4423e-04, 9.0979e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,460][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.0785e-02, 2.8894e-03, 9.6092e-01, 7.8952e-04, 4.5278e-03, 1.4742e-03,
        1.2356e-03, 8.1022e-03, 8.9847e-03, 2.9079e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,461][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6977, 0.1291, 0.1352, 0.0163, 0.0027, 0.0011, 0.0055, 0.0034, 0.0021,
        0.0068], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,462][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.7963e-04, 3.0595e-05, 9.9744e-01, 8.2185e-06, 1.0134e-03, 5.1679e-05,
        1.4718e-05, 1.6672e-04, 1.0964e-03, 2.2555e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,463][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.3158e-01, 1.2097e-03, 6.6416e-02, 3.6654e-05, 3.3947e-04, 2.7306e-05,
        1.9498e-04, 5.0712e-05, 1.2641e-04, 2.1509e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,464][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([7.5446e-02, 2.9774e-04, 9.2309e-01, 5.5137e-05, 5.0705e-04, 5.9254e-05,
        7.7435e-05, 2.9680e-04, 1.6156e-04, 4.9840e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument,]
[2024-07-24 10:25:34,465][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0191, 0.0310, 0.6623, 0.0044, 0.0419, 0.0111, 0.0548, 0.0472, 0.1160,
        0.0088, 0.0034], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,466][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.6533e-04, 2.4657e-04, 9.9682e-01, 2.1211e-05, 2.3486e-03, 7.7405e-05,
        1.4811e-05, 1.0432e-04, 7.8528e-05, 1.9277e-05, 5.8901e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,467][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.0024e-05, 3.1583e-03, 9.1230e-01, 8.4811e-04, 8.0138e-02, 3.1016e-04,
        6.8781e-04, 1.1026e-03, 1.2672e-03, 1.1763e-04, 5.7000e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,468][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([3.6395e-04, 1.2428e-04, 9.9269e-01, 9.8385e-05, 4.3306e-03, 1.7487e-04,
        3.2451e-04, 9.3085e-04, 9.3907e-04, 1.8963e-05, 8.6981e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,469][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([8.9575e-06, 1.3484e-01, 4.2494e-01, 2.0634e-01, 5.4938e-02, 1.5536e-02,
        1.3163e-02, 5.3004e-02, 1.4669e-02, 3.0745e-02, 5.1816e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,470][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([4.4137e-04, 2.0643e-04, 9.7965e-01, 5.8637e-05, 9.0153e-03, 5.6542e-04,
        2.6305e-04, 2.4341e-03, 7.3249e-03, 3.0931e-05, 1.0889e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,471][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([3.0721e-05, 1.8179e-04, 9.8998e-01, 3.0648e-04, 5.9999e-03, 2.3821e-04,
        1.9865e-04, 2.0606e-03, 9.0056e-04, 6.6562e-05, 3.3336e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,472][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.9408e-02, 1.1468e-03, 9.6162e-01, 3.2774e-04, 3.7221e-03, 8.6439e-04,
        8.7374e-04, 5.9442e-03, 5.9229e-03, 1.1628e-04, 5.3116e-05],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,473][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3140, 0.3129, 0.2707, 0.0411, 0.0051, 0.0023, 0.0115, 0.0071, 0.0039,
        0.0176, 0.0137], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,474][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([3.3477e-04, 1.1514e-05, 9.9753e-01, 4.3187e-06, 9.8158e-04, 4.3195e-05,
        1.1995e-05, 1.6467e-04, 9.1682e-04, 9.0227e-07, 7.1013e-07],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,475][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.4529e-01, 8.5065e-04, 5.3259e-02, 3.0682e-05, 2.5991e-04, 1.7285e-05,
        1.3719e-04, 4.2917e-05, 8.4949e-05, 1.8198e-05, 7.0810e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,476][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.0562e-01, 2.4504e-04, 8.9296e-01, 4.8857e-05, 5.1514e-04, 6.8591e-05,
        7.3158e-05, 2.7614e-04, 1.8489e-04, 3.8158e-06, 2.5226e-06],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and]
[2024-07-24 10:25:34,478][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0312, 0.0550, 0.6274, 0.0077, 0.0698, 0.0101, 0.0326, 0.0257, 0.0936,
        0.0114, 0.0081, 0.0275], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,478][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([7.2035e-04, 1.0982e-03, 9.7541e-01, 2.2098e-04, 1.9442e-02, 5.6980e-04,
        1.4632e-04, 8.2948e-04, 4.3933e-04, 1.7370e-04, 6.7657e-05, 8.7981e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,479][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([1.9476e-05, 4.9140e-03, 8.2480e-01, 3.5324e-03, 1.5754e-01, 7.2522e-04,
        1.4060e-03, 2.6247e-03, 2.0180e-03, 5.8019e-04, 4.6201e-04, 1.3794e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,480][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([2.1930e-04, 1.0619e-03, 9.9270e-01, 3.4679e-04, 2.8246e-03, 1.4418e-04,
        2.4297e-04, 1.0737e-03, 7.8382e-04, 1.1320e-04, 6.2933e-05, 4.2526e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,481][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([7.4056e-06, 1.5299e-01, 3.0381e-01, 2.5143e-01, 5.9817e-02, 2.4032e-02,
        1.3407e-02, 4.4877e-02, 1.0103e-02, 4.2785e-02, 8.4665e-02, 1.2072e-02],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,482][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([1.9076e-04, 8.1598e-04, 9.5332e-01, 3.9790e-04, 1.8590e-02, 3.0434e-03,
        1.2176e-03, 5.5735e-03, 1.0767e-02, 3.5587e-04, 1.5801e-04, 5.5679e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,483][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([2.2543e-05, 2.4083e-04, 9.7460e-01, 7.2477e-04, 1.5376e-02, 5.9693e-04,
        3.9743e-04, 5.7248e-03, 1.4964e-03, 2.1456e-04, 1.6711e-04, 4.4301e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,485][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0043, 0.0077, 0.8795, 0.0023, 0.0148, 0.0053, 0.0039, 0.0316, 0.0235,
        0.0012, 0.0009, 0.0248], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,486][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.5850, 0.0426, 0.2832, 0.0083, 0.0138, 0.0114, 0.0129, 0.0078, 0.0139,
        0.0074, 0.0044, 0.0093], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,487][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.8267e-04, 4.7045e-05, 9.8597e-01, 3.0664e-05, 8.3830e-03, 3.4758e-04,
        1.1486e-04, 1.0853e-03, 2.3802e-03, 1.1679e-05, 8.8963e-06, 1.4408e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,488][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.3865e-01, 3.7825e-02, 8.0747e-01, 8.9663e-04, 5.2896e-03, 6.9249e-04,
        3.0098e-03, 5.9710e-04, 1.3459e-03, 5.2058e-04, 2.3956e-04, 3.4560e-03],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,489][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.0509e-03, 4.3917e-03, 9.7911e-01, 2.0494e-03, 4.9754e-03, 8.0444e-04,
        7.6806e-04, 3.7332e-03, 1.0571e-03, 3.4449e-04, 3.9928e-04, 3.1181e-04],
       device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards]
[2024-07-24 10:25:34,490][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Jesse] are: tensor([0.0053, 0.0600, 0.4756, 0.0084, 0.1156, 0.0168, 0.0823, 0.0454, 0.1207,
        0.0163, 0.0084, 0.0373, 0.0078], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,491][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Jesse] are: tensor([2.2999e-04, 1.1403e-03, 9.7229e-01, 1.3043e-04, 2.3834e-02, 3.6108e-04,
        9.7309e-05, 5.2079e-04, 2.9410e-04, 1.0003e-04, 4.5117e-05, 8.9950e-04,
        5.4630e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,492][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Jesse] are: tensor([8.9774e-07, 4.3336e-03, 9.0690e-01, 1.3325e-03, 8.3629e-02, 3.7377e-04,
        5.5861e-04, 8.1271e-04, 1.1129e-03, 2.0531e-04, 1.4652e-04, 5.3617e-04,
        5.6408e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,493][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Jesse] are: tensor([1.0999e-05, 1.4644e-04, 9.9396e-01, 9.2549e-05, 4.0893e-03, 8.0043e-05,
        7.4673e-05, 5.0573e-04, 4.4224e-04, 3.3512e-05, 1.1756e-05, 5.5167e-04,
        2.2720e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,494][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Jesse] are: tensor([6.5467e-07, 1.3073e-01, 3.2814e-01, 2.5922e-01, 8.1795e-02, 2.7869e-02,
        1.6693e-02, 4.7027e-02, 1.0379e-02, 2.7869e-02, 5.6718e-02, 1.2999e-02,
        5.6378e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,494][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Jesse] are: tensor([7.9339e-05, 5.4167e-04, 9.7216e-01, 2.2671e-04, 1.6599e-02, 9.5715e-04,
        4.7566e-04, 2.3135e-03, 3.7986e-03, 8.9245e-05, 5.3560e-05, 2.5918e-03,
        1.1542e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,495][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Jesse] are: tensor([6.1613e-06, 1.6563e-04, 9.7991e-01, 4.2473e-04, 1.5624e-02, 2.7749e-04,
        2.4477e-04, 2.5096e-03, 5.0900e-04, 8.9937e-05, 6.4993e-05, 1.4582e-04,
        2.6116e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,495][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Jesse] are: tensor([1.5355e-03, 1.6581e-03, 9.7072e-01, 4.5334e-04, 6.2958e-03, 1.6137e-03,
        1.1674e-03, 5.5293e-03, 7.0632e-03, 1.5319e-04, 1.0356e-04, 3.6332e-03,
        7.8343e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,495][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Jesse] are: tensor([0.0608, 0.1939, 0.4769, 0.0242, 0.0399, 0.0397, 0.0344, 0.0365, 0.0266,
        0.0266, 0.0138, 0.0228, 0.0038], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,496][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Jesse] are: tensor([4.3615e-05, 3.2606e-05, 9.9337e-01, 1.1562e-05, 4.1822e-03, 8.2306e-05,
        3.4889e-05, 4.3586e-04, 9.5414e-04, 3.3607e-06, 2.7768e-06, 8.3589e-04,
        9.2422e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,496][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Jesse] are: tensor([5.5129e-02, 6.8084e-03, 9.2564e-01, 2.0082e-04, 5.7278e-03, 1.1169e-04,
        5.2225e-04, 2.3485e-04, 4.9660e-04, 1.3289e-04, 6.0276e-05, 4.8171e-03,
        1.1351e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,497][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Jesse] are: tensor([4.8705e-04, 9.5087e-04, 9.9164e-01, 4.2637e-04, 4.3166e-03, 1.2736e-04,
        1.0198e-04, 1.2875e-03, 3.0037e-04, 6.1032e-05, 6.1829e-05, 2.4046e-04,
        3.2701e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse]
[2024-07-24 10:25:34,498][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0530, 0.0552, 0.5792, 0.0065, 0.0659, 0.0139, 0.0463, 0.0270, 0.0662,
        0.0089, 0.0053, 0.0213, 0.0033, 0.0481], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,499][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([3.8780e-04, 5.6568e-04, 9.7605e-01, 7.6866e-05, 2.0737e-02, 4.0958e-04,
        8.9534e-05, 4.1014e-04, 3.1754e-04, 5.8479e-05, 1.9624e-05, 5.6814e-04,
        4.3183e-05, 2.6502e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,500][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([9.2767e-06, 5.6975e-03, 7.3373e-01, 2.0261e-03, 2.5092e-01, 6.2133e-04,
        1.2720e-03, 1.7435e-03, 2.0241e-03, 2.1520e-04, 1.3323e-04, 7.4588e-04,
        1.5601e-04, 7.0537e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,501][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.1097e-03, 6.9216e-04, 9.9096e-01, 2.2140e-04, 3.8080e-03, 1.1631e-04,
        1.9793e-04, 4.3828e-04, 3.8615e-04, 4.5087e-05, 2.4797e-05, 3.5997e-04,
        2.8484e-06, 1.6398e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,502][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([4.4234e-06, 1.7358e-01, 3.2070e-01, 2.6142e-01, 7.1993e-02, 2.4062e-02,
        1.3651e-02, 2.8520e-02, 7.3874e-03, 2.3791e-02, 5.2785e-02, 1.0809e-02,
        4.0473e-04, 1.0896e-02], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,503][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([3.9329e-04, 1.2884e-04, 9.6925e-01, 9.4100e-05, 1.6463e-02, 9.6376e-04,
        3.5487e-04, 2.4176e-03, 4.6189e-03, 4.3425e-05, 2.3406e-05, 4.3678e-03,
        1.2831e-04, 7.4790e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,504][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([1.9373e-05, 5.1316e-05, 9.8571e-01, 2.0991e-04, 1.0954e-02, 2.1550e-04,
        2.0904e-04, 1.7221e-03, 4.6184e-04, 3.2756e-05, 2.2947e-05, 1.4848e-04,
        1.6560e-05, 2.3136e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,505][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([3.8527e-03, 5.8368e-04, 9.6413e-01, 1.8006e-04, 6.4197e-03, 1.8948e-03,
        1.0930e-03, 6.1325e-03, 7.6377e-03, 6.9991e-05, 4.2374e-05, 3.8756e-03,
        7.1532e-05, 4.0133e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,506][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([7.6262e-01, 3.4788e-02, 1.6432e-01, 4.6529e-03, 4.7393e-03, 3.6370e-03,
        6.1421e-03, 3.6886e-03, 3.0566e-03, 4.0158e-03, 2.2059e-03, 2.6491e-03,
        2.4303e-04, 3.2426e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,507][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([5.6592e-04, 1.7348e-05, 9.9275e-01, 6.3998e-06, 3.4894e-03, 1.1190e-04,
        4.2556e-05, 3.9728e-04, 1.3605e-03, 1.4433e-06, 9.6225e-07, 1.2037e-03,
        6.6718e-06, 4.7768e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,508][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([3.2680e-01, 1.7117e-02, 6.4431e-01, 2.5790e-04, 4.0244e-03, 2.5172e-04,
        1.5793e-03, 1.6331e-04, 4.2147e-04, 1.0605e-04, 3.8759e-05, 2.7326e-03,
        7.3379e-05, 2.1245e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,509][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.4249e-02, 5.0034e-03, 9.6032e-01, 9.6298e-04, 3.1114e-03, 4.5507e-04,
        4.7829e-04, 2.1060e-03, 5.2564e-04, 1.0957e-04, 1.2553e-04, 2.3640e-04,
        3.4636e-06, 2.3109e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said]
[2024-07-24 10:25:34,510][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0446, 0.0659, 0.5423, 0.0086, 0.0522, 0.0105, 0.0491, 0.0257, 0.0850,
        0.0118, 0.0065, 0.0170, 0.0034, 0.0402, 0.0369], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,511][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.4145e-03, 1.3672e-03, 9.8709e-01, 1.0375e-04, 8.5610e-03, 2.7626e-04,
        7.8802e-05, 2.6226e-04, 1.9290e-04, 6.6735e-05, 2.4405e-05, 3.4533e-04,
        1.7918e-05, 1.6553e-04, 3.2082e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,512][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.1074e-05, 1.1157e-02, 7.2215e-01, 3.5155e-03, 2.5211e-01, 7.1938e-04,
        2.2290e-03, 2.3601e-03, 2.6818e-03, 3.3841e-04, 2.1541e-04, 7.3245e-04,
        1.8262e-04, 1.1711e-03, 4.2069e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,513][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.7648e-03, 1.0843e-03, 9.8133e-01, 4.8191e-04, 3.4819e-03, 1.4749e-04,
        2.9595e-04, 4.7693e-04, 3.5322e-04, 6.7232e-05, 4.1475e-05, 4.7698e-04,
        3.3693e-06, 1.7179e-03, 2.7744e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,514][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([3.4638e-06, 2.3437e-01, 2.4691e-01, 3.1305e-01, 4.1005e-02, 1.6139e-02,
        1.3377e-02, 2.6625e-02, 5.8778e-03, 2.8977e-02, 5.1594e-02, 8.2275e-03,
        2.5247e-04, 5.7487e-03, 7.8411e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,515][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.0329e-04, 7.0200e-04, 9.7588e-01, 1.3412e-04, 1.3179e-02, 6.2621e-04,
        3.7866e-04, 1.2553e-03, 4.1190e-03, 7.4074e-05, 2.9603e-05, 2.0999e-03,
        1.1047e-04, 5.7915e-04, 1.2731e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,516][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([5.7153e-05, 1.6630e-04, 9.8568e-01, 3.1635e-04, 9.9090e-03, 3.1972e-04,
        3.3639e-04, 1.9982e-03, 6.4269e-04, 5.3248e-05, 2.9120e-05, 1.1077e-04,
        1.3277e-05, 3.0157e-04, 6.6506e-05], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,517][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.9862e-02, 2.0821e-03, 9.4751e-01, 5.1965e-04, 5.1542e-03, 1.2796e-03,
        1.5078e-03, 6.6211e-03, 6.8620e-03, 1.5338e-04, 8.2820e-05, 4.1655e-03,
        5.2209e-05, 3.0326e-03, 1.1121e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,518][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([8.9392e-01, 3.7736e-02, 4.8625e-02, 3.6416e-03, 1.5657e-03, 8.9099e-04,
        2.3845e-03, 1.0744e-03, 8.7848e-04, 2.0108e-03, 1.4945e-03, 9.8948e-04,
        1.4835e-04, 1.0401e-03, 3.5975e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,520][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.4059e-04, 2.6872e-05, 9.9452e-01, 7.0509e-06, 2.0645e-03, 6.6048e-05,
        2.7532e-05, 1.7981e-04, 1.2731e-03, 2.1915e-06, 1.4672e-06, 8.4447e-04,
        5.3186e-06, 2.6502e-05, 9.9141e-06], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,520][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.3005e-01, 1.2999e-02, 1.5315e-01, 1.5389e-04, 5.0959e-04, 4.5770e-05,
        4.1148e-04, 6.2646e-05, 1.3812e-04, 6.2970e-05, 3.0144e-05, 7.7700e-04,
        1.5975e-05, 5.8323e-04, 1.0116e-03], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,521][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.6555e-02, 1.3226e-03, 9.5822e-01, 3.3673e-04, 1.7281e-03, 1.7472e-04,
        1.7187e-04, 6.1214e-04, 1.7882e-04, 2.2103e-05, 2.1151e-05, 9.7913e-05,
        1.0397e-06, 4.1240e-04, 1.4592e-04], device='cuda:0') for source tokens [Then, Christina and Jesse had a long argument, and afterwards Jesse said to]
[2024-07-24 10:25:34,523][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:25:34,525][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[9937],
        [  30],
        [   4],
        [   1],
        [   1],
        [   2],
        [   2],
        [   1],
        [   1],
        [   1],
        [   2],
        [   1],
        [   1],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:25:34,526][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[9601],
        [  43],
        [   9],
        [   4],
        [   8],
        [  10],
        [   6],
        [  13],
        [  16],
        [  10],
        [   9],
        [  13],
        [  18],
        [  12],
        [   8]], device='cuda:0')
[2024-07-24 10:25:34,528][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 9303],
        [12122],
        [ 5083],
        [ 4787],
        [ 5200],
        [ 5272],
        [ 5525],
        [ 5835],
        [ 5828],
        [ 5976],
        [ 5821],
        [ 5972],
        [ 6857],
        [ 6110],
        [ 6299]], device='cuda:0')
[2024-07-24 10:25:34,529][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1023],
        [ 2811],
        [11917],
        [50253],
        [50249],
        [50251],
        [50251],
        [50248],
        [50248],
        [50251],
        [50251],
        [50239],
        [50238],
        [50238],
        [50239]], device='cuda:0')
[2024-07-24 10:25:34,531][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4272],
        [ 8497],
        [13799],
        [ 1274],
        [ 1370],
        [ 1247],
        [ 1174],
        [ 1192],
        [ 1155],
        [  981],
        [  859],
        [  864],
        [  866],
        [  848],
        [  848]], device='cuda:0')
[2024-07-24 10:25:34,532][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 5255],
        [27993],
        [44587],
        [44491],
        [43087],
        [42883],
        [42532],
        [41564],
        [37738],
        [35778],
        [32318],
        [30052],
        [29417],
        [29809],
        [26359]], device='cuda:0')
[2024-07-24 10:25:34,533][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18288],
        [ 5916],
        [ 2359],
        [ 2475],
        [ 2636],
        [ 2751],
        [ 2717],
        [ 3436],
        [ 3437],
        [ 3016],
        [ 2958],
        [ 3257],
        [ 3226],
        [ 3139],
        [ 3340]], device='cuda:0')
[2024-07-24 10:25:34,535][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[47406],
        [31965],
        [  748],
        [  733],
        [  767],
        [  751],
        [  761],
        [  825],
        [  807],
        [  782],
        [  767],
        [  815],
        [  785],
        [  773],
        [  785]], device='cuda:0')
[2024-07-24 10:25:34,536][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31050],
        [ 4366],
        [ 1193],
        [  275],
        [  247],
        [  319],
        [  974],
        [  692],
        [  538],
        [  994],
        [ 1199],
        [ 1400],
        [  771],
        [  500],
        [ 1433]], device='cuda:0')
[2024-07-24 10:25:34,537][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45967],
        [45278],
        [34781],
        [33015],
        [32733],
        [32728],
        [32752],
        [33823],
        [33841],
        [32972],
        [32879],
        [34272],
        [32895],
        [32980],
        [33090]], device='cuda:0')
[2024-07-24 10:25:34,538][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[18805],
        [18804],
        [18727],
        [18709],
        [18770],
        [18748],
        [18796],
        [18789],
        [18778],
        [18629],
        [18391],
        [18746],
        [18118],
        [16628],
        [17039]], device='cuda:0')
[2024-07-24 10:25:34,540][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12022],
        [13702],
        [28964],
        [32277],
        [31217],
        [32391],
        [32987],
        [30889],
        [29639],
        [32488],
        [32824],
        [28325],
        [29745],
        [29542],
        [30713]], device='cuda:0')
[2024-07-24 10:25:34,541][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41541],
        [41515],
        [27978],
        [39086],
        [  114],
        [    1],
        [  289],
        [    2],
        [    1],
        [ 7045],
        [12800],
        [    2],
        [    2],
        [    1],
        [  226]], device='cuda:0')
[2024-07-24 10:25:34,542][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23984],
        [23900],
        [37558],
        [38024],
        [38067],
        [38013],
        [37977],
        [38010],
        [37875],
        [38067],
        [38048],
        [37725],
        [37935],
        [37766],
        [37998]], device='cuda:0')
[2024-07-24 10:25:34,544][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21528],
        [ 6635],
        [15290],
        [ 6392],
        [15086],
        [ 9960],
        [ 6423],
        [ 7008],
        [ 6837],
        [ 5538],
        [ 6544],
        [ 4493],
        [12567],
        [ 7661],
        [ 6209]], device='cuda:0')
[2024-07-24 10:25:34,545][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29799],
        [25538],
        [19341],
        [17726],
        [18730],
        [18481],
        [19572],
        [20199],
        [19962],
        [20120],
        [19874],
        [19993],
        [21305],
        [20509],
        [21045]], device='cuda:0')
[2024-07-24 10:25:34,547][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25823],
        [32217],
        [33506],
        [35920],
        [35997],
        [36074],
        [36001],
        [36149],
        [36142],
        [35935],
        [35932],
        [36076],
        [36102],
        [36074],
        [35979]], device='cuda:0')
[2024-07-24 10:25:34,548][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[34788],
        [32811],
        [ 4850],
        [ 4748],
        [ 4930],
        [ 6590],
        [ 6381],
        [10286],
        [ 8411],
        [ 5502],
        [ 5380],
        [ 6316],
        [ 5437],
        [ 7632],
        [ 7801]], device='cuda:0')
[2024-07-24 10:25:34,550][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15723],
        [17129],
        [25046],
        [25142],
        [25144],
        [25153],
        [25149],
        [25149],
        [25146],
        [25152],
        [25155],
        [25143],
        [25156],
        [25150],
        [25148]], device='cuda:0')
[2024-07-24 10:25:34,551][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28025],
        [45295],
        [34509],
        [36497],
        [35111],
        [32163],
        [33187],
        [37163],
        [36064],
        [37395],
        [34979],
        [37526],
        [35598],
        [36589],
        [39661]], device='cuda:0')
[2024-07-24 10:25:34,552][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11545],
        [15365],
        [30994],
        [31018],
        [31137],
        [31225],
        [31130],
        [31279],
        [31215],
        [31087],
        [31087],
        [31164],
        [31163],
        [31174],
        [31120]], device='cuda:0')
[2024-07-24 10:25:34,554][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[19448],
        [36079],
        [ 9892],
        [ 9899],
        [ 9907],
        [ 9908],
        [ 9909],
        [10161],
        [ 9989],
        [ 9961],
        [ 9955],
        [10028],
        [ 9966],
        [ 9948],
        [ 9959]], device='cuda:0')
[2024-07-24 10:25:34,555][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27841],
        [19742],
        [16266],
        [16165],
        [16146],
        [16142],
        [16136],
        [15878],
        [15805],
        [16036],
        [16081],
        [15650],
        [16053],
        [16033],
        [16034]], device='cuda:0')
[2024-07-24 10:25:34,557][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23749],
        [23728],
        [22727],
        [22615],
        [18621],
        [21817],
        [23550],
        [23012],
        [22557],
        [23183],
        [19399],
        [22959],
        [11987],
        [23431],
        [23600]], device='cuda:0')
[2024-07-24 10:25:34,558][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18551],
        [28277],
        [14823],
        [14822],
        [14835],
        [14836],
        [14833],
        [14876],
        [14893],
        [14839],
        [14839],
        [14887],
        [14859],
        [14851],
        [14839]], device='cuda:0')
[2024-07-24 10:25:34,559][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20598],
        [20650],
        [21775],
        [20812],
        [26216],
        [23699],
        [25385],
        [23342],
        [23333],
        [23298],
        [22714],
        [22819],
        [22966],
        [23381],
        [26775]], device='cuda:0')
[2024-07-24 10:25:34,561][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[15968],
        [15955],
        [22105],
        [23553],
        [23886],
        [23903],
        [23892],
        [23904],
        [23904],
        [23860],
        [23815],
        [23940],
        [23900],
        [23944],
        [23895]], device='cuda:0')
[2024-07-24 10:25:34,562][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23993],
        [18297],
        [28582],
        [28613],
        [26920],
        [26566],
        [26186],
        [24650],
        [25528],
        [26970],
        [27651],
        [26365],
        [28637],
        [25611],
        [24737]], device='cuda:0')
[2024-07-24 10:25:34,564][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27200],
        [40826],
        [35029],
        [40962],
        [39020],
        [38214],
        [42027],
        [41074],
        [42452],
        [43273],
        [39784],
        [44063],
        [36983],
        [41081],
        [42551]], device='cuda:0')
[2024-07-24 10:25:34,565][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924],
        [23924]], device='cuda:0')
